{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f956ea8-50e6-41c4-8a70-618337b02bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# Connectivity\n",
    "!pip install psycopg2-binary  # PostgreSQL adapter\n",
    "# !pip install snowflake-connector-python  # Snowflake connector\n",
    "!pip install snowflake-connector-python==3.15.0 # Snowflake connector Older Version\n",
    "!pip install snowflake-sqlalchemy  # Snowflake SQLAlchemy connector\n",
    "!pip install warnings # Warnings management\n",
    "# !pip install pyarrow # Serialization\n",
    "!pip install keyring==23.11.0 # Key management\n",
    "!pip install sqlalchemy==1.4.46 # SQLAlchemy\n",
    "!pip install requests # HTTP requests\n",
    "!pip install boto3 # AWS SDK\n",
    "# !pip install slackclient # Slack API\n",
    "!pip install oauth2client # Google Sheets API\n",
    "!pip install gspread==5.9.0 # Google Sheets API\n",
    "!pip install gspread_dataframe # Google Sheets API\n",
    "!pip install google.cloud # Google Cloud\n",
    "# Data manipulation and analysis\n",
    "!pip install polars\n",
    "!pip install pandas==2.2.1\n",
    "!pip install numpy\n",
    "# !pip install fastparquet\n",
    "!pip install openpyxl # Excel file handling\n",
    "!pip install xlsxwriter # Excel file handling\n",
    "# Linear programming\n",
    "!pip install pulp\n",
    "# Date and time handling\n",
    "!pip install --upgrade datetime\n",
    "!pip install python-time\n",
    "!pip install --upgrade pytz\n",
    "# Progress bar\n",
    "!pip install tqdm\n",
    "# Database data types\n",
    "!pip install db-dtypes\n",
    "# Geospatial data handling\n",
    "# !pip install geopandas\n",
    "# !pip install shapely\n",
    "# !pip install fiona\n",
    "# !pip install haversine\n",
    "# Plotting\n",
    "\n",
    "# Modeling\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn\n",
    "\n",
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7293e2a3-ff14-48f1-a8f2-2d1354a2c60f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import setup_environment_2\n",
    "import importlib\n",
    "import import_ipynb\n",
    "import warnings\n",
    "import time\n",
    "import boto3\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import base64\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(setup_environment_2)\n",
    "setup_environment_2.initialize_env()\n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a1dee6-9275-474a-ba95-8beb65e51a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_snowflake(query, columns=[]):\n",
    "    import os\n",
    "    import snowflake.connector\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    con = snowflake.connector.connect(\n",
    "        user =  os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account= os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password= os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database =os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        if len(columns) == 0:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()))\n",
    "        else:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()),columns=columns)\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71be5b7-c840-417a-b174-5277b306f6e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scope = [\"https://spreadsheets.google.com/feeds\",\n",
    "         'https://www.googleapis.com/auth/spreadsheets',\n",
    "         \"https://www.googleapis.com/auth/drive.file\",\n",
    "         \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_dict(json.loads(setup_environment_2.get_secret(\"prod/maxab-sheets\")), scope)\n",
    "client = gspread.authorize(creds)\n",
    "\"\"\n",
    "add_rets = client.open('Wholesale_retailers').worksheet('Add')\n",
    "remove_rets = client.open('Wholesale_retailers').worksheet('remove')\n",
    "\n",
    "add_rets_list = pd.DataFrame(add_rets.get_all_records())\n",
    "remove_rets_list = pd.DataFrame(remove_rets.get_all_records())\n",
    "\n",
    "\n",
    "try : \n",
    "    add_rets_list = add_rets_list.retailer_id.values\n",
    "except:\n",
    "    add_rets_list = []\n",
    "try : \n",
    "    remove_rets_list = remove_rets_list.retailer_id.values\n",
    "except:\n",
    "    remove_rets_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f401c36-a980-4792-9c1f-1562b1ff3b59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([957079,  26136, 671177, 219452, 788525, 502560, 316760, 960301,\n",
       "       309585, 926600, 960567, 520836, 960356, 245530, 384286, 950811,\n",
       "       887265, 638730, 872003,  32645, 133494, 905188, 623645, 962058,\n",
       "       356133, 873681, 330845, 234636, 962432, 373560, 464192, 585135,\n",
       "       766450, 573350, 732075])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_rets_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60635144-ad09-4e27-8f6a-b986f53d8714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(add_rets_list) > 0:\n",
    "    ret_add_filter = f\"where r.id IN ({','.join([repr(b) for b in add_rets_list])})\"\n",
    "else:     \n",
    "    ret_add_filter = \"where r.id = -999\"\n",
    "if len(remove_rets_list) > 0:    \n",
    "    ret_remove_filter = f\"where retailer_id not IN ({','.join([repr(b) for b in remove_rets_list])})\"\n",
    "else:\n",
    "    ret_remove_filter = \"where retailer_id <> -999\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe5ad3f3-fae4-498e-884d-ad6c535d1e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "with new_rets as (\n",
    "select r.id as retailer_id,case when regions.name_en like '%Delta%' then 'Delta' else regions.name_en end as region \n",
    "from retailers r \n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=r.id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "JOIN cities on cities.id=districts.city_id\n",
    "join states on states.id=cities.state_id\n",
    "join regions on regions.id=states.region_id\n",
    "{ret_add_filter}\n",
    "),\n",
    "tags as (\n",
    "select dta.id as tag_id,dta.name as tag_name, \n",
    "case when name like '%Delta%' then 'Delta'\n",
    "when name like '%Alex%' then 'Alexandria'\n",
    "when name like '%sohag%' then 'Upper Egypt'\n",
    "when name like '%cairo%' then 'Greater Cairo'\n",
    "else '' end as region\n",
    "from dynamic_tags dta\n",
    "where dta.name like '%whole_sale%'\n",
    "and dta.id > 3000\n",
    ")\n",
    "\n",
    "select * \n",
    "from (\n",
    "select nr.retailer_id ,tag_id ,tag_name\n",
    "from new_rets nr \n",
    "join tags t on t.region = nr.region \n",
    "\n",
    "union all \n",
    "\n",
    "select dt.taggable_id as retailer_id, dta.id as tag_id ,dta.name as tag_name\n",
    "from dynamic_taggables dt \n",
    "join dynamic_tags dta  on dta.id = dt.dynamic_tag_id\n",
    "where dta.name like '%whole_sale%'\n",
    "and dta.id > 3000\n",
    ")\n",
    "{ret_remove_filter}\n",
    "order by 1 \n",
    "\n",
    "'''\n",
    "ret_tag  = query_snowflake(query, columns = ['retailer_id','tag_id','tag_name'])\n",
    "ret_tag.columns = ret_tag.columns.str.lower()\n",
    "for col in ret_tag.columns:\n",
    "    ret_tag[col] = pd.to_numeric(ret_tag[col], errors='ignore') \n",
    "ret_tag = ret_tag.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b3cbe69-de2a-4772-9432-4cb626df7faa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_id\n",
       "3038    2318\n",
       "3151     619\n",
       "3153     698\n",
       "3154     349\n",
       "Name: retailer_id, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret_tag.groupby('tag_id')['retailer_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65097a7b-0293-4549-a7f5-12d32e82d6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # In this sample we only handle the specific exceptions for the 'GetSecretValue' API.\n",
    "    # See https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "    # We rethrow the exception by default.\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            # Secrets Manager can't decrypt the protected secret text using the provided KMS key.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            # An error occurred on the server side.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            # You provided an invalid value for a parameter.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            # You provided a parameter value that is not valid for the current state of the resource.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            # We can't find the resource that you asked for.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "    else:\n",
    "        # Decrypts secret using the associated KMS CMK.\n",
    "        # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            return get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            return base64.b64decode(get_secret_value_response['SecretBinary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ac0781e-6586-4e97-8368-0b8d5a950a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pricing_api_secret = json.loads(get_secret(\"prod/pricing/api/\"))\n",
    "username = pricing_api_secret[\"egypt_username\"]\n",
    "password = pricing_api_secret[\"egypt_password\"]\n",
    "secret = pricing_api_secret[\"egypt_secret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc3ab0f9-479c-414b-9f6d-db64973cd72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_access_token(url, client_id, client_secret):\n",
    "    \"\"\"\n",
    "    get_access_token function takes three parameters and returns a session token\n",
    "    to connect to MaxAB APIs\n",
    "\n",
    "    :param url: production MaxAB token URL\n",
    "    :param client_id: client ID\n",
    "    :param client_secret: client sercret\n",
    "    :return: session token\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        data={\"grant_type\": \"password\",\n",
    "              \"username\": username,\n",
    "              \"password\": password},\n",
    "        auth=(client_id, client_secret),\n",
    "    )\n",
    "    return response.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a34f6e8-ffd7-4895-9d87-940adcaf3747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def clear_directory(directory):\n",
    "    \"\"\"Delete all files in directory but keep the directory\"\"\"\n",
    "    files = glob.glob(os.path.join(directory, '*'))\n",
    "    for f in files:\n",
    "        if os.path.isfile(f):\n",
    "            os.remove(f)\n",
    "            print(f\"Deleted: {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed77e7ea-61bf-4241-8f0d-b7603125fe42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: WS_tags/tag_3154_list.xlsx\n",
      "Deleted: WS_tags/tag_3151_list.xlsx\n",
      "Deleted: WS_tags/tag_3038_list.xlsx\n",
      "Deleted: WS_tags/tag_3153_list.xlsx\n",
      "Found 4 unique tags to process\n",
      "\n",
      "[1/4] Processing tag 3038: cairo_whole_sale_tag\n",
      "  - Retailers: 2356\n",
      "  ✓ Saved: WS_tags/tag_3038_list.xlsx\n",
      "  ✓ Upload successful: 200\n",
      "\n",
      "[2/4] Processing tag 3153: Delta_whole_sale_tag\n",
      "  - Retailers: 677\n",
      "  ✓ Saved: WS_tags/tag_3153_list.xlsx\n",
      "  ✓ Upload successful: 200\n",
      "\n",
      "[3/4] Processing tag 3151: sohag_whole_sale_tag\n",
      "  - Retailers: 581\n",
      "  ✓ Saved: WS_tags/tag_3151_list.xlsx\n",
      "  ✓ Upload successful: 200\n",
      "\n",
      "[4/4] Processing tag 3154: Alex_whole_sale_tag\n",
      "  - Retailers: 343\n",
      "  ✓ Saved: WS_tags/tag_3154_list.xlsx\n",
      "  ✓ Upload successful: 200\n",
      "\n",
      "\n",
      "============================================================\n",
      "Summary:\n",
      "  Success: 4\n",
      "  Failed: 0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def upload_dynamic_tags(req_data, secret):\n",
    "    \"\"\"Upload dynamic tags to API\"\"\"\n",
    "    os.makedirs('WS_tags', exist_ok=True)\n",
    "    \n",
    "    # Get unique tags\n",
    "    unique_tags = req_data[['tag_id', 'tag_name']].drop_duplicates()\n",
    "    \n",
    "    print(f\"Found {len(unique_tags)} unique tags to process\\n\")\n",
    "    \n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    \n",
    "    for idx, (tag_id, tag_name) in enumerate(unique_tags.itertuples(index=False), 1):\n",
    "        # Convert to Python native types\n",
    "        tag_id = int(tag_id)\n",
    "        tag_name = str(tag_name)\n",
    "        \n",
    "        print(f\"[{idx}/{len(unique_tags)}] Processing tag {tag_id}: {tag_name}\")\n",
    "        \n",
    "        # Get data for this tag\n",
    "        tag_data = req_data[req_data['tag_id'] == tag_id]\n",
    "        to_upload = tag_data[['retailer_id']].drop_duplicates()\n",
    "        \n",
    "        print(f\"  - Retailers: {len(to_upload)}\")\n",
    "        \n",
    "        # Save to Excel\n",
    "        file_path = f'WS_tags/tag_{tag_id}_list.xlsx'\n",
    "        to_upload.to_excel(file_path, index=False, sheet_name='Sheet1')\n",
    "        print(f\"  ✓ Saved: {file_path}\")\n",
    "        \n",
    "        # Read as binary\n",
    "        with open(file_path, 'rb') as f:\n",
    "            file_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "        \n",
    "        # Get token\n",
    "        try:\n",
    "            token = get_access_token(\n",
    "                'https://sso.maxab.info/auth/realms/maxab/protocol/openid-connect/token',\n",
    "                'main-system-externals',\n",
    "                secret\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Failed to get token: {e}\\n\")\n",
    "            fail_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Upload to API\n",
    "        url = f\"https://api.maxab.info/commerce/api/admins/v1/internal-dynamic-tags/{tag_id}\"\n",
    "        \n",
    "        headers = {\n",
    "            'accept': 'application/json',\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {token}'\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"basic_info\": {\n",
    "                \"id\": tag_id,\n",
    "                \"type\": 1,\n",
    "                \"method\": 2,\n",
    "                \"name\": tag_name\n",
    "            },\n",
    "            \"file\": file_base64,\n",
    "            \"file_extension\": \"xlsx\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.put(url, headers=headers, json=payload)\n",
    "            \n",
    "            if response.status_code in [200, 201, 204]:\n",
    "                print(f\"  ✓ Upload successful: {response.status_code}\")\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"  ✗ Upload failed: {response.status_code}\")\n",
    "                print(f\"    Error: {response.text}\")\n",
    "                fail_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Request failed: {e}\")\n",
    "            fail_count += 1\n",
    "        \n",
    "        print()\n",
    "        time.sleep(2)  # Rate limiting\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Summary:\")\n",
    "    print(f\"  Success: {success_count}\")\n",
    "    print(f\"  Failed: {fail_count}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Usage\n",
    "clear_directory('WS_tags')\n",
    "upload_dynamic_tags(ret_tag, secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd112df9-279a-4b56-8f4e-e298f1fcdb10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "add_rets.delete_rows(2, add_rets.row_count)\n",
    "remove_rets.delete_rows(2, remove_rets.row_count)\n",
    "print(\"✅ Cleared all data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dc698b-383a-4d7f-aa0f-dd40c8914cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
