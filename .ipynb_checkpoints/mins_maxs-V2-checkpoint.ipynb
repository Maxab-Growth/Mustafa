{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a2e32a9-ef1a-474a-a2f7-e291561f6da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# Connectivity\n",
    "!pip install psycopg2-binary  # PostgreSQL adapter\n",
    "# !pip install snowflake-connector-python  # Snowflake connector\n",
    "!pip install snowflake-connector-python==3.15.0 # Snowflake connector Older Version\n",
    "!pip install snowflake-sqlalchemy  # Snowflake SQLAlchemy connector\n",
    "!pip install warnings # Warnings management\n",
    "# !pip install pyarr # Serialization\n",
    "!pip install keyring==23.11.0 # Key management\n",
    "!pip install sqlalchemy==1.4.46 # SQLAlchemy\n",
    "!pip install requests # HTTP requests\n",
    "!pip install boto3 # AWS SDK\n",
    "# !pip install slackclient # Slack API\n",
    "!pip install oauth2client # Google Sheets API\n",
    "!pip install gspread==5.9.0 # Google Sheets API\n",
    "!pip install gspread_dataframe # Google Sheets API\n",
    "!pip install google.cloud # Google Cloud\n",
    "# Data manipulation and analysis\n",
    "!pip install polars\n",
    "!pip install pandas==2.2.1\n",
    "!pip install numpy\n",
    "# !pip install fastparquet\n",
    "!pip install openpyxl # Excel file handling\n",
    "!pip install xlsxwriter # Excel file handling\n",
    "# Linear programming\n",
    "!pip install pulp\n",
    "# Date and time handling\n",
    "!pip install --upgrade datetime\n",
    "!pip install python-time\n",
    "!pip install --upgrade pytz\n",
    "# Progress bar\n",
    "!pip install tqdm\n",
    "# Database data types\n",
    "!pip install db-dtypes\n",
    "# Geospatial data handling\n",
    "# !pip install geopandas\n",
    "# !pip install shapely\n",
    "# !pip install fiona\n",
    "# !pip install haversine\n",
    "# Plotting\n",
    "\n",
    "# Modeling\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn\n",
    "\n",
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b73aac-2b7a-491b-80f9-674d0b9a67a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import setup_environment_2\n",
    "import importlib\n",
    "import import_ipynb\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(setup_environment_2)\n",
    "setup_environment_2.initialize_env()\n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9ec765-6d3d-436f-bd59-76eda7de4e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "status = \"min_market\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc41c3e-734d-43f3-8964-1c9fd8e676bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_snowflake(query, columns=[]):\n",
    "    import os\n",
    "    import snowflake.connector\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    con = snowflake.connector.connect(\n",
    "        user =  os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account= os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password= os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database =os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        if len(columns) == 0:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()))\n",
    "        else:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()),columns=columns)\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4843f389-c610-4185-bec0-0978a722587f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'America/Los_Angeles'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SHOW PARAMETERS LIKE 'TIMEZONE'\n",
    "'''\n",
    "x  = query_snowflake(query)\n",
    "zone_to_use = x[1].values[0]\n",
    "zone_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5198399c-507c-4f5b-b61e-b030873c2694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scope = [\"https://spreadsheets.google.com/feeds\",\n",
    "         'https://www.googleapis.com/auth/spreadsheets',\n",
    "         \"https://www.googleapis.com/auth/drive.file\",\n",
    "         \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_dict(json.loads(setup_environment_2.get_secret(\"prod/maxab-sheets\")), scope)\n",
    "client = gspread.authorize(creds)\n",
    "min_max = client.open('Demand Based Dynamic Pricing').worksheet('min_max_margin_cohort')\n",
    "min_max_df = pd.DataFrame(min_max.get_all_records())\n",
    "for col in min_max_df.columns:\n",
    "    min_max_df[col] = pd.to_numeric(min_max_df[col], errors='ignore') \n",
    "min_max_df = min_max_df[min_max_df['min_margin']>0.01]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87883b4b-bad9-4d21-9f69-6685e716ea4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Blue_FD_brands =  client.open('Anniversary Campaign 2025 (Final)').worksheet('Suppliers Brands')\n",
    "Blue_FD_brands_df = pd.DataFrame(Blue_FD_brands.get_all_records())[['Brands']].drop_duplicates()\n",
    "blue_list = [brand  for brand in Blue_FD_brands_df['Brands']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ade36b5b-e61d-4d32-a310-6f5f610f838b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "WITH whs as (SELECT *\n",
    "             FROM   (values\n",
    "                            ('Cairo', 'El-Marg', 38,700),\n",
    "                            ('Cairo', 'Mostorod', 1,700),\n",
    "                            ('Giza', 'Barageel', 236,701),\n",
    "                            ('Delta West', 'El-Mahala', 337,703),\n",
    "                            ('Delta West', 'Tanta', 8,703),\n",
    "                            ('Delta East', 'Mansoura FC', 339,704),\n",
    "                            ('Delta East', 'Sharqya', 170,704),\n",
    "                            ('Upper Egypt', 'Assiut FC', 501,1124),\n",
    "                            ('Upper Egypt', 'Bani sweif', 401,1126),\n",
    "                            ('Upper Egypt', 'Menya Samalot', 703,1123),\n",
    "                            ('Upper Egypt', 'Sohag', 632,1125),\n",
    "                            ('Alexandria', 'Khorshed Alex', 797,702),\n",
    "\t\t\t\t\t\t\t('Giza', 'Sakkarah', 962,701)\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t)\n",
    "                    x(region, wh, warehouse_id,cohort_id)),\n",
    "full_data as (\n",
    "select products.id as product_id, region\n",
    "from products , whs \n",
    "where activation = 'true'\n",
    "),\t\t\t\t\n",
    "\n",
    "MP as (\n",
    "select region,product_id,\n",
    "min(min_price) as min_price,\n",
    "min(max_price) as max_price,\n",
    "min(mod_price) as mod_price,\n",
    "min(true_min) as true_min,\n",
    "min(true_max) as true_max\n",
    "\n",
    "from (\n",
    "select mp.region,mp.product_id,mp.pu_id,\n",
    "min_price/BASIC_UNIT_COUNT as min_price,\n",
    "max_price/BASIC_UNIT_COUNT as max_price,\n",
    "mod_price/BASIC_UNIT_COUNT as mod_price,\n",
    "TRUE_MIN_PRICE/BASIC_UNIT_COUNT as true_min,\n",
    "TRUE_MAX_PRICE/BASIC_UNIT_COUNT as true_max\n",
    "from materialized_views.marketplace_prices mp \n",
    "join packing_unit_products pup on pup.product_id = mp.product_id and pup.packing_unit_id = mp.pu_id\n",
    "join finance.all_cogs f on f.product_id = mp.product_id and CURRENT_TIMESTAMP between f.from_date and f.to_date\n",
    "where  least(min_price,mod_price) between wac_p*0.9 and wac_p*1.3 \n",
    ")\n",
    "group by all \n",
    "),\n",
    "region_mapping AS (\n",
    "    SELECT * \n",
    "\tFROM \n",
    "\t(\tVALUES\n",
    "        ('Delta East', 'Delta West'),\n",
    "        ('Delta West', 'Delta East'),\n",
    "        ('Alexandria', 'Cairo'),\n",
    "        ('Alexandria', 'Giza'),\n",
    "        ('Upper Egypt', 'Cairo'),\n",
    "        ('Upper Egypt', 'Giza'),\n",
    "\t\t('Cairo','Giza'),\n",
    "\t\t('Giza','Cairo'),\n",
    "\t\t('Delta West', 'Cairo'),\n",
    "\t\t('Delta East', 'Cairo'),\n",
    "\t\t('Delta West', 'Giza'),\n",
    "\t\t('Delta East', 'Giza')\n",
    "\t\t)\n",
    "    AS region_mapping(region, fallback_region)\n",
    "),\n",
    "final_mp as (\n",
    "select region,product_id,\n",
    "min(final_min_price) as final_min_price,\n",
    "min(final_max_price) as final_max_price,\n",
    "min(final_mod_price) as final_mod_price,\n",
    "min(final_true_min) as final_true_min,\n",
    "min(final_true_max) as final_true_max\n",
    "\n",
    "from (\n",
    "SELECT\n",
    "distinct \n",
    "\tw.region,\n",
    "\tw.product_id,\n",
    "    COALESCE(m1.min_price, m2.min_price) AS final_min_price,\n",
    "    COALESCE(m1.max_price, m2.max_price) AS final_max_price,\n",
    "    COALESCE(m1.mod_price, m2.mod_price) AS final_mod_price,\n",
    "\tCOALESCE(m1.true_min, m2.true_min) AS final_true_min,\n",
    "\tCOALESCE(m1.true_max, m2.true_max) AS final_true_max,\n",
    "FROM full_data w\n",
    "LEFT JOIN MP m1\n",
    "    ON w.region = m1.region and w.product_id = m1.product_id\n",
    "JOIN region_mapping rm\n",
    "    ON w.region = rm.region\n",
    "LEFT JOIN MP m2\n",
    "    ON rm.fallback_region = m2.region\n",
    "   AND w.product_id = m2.product_id\n",
    ")\n",
    "where final_min_price is not null \n",
    "group by all \n",
    "),\n",
    "ben_soliman as (\n",
    "select z.* \n",
    "from (\n",
    "select maxab_product_id as product_id,maxab_sku as sku,avg(bs_final_price) as ben_soliman_price\n",
    "from (\n",
    "select * , row_number()over(partition by maxab_product_id order by diff) as rnk_2\n",
    "from (\n",
    "select *,(bs_final_price-wac_p)/wac_p as diff_2\n",
    "from (\n",
    "select * ,bs_price/maxab_basic_unit_count as bs_final_price\n",
    "from (\n",
    "select *,row_number()over(partition by maxab_product_id,maxab_pu order by diff) as rnk \n",
    "from (\n",
    "select sm.* ,max(INJECTION_DATE::date)over(partition by maxab_product_id,maxab_pu) as max_date,wac1,wac_p,abs(bs_price-(wac_p*maxab_basic_unit_count))/(wac_p*maxab_basic_unit_count) as diff \n",
    "from materialized_views.savvy_mapping sm \n",
    "join finance.all_cogs f on f.product_id = sm.maxab_product_id and current_timestamp between f.from_Date and f.to_date\n",
    "where bs_price is not null \n",
    "and INJECTION_DATE::date >= CURRENT_DATE- 5\n",
    "qualify INJECTION_DATE::date = max_date\n",
    ")\n",
    "qualify rnk = 1 \n",
    ")\n",
    ")\n",
    "where diff_2 between -0.5 and 0.5 \n",
    ")\n",
    "qualify rnk_2 = 1 \n",
    ")\n",
    "group by all\n",
    ")z \n",
    "join finance.all_cogs f on f.product_id = z.product_id and current_timestamp between f.from_Date and f.to_date\n",
    "\n",
    "where ben_soliman_price between f.wac_p*0.7 and f.wac_p*1.3\n",
    "),\n",
    "scrapped_data as (\n",
    "select product_id,cat,brand,region,max_date,min(MARKET_PRICE) as min_scrapped,max(MARKET_PRICE) as max_scrapped,median(MARKET_PRICE) as median_scrapped\n",
    "from (\n",
    "select MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES.*,max(date)over(partition by region,MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES.product_id,competitor) as max_date\n",
    "from MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES\n",
    "join finance.all_cogs f on f.product_id = MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES.product_id and CURRENT_TIMESTAMP between f.from_date and f.to_date \n",
    "where date>= current_date -5\n",
    "and MARKET_PRICE between f.wac_p * 0.7 and wac_p*1.3\n",
    "qualify date = max_date \n",
    ")\n",
    "group by all \n",
    "),\n",
    "local_prices as (\n",
    "SELECT  case when cpu.cohort_id in (700) then 'Cairo'\n",
    "             when cpu.cohort_id in (701) then 'Giza'\n",
    "             when cpu.cohort_id in (704) then 'Delta East'\n",
    "             when cpu.cohort_id in (703) then 'Delta West'\n",
    "             when cpu.cohort_id in (1123,1124,1125,1126) then 'Upper Egypt'\n",
    "             when cpu.cohort_id in (702) then 'Alexandria'\n",
    "        end as region,\n",
    "\t\tcohort_id,\n",
    "        pu.product_id,\n",
    "\t\tpu.packing_unit_id as packing_unit_id,\n",
    "\t\tpu.basic_unit_count,\n",
    "        avg(cpu.price) as price\n",
    "FROM    cohort_product_packing_units cpu\n",
    "join    PACKING_UNIT_PRODUCTS pu on pu.id = cpu.product_packing_unit_id\n",
    "WHERE   cpu.cohort_id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    "    and cpu.created_at::date<>'2023-07-31'\n",
    "    and cpu.is_customized = true\n",
    "\tgroup by all \n",
    "),\n",
    "live_prices as (\n",
    "select region,cohort_id,product_id,pu_id as packing_unit_id,buc as basic_unit_count,NEW_PRICE as price\n",
    "from materialized_views.DBDP_PRICES\n",
    "where created_at = Current_timestamp::date\n",
    "and DATE_PART('hour', Current_timestamp::time) BETWEEN SPLIT_PART(time_slot, '-', 1)::int AND SPLIT_PART(time_slot, '-', 2)::int\n",
    "and cohort_id in (700,701,702,703,704,696,695,698,697,699,1123,1124,1125,1126)\n",
    "),\n",
    "prices as (\n",
    "select *\n",
    "from (\n",
    "    SELECT *, 1 AS priority FROM live_prices\n",
    "    UNION ALL\n",
    "    SELECT *, 2 AS priority FROM local_prices\n",
    ")\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY region,cohort_id,product_id,packing_unit_id ORDER BY priority) = 1\n",
    "),\n",
    "\n",
    "maxab_prices as (\n",
    "select region,cohort_id,product_id,price \n",
    "from prices \n",
    "where basic_unit_count = 1 \n",
    "),\n",
    "sales as (\n",
    "SELECT  DISTINCT\n",
    "\t\tcpc.cohort_id,\n",
    "\t\tpso.product_id,\n",
    "        sum(pso.total_price) as nmv\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id   \n",
    "join COHORT_PRICING_CHANGES cpc on cpc.id = pso.cohort_pricing_change_id\n",
    "WHERE   True\n",
    "    AND so.created_at::date between date_trunc('month', Current_timestamp::date - 120) and Current_timestamp::date - 1\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "GROUP BY ALL\n",
    "),\n",
    "margin_change as (\n",
    "select product_id,cohort_id,(0.6*product_std) +(0.3*brand_std) + (0.1*cat_std) as std,avg_margin\n",
    "from (\n",
    "select product_id,cohort_id,stddev(product_margin) as product_std , stddev(brand_margin) as brand_std,stddev(cat_margin) as cat_std,avg(product_margin) as avg_margin\n",
    "from (\n",
    "select distinct product_id,order_date,cohort_id,(nmv-cogs_p)/nmv as product_margin,(brand_nmv-brand_cogs)/brand_nmv as brand_margin,(cat_nmv-cat_cogs)/cat_nmv as cat_margin\n",
    "from(\n",
    "SELECT  DISTINCT\n",
    "\t\tso.created_at::date as order_date,\n",
    "\t\tcpc.cohort_id,\n",
    "\t\tpso.product_id,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\n",
    "       sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs_p,\n",
    "    \tsum(pso.total_price) as nmv,\n",
    "\t\tsum(nmv) over(partition by order_date,cat,brand) as brand_nmv,\n",
    "\t\tsum(cogs_p) over(partition by order_date,cat,brand) as brand_cogs,\n",
    "\t\tsum(nmv) over(partition by order_date,cat) as cat_nmv,\n",
    "\t\tsum(cogs_p) over(partition by order_date,cat) as cat_cogs\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id   \n",
    "join COHORT_PRICING_CHANGES cpc on cpc.id = pso.cohort_pricing_change_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN finance.all_cogs f  ON f.product_id = pso.product_id\n",
    "                        AND f.from_date::date <= so.created_at::date\n",
    "                        AND f.to_date::date > so.created_at::date\n",
    "\t\t\t\t\t\t\n",
    "WHERE  so.created_at::date between date_trunc('month', Current_timestamp::date - 120) and Current_timestamp::date\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "GROUP BY ALL\n",
    ")\n",
    ")\n",
    "\n",
    "group by all \n",
    ")\n",
    "),\n",
    "cat_brand_target as (\n",
    "SELECT DISTINCT cat, brand, margin as target_bm\n",
    "FROM    performance.commercial_targets cplan\n",
    "QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE)OVER()) = DATE_TRUNC('month', Current_timestamp::date) THEN DATE_TRUNC('month', Current_timestamp::date)\n",
    "ELSE DATE_TRUNC('month', Current_timestamp::date - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    "),\n",
    "cat_target as (\n",
    "\n",
    "select cat,sum(target_bm *(target_nmv/cat_total)) as cat_target_margin\n",
    "from (\n",
    "select *,sum(target_nmv)over(partition by cat) as cat_total\n",
    "from (\n",
    "select cat,brand,avg(target_bm) as target_bm , sum(target_nmv) as target_nmv\n",
    "from (\n",
    "SELECT DISTINCT date,city as region,cat, brand, margin as target_bm,nmv as target_nmv\n",
    "FROM    performance.commercial_targets cplan\n",
    "QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE)OVER()) = DATE_TRUNC('month', Current_timestamp::date) THEN DATE_TRUNC('month', Current_timestamp::date)\n",
    "ELSE DATE_TRUNC('month', Current_timestamp::date - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    ")\n",
    "group by all\n",
    ")\n",
    ")\n",
    "group by all \n",
    ")\n",
    "\n",
    "\n",
    "select distinct maxab.cohort_id,\n",
    "maxab.product_id,\n",
    "CONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "brands.name_ar as brand, \n",
    "categories.name_ar as cat,\n",
    "sections.name_ar as section_name,\n",
    "maxab.price as maxab_price,\n",
    "bs.ben_soliman_price,\n",
    "final_min_price,\n",
    "final_max_price,\n",
    "final_mod_price,\n",
    "min_scrapped,\n",
    "median_scrapped,\n",
    "max_scrapped,\n",
    "wac_p,\n",
    "coalesce(nmv,0) as nmv,\n",
    "coalesce(mc.std,0.01) as std,\n",
    "coalesce(coalesce(cbt.target_bm , ct.cat_target_margin),0) as target_margin,\n",
    "coalesce(avg_margin,0) as avg_margin\n",
    "\n",
    "from maxab_prices maxab\n",
    "left join ben_soliman bs on bs.product_id = maxab.product_id\n",
    "left join final_mp fmp on fmp.product_id = maxab.product_id and fmp.region = maxab.region\n",
    "left join sales s on s.product_id = maxab.product_id and s.cohort_id = maxab.cohort_id\n",
    "left join scrapped_data  sd on sd.product_id = maxab.product_id and sd.region = maxab.region\n",
    "join finance.all_cogs f on f.product_id = maxab.product_id and  CURRENT_TIMESTAMP between f.from_date and f.to_date\n",
    "JOIN products on products.id=maxab.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN sections ON sections.id = categories.section_id\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "left join margin_change mc on mc.product_id = maxab.product_id and mc.cohort_id = maxab.cohort_id\n",
    "left join cat_brand_target cbt on cbt.brand = brands.name_ar and cbt.cat = categories.name_ar \n",
    "left join cat_target ct on ct.cat = categories.name_ar \n",
    "'''\n",
    "market_main_data   = query_snowflake(query, columns = ['cohort_id','product_id','sku','brand','cat','section_name','maxab_price','ben_soliman_price','final_min_price','final_max_price','final_mod_price','min_scrapped','median_scrapped','max_scrapped','wac_p','nmv','std','target_margin','avg_margin'])\n",
    "for col in market_main_data.columns:\n",
    "    market_main_data[col] = pd.to_numeric(market_main_data[col], errors='ignore')   \n",
    "market_main_data = market_main_data[['cohort_id','product_id','sku','brand','cat','section_name','maxab_price','ben_soliman_price','final_min_price','final_max_price','final_mod_price','min_scrapped','median_scrapped','max_scrapped','wac_p','nmv','std','target_margin','avg_margin']]   \n",
    "market_main_data=market_main_data.drop_duplicates(subset=['cohort_id','product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0490c145-f6da-49d8-9ab8-bd241f6a0e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select * \n",
    "from materialized_views.sku_commercial_groups\n",
    "'''\n",
    "groups  = setup_environment_2.dwh_pg_query(query, columns = ['product_id','group'])\n",
    "groups.columns = groups.columns.str.lower()\n",
    "for col in groups.columns:\n",
    "    groups[col] = pd.to_numeric(groups[col], errors='ignore')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1a60ce8-9362-4bbd-8d62-e969f2135d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query ='''\n",
    "select region , product_id,new_pp,forecasted_date\n",
    "from materialized_views.DBDP_PRICE_UPS\n",
    "'''\n",
    "price_ups  = query_snowflake(query, columns = ['region','product_id','new_pp','forcasted_date'])\n",
    "price_ups.columns = price_ups.columns.str.lower()\n",
    "for col in price_ups.columns:\n",
    "    price_ups[col] = pd.to_numeric(price_ups[col], errors='ignore')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "986e7772-bc1f-4e0c-8165-8fcac88753ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT  DISTINCT\n",
    "\t\tcpc.cohort_id,  \n",
    "\t\tpso.product_id,\n",
    "\t\tCONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\n",
    "        sum(pso.total_price) as nmv\n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "join COHORT_PRICING_CHANGES cpc on cpc.id = pso.COHORT_PRICING_CHANGE_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "          \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at::date between  current_date - 120 and current_date -1 \n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "    and cpc.cohort_id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    "\n",
    "GROUP BY ALL\n",
    "'''\n",
    "sales  = query_snowflake(query, columns = ['cohort_id','product_id','sku','brand','cat','nmv'])\n",
    "sales.columns = sales.columns.str.lower()\n",
    "for col in sales.columns:\n",
    "    sales[col] = pd.to_numeric(sales[col], errors='ignore')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f390dc2b-c772-4d2e-b7cc-bdcc2695a411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_tier(cumulative_contribution):\n",
    "    if cumulative_contribution <= 0.4:\n",
    "        return 1\n",
    "    elif cumulative_contribution <= 0.6:\n",
    "        return 2\n",
    "    elif cumulative_contribution <= 0.8:\n",
    "        return 3\n",
    "    elif cumulative_contribution <= 0.95:\n",
    "        return 4\n",
    "    else: \n",
    "        return 5 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc2f8918-f784-4364-8b3c-b6fc7c0cc47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "below_market = ['شويبس','كوكا كولا']\n",
    "min_brands = ['فاميليا','مولبد','مولفيكس','اوكسي','جوي','ريفولي','البوادي','هارفست فوودز','هاينز','بيبسي']\n",
    "avg_brands = ['بخيره','جود كير']\n",
    "max_brands =['فيوري']\n",
    "min_cats = ['تونة و سمك']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aab29e4-c8fc-42d9-a816-616d55f867da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales['total_nmv'] = sales.groupby('cohort_id')['nmv'].transform(sum)\n",
    "sales['cntrb_nmv'] = sales['nmv']/sales['total_nmv']\n",
    "sales = sales.sort_values(['cohort_id', 'nmv'], ascending=[True, False])\n",
    "sales['nmv_cumulative_cntrb'] = sales.groupby('cohort_id')['cntrb_nmv'].cumsum()\n",
    "sales['tier'] = sales['nmv_cumulative_cntrb'].apply(assign_tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8846fc1c-3e90-484e-8233-5e1b24369d15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales.loc[sales['cat'].isin(min_cats),'tier']=np.maximum(sales['tier']-1,1)\n",
    "sales.loc[sales['brand'].isin(blue_list),'tier']=np.maximum(sales['tier']-1,1)\n",
    "sales.loc[sales['brand'].isin(min_brands),'tier']=1\n",
    "sales.loc[sales['brand'].isin(below_market),'tier']=0\n",
    "sales.loc[sales['brand'].isin(avg_brands),'tier']=3\n",
    "sales.loc[sales['brand'].isin(max_brands),'tier']=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f459c984-aff5-484e-9e3c-c61da9f9c290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if 'min' in status:\n",
    "    sales['new_tier'] = sales['tier']\n",
    "    sales['new_tier'] = np.maximum(sales['tier']-1,0)\n",
    "    sales['tier'] =sales['new_tier']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cc0fe18-8f02-4be7-a0f6-86695bdc957e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_data =market_main_data.copy() \n",
    "market_data=market_data.merge(groups,on='product_id',how='left')\n",
    "groups_data = market_data[(~market_data['group'].isna())]\n",
    "groups_data['group_nmv'] = groups_data.groupby(['group','cohort_id'])['nmv'].transform(sum)\n",
    "groups_data['cntrb']  = (groups_data['nmv']/groups_data['group_nmv']).fillna(1)\n",
    "groups_data = groups_data.groupby(['group','cohort_id']).agg({'ben_soliman_price':'median','final_min_price':'median','final_max_price':'median','final_mod_price':'median','min_scrapped':'median','median_scrapped':'median','max_scrapped':'median'}).reset_index()\n",
    "merged = market_data.merge(\n",
    "    groups_data,\n",
    "    on=['group','cohort_id'],\n",
    "    how='left',\n",
    "    suffixes=('', '_group')\n",
    ")\n",
    "cols = ['ben_soliman_price','final_min_price','final_max_price','final_mod_price','min_scrapped','median_scrapped','max_scrapped']\n",
    "for col in cols:\n",
    "    merged[col] = merged[col].fillna(merged[col + '_group'])\n",
    "\n",
    "merged = merged.drop(columns=[c + '_group' for c in cols])\n",
    "market_data = merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fbd040b-9e06-49c4-848d-d93627c2da49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_data['remove'] = 0\n",
    "#market_data.loc[(market_data['ben_soliman_price'].isna())&(((market_data['final_min_price'] == market_data['final_mod_price']) & (market_data['final_max_price'] == market_data['final_mod_price'])&(market_data['min_scrapped'].isna()))|   ((market_data['min_scrapped'] == market_data['median_scrapped']) & (market_data['median_scrapped'] == market_data['max_scrapped'])&(market_data['final_min_price'].isna()))),'remove'] = 1 \n",
    "market_data = market_data[market_data['remove']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38447844-b1c3-49bf-b8f0-c0f70242d196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def price_analysis(r):\n",
    "    price = r['maxab_price']\n",
    "    wac = r['wac_p']\n",
    "    avg_margin = r['avg_margin']\n",
    "    std = r['std']\n",
    "    target_margin = r['target_margin']\n",
    "    price_list = [\n",
    "    r['ben_soliman_price'],\n",
    "    r['final_min_price'],\n",
    "    r['final_mod_price'],\n",
    "    r['final_max_price'],\n",
    "    r['min_scrapped'],\n",
    "    r['median_scrapped'], \n",
    "    r['max_scrapped']   \n",
    "    ]\n",
    "    if avg_margin < 0.01:\n",
    "        avg_margin = target_margin\n",
    "        \n",
    "    price_list= list({x for x in price_list if x not in [0, np.nan] and not pd.isna(x)})\n",
    "    price_list= list({x for x in price_list if x >= wac/(1-(avg_margin-(2.5*std))) and x<= wac/(1-(avg_margin+(4*std))) and x>=wac})\n",
    "    price_list.sort()\n",
    "    if len(price_list) > 0 :\n",
    "        minimum = np.min(price_list)\n",
    "        percentile_25 = np.percentile(price_list, 25)\n",
    "        percentile_50 = np.percentile(price_list, 50)\n",
    "        percentile_75 = np.percentile(price_list, 75)\n",
    "        maximum = np.max(price_list)\n",
    "    else:\n",
    "        minimum = np.nan\n",
    "        percentile_25=np.nan\n",
    "        percentile_50 = np.nan\n",
    "        percentile_75 = np.nan\n",
    "        maximum = np.nan\n",
    "    return  minimum,percentile_25,percentile_50,percentile_75,maximum\n",
    "\n",
    "market_data[['minimum','percentile_25','percentile_50','percentile_75','maximum']] = market_data.apply(price_analysis, axis=1, result_type='expand')\n",
    "market_data = market_data[~market_data['minimum'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d20302c-606e-4a6d-a00f-07cbfd4fee53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def step_min_max(x):\n",
    "    wac = x['wac_p']\n",
    "    price = x['maxab_price']\n",
    "    array = [x['minimum'],x['percentile_25'],x['percentile_50'],x['percentile_75'],x['maximum']]\n",
    "    std = x['std']\n",
    "    sa = []\n",
    "    minimum = x['minimum']\n",
    "    maximum = x['maximum']\n",
    "    for i in range(0,len(array)-1):\n",
    "        v1 = array[i]\n",
    "        v2 = array[i+1]\n",
    "        step = v2-v1\n",
    "        step_value = step / wac\n",
    "        if(step_value <= std *1.2):\n",
    "            sa.append(v2-v1)\n",
    "    avg_step =  (np.mean(sa))\n",
    "    if avg_step ==0:\n",
    "        avg_step = np.minimum(2*std,0.2*x['target_margin'])\n",
    "    new_min = minimum-avg_step\n",
    "    new_max = maximum+avg_step\n",
    "    if new_min < wac:\n",
    "        new_min = minimum\n",
    "    if new_max < wac:\n",
    "        new_max = maximum\n",
    "    \n",
    "    return  new_min , new_max\n",
    "        \n",
    "market_data[['below_market','above_market']] = market_data.apply(step_min_max, axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce78a5b2-84a5-40c0-a2ce-559e16307de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_data = market_data[['cohort_id', 'product_id','maxab_price','wac_p', 'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum','below_market','above_market']]\n",
    "market_data['below_market'] = (market_data['below_market'] -market_data['wac_p'])/market_data['below_market'] \n",
    "market_data['market_min'] = (market_data['minimum'] -market_data['wac_p'])/market_data['minimum'] \n",
    "market_data['market_25'] = (market_data['percentile_25'] -market_data['wac_p'])/market_data['percentile_25'] \n",
    "market_data['market_50'] = (market_data['percentile_50'] -market_data['wac_p'])/market_data['percentile_50'] \n",
    "market_data['market_75'] = (market_data['percentile_75'] -market_data['wac_p'])/market_data['percentile_75'] \n",
    "market_data['market_max'] = (market_data['maximum'] -market_data['wac_p'])/market_data['maximum'] \n",
    "market_data['above_market'] = (market_data['above_market'] -market_data['wac_p'])/market_data['above_market'] \n",
    "market_data['current_margin'] = (market_data['maxab_price'] -market_data['wac_p'])/market_data['maxab_price'] \n",
    "market_data = market_data[['cohort_id', 'product_id','current_margin','below_market' ,'market_min', 'market_25','market_50', 'market_75', 'market_max','above_market']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7c6f910-9114-45ef-895a-2df61a1b9f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "found = min_max_df.merge(market_data,on=['cohort_id','product_id'])\n",
    "found = found.merge(sales[['cohort_id','product_id','tier']],on=['cohort_id','product_id'])\n",
    "\n",
    "cond = [found['tier']==0,found['tier']==1,found['tier']==2,found['tier']==3,found['tier']==4,found['tier']==5] \n",
    "cho = [found['below_market'],found['market_min'],found['market_25'],found['market_50'],found['market_75'],found['market_max']]\n",
    "cho2 = [found['market_min'],found['market_25'],found['market_50'],found['market_75'],found['market_max'],found['market_max']*1.2]\n",
    "\n",
    "found['selected_min'] = np.select(cond,cho,default =found['market_min'] )\n",
    "found['selected_max'] = np.select(cond,cho2,default =found['market_min'] )\n",
    "\n",
    "found['min_cu_diff'] = (found['selected_min']-found['current_margin'])/found['current_margin']\n",
    "found['min_min_diff'] = (found['selected_min']-found['min_margin'])/found['min_margin']\n",
    "\n",
    "found = found[((found['min_cu_diff'] <= 0.55) & (found['min_cu_diff'] >= -0.55))|((found['min_min_diff'] <= 0.55) & (found['min_min_diff'] >= -0.55))]\n",
    "\n",
    "found['diff'] = (found['max_margin'] - found['min_margin'])/found['min_margin']\n",
    "\n",
    "found['new_min'] = found['selected_min']\n",
    "found['new_max'] = np.minimum(np.maximum(np.maximum((found['diff']+1)*found['selected_min'],found['selected_max']),found['selected_min']+0.01),found['selected_min']+0.04)\n",
    "found=found[['cohort_id','product_id','new_min','new_max']]\n",
    "found['type'] = 'both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebc9aae5-7c74-41c2-a60d-5496eea24009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_max_df['flag']=1\n",
    "not_found = market_data.merge(min_max_df[['cohort_id','product_id','flag']],on=['cohort_id','product_id'],how='left')\n",
    "not_found = not_found.merge(sales[['cohort_id','product_id','tier']],on=['cohort_id','product_id'])\n",
    "not_found = not_found[not_found['flag'].isna()]\n",
    "cond = [not_found['tier']==0,not_found['tier']==1,not_found['tier']==2,not_found['tier']==3,not_found['tier']==4,not_found['tier']==5] \n",
    "cho = [not_found['below_market'],not_found['market_min'],not_found['market_25'],not_found['market_50'],not_found['market_75'],not_found['market_max']]\n",
    "cho2 = [not_found['market_min'],not_found['market_25'],not_found['market_50'],not_found['market_75'],not_found['market_max'],not_found['market_max']*1.2]\n",
    "not_found['selected_min'] = np.select(cond,cho,default =not_found['market_min'] )\n",
    "not_found['selected_max'] = np.select(cond,cho2,default =not_found['market_min'] )\n",
    "not_found['min_cu_diff'] = (not_found['selected_min']-not_found['current_margin'])/not_found['current_margin']\n",
    "not_found = not_found[((not_found['min_cu_diff'] <= 2) & (not_found['min_cu_diff'] >= -2))]\n",
    "not_found['new_min'] = not_found['selected_min']\n",
    "not_found['new_max'] = np.minimum(np.maximum(not_found['selected_max'],not_found['selected_min']+0.01),not_found['selected_min']+0.04)\n",
    "not_found=not_found[['cohort_id','product_id','new_min','new_max']]\n",
    "not_found['type'] = 'MP_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c394895-f070-4c5f-a9db-408c2c752d35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>new_min</th>\n",
       "      <th>new_max</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.081171</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>701</td>\n",
       "      <td>3</td>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>702</td>\n",
       "      <td>3</td>\n",
       "      <td>0.043734</td>\n",
       "      <td>0.059734</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050679</td>\n",
       "      <td>0.082501</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704</td>\n",
       "      <td>3</td>\n",
       "      <td>0.047987</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10636</th>\n",
       "      <td>1123</td>\n",
       "      <td>2109</td>\n",
       "      <td>0.050446</td>\n",
       "      <td>0.060446</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10665</th>\n",
       "      <td>701</td>\n",
       "      <td>23380</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.068091</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10744</th>\n",
       "      <td>703</td>\n",
       "      <td>10596</td>\n",
       "      <td>0.050042</td>\n",
       "      <td>0.060042</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10771</th>\n",
       "      <td>1123</td>\n",
       "      <td>7182</td>\n",
       "      <td>0.044240</td>\n",
       "      <td>0.056313</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10806</th>\n",
       "      <td>1123</td>\n",
       "      <td>10906</td>\n",
       "      <td>0.074732</td>\n",
       "      <td>0.114732</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10626 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cohort_id  product_id   new_min   new_max     type\n",
       "0            700           3  0.051860  0.081171     both\n",
       "1            701           3  0.041931  0.066391     both\n",
       "2            702           3  0.043734  0.059734     both\n",
       "3            703           3  0.050679  0.082501     both\n",
       "4            704           3  0.047987  0.070307     both\n",
       "...          ...         ...       ...       ...      ...\n",
       "10636       1123        2109  0.050446  0.060446  MP_only\n",
       "10665        701       23380  0.058091  0.068091  MP_only\n",
       "10744        703       10596  0.050042  0.060042  MP_only\n",
       "10771       1123        7182  0.044240  0.056313  MP_only\n",
       "10806       1123       10906  0.074732  0.114732  MP_only\n",
       "\n",
       "[10626 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([found,not_found],axis=0)\n",
    "final_df=final_df.drop_duplicates()\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "283b3ac9-7f3c-48d0-b4d2-d52c2189de6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>min_margin</th>\n",
       "      <th>max_margin</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.081171</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>701</td>\n",
       "      <td>3</td>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>702</td>\n",
       "      <td>3</td>\n",
       "      <td>0.043734</td>\n",
       "      <td>0.059734</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050679</td>\n",
       "      <td>0.082501</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704</td>\n",
       "      <td>3</td>\n",
       "      <td>0.047987</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10621</th>\n",
       "      <td>1123</td>\n",
       "      <td>2109</td>\n",
       "      <td>0.050446</td>\n",
       "      <td>0.060446</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10622</th>\n",
       "      <td>701</td>\n",
       "      <td>23380</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.068091</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10623</th>\n",
       "      <td>703</td>\n",
       "      <td>10596</td>\n",
       "      <td>0.050042</td>\n",
       "      <td>0.060042</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>1123</td>\n",
       "      <td>7182</td>\n",
       "      <td>0.044240</td>\n",
       "      <td>0.056313</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>1123</td>\n",
       "      <td>10906</td>\n",
       "      <td>0.074732</td>\n",
       "      <td>0.114732</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10626 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cohort_id  product_id  min_margin  max_margin     type\n",
       "0            700           3    0.051860    0.081171     both\n",
       "1            701           3    0.041931    0.066391     both\n",
       "2            702           3    0.043734    0.059734     both\n",
       "3            703           3    0.050679    0.082501     both\n",
       "4            704           3    0.047987    0.070307     both\n",
       "...          ...         ...         ...         ...      ...\n",
       "10621       1123        2109    0.050446    0.060446  MP_only\n",
       "10622        701       23380    0.058091    0.068091  MP_only\n",
       "10623        703       10596    0.050042    0.060042  MP_only\n",
       "10624       1123        7182    0.044240    0.056313  MP_only\n",
       "10625       1123       10906    0.074732    0.114732  MP_only\n",
       "\n",
       "[10626 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions = pd.DataFrame({\n",
    "    'region': ['Cairo', 'Giza', 'Delta West', 'Delta East', 'Upper Egypt', \n",
    "               'Upper Egypt', 'Upper Egypt', 'Upper Egypt', 'Alexandria'],\n",
    "    'cohort_id': [700, 701, 703, 704, 1124, 1126, 1123, 1125, 702]\n",
    "})\n",
    "final_df=final_df.merge(regions,on=['cohort_id'])\n",
    "final_df=final_df[['cohort_id','product_id','new_min','new_max','type']]\n",
    "final_df=final_df.drop_duplicates()\n",
    "final_df.columns = ['cohort_id','product_id','min_margin','max_margin','type']\n",
    "#final_df = pd.concat([final_df,main_found[['cohort_id','product_id','min_margin','max_margin','type']]],axis=0)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71de92b0-2384-4b65-8fcd-af42a6f67ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 48 47\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "week_number = datetime.now().isocalendar()[1]\n",
    "week_number_c = str(week_number)\n",
    "week_number_p = str(week_number-1)\n",
    "week_number_p2 = str(week_number-2)\n",
    "print(week_number_c,week_number_p,week_number_p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5c94bf1-7de2-478c-964b-6b1360968d67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse</th>\n",
       "      <th>stocks</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     warehouse  stocks  product_id\n",
       "18     Sharqya    24.0       12345\n",
       "20     Sharqya    27.0        1064\n",
       "21     Sharqya     7.0        8638\n",
       "29     Sharqya    37.0        2270\n",
       "36     Sharqya    11.0       12858\n",
       "...        ...     ...         ...\n",
       "2112     Tanta     1.0        8486\n",
       "2114     Tanta     8.0        9620\n",
       "2125     Tanta     6.0       11295\n",
       "2131     Tanta     5.0        8935\n",
       "2177     Tanta     1.0        5189\n",
       "\n",
       "[173 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope = [\"https://spreadsheets.google.com/feeds\",\n",
    "         'https://www.googleapis.com/auth/spreadsheets',\n",
    "         \"https://www.googleapis.com/auth/drive.file\",\n",
    "         \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_dict(json.loads(setup_environment_2.get_secret(\"prod/maxab-sheets\")), scope)\n",
    "client = gspread.authorize(creds)\n",
    "tgto = client.open('Egypt SKUs Aging Monitor').worksheets()\n",
    "worksheet_names = [ws.title for ws in tgto]\n",
    "sheet_name = \"\"\n",
    "for name in worksheet_names:\n",
    "    if week_number_c in name:\n",
    "        sheet_name = name\n",
    "        break\n",
    "    elif week_number_p in name:\n",
    "        sheet_name = name \n",
    "    elif week_number_p2 in name:\n",
    "        sheet_name = name \n",
    "tgto = client.open('Egypt SKUs Aging Monitor').worksheet(f'{sheet_name}')\n",
    "\n",
    "data = tgto.get_all_values()\n",
    "\n",
    "# Convert to DataFrame\n",
    "if data:\n",
    "    tgto_df = pd.DataFrame(data[2:], columns=data[1])\n",
    "    tgto_df = tgto_df.iloc[:, :21]\n",
    "    print(\"ok\")\n",
    "else:\n",
    "    tgto_df = pd.DataFrame()\n",
    "for col in tgto_df.columns:\n",
    "    tgto_df[col] = pd.to_numeric(tgto_df[col], errors='ignore')   \n",
    "tgto_df = tgto_df[tgto_df['Fulfillment confirmation']=='confirmed']\n",
    "\n",
    "\n",
    "tgto_df=tgto_df[['SKU', 'Sharqya', 'Khorshed Alex', 'Bani sweif',\n",
    "       'Mostorod', 'Barageel', 'El-Mahala', 'Sohag', 'Mansoura FC',\n",
    "       'Assiut FC', 'Menya Samalot', 'Tanta']]    \n",
    "def convert_string(x):\n",
    "    id_ = x.SKU\n",
    "    try:\n",
    "        id_ = id_.replace(\",\", \"\")\n",
    "        id_ = int(id_)\n",
    "    except:\n",
    "        pass\n",
    "    return id_\n",
    "df_long = tgto_df.melt(\n",
    "    id_vars=['SKU'], \n",
    "    var_name='warehouse', \n",
    "    value_name='stocks'\n",
    ")\n",
    "df_long['product_id'] = df_long.apply(convert_string,axis=1)\n",
    "df_long = df_long.drop(columns = 'SKU')\n",
    "df_long = df_long[~df_long['stocks'].isna()]\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d065a5e8-d5cf-4c0f-b69d-7de929b3be34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select product_id,wac_p\n",
    "from finance.all_cogs f \n",
    "where CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp()) between f.from_date and f.to_date \n",
    "'''\n",
    "wacs   = query_snowflake(query, columns = ['product_id','wac_p'])\n",
    "wacs.columns = wacs.columns.str.lower()\n",
    "for col in wacs.columns:\n",
    "    wacs[col] = pd.to_numeric(wacs[col], errors='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7518e53c-478a-4334-8699-18c1bf089c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "whs = pd.DataFrame([\n",
    "    ('Cairo', 'El-Marg', 38, 700),\n",
    "    ('Cairo', 'Mostorod', 1, 700),\n",
    "    ('Giza', 'Barageel', 236, 701),\n",
    "    ('Delta West', 'El-Mahala', 337, 703),\n",
    "    ('Delta West', 'Tanta', 8, 703),\n",
    "    ('Delta East', 'Mansoura FC', 339, 704),\n",
    "    ('Delta East', 'Sharqya', 170, 704),\n",
    "    ('Upper Egypt', 'Assiut FC', 501, 1124),\n",
    "    ('Upper Egypt', 'Bani sweif', 401, 1126),\n",
    "    ('Upper Egypt', 'Menya Samalot', 703, 1123),\n",
    "    ('Upper Egypt', 'Sohag', 632, 1125),\n",
    "    ('Alexandria', 'Khorshed Alex', 797, 702),\n",
    "    ('Giza', 'Sakkarah', 962, 701)\n",
    "], columns=['region', 'warehouse', 'warehouse_id', 'cohort_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c23032ae-a99a-45a1-bdf0-3c4e93cea1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT product_warehouse.warehouse_id,\n",
    "                product_warehouse.product_id,\n",
    "                (product_warehouse.available_stock)::integer as stocks,\n",
    "        from  product_warehouse \n",
    "        JOIN products on product_warehouse.product_id = products.id\n",
    "        JOIN product_units ON products.unit_id = product_units.id\n",
    "        where   product_warehouse.warehouse_id not in (6,9,10)\n",
    "            AND product_warehouse.activation = 'true'\n",
    "            AND product_warehouse.is_basic_unit = 1\n",
    "'''\n",
    "stocks   = query_snowflake(query, columns = ['warehouse_id','product_id','cu_stocks'])\n",
    "stocks.columns = stocks.columns.str.lower()\n",
    "for col in stocks.columns:\n",
    "    stocks[col] = pd.to_numeric(stocks[col], errors='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ee31ff4-c77d-44f2-973a-2072e118a13f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select region,product_id,optimal_bm,MIN_BOUNDARY,MAX_BOUNDARY,MEDIAN_BM\n",
    "from (\n",
    "select region,product_id,target_bm,optimal_bm,MIN_BOUNDARY,MAX_BOUNDARY,MEDIAN_BM,max(created_at) over(partition by product_id,region) as max_date,created_at\n",
    "from materialized_views.PRODUCT_STATISTICS\n",
    "where created_at::date >= date_trunc('month',current_date - 60)\n",
    "qualify max_date = created_at\n",
    ")\n",
    "\n",
    "'''\n",
    " \n",
    "stats = query_snowflake(query, columns = ['region','product_id','optimal_bm','MIN_BOUNDARY','MAX_BOUNDARY','MEDIAN_BM'])\n",
    "stats.columns = stats.columns.str.lower()\n",
    "for col in stats.columns:\n",
    "    stats[col] = pd.to_numeric(stats[col], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58a42817-656e-404b-8d94-a5bf83dc899c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>remove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8673</td>\n",
       "      <td>401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  warehouse_id  remove\n",
       "0        8673           401       1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to_remove = pd.DataFrame([\n",
    "# (8673,401)\n",
    "# ], columns=['product_id', 'warehouse_id'])\n",
    "# to_remove['remove'] =1 \n",
    "# to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c6cb2d42-0520-4e1e-a42f-2c643bb9fe2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>min_margin</th>\n",
       "      <th>max_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>701</td>\n",
       "      <td>1069</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.013468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>701</td>\n",
       "      <td>9353</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>0.008440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>701</td>\n",
       "      <td>9570</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701</td>\n",
       "      <td>10384</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>0.011544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701</td>\n",
       "      <td>10667</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>0.015649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1126</td>\n",
       "      <td>12031</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>0.024704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1126</td>\n",
       "      <td>12032</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>0.024704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1126</td>\n",
       "      <td>12343</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1126</td>\n",
       "      <td>12533</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.007619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1126</td>\n",
       "      <td>20670</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>0.009877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cohort_id  product_id  min_margin  max_margin\n",
       "0         701        1069    0.013468    0.013468\n",
       "1         701        9353    0.008440    0.008440\n",
       "2         701        9570    0.037267    0.037267\n",
       "3         701       10384    0.011544    0.011544\n",
       "4         701       10667    0.015649    0.015649\n",
       "..        ...         ...         ...         ...\n",
       "91       1126       12031    0.024704    0.024704\n",
       "92       1126       12032    0.024704    0.024704\n",
       "93       1126       12343    0.026500    0.026500\n",
       "94       1126       12533    0.007619    0.007619\n",
       "95       1126       20670    0.009877    0.009877\n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgtg = df_long.merge(wacs,on='product_id')\n",
    "tgtg = tgtg.merge(whs,on='warehouse')\n",
    "tgtg=tgtg.merge(to_remove,on=['product_id','warehouse_id'],how='left')\n",
    "tgtg=tgtg[tgtg['remove'].isna()]\n",
    "tgtg = tgtg.merge(stocks,on=['warehouse_id','product_id'])\n",
    "tgtg =tgtg[tgtg['cu_stocks']>0] \n",
    "tgtg['stock_value'] = tgtg['cu_stocks'] * tgtg['wac_p']\n",
    "tgtg =tgtg.sort_values(by ='stock_value',ascending = False) \n",
    "tgtg = tgtg[tgtg['stock_value']>100]\n",
    "tgtg = tgtg.merge(market_data,on=['cohort_id','product_id'],how='left')\n",
    "tgtg = tgtg.merge(stats,on=['region','product_id'])\n",
    "tgtg = tgtg.merge(market_main_data[['cohort_id','product_id','target_margin']],on=['cohort_id','product_id'],how='left')\n",
    "tgtg=tgtg.fillna(1000)\n",
    "tgtg['min_margin'] = np.minimum(np.minimum(np.minimum(tgtg['market_min']*0.8,tgtg['target_margin']/4),tgtg['min_boundary']*0.9),tgtg['optimal_bm']*0.75)\n",
    "tgtg['max_margin'] = tgtg['min_margin']\n",
    "tgtg.to_excel(\"Min_max_data/tgtg.xlsx\")\n",
    "tgtg = tgtg[['cohort_id', 'product_id','min_margin', 'max_margin']]\n",
    "tgtg = tgtg.groupby(['cohort_id', 'product_id']).agg({'min_margin':min,'max_margin':min}).reset_index()\n",
    "tgtg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "660e4534-3f0a-4398-870a-64ee3ca84093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tgtg['type'] = 'TGTG'\n",
    "result = final_df.merge(tgtg[['product_id', 'cohort_id']], \n",
    "                   on=['product_id', 'cohort_id'], \n",
    "                   how='left', indicator=True)\n",
    "\n",
    "result = result[result['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "final_df = pd.concat([result,tgtg],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6dfd282-3306-455b-8fbd-b96fc1b8cce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "price_ups=price_ups.merge(regions,on=['region'])\n",
    "final_df=final_df.merge(price_ups,on=['product_id','cohort_id'],how='left')\n",
    "final_df.loc[(~final_df['new_pp'].isna())&(final_df['type']!='TGTG'),'max_margin'] = np.minimum(final_df['max_margin']+0.15,final_df['min_margin']+0.2)\n",
    "final_df['enforce'] = np.nan\n",
    "final_df.loc[~final_df['new_pp'].isna(),'enforce']= 1  \n",
    "final_df=final_df.drop_duplicates()\n",
    "final_df = final_df.merge(sales,on=['cohort_id','product_id'],how='left')\n",
    "final_df = final_df[['cohort_id', 'product_id','sku', 'min_margin', 'max_margin', 'enforce','brand','type']]\n",
    "final_df = final_df.merge(min_max_df[['cohort_id', 'product_id','min_margin', 'max_margin']].rename(columns = {'min_margin':'old_min','max_margin':'old_max'}),on=['cohort_id', 'product_id'],how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4ff707d-7974-4321-9f13-9f1a7c383fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# final_df.loc[final_df['product_id'].isin([7630,95]),'min_margin'] = final_df['old_min']\n",
    "# final_df.loc[final_df['product_id'].isin([7630,95]),'max_margin'] = final_df['old_max']\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8858cc8-a2a3-4387-b405-91d004786ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df.to_excel('Min_max_data/min_max_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45b608-51c2-48d9-ae5f-aa32e2e328d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
