{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f956ea8-50e6-41c4-8a70-618337b02bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# Connectivity\n",
    "!pip install psycopg2-binary  # PostgreSQL adapter\n",
    "# !pip install snowflake-connector-python  # Snowflake connector\n",
    "!pip install snowflake-connector-python==3.15.0 # Snowflake connector Older Version\n",
    "!pip install snowflake-sqlalchemy  # Snowflake SQLAlchemy connector\n",
    "!pip install warnings # Warnings management\n",
    "# !pip install pyarrow # Serialization\n",
    "!pip install keyring==23.11.0 # Key management\n",
    "!pip install sqlalchemy==1.4.46 # SQLAlchemy\n",
    "!pip install requests # HTTP requests\n",
    "!pip install boto3 # AWS SDK\n",
    "# !pip install slackclient # Slack API\n",
    "!pip install oauth2client # Google Sheets API\n",
    "!pip install gspread==5.9.0 # Google Sheets API\n",
    "!pip install gspread_dataframe # Google Sheets API\n",
    "!pip install google.cloud # Google Cloud\n",
    "# Data manipulation and analysis\n",
    "!pip install polars\n",
    "!pip install pandas==2.2.1\n",
    "!pip install numpy\n",
    "# !pip install fastparquet\n",
    "!pip install openpyxl # Excel file handling\n",
    "!pip install xlsxwriter # Excel file handling\n",
    "# Linear programming\n",
    "!pip install pulp\n",
    "# Date and time handling\n",
    "!pip install --upgrade datetime\n",
    "!pip install python-time\n",
    "!pip install --upgrade pytz\n",
    "# Progress bar\n",
    "!pip install tqdm\n",
    "# Database data types\n",
    "!pip install db-dtypes\n",
    "# Geospatial data handling\n",
    "# !pip install geopandas\n",
    "# !pip install shapely\n",
    "# !pip install fiona\n",
    "# !pip install haversine\n",
    "# Plotting\n",
    "\n",
    "# Modeling\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn\n",
    "\n",
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7293e2a3-ff14-48f1-a8f2-2d1354a2c60f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import setup_environment_2\n",
    "import importlib\n",
    "import import_ipynb\n",
    "import warnings\n",
    "import time\n",
    "import boto3\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import base64\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(setup_environment_2)\n",
    "setup_environment_2.initialize_env()\n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10a1dee6-9275-474a-ba95-8beb65e51a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_snowflake(query, columns=[]):\n",
    "    import os\n",
    "    import snowflake.connector\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    con = snowflake.connector.connect(\n",
    "        user =  os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account= os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password= os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database =os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        if len(columns) == 0:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()))\n",
    "        else:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()),columns=columns)\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60635144-ad09-4e27-8f6a-b986f53d8714",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SHOW PARAMETERS LIKE 'TIMEZONE'\n",
    "'''\n",
    "x  = query_snowflake(query)\n",
    "zone_to_use = x[1].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe5ad3f3-fae4-498e-884d-ad6c535d1e9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "with new_rets as (\n",
    "select r.id as retailer_id,case when regions.name_en like '%Delta%' then 'Delta' else regions.name_en end as region \n",
    "from retailers r \n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=r.id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "JOIN cities on cities.id=districts.city_id\n",
    "join states on states.id=cities.state_id\n",
    "join regions on regions.id=states.region_id\n",
    "where r.id in (164812,454300,948856,949828,13026,489945,951661,101228,408392,943844,24891,456499,573350,90837,564005,294183,188186,134581,581875,816040,732075,339270,406087)\n",
    "),\n",
    "tags as (\n",
    "select dta.id as tag_id,dta.name, \n",
    "case when name like '%Delta%' then 'Delta'\n",
    "when name like '%Alex%' then 'Alexandria'\n",
    "when name like '%sohag%' then 'Upper Egypt'\n",
    "when name like '%cairo%' then 'Greater Cairo'\n",
    "else '' end as region\n",
    "from dynamic_tags dta\n",
    "where dta.name like '%whole_sale%'\n",
    "and dta.id > 3000\n",
    ")\n",
    "\n",
    "select * \n",
    "from (\n",
    "select nr.retailer_id ,tag_id \n",
    "from new_rets nr \n",
    "join tags t on t.region = nr.region \n",
    "\n",
    "union all \n",
    "\n",
    "select dt.taggable_id as retailer_id, dta.id as tag_id \n",
    "from dynamic_taggables dt \n",
    "join dynamic_tags dta  on dta.id = dt.dynamic_tag_id\n",
    "where dta.name like '%whole_sale%'\n",
    "and dta.id > 3000\n",
    ")\n",
    "order by 1 \n",
    "\n",
    "\n",
    "'''\n",
    "tag_rets  = query_snowflake(query, columns = ['retailer_id','tag_id'])\n",
    "tag_rets.columns = tag_rets.columns.str.lower()\n",
    "for col in tag_rets.columns:\n",
    "    tag_rets[col] = pd.to_numeric(tag_rets[col], errors='ignore')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9549d07-a3f7-4e68-a22f-dd0ed2129b43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "with base as (\n",
    "select c.id as cohort_id,dt.dynamic_tag_id,taggable_id as retailer_id\n",
    "from cohorts c \n",
    "join  dynamic_taggables dt on dt.dynamic_tag_id = c.dynamic_tag_id\n",
    "where c.id in (700,701,702,703,704,1124,1125,1126,1123)\n",
    "and dt.taggable_id not in (select taggable_id from dynamic_taggables where dynamic_tag_id in (3038,3151,3153,3154))\n",
    "),\n",
    "mapping as (\n",
    "select * \n",
    "from (\n",
    "values\n",
    "('Cairo',700,2807),\n",
    "('Giza',701,2808),\n",
    "('Alexandria',702,2809),\n",
    "('Delta East',704,2811),\n",
    "('Delta West',703,2812),\n",
    "('Upper Egypt',1123,2810),\n",
    "('Upper Egypt',1124,2810),\n",
    "('Upper Egypt',1125,2810),\n",
    "('Upper Egypt',1126,2810)\n",
    ")x(region,cohort_id,tag_id)\n",
    "\n",
    "),\n",
    "final_data as (\n",
    "select cohort_id,dynamic_tag_id,retailer_id,sum(percent*cntrb) as final_perc\n",
    "from (\n",
    "select *,\n",
    "PERCENTILE_CONT(0.8) WITHIN GROUP (ORDER BY qty) over(partition by product_id,dynamic_tag_id) as perc_80,\n",
    "case when qty>perc_80 then least((qty/perc_80)*80,100) else greatest((qty/perc_80)*80,40) end as percent,\n",
    "nmv/sum(nmv)over(partition by retailer_id) as cntrb\n",
    "from (\n",
    "select \n",
    "base.cohort_id,\n",
    "base.dynamic_tag_id,\n",
    "so.retailer_id,\n",
    "pso.product_id,\n",
    "sum(purchased_item_count*basic_unit_count) as qty,\n",
    "sum(pso.total_price) as nmv\n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "join base on base.retailer_id = so.retailer_id\n",
    "        \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at::date between date_trunc('month',current_date - interval '4 months') and date_trunc('month',current_date)\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\n",
    "GROUP BY ALL\n",
    ")\n",
    ")\n",
    "group by all \n",
    "HAVING final_perc > 80\n",
    ")\n",
    "\n",
    "select tag_id,retailer_id,dt.name as tag_name\n",
    "from final_data fd\n",
    "join mapping m on fd.cohort_id = m.cohort_id\n",
    "join dynamic_tags dt on dt.id = m.tag_id\n",
    "\n",
    "'''\n",
    "tags_recc_rets  = query_snowflake(query, columns = ['tag_id','retailer_id','tag_name'])\n",
    "tags_recc_rets.columns = tags_recc_rets.columns.str.lower()\n",
    "for col in tags_recc_rets.columns:\n",
    "    tags_recc_rets[col] = pd.to_numeric(tags_recc_rets[col], errors='ignore')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7285289-7ddf-4afc-86a3-314cc65493f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag_id</th>\n",
       "      <th>retailer_id</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>sales_order_status_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2807</td>\n",
       "      <td>384</td>\n",
       "      <td>Cairo_quantity_discount</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2807</td>\n",
       "      <td>387</td>\n",
       "      <td>Cairo_quantity_discount</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2807</td>\n",
       "      <td>439</td>\n",
       "      <td>Cairo_quantity_discount</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2807</td>\n",
       "      <td>449</td>\n",
       "      <td>Cairo_quantity_discount</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2807</td>\n",
       "      <td>491</td>\n",
       "      <td>Cairo_quantity_discount</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16975</th>\n",
       "      <td>2812</td>\n",
       "      <td>948044</td>\n",
       "      <td>DW_quantity_discount</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16976</th>\n",
       "      <td>2812</td>\n",
       "      <td>948116</td>\n",
       "      <td>DW_quantity_discount</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16977</th>\n",
       "      <td>2812</td>\n",
       "      <td>948584</td>\n",
       "      <td>DW_quantity_discount</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16978</th>\n",
       "      <td>2812</td>\n",
       "      <td>948641</td>\n",
       "      <td>DW_quantity_discount</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16979</th>\n",
       "      <td>2812</td>\n",
       "      <td>948992</td>\n",
       "      <td>DW_quantity_discount</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14312 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tag_id  retailer_id                 tag_name  sales_order_status_id\n",
       "2        2807          384  Cairo_quantity_discount                    6.0\n",
       "3        2807          387  Cairo_quantity_discount                    6.0\n",
       "4        2807          439  Cairo_quantity_discount                    6.0\n",
       "5        2807          449  Cairo_quantity_discount                    0.0\n",
       "6        2807          491  Cairo_quantity_discount                   12.0\n",
       "...       ...          ...                      ...                    ...\n",
       "16975    2812       948044     DW_quantity_discount                    6.0\n",
       "16976    2812       948116     DW_quantity_discount                    6.0\n",
       "16977    2812       948584     DW_quantity_discount                    6.0\n",
       "16978    2812       948641     DW_quantity_discount                    6.0\n",
       "16979    2812       948992     DW_quantity_discount                    6.0\n",
       "\n",
       "[14312 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "req_data = tags_recc_rets.merge(retailer_status,on=['retailer_id'],how='left')\n",
    "req_data = req_data.fillna(0)\n",
    "req_data = req_data.groupby(['tag_id','retailer_id','tag_name'])['sales_order_status_id'].max().reset_index()\n",
    "req_data = req_data[req_data['sales_order_status_id'].isin([0,6,9,12])]\n",
    "req_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65097a7b-0293-4549-a7f5-12d32e82d6a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # In this sample we only handle the specific exceptions for the 'GetSecretValue' API.\n",
    "    # See https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "    # We rethrow the exception by default.\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            # Secrets Manager can't decrypt the protected secret text using the provided KMS key.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            # An error occurred on the server side.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            # You provided an invalid value for a parameter.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            # You provided a parameter value that is not valid for the current state of the resource.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            # We can't find the resource that you asked for.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "    else:\n",
    "        # Decrypts secret using the associated KMS CMK.\n",
    "        # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            return get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            return base64.b64decode(get_secret_value_response['SecretBinary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ac0781e-6586-4e97-8368-0b8d5a950a80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pricing_api_secret = json.loads(get_secret(\"prod/pricing/api/\"))\n",
    "username = pricing_api_secret[\"egypt_username\"]\n",
    "password = pricing_api_secret[\"egypt_password\"]\n",
    "secret = pricing_api_secret[\"egypt_secret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc3ab0f9-479c-414b-9f6d-db64973cd72d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_access_token(url, client_id, client_secret):\n",
    "    \"\"\"\n",
    "    get_access_token function takes three parameters and returns a session token\n",
    "    to connect to MaxAB APIs\n",
    "\n",
    "    :param url: production MaxAB token URL\n",
    "    :param client_id: client ID\n",
    "    :param client_secret: client sercret\n",
    "    :return: session token\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        data={\"grant_type\": \"password\",\n",
    "              \"username\": username,\n",
    "              \"password\": password},\n",
    "        auth=(client_id, client_secret),\n",
    "    )\n",
    "    return response.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a34f6e8-ffd7-4895-9d87-940adcaf3747",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def clear_directory(directory):\n",
    "    \"\"\"Delete all files in directory but keep the directory\"\"\"\n",
    "    files = glob.glob(os.path.join(directory, '*'))\n",
    "    for f in files:\n",
    "        if os.path.isfile(f):\n",
    "            os.remove(f)\n",
    "            print(f\"Deleted: {f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed77e7ea-61bf-4241-8f0d-b7603125fe42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: dynamic_tags/tag_2809_list.xlsx\n",
      "Deleted: dynamic_tags/tag_2807_list.xlsx\n",
      "Deleted: dynamic_tags/tag_2811_list.xlsx\n",
      "Deleted: dynamic_tags/tag_2810_list.xlsx\n",
      "Deleted: dynamic_tags/tag_2812_list.xlsx\n",
      "Deleted: dynamic_tags/tag_2808_list.xlsx\n",
      "Found 6 unique tags to process\n",
      "\n",
      "[1/6] Processing tag 2807: Cairo_quantity_discount\n",
      "  - Retailers: 3385\n",
      "  ✓ Saved: dynamic_tags/tag_2807_list.xlsx\n",
      "  ✓ Upload successful: 200\n",
      "\n",
      "[2/6] Processing tag 2808: Giza_quantity_discount\n",
      "  - Retailers: 2088\n",
      "  ✓ Saved: dynamic_tags/tag_2808_list.xlsx\n",
      "  ✓ Upload successful: 200\n",
      "\n",
      "[3/6] Processing tag 2809: Alex_quantity_discount\n",
      "  - Retailers: 1299\n",
      "  ✓ Saved: dynamic_tags/tag_2809_list.xlsx\n",
      "  ✓ Upload successful: 200\n",
      "\n",
      "[4/6] Processing tag 2810: UE_quantity_discount\n",
      "  - Retailers: 2929\n",
      "  ✓ Saved: dynamic_tags/tag_2810_list.xlsx\n",
      "  ✓ Upload successful: 200\n",
      "\n",
      "[5/6] Processing tag 2811: DE_quantity_discount\n",
      "  - Retailers: 2072\n",
      "  ✓ Saved: dynamic_tags/tag_2811_list.xlsx\n",
      "  ✓ Upload successful: 200\n",
      "\n",
      "[6/6] Processing tag 2812: DW_quantity_discount\n",
      "  - Retailers: 2539\n",
      "  ✓ Saved: dynamic_tags/tag_2812_list.xlsx\n",
      "  ✓ Upload successful: 200\n",
      "\n",
      "\n",
      "============================================================\n",
      "Summary:\n",
      "  Success: 6\n",
      "  Failed: 0\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def upload_dynamic_tags(req_data, secret):\n",
    "    \"\"\"Upload dynamic tags to API\"\"\"\n",
    "    os.makedirs('dynamic_tags', exist_ok=True)\n",
    "    \n",
    "    # Get unique tags\n",
    "    unique_tags = req_data[['tag_id', 'tag_name']].drop_duplicates()\n",
    "    \n",
    "    print(f\"Found {len(unique_tags)} unique tags to process\\n\")\n",
    "    \n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    \n",
    "    for idx, (tag_id, tag_name) in enumerate(unique_tags.itertuples(index=False), 1):\n",
    "        # Convert to Python native types\n",
    "        tag_id = int(tag_id)\n",
    "        tag_name = str(tag_name)\n",
    "        \n",
    "        print(f\"[{idx}/{len(unique_tags)}] Processing tag {tag_id}: {tag_name}\")\n",
    "        \n",
    "        # Get data for this tag\n",
    "        tag_data = req_data[req_data['tag_id'] == tag_id]\n",
    "        to_upload = tag_data[['retailer_id']].drop_duplicates()\n",
    "        \n",
    "        print(f\"  - Retailers: {len(to_upload)}\")\n",
    "        \n",
    "        # Save to Excel\n",
    "        file_path = f'dynamic_tags/tag_{tag_id}_list.xlsx'\n",
    "        to_upload.to_excel(file_path, index=False, sheet_name='Sheet1')\n",
    "        print(f\"  ✓ Saved: {file_path}\")\n",
    "        \n",
    "        # Read as binary\n",
    "        with open(file_path, 'rb') as f:\n",
    "            file_base64 = base64.b64encode(f.read()).decode('utf-8')\n",
    "        \n",
    "        # Get token\n",
    "        try:\n",
    "            token = get_access_token(\n",
    "                'https://sso.maxab.info/auth/realms/maxab/protocol/openid-connect/token',\n",
    "                'main-system-externals',\n",
    "                secret\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Failed to get token: {e}\\n\")\n",
    "            fail_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Upload to API\n",
    "        url = f\"https://api.maxab.info/commerce/api/admins/v1/internal-dynamic-tags/{tag_id}\"\n",
    "        \n",
    "        headers = {\n",
    "            'accept': 'application/json',\n",
    "            'Content-Type': 'application/json',\n",
    "            'Authorization': f'Bearer {token}'\n",
    "        }\n",
    "        \n",
    "        payload = {\n",
    "            \"basic_info\": {\n",
    "                \"id\": tag_id,\n",
    "                \"type\": 1,\n",
    "                \"method\": 2,\n",
    "                \"name\": tag_name\n",
    "            },\n",
    "            \"file\": file_base64,\n",
    "            \"file_extension\": \"xlsx\"\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.put(url, headers=headers, json=payload)\n",
    "            \n",
    "            if response.status_code in [200, 201, 204]:\n",
    "                print(f\"  ✓ Upload successful: {response.status_code}\")\n",
    "                success_count += 1\n",
    "            else:\n",
    "                print(f\"  ✗ Upload failed: {response.status_code}\")\n",
    "                print(f\"    Error: {response.text}\")\n",
    "                fail_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Request failed: {e}\")\n",
    "            fail_count += 1\n",
    "        \n",
    "        print()\n",
    "        time.sleep(2)  # Rate limiting\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Summary:\")\n",
    "    print(f\"  Success: {success_count}\")\n",
    "    print(f\"  Failed: {fail_count}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# Usage\n",
    "clear_directory('dynamic_tags')\n",
    "upload_dynamic_tags(req_data, secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd112df9-279a-4b56-8f4e-e298f1fcdb10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
