{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2603154f-ffde-49b1-8350-0f157d6f736a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# Connectivity\n",
    "!pip install psycopg2-binary  # PostgreSQL adapter\n",
    "# !pip install snowflake-connector-python  # Snowflake connector\n",
    "!pip install snowflake-connector-python==3.15.0 # Snowflake connector Older Version\n",
    "!pip install snowflake-sqlalchemy  # Snowflake SQLAlchemy connector\n",
    "!pip install warnings # Warnings management\n",
    "# !pip install pyarrow # Serialization\n",
    "!pip install keyring==23.11.0 # Key management\n",
    "!pip install sqlalchemy==1.4.46 # SQLAlchemy\n",
    "!pip install requests # HTTP requests\n",
    "!pip install boto3 # AWS SDK\n",
    "# !pip install slackclient # Slack API\n",
    "!pip install oauth2client # Google Sheets API\n",
    "!pip install gspread==5.9.0 # Google Sheets API\n",
    "!pip install gspread_dataframe # Google Sheets API\n",
    "!pip install google.cloud # Google Cloud\n",
    "# Data manipulation and analysis\n",
    "!pip install polars\n",
    "!pip install pandas==2.2.1\n",
    "!pip install numpy\n",
    "# !pip install fastparquet\n",
    "!pip install openpyxl # Excel file handling\n",
    "!pip install xlsxwriter # Excel file handling\n",
    "# Linear programming\n",
    "!pip install pulp\n",
    "# Date and time handling\n",
    "!pip install --upgrade datetime\n",
    "!pip install python-time\n",
    "!pip install --upgrade pytz\n",
    "# Progress bar\n",
    "!pip install tqdm\n",
    "# Database data types\n",
    "!pip install db-dtypes\n",
    "# Geospatial data handling\n",
    "# !pip install geopandas\n",
    "# !pip install shapely\n",
    "# !pip install fiona\n",
    "# !pip install haversine\n",
    "# Plotting\n",
    "\n",
    "# Modeling\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn\n",
    "\n",
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "002772d2-d36b-4bf7-afe2-8467fd4f4a31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/snowflake/connector/options.py:104: UserWarning: You have an incompatible version of 'pyarrow' installed (21.0.0), please install a version that adheres to: 'pyarrow<19.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import setup_environment_2\n",
    "import importlib\n",
    "import import_ipynb\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import pytz  \n",
    "import os\n",
    "import snowflake.connector\n",
    "import boto3\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(setup_environment_2)\n",
    "setup_environment_2.initialize_env()\n",
    "import base64\n",
    "from botocore.exceptions import ClientError\n",
    "from requests import get\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import time\n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba94f00-73d0-45fe-9398-270389bb4a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_snowflake(query, columns=[]):\n",
    "    import os\n",
    "    import snowflake.connector\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    con = snowflake.connector.connect(\n",
    "        user =  os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account= os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password= os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database =os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        if len(columns) == 0:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()))\n",
    "        else:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()),columns=columns)\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4e2348-7bd2-4856-8fff-2320f1ef610b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "WITH prs AS (\n",
    "SELECT DISTINCT product_purchased_receipts.purchased_receipt_id,\n",
    "                purchased_receipts.purchased_order_id,\n",
    "                DATE_PART('Day', purchased_receipts.date::date) AS DAY,\n",
    "                DATE_PART('month', purchased_receipts.date::date) AS MONTH,\n",
    "                DATE_Part('year', purchased_receipts.date::date) AS YEAR,\n",
    "\t\t\t\tDATE_Part('hour', purchased_receipts.date) AS hour,\n",
    "                products.id AS product_id,\n",
    "                CONCAT(products.name_ar, ' ', products.size, ' ', product_units.name_ar) AS sku,\n",
    "                brands.name_ar AS Brand,\n",
    "                categories.name_ar as category,\n",
    "                products.description,\n",
    "                purchased_receipts.warehouse_id AS warehouse_id,\n",
    "                warehouses.name as warehouse,\n",
    "                packing_units.name_ar AS packing_unit,\n",
    "                purchased_receipts.discount AS Total_discount,\n",
    "                purchased_receipts.return_orders_discount,\n",
    "                purchased_receipts.discount_type_id,\n",
    "                suppliers.id AS supplier_id,\n",
    "                suppliers.name AS supplier_name,\n",
    "                purchased_receipt_statuses.name_ar AS PR_status,\n",
    "                product_purchased_receipts.basic_unit_count,\n",
    "                product_purchased_receipts.purchased_item_count AS purchase_count,\n",
    "                product_purchased_receipts.purchased_item_count*product_purchased_receipts.basic_unit_count AS purchase_min_count,\n",
    "                product_purchased_receipts.item_price,\n",
    "                product_purchased_receipts.final_price/product_purchased_receipts.purchased_item_count AS final_item_price,\n",
    "                product_purchased_receipts.total_price AS purchase_price,\n",
    "                CASE WHEN product_purchased_receipts.vat = 'true' THEN product_purchased_receipts.total_price * 0.14\n",
    "                     ELSE CASE WHEN product_purchased_receipts.vat = 'false' THEN product_purchased_receipts.total_price * 0\n",
    "                               END\n",
    "                END AS vat,\n",
    "                CASE WHEN purchased_receipts.discount_type_id = 2 THEN (product_purchased_receipts.discount/100) * product_purchased_receipts.total_price\n",
    "                     ELSE product_purchased_receipts.discount\n",
    "                END AS SKU_discount,\n",
    "                purchased_receipts.total_price AS pr_value,\n",
    "                CASE\n",
    "                    WHEN product_purchased_receipts.t_tax_id = 1 THEN product_purchased_receipts.total_price * 0.05\n",
    "                    ELSE CASE\n",
    "                             WHEN product_purchased_receipts.t_tax_id = 2 THEN product_purchased_receipts.total_price * 0.08\n",
    "                             ELSE CASE\n",
    "                                      WHEN product_purchased_receipts.t_tax_id = 3 THEN product_purchased_receipts.total_price * 0.1\n",
    "                                      ELSE 0\n",
    "                                  END\n",
    "                         END\n",
    "                END AS table_tax,\n",
    "                product_purchased_receipts.final_price AS Final_Price,\n",
    "                product_purchased_receipts.product_type_id,\n",
    "                purchased_receipts.debt_note_value as credit_note,\n",
    "                purchased_receipts.tips,\n",
    "                purchased_receipts.delivery_fees,\n",
    "                case when purchased_receipts.is_actual = 'true' then 'Real' \n",
    "                     else 'Virtual' \n",
    "                     end as is_actual\n",
    "                     \n",
    "FROM product_purchased_receipts\n",
    "LEFT JOIN products ON products.id = product_purchased_receipts.product_id\n",
    "LEFT JOIN packing_unit_products ON packing_unit_products.product_id = products.id\n",
    "LEFT JOIN purchased_receipts ON purchased_receipts.id = product_purchased_receipts.purchased_receipt_id\n",
    "LEFT JOIN purchased_receipt_statuses ON purchased_receipt_statuses.id = purchased_receipts.purchased_receipt_status_id\n",
    "LEFT JOIN packing_units ON packing_units.id = product_purchased_receipts.packing_unit_id\n",
    "LEFT JOIN product_units ON products.unit_id = product_units.id\n",
    "LEFT JOIN suppliers ON suppliers.id = purchased_receipts.supplier_id\n",
    "LEFT JOIN brands ON brands.id = products.brand_id\n",
    "left join categories on categories.id = products.category_id\n",
    "left join warehouses on warehouses.id = purchased_receipts.warehouse_id\n",
    "WHERE product_purchased_receipts.purchased_item_count <> 0\n",
    "      AND purchased_receipts.purchased_receipt_status_id IN (4,5,7)\n",
    "      AND purchased_receipts.date::date >= current_date\n",
    "    and product_purchased_receipts.final_price > 0 \n",
    "     \n",
    "     \n",
    "    )\n",
    "    SELECT product_id,\n",
    "\tsum(purchase_min_count) as all_day_qty ,\n",
    "\tcoalesce(sum(case when hour between DATE_Part('hour',CURRENT_TIME) -1 and DATE_Part('hour',CURRENT_TIME) then purchase_min_count end),0) as last_hour_qty,\n",
    "\tavg(final_item_price/basic_unit_count) as item_price\n",
    "    FROM prs\n",
    "\tgroup by 1\n",
    "'''\n",
    "prs_data = setup_environment_2.dwh_pg_query(query, columns = ['product_id','all_day_qty','last_hour_qty','item_price']) \n",
    "prs_data.product_id=pd.to_numeric(prs_data.product_id)\n",
    "prs_data.all_day_qty=pd.to_numeric(prs_data.all_day_qty)\n",
    "prs_data.last_hour_qty=pd.to_numeric(prs_data.last_hour_qty)\n",
    "prs_data.item_price=pd.to_numeric(prs_data.item_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a9c69-cfaf-4fde-a245-797db68ba31f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "  t_product_id AS product_id,\n",
    "  s_beg_stock AS av_STOCKS,\n",
    "  p_purchased_item_count AS pr_qty,\n",
    "  p_final_price AS pr_value,\n",
    "  CASE\n",
    "    WHEN p_purchased_item_count <> 0 THEN p_final_price / p_purchased_item_count\n",
    "    ELSE 0\n",
    "  END AS item_price\n",
    "FROM\n",
    "  finance.wac_tracker wt\n",
    "  JOIN products ON products.id = wt.t_product_id \n",
    "  JOIN brands ON brands.id = products.brand_id\n",
    "  JOIN categories c ON c.id = products.category_id\n",
    "  JOIN product_units ON product_units.id = products.unit_id\n",
    "  where wt.t_date::date = CURRENT_DATE\n",
    "  and p_purchased_item_count > 0 \n",
    "'''\n",
    "try:\n",
    "    reflected_in_wac = setup_environment_2.dwh_pg_query(query, columns = ['product_id','av_STOCKS','pr_qty','pr_value','cu_item_price']) \n",
    "    reflected_in_wac.product_id=pd.to_numeric(reflected_in_wac.product_id)\n",
    "    reflected_in_wac.av_STOCKS=pd.to_numeric(reflected_in_wac.av_STOCKS)\n",
    "    reflected_in_wac.pr_qty=pd.to_numeric(reflected_in_wac.pr_qty)\n",
    "    reflected_in_wac.cu_item_price=pd.to_numeric(reflected_in_wac.cu_item_price)\n",
    "    reflected_in_wac.pr_value=pd.to_numeric(reflected_in_wac.pr_value)\n",
    "except:    \n",
    "    columns = ['product_id','av_STOCKS','pr_qty','pr_value','cu_item_price']\n",
    "    reflected_in_wac = pd.DataFrame(columns=columns)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9bd4f1-800d-481b-9779-8c72f7720638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select \n",
    "\t\tf.product_id,\n",
    "\t\tCONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\t\n",
    "\t\tf.wac1,\n",
    "\t\tf.wac_p\n",
    "from finance.all_cogs f\n",
    "JOIN products on products.id=f.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "where current_timestamp between f.from_date and f.to_date \n",
    "and not categories.name_ar in (\n",
    "    SELECT categories.name_ar AS cat\n",
    "                    FROM categories\n",
    "                    JOIN sections s ON s.id = categories.section_id\n",
    "                    WHERE   categories.name_ar LIKE '%سايب%'\n",
    "                        OR  categories.name_ar LIKE '%بالتة%'\n",
    "                        OR  categories.section_id IN (225, 318, 285, 121, 87, 351, 417)\n",
    "\n",
    ")\n",
    "'''\n",
    "\n",
    "wacs = query_snowflake(query, columns = ['product_id','sku','brand','cat','wac1','wac_p']) \n",
    "wacs.product_id=pd.to_numeric(wacs.product_id)\n",
    "wacs.wac1=pd.to_numeric(wacs.wac1)\n",
    "wacs.wac_p=pd.to_numeric(wacs.wac_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41b5ab0-6980-4e22-ae39-523d31ec040a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query ='''\n",
    "\n",
    "select region,cohort_id,product_id,packing_unit_id,basic_unit_count,price\n",
    "from (\n",
    "select   case when cpc.cohort_id in (700,695) then 'Cairo'\n",
    "             when cpc.cohort_id in (701) then 'Giza'\n",
    "             when cpc.cohort_id in (704,698) then 'Delta East'\n",
    "             when cpc.cohort_id in (703,697) then 'Delta West'\n",
    "             when cpc.cohort_id in (696,1123,1124,1125,1126) then 'Upper Egypt'\n",
    "             when cpc.cohort_id in (702,699) then 'Alexandria'\n",
    "        end as region,\n",
    "\t\tcohort_id,\n",
    "        pu.product_id,\n",
    "\t\tpu.packing_unit_id as packing_unit_id,\n",
    "\t\tpu.basic_unit_count,\n",
    "        cpc.price as price,\n",
    "\t\tcpc.created_at,\n",
    "\t\tmax(cpc.created_at)over(partition by pu.product_id ,pu.packing_unit_id,cohort_id) as max_date \n",
    "from cohort_pricing_changes cpc \n",
    "join    PACKING_UNIT_PRODUCTS pu on pu.id = cpc.product_packing_unit_id\n",
    "WHERE   cpc.cohort_id in (700,701,702,703,704,696,695,698,697,699,1123,1124,1125,1126)\n",
    ")x \n",
    "where created_at = max_date\n",
    "'''\n",
    "prices = setup_environment_2.dwh_pg_query(query, columns = ['region','cohort_id','product_id','packing_unit_id','basic_unit_count','price'])\n",
    "prices.product_id=pd.to_numeric(prices.product_id)\n",
    "prices.cohort_id=pd.to_numeric(prices.cohort_id)\n",
    "prices.packing_unit_id=pd.to_numeric(prices.packing_unit_id)\n",
    "prices.basic_unit_count=pd.to_numeric(prices.basic_unit_count)\n",
    "prices.price=pd.to_numeric(prices.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f0cc9-0c50-4932-ae07-a286fce7f77f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select region,product_id,optimal_margin,coalesce(MIN_BOUNDARY,optimal_margin) as MIN_BOUNDARY\n",
    "from (\n",
    "select region,product_id,greatest(optimal_bm,coalesce(MIN_BOUNDARY,optimal_bm)) as optimal_margin,MIN_BOUNDARY,row_number()over(partition by region,product_id order by created_at desc) as rnk \n",
    "from materialized_views.PRODUCT_STATISTICS\n",
    "qualify rnk = 1 \n",
    ")\n",
    "where optimal_margin is not null\n",
    "'''\n",
    "stats = query_snowflake(query, columns = ['region','product_id','optimal_margin','min_margin'])\n",
    "stats.product_id=pd.to_numeric(stats.product_id)\n",
    "stats.optimal_margin=pd.to_numeric(stats.optimal_margin)\n",
    "stats.min_margin=pd.to_numeric(stats.min_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc28d9e-89ee-4d92-b6c2-29a6eb3d6135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT cat, brand, margin as target_bm\n",
    "FROM    performance.commercial_targets cplan\n",
    "QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE)OVER()) = DATE_TRUNC('month', CURRENT_DATE) THEN DATE_TRUNC('month', CURRENT_DATE)\n",
    "ELSE DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    "'''\n",
    "brand_cat_target  = query_snowflake(query, columns = ['cat','brand','target_bm'])\n",
    "brand_cat_target.target_bm=pd.to_numeric(brand_cat_target.target_bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2901fd1-5624-4d11-b602-7907c70c651f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select cat,sum(target_bm *(target_nmv/cat_total)) as cat_target_margin\n",
    "from (\n",
    "select *,sum(target_nmv)over(partition by cat) as cat_total\n",
    "from (\n",
    "select cat,brand,avg(target_bm) as target_bm , sum(target_nmv) as target_nmv\n",
    "from (\n",
    "SELECT DISTINCT date,city as region,cat, brand, margin as target_bm,nmv as target_nmv\n",
    "FROM    performance.commercial_targets cplan\n",
    "QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE)OVER()) = DATE_TRUNC('month', CURRENT_DATE) THEN DATE_TRUNC('month', CURRENT_DATE)\n",
    "ELSE DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    ")\n",
    "group by all\n",
    ")\n",
    ")\n",
    "group by all \n",
    "'''\n",
    "cat_target  = query_snowflake(query, columns = ['cat','cat_target_margin'])\n",
    "cat_target.cat_target_margin=pd.to_numeric(cat_target.cat_target_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9930077-3984-4594-a72a-2176ef9392fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select * \n",
    "from materialized_views.negative_margin_exceptions\n",
    "'''\n",
    "exceptions = query_snowflake(query, columns = ['region','product_id','sku'])\n",
    "exceptions.product_id=pd.to_numeric(exceptions.product_id)\n",
    "exceptions=exceptions[['region','product_id']]\n",
    "exceptions['exception']=1\n",
    "\n",
    "cohort_def = {\n",
    "    'region': ['Cairo', 'Giza', 'Alexandria', 'Delta East', 'Delta West','Upper Egypt','Upper Egypt','Upper Egypt','Upper Egypt'],\n",
    "    'cohort_id': [700, 701, 702, 704, 703, 1123,1124,1125,1126]\n",
    "}\n",
    "region_cohort_map = pd.DataFrame(cohort_def)\n",
    "exceptions = exceptions.merge(region_cohort_map,on='region')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b057cc-5959-4118-b920-a076a3527108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select  product_id ,sum(AVAILABLE_STOCK) as stocks\n",
    "from materialized_views.stock_snap_shots_recent \n",
    "where date_trunc('hour',Timestamp)  =  date_trunc('hour',CURRENT_TIMESTAMP) - interval '1 hour'\n",
    "and   warehouse_id not in (6,9,10)\n",
    "group by all \n",
    "'''\n",
    "stocks = query_snowflake(query, columns = ['product_id','stocks'])\n",
    "stocks.product_id=pd.to_numeric(stocks.product_id)\n",
    "stocks.stocks=pd.to_numeric(stocks.stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ae955-4187-4d11-a90b-511e22d41087",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged_data = prs_data.merge(reflected_in_wac,on='product_id',how='left')\n",
    "merged_data=merged_data.fillna(0)\n",
    "final_data = wacs.merge(merged_data,on='product_id',how='left')\n",
    "final_data = final_data.merge(stocks,on='product_id',how='left')\n",
    "final_data = final_data.fillna(0)\n",
    "final_data['av_STOCKS'] =final_data['stocks']\n",
    "final_data['not_reflected_qty'] = final_data['all_day_qty'] - final_data['pr_qty']\n",
    "final_data['not_reflected_qty'] = final_data['not_reflected_qty'].fillna(0)\n",
    "final_data['new_wac1'] = (((final_data['av_STOCKS']+final_data['pr_qty'])*final_data['wac1'])+(final_data['not_reflected_qty']*final_data['item_price']))/(final_data['av_STOCKS']+final_data['pr_qty']+final_data['not_reflected_qty'])\n",
    "final_data['wac1_change'] = (final_data['new_wac1']-final_data['wac1'])/final_data['wac1']\n",
    "final_data['new_wac_p'] = final_data['wac_p'] *(1+final_data['wac1_change'])\n",
    "final_data['new_wac_p'] = final_data['new_wac_p'].fillna(final_data['wac_p'])\n",
    "final_data = final_data.merge(prices,on='product_id')\n",
    "final_data['new_wac_p'] = final_data['new_wac_p']*final_data['basic_unit_count'] \n",
    "final_data['bm'] = (final_data['price']-final_data['new_wac_p'])/final_data['price']\n",
    "final_data = final_data.merge(stats,on=['product_id','region'],how='left')\n",
    "final_data = final_data.merge(brand_cat_target,on=['cat','brand'],how='left')\n",
    "final_data = final_data.merge(cat_target,on=['cat'])\n",
    "final_data['final_optimal'] = final_data['optimal_margin'].fillna(final_data[\"target_bm\"]).fillna(final_data[\"cat_target_margin\"])\n",
    "final_data['final_min'] = final_data['min_margin'].fillna(final_data[\"target_bm\"]*0.8).fillna(final_data[\"cat_target_margin\"]*0.8)\n",
    "\n",
    "cond = [\n",
    "    \n",
    "    ((final_data['av_STOCKS'].isna()) & (final_data['bm']<0)),\n",
    "    ((~final_data['av_STOCKS'].isna()) & (final_data['bm']<final_data['final_min']*0.5)&(final_data['cat'] != 'حاجه ساقعه')),\n",
    "    ((~final_data['av_STOCKS'].isna()) & (final_data['bm']<0)&(final_data['cat'] == 'حاجه ساقعه')),\n",
    "    \n",
    "] \n",
    "cho = [\n",
    "    final_data['new_wac_p']/(1-final_data['final_optimal']) , \n",
    "    final_data['new_wac_p']/(1-final_data['final_optimal']),\n",
    "    final_data['new_wac_p']/(1-final_data['final_optimal'])\n",
    "    \n",
    "]\n",
    "final_data['final_new_price'] = np.select(cond,cho,np.nan)\n",
    "final_data['final_new_price'] = np.round(final_data['final_new_price']/4)*4\n",
    "final_data = final_data[~final_data['final_new_price'].isna()]\n",
    "final_data = final_data[final_data['final_new_price']>=final_data['price']*1.005]\n",
    "\n",
    "final_data = final_data[(final_data['stocks']> 0)|(final_data['all_day_qty']>0)]\n",
    "final_data = final_data.merge(exceptions,on=['product_id','region','cohort_id'],how='left')\n",
    "final_data=final_data[final_data['exception'].isna()]\n",
    "final_data.sort_values(['cohort_id', 'product_id', 'basic_unit_count']).reset_index(drop=True)\n",
    "final_data['ind'] = 1\n",
    "final_data['ind'] = final_data.groupby(['cohort_id', 'product_id']).ind.cumsum()\n",
    "remove_min_pu = pd.read_csv('skus_to_remove_min.csv')\n",
    "remove_min_pu['remove_min'] = 1\n",
    "final_data = final_data.merge(remove_min_pu[['product_id','remove_min']], on='product_id', how='left')\n",
    "\n",
    "to_upload = final_data[['cohort_id','product_id','sku','packing_unit_id','final_new_price','region','ind','remove_min']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d4739c-d0c5-4d5f-bc3b-9538c12de757",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11b86b16-78bd-44b5-99e2-a40e2b714ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import base64\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "from requests import get\n",
    "from pathlib import Path\n",
    "import requests\n",
    "    \n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # In this sample we only handle the specific exceptions for the 'GetSecretValue' API.\n",
    "    # See https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "    # We rethrow the exception by default.\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            # Secrets Manager can't decrypt the protected secret text using the provided KMS key.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            # An error occurred on the server side.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            # You provided an invalid value for a parameter.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            # You provided a parameter value that is not valid for the current state of the resource.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            # We can't find the resource that you asked for.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "    else:\n",
    "        # Decrypts secret using the associated KMS CMK.\n",
    "        # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            return get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            return base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "\n",
    "        \n",
    "pricing_api_secret = json.loads(get_secret(\"prod/pricing/api/\"))\n",
    "username = pricing_api_secret[\"egypt_username\"]\n",
    "password = pricing_api_secret[\"egypt_password\"]\n",
    "secret = pricing_api_secret[\"egypt_secret\"]\n",
    "\n",
    "# get access token\n",
    "def get_access_token(url, client_id, client_secret):\n",
    "    \"\"\"\n",
    "    get_access_token function takes three parameters and returns a session token\n",
    "    to connect to MaxAB APIs\n",
    "\n",
    "    :param url: production MaxAB token URL\n",
    "    :param client_id: client ID\n",
    "    :param client_secret: client sercret\n",
    "    :return: session token\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        data={\"grant_type\": \"password\",\n",
    "              \"username\": username,\n",
    "              \"password\": password},\n",
    "        auth=(client_id, client_secret),\n",
    "    )\n",
    "    return response.json()[\"access_token\"]\n",
    "\n",
    "\n",
    "def post_prices(id_,file_name):\n",
    "    token = get_access_token('https://sso.maxab.info/auth/realms/maxab/protocol/openid-connect/token',\n",
    "                             'main-system-externals',\n",
    "                             secret)\n",
    "    url = \"https://api.maxab.info/main-system/api/admin-portal/cohorts/{}/pricing\".format(id_)\n",
    "    payload={}\n",
    "    files=[\n",
    "      ('sheet',(file_name,open(file_name,'rb'),'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'))\n",
    "    ]\n",
    "    headers = {\n",
    "      'Authorization': 'bearer {}'.format(token)}\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload, files=files)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b66736f-666b-437e-9d13-659bcbf6fcbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prices are upoladed successfuly cohort:701\n",
      "Prices are upoladed successfuly cohort:1124\n",
      "Prices are upoladed successfuly cohort:700\n",
      "Prices are upoladed successfuly cohort:1126\n",
      "Prices are upoladed successfuly cohort:1125\n",
      "Prices are upoladed successfuly cohort:1123\n",
      "Prices are upoladed successfuly cohort:703\n",
      "Prices are upoladed successfuly cohort:704\n",
      "Prices are upoladed successfuly cohort:702\n"
     ]
    }
   ],
   "source": [
    "for cohort in to_upload.cohort_id.unique():\n",
    "        upload = to_upload[to_upload['cohort_id']==cohort]\n",
    "        out=upload[['product_id', 'sku', 'packing_unit_id', 'final_new_price', 'ind', 'remove_min']].copy()\n",
    "        out.columns = ['Product ID','Product Name','Packing Unit ID','Price','ind','remove_min']\n",
    "        out['Visibility (YES/NO)'] = 'YES'\n",
    "        out.loc[(out['ind'] == 1) & (out['remove_min'] == 1), 'Visibility (YES/NO)'] = 'NO'\n",
    "        out.drop(columns=['ind','remove_min'], inplace=True)\n",
    "        out = out.drop_duplicates()\n",
    "        out['Execute At (format:dd/mm/yyyy HH:mm)'] = None\n",
    "        out['Tags'] = None\n",
    "        file_name_ = 'Uploads/1_new_{}.xlsx'.format(cohort).replace(' ','_')\n",
    "        out.to_excel(file_name_,index = False,engine = 'xlsxwriter')\n",
    "        time.sleep(5)\n",
    "        x = post_prices(cohort, 'Uploads/1_new_{}.xlsx'.format(cohort).replace(' ','_'))\n",
    "        if ('\"success\":true' in str(x.content).lower()):\n",
    "            print(f\"Prices are upoladed successfuly cohort:{cohort}\")\n",
    "        else:\n",
    "            print(f\"ERROR cohort: {cohort}\")\n",
    "            print(x.content)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a8af77-eff0-4e47-a106-dd787762d5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083f9be-7f88-4d48-92ca-21c920fb2459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
