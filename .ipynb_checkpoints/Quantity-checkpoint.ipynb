{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353eed4b-fed6-4ddb-930f-0d1c581aaf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# Connectivity\n",
    "!pip install psycopg2-binary  # PostgreSQL adapter\n",
    "# !pip install snowflake-connector-python  # Snowflake connector\n",
    "!pip install snowflake-connector-python==3.15.0 # Snowflake connector Older Version\n",
    "!pip install snowflake-sqlalchemy  # Snowflake SQLAlchemy connector\n",
    "!pip install warnings # Warnings management\n",
    "# !pip install pyarrow # Serialization\n",
    "!pip install keyring==23.11.0 # Key management\n",
    "!pip install sqlalchemy==1.4.46 # SQLAlchemy\n",
    "!pip install requests # HTTP requests\n",
    "!pip install boto3 # AWS SDK\n",
    "# !pip install slackclient # Slack API\n",
    "!pip install oauth2client # Google Sheets API\n",
    "!pip install gspread==5.9.0 # Google Sheets API\n",
    "!pip install gspread_dataframe # Google Sheets API\n",
    "!pip install google.cloud # Google Cloud\n",
    "# Data manipulation and analysis\n",
    "!pip install polars\n",
    "!pip install pandas==2.2.1\n",
    "!pip install numpy\n",
    "# !pip install fastparquet\n",
    "!pip install openpyxl # Excel file handling\n",
    "!pip install xlsxwriter # Excel file handling\n",
    "# Linear programming\n",
    "!pip install pulp\n",
    "# Date and time handling\n",
    "!pip install --upgrade datetime\n",
    "!pip install python-time\n",
    "!pip install --upgrade pytz\n",
    "# Progress bar\n",
    "!pip install tqdm\n",
    "# Database data types\n",
    "!pip install db-dtypes\n",
    "# Geospatial data handling\n",
    "# !pip install geopandas\n",
    "# !pip install shapely\n",
    "# !pip install fiona\n",
    "# !pip install haversine\n",
    "# Plotting\n",
    "\n",
    "# Modeling\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn\n",
    "\n",
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64355078-99bc-436e-b5a9-69fbc4f983fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import setup_environment_2\n",
    "import importlib\n",
    "import import_ipynb\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(setup_environment_2)\n",
    "setup_environment_2.initialize_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b5cdc8b-89b2-4b8a-a04e-9e70a9a878f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_snowflake(query, columns=[]):\n",
    "    import os\n",
    "    import snowflake.connector\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    con = snowflake.connector.connect(\n",
    "        user =  os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account= os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password= os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database =os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        if len(columns) == 0:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()))\n",
    "        else:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()),columns=columns)\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a02939-f4ba-445d-bc88-940f233ae3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "command_string = '''\n",
    "with stocks as (\n",
    "WITH whs as (SELECT *\n",
    "             FROM   (values\n",
    "                            ('Cairo', 'El-Marg', 38),\n",
    "                            ('Cairo', 'Mostorod', 1),\n",
    "                            ('Giza', 'Barageel', 236),\n",
    "                            ('Giza', 'Basatin', 39),\n",
    "                            ('Delta West', 'El-Mahala', 337),\n",
    "                            ('Delta West', 'Tanta', 8),\n",
    "                            ('Delta East', 'Mansoura FC', 339),\n",
    "                            ('Delta East', 'Sharqya', 170),\n",
    "                            ('Upper Egypt', 'Assiut FC', 501),\n",
    "                            ('Upper Egypt', 'Bani sweif', 401),\n",
    "                            ('Upper Egypt', 'Menya Samalot', 703),\n",
    "                            ('Upper Egypt', 'Sohag', 632),\n",
    "                            ('Alexandria', 'Khorshed Alex', 797))\n",
    "                    x(region, wh, warehouse_id))\n",
    "\n",
    "SELECT  region,\n",
    "        product_id,\n",
    "        SUM(stocks) as stocks\n",
    "FROM    (SELECT DISTINCT whs.region,\n",
    "                whs.wh,\n",
    "                product_warehouse.product_id,\n",
    "                (product_warehouse.available_stock)::integer as stocks\n",
    "        from whs\n",
    "        JOIN product_warehouse ON product_warehouse.warehouse_id = whs.warehouse_id\n",
    "        JOIN products on product_warehouse.product_id = products.id\n",
    "        JOIN product_units ON products.unit_id = product_units.id\n",
    "\n",
    "        where   product_warehouse.warehouse_id not in (6,9,10)\n",
    "            AND product_warehouse.is_basic_unit = 1\n",
    "        group by 1,2,3,4)\t\t\n",
    "GROUP BY 1,2\n",
    "having sum(stocks) > 0 \n",
    "\n",
    "),\n",
    "selected_skus as (\n",
    "select region,product_id,cat,brand,row_number()over(partition by region,cat order by cntrb) as num_skus\n",
    "from (\n",
    "select *,min(case when cumulative_sum > 0.3 then cumulative_sum end) over(partition by cat, region) as thres\n",
    "from (\n",
    "select *,SUM(cntrb) OVER (partition by cat, region ORDER BY cntrb desc ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum\n",
    "from (\n",
    "select *, num_order/sum(num_order)over(partition by cat,region) as cntrb\n",
    "from (\n",
    "SELECT  DISTINCT\n",
    "\t\tcase when regions.id = 2 then cities.name_en else regions.name_en end as region,\n",
    "\t\tpso.product_id,\n",
    "\t\tCONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\n",
    "\t\tcount(distinct parent_sales_order_id) as num_order ,\n",
    "        sum(pso.total_price) as nmv,\n",
    "       sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs,\n",
    "\t   (nmv-cogs)/nmv as bm \n",
    "\t\t\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id\n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN finance.all_cogs f  ON f.product_id = pso.product_id\n",
    "                        AND f.from_date::date <= so.created_at::date\n",
    "                        AND f.to_date::date > so.created_at::date\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "JOIN cities on cities.id=districts.city_id\n",
    "join states on states.id=cities.state_id\n",
    "join regions on regions.id=states.region_id   \n",
    "join stocks s on s.product_id = pso.product_id and s.region = case when regions.id = 2 then cities.name_en else regions.name_en end\n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at::date between date_trunc('month',current_date - interval '2 months') and CURRENT_date-1\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\n",
    "GROUP BY ALL\n",
    ")\n",
    ")\n",
    ")\n",
    ")\n",
    "where cumulative_sum <= thres\n",
    "qualify num_skus <= 5 \n",
    "),\n",
    "main as (\n",
    "SELECT  DISTINCT\n",
    "\t\tso.created_at::date as date,\n",
    "\t\tparent_sales_order_id,\n",
    "\t\tso.retailer_id,\n",
    "\t\tcase when regions.id = 2 then cities.name_en else regions.name_en end as region,\n",
    "\t\tpso.product_id,\n",
    "\t\tCONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "\t\tpacking_unit_id,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\n",
    "\t\tsum(pso.purchased_item_count) as qty,\n",
    "        sum(pso.total_price) as nmv,\n",
    "       sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs,\n",
    "\t   (nmv-cogs)/nmv as bm \n",
    "\t\t\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id\n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN finance.all_cogs f  ON f.product_id = pso.product_id\n",
    "                        AND f.from_date::date <= so.created_at::date\n",
    "                        AND f.to_date::date > so.created_at::date\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "JOIN cities on cities.id=districts.city_id\n",
    "join states on states.id=cities.state_id\n",
    "join regions on regions.id=states.region_id \n",
    "join selected_skus ss on ss.product_id = pso.product_id and ss.region = case when regions.id = 2 then cities.name_en else regions.name_en end\n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at::date between date_trunc('month',current_date - interval '2 months') and CURRENT_date-1\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\n",
    "GROUP BY ALL\n",
    "),\n",
    "region_data as (\n",
    "select region,product_id,sku,brand,cat,packing_unit_id,\n",
    "PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY qty) AS region_q1,\n",
    "MEDIAN(qty) as region_median,\n",
    "PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY qty) AS region_q3,\n",
    "PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY qty) AS region_95,\n",
    "STDDEV_POP(qty) as std\n",
    "from main\n",
    "group by all \n",
    "),\n",
    "recent_region_data as (\n",
    "select region,product_id,sku,brand,cat,packing_unit_id,\n",
    "MEDIAN(qty) as recent_region_median,\n",
    "PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY qty) AS recent_region_q3,\n",
    "STDDEV_POP(qty) as recent_std\n",
    "from main\n",
    "where date between current_date - 8 and current_date - 1 \n",
    "group by all \n",
    "\n",
    "),\n",
    " freq_table AS (\n",
    "  SELECT\n",
    "  \tregion,\n",
    "    PRODUCT_ID,sku,brand,cat,\n",
    "\tpacking_unit_id,\n",
    "    qty,\n",
    "    COUNT(distinct parent_sales_order_id) AS freq\n",
    "  FROM main\n",
    "  GROUP BY all\n",
    "),\n",
    "lag_lead AS (\n",
    "  SELECT\n",
    "  region,\n",
    "    PRODUCT_ID,sku,brand,cat,\n",
    "\tpacking_unit_id,\n",
    "    qty,\n",
    "    freq,\n",
    "    LAG(freq) OVER (PARTITION BY region,PRODUCT_ID,packing_unit_id ORDER BY qty) AS prev_freq,\n",
    "    LEAD(freq) OVER (PARTITION BY region,PRODUCT_ID,packing_unit_id ORDER BY qty) AS next_freq\n",
    "  FROM freq_table\n",
    "),\n",
    "most_freq as (\n",
    "select * \n",
    "from (\n",
    "select *,max(cntrb)over(partition by product_id,packing_unit_id,region) as max_cntrb\n",
    "from (\n",
    "SELECT *, freq/sum(freq) over(partition by product_id,packing_unit_id,region) as cntrb\n",
    "FROM lag_lead ll \n",
    "WHERE (freq > COALESCE(prev_freq, -1))\n",
    "  AND (freq > COALESCE(next_freq, -1))\n",
    "  )\n",
    "  )\n",
    "  where cntrb >= max_cntrb- 0.05\n",
    "  order by product_id\n",
    "),\n",
    "most_qty as (\n",
    "select region,product_id,sku,cat,brand,packing_unit_id,ceil(sum(freq_cntrb*qty)) as final_qty \n",
    "from (\n",
    "select *,freq/sum(freq)over(partition by  product_id,packing_unit_id,region) as freq_cntrb\n",
    "from most_freq \n",
    ")\n",
    "group by all \n",
    "),\n",
    "final_data as (\n",
    "select *,\n",
    "ceil(GREATEST(\n",
    "      recent_region_median + 0.75 * recent_std,\n",
    "      final_qty,\n",
    "\t  region_median+0.75*std,\n",
    "\t  region_median+2,\n",
    "\t  2\n",
    "    )) as tier_1,\n",
    " ceil(GREATEST(\n",
    "      final_qty + 0.5 * std,\n",
    "      region_q3 + 0.5 * std,\n",
    "\t  region_95 + 0.3*std,\n",
    "      recent_region_q3 + 0.5 * recent_std,\n",
    "\t  tier_1*1.3\n",
    "    )) as tier_2\n",
    "from (\n",
    "select  mq.*,region_q1,\n",
    "region_median,\n",
    "region_q3,\n",
    "region_95,\n",
    "std,\n",
    "COALESCE(recent_region_median,0) as recent_region_median,\n",
    "COALESCE(recent_region_q3,0) as recent_region_q3,\n",
    "COALESCE(recent_std,0) as recent_std\n",
    "from region_data rd \n",
    "join most_qty mq on rd.region =mq.region\n",
    "and rd.product_id =  mq.product_id\n",
    "and rd.packing_unit_id = mq.packing_unit_id \n",
    "left join recent_region_data rrd on rrd.region =mq.region\n",
    "and rrd.product_id =  mq.product_id\n",
    "and rrd.packing_unit_id = mq.packing_unit_id \n",
    ")\n",
    "),\n",
    "prices as (\n",
    "SELECT  case when cpu.cohort_id in (700,695) then 'Cairo'\n",
    "             when cpu.cohort_id in (701,695) then 'Giza'\n",
    "             when cpu.cohort_id in (704,698) then 'Delta East'\n",
    "             when cpu.cohort_id in (703,697) then 'Delta West'\n",
    "             when cpu.cohort_id in (696) then 'Upper Egypt'\n",
    "             when cpu.cohort_id in (702,699) then 'Alexandria'\n",
    "        end as region,\n",
    "        pu.product_id,\n",
    "\t\tpu.packing_unit_id as packing_unit_id,\n",
    "\t\tpu.basic_unit_count,\n",
    "        avg(cpu.price) as price\n",
    "FROM    cohort_product_packing_units cpu\n",
    "join    PACKING_UNIT_PRODUCTS pu on pu.id = cpu.product_packing_unit_id\n",
    "WHERE   cpu.cohort_id in (700,701,702,703,704,696,695,698,697,699)\n",
    "    and cpu.created_at::date<>'2023-07-31'\n",
    "    and cpu.is_customized = true\n",
    "\tgroup by all \n",
    "),\n",
    "elast as (\n",
    "with fill_rate as (\n",
    "\n",
    "\n",
    "\n",
    "WITH\n",
    "  whs AS (\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      (\n",
    "        VALUES\n",
    "          ('Cairo', 'El-Marg', 38),\n",
    "          ('Cairo', 'Mostorod', 1),\n",
    "          ('Giza', 'Barageel', 236),\n",
    "          ('Giza', 'Basatin', 39),\n",
    "          ('Delta West', 'El-Mahala', 337),\n",
    "          ('Delta West', 'Tanta', 8),\n",
    "          ('Delta East', 'Mansoura FC', 339),\n",
    "          ('Delta East', 'Sharqya', 170),\n",
    "          ('Upper Egypt', 'Assiut FC', 501),\n",
    "          ('Upper Egypt', 'Bani sweif', 401),\n",
    "          ('Upper Egypt', 'Menya Samalot', 703),\n",
    "          ('Upper Egypt', 'Sohag', 632),\n",
    "          ('Alexandria', 'Khorshed Alex', 797)\n",
    "      ) x (region, wh, warehouse_id)\n",
    "  ),\n",
    "  active_skus AS (\n",
    "    SELECT\n",
    "      CASE\n",
    "        WHEN regions.name_en = 'Greater Cairo' THEN cities.name_en\n",
    "        ELSE regions.name_en\n",
    "      END AS region,\n",
    "      pso.product_id AS product_id,\n",
    "      sum(pso.total_price) AS nmv\n",
    "    FROM\n",
    "      sales_orders so\n",
    "      JOIN product_sales_order pso ON so.id = pso.sales_order_id\n",
    "      JOIN materialized_views.retailer_polygon ON materialized_views.retailer_polygon.retailer_id = so.retailer_id\n",
    "      JOIN districts ON districts.id = materialized_views.retailer_polygon.district_id\n",
    "      JOIN cities ON cities.id = districts.city_id\n",
    "      JOIN states ON states.id = cities.state_id\n",
    "      JOIN regions ON regions.id = states.region_id\n",
    "    WHERE\n",
    "      so.created_at::DATE >= DATE_TRUNC('month', CURRENT_DATE - INTERVAL '3 month')\n",
    "      AND sales_order_status_id NOT IN (7, 12)\n",
    "      AND so.channel IN ('telesales', 'retailer')\n",
    "      AND pso.PURCHASED_ITEM_COUNT > 0\n",
    "    GROUP BY\n",
    "      ALL\n",
    "    HAVING\n",
    "      nmv > 0\n",
    "  ),\n",
    "  weighted_fill_rate AS (\n",
    "    SELECT\n",
    "      DAY,\n",
    "      product_id,\n",
    "      region,\n",
    "      1 - (oos / total) AS fill_rate\n",
    "    FROM\n",
    "      (\n",
    "        SELECT\n",
    "          timestamp::DATE AS DAY,\n",
    "          whs.region,\n",
    "          categories.name_ar AS cat,\n",
    "          brands.name_ar AS brand,\n",
    "          products.id AS product_id,\n",
    "          nmv,\n",
    "          count(\n",
    "            CASE\n",
    "              WHEN ss.activation = FALSE\n",
    "              OR ss.available_stock = 0 THEN timestamp\n",
    "            END\n",
    "          ) AS oos,\n",
    "          count(timestamp) AS total\n",
    "        FROM\n",
    "          materialized_views.STOCK_SNAP_SHOTS_RECENT ss\n",
    "          JOIN whs ON whs.warehouse_id = ss.warehouse_id\n",
    "          JOIN products ON products.id = ss.product_id\n",
    "          JOIN product_units ON product_units.id = products.unit_id\n",
    "          JOIN categories ON categories.id = products.category_id\n",
    "          JOIN brands ON brands.id = products.brand_id\n",
    "          JOIN active_skus ON active_skus.region = whs.region\n",
    "          AND active_skus.product_id = ss.product_id\n",
    "        WHERE\n",
    "          ss.timestamp::DATE >= DATE_TRUNC('month', CURRENT_DATE - INTERVAL '3 months')\n",
    "        GROUP BY\n",
    "          ALL\n",
    "      )\n",
    "  ),\n",
    "  prs_in AS (\n",
    "    WITH\n",
    "      prs AS (\n",
    "        SELECT DISTINCT\n",
    "          purchased_receipts.date::DATE AS pr_date,\n",
    "          max(date_part('hour', purchased_receipts.date)) AS HOUR,\n",
    "          products.id AS product_id,\n",
    "          CONCAT(\n",
    "            products.name_ar,\n",
    "            ' ',\n",
    "            products.size,\n",
    "            ' ',\n",
    "            product_units.name_ar\n",
    "          ) AS sku,\n",
    "          brands.name_ar AS Brand,\n",
    "          categories.name_ar AS category,\n",
    "          purchased_receipts.warehouse_id AS warehouse_id,\n",
    "          warehouses.name AS warehouse,\n",
    "          sum(\n",
    "            product_purchased_receipts.purchased_item_count * product_purchased_receipts.basic_unit_count\n",
    "          ) AS purchase_min_count,\n",
    "        FROM\n",
    "          product_purchased_receipts\n",
    "          LEFT JOIN products ON products.id = product_purchased_receipts.product_id\n",
    "          LEFT JOIN packing_unit_products ON packing_unit_products.product_id = products.id\n",
    "          LEFT JOIN purchased_receipts ON purchased_receipts.id = product_purchased_receipts.purchased_receipt_id\n",
    "          LEFT JOIN purchased_receipt_statuses ON purchased_receipt_statuses.id = purchased_receipts.purchased_receipt_status_id\n",
    "          LEFT JOIN packing_units ON packing_units.id = product_purchased_receipts.packing_unit_id\n",
    "          LEFT JOIN product_units ON products.unit_id = product_units.id\n",
    "          LEFT JOIN suppliers ON suppliers.id = purchased_receipts.supplier_id\n",
    "          LEFT JOIN brands ON brands.id = products.brand_id\n",
    "          LEFT JOIN categories ON categories.id = products.category_id\n",
    "          LEFT JOIN warehouses ON warehouses.id = purchased_receipts.warehouse_id\n",
    "        WHERE\n",
    "          product_purchased_receipts.purchased_item_count <> 0\n",
    "          AND purchased_receipts.purchased_receipt_status_id IN (4, 5, 7)\n",
    "          AND purchased_receipts.date::DATE >= date_trunc('month', CURRENT_DATE - interval '3 months')\n",
    "          --  AND purchased_receipts.is_actual = 'true'\n",
    "        GROUP BY\n",
    "          ALL\n",
    "      ),\n",
    "      sales_cntrb AS (\n",
    "        SELECT\n",
    "          date_part('hour', so.created_at) AS HOUR,\n",
    "          pso.warehouse_id AS warehouse_id,\n",
    "          sum(pso.total_price) AS nmv\n",
    "        FROM\n",
    "          sales_orders so\n",
    "          JOIN product_sales_order pso ON so.id = pso.sales_order_id\n",
    "        WHERE\n",
    "          so.created_at::DATE BETWEEN CURRENT_DATE -30 AND CURRENT_DATE  -1\n",
    "          AND sales_order_status_id NOT IN (7, 12)\n",
    "          AND pso.purchased_item_count <> 0\n",
    "          AND channel <> 'admin'\n",
    "        GROUP BY\n",
    "          ALL\n",
    "      ),\n",
    "      whs AS (\n",
    "        SELECT\n",
    "          *\n",
    "        FROM\n",
    "          (\n",
    "            VALUES\n",
    "              ('Cairo', 'El-Marg', 38),\n",
    "              ('Cairo', 'Mostorod', 1),\n",
    "              ('Giza', 'Barageel', 236),\n",
    "              ('Giza', 'Basatin', 39),\n",
    "              ('Delta West', 'El-Mahala', 337),\n",
    "              ('Delta West', 'Tanta', 8),\n",
    "              ('Delta East', 'Mansoura FC', 339),\n",
    "              ('Delta East', 'Sharqya', 170),\n",
    "              ('Upper Egypt', 'Assiut FC', 501),\n",
    "              ('Upper Egypt', 'Bani sweif', 401),\n",
    "              ('Upper Egypt', 'Menya Samalot', 703),\n",
    "              ('Upper Egypt', 'Sohag', 632),\n",
    "              ('Alexandria', 'Khorshed Alex', 797)\n",
    "          ) x (region, wh, warehouse_id)\n",
    "      )\n",
    "    SELECT\n",
    "      pr_date,\n",
    "      product_id,\n",
    "      sku,\n",
    "      region,\n",
    "      round(sum((1 - cntrb) * purchase_min_count), 0) AS in_stocks\n",
    "    FROM\n",
    "      (\n",
    "        SELECT\n",
    "          x.pr_date,\n",
    "          x.hour,\n",
    "          x.product_id,\n",
    "          x.sku,\n",
    "          x.warehouse_id,\n",
    "          x.purchase_min_count,\n",
    "          x.cntrb,\n",
    "          region\n",
    "        FROM\n",
    "          (\n",
    "            SELECT\n",
    "              prs.*,\n",
    "              sum(\n",
    "                CASE\n",
    "                  WHEN sc.hour < prs.hour THEN nmv\n",
    "                END\n",
    "              ) / sum(nmv) AS cntrb\n",
    "            FROM\n",
    "              prs\n",
    "              LEFT JOIN sales_cntrb sc ON prs.warehouse_id = sc.warehouse_id\n",
    "            GROUP BY\n",
    "              ALL\n",
    "          ) x\n",
    "          JOIN whs ON whs.warehouse_id = x.warehouse_id\n",
    "      )\n",
    "    GROUP BY\n",
    "      ALL\n",
    "  )\n",
    "        SELECT\n",
    "          DATE,\n",
    "          product_id,\n",
    "          cat,\n",
    "          brand,\n",
    "          region,\n",
    "          day_stocks,\n",
    "          fill_rate\n",
    "        FROM\n",
    "          (\n",
    "            SELECT\n",
    "              *,\n",
    "              coalesce(\n",
    "                CASE\n",
    "                  WHEN opening_stocks = 0\n",
    "                  AND closing_stocks > 0 and fill_rate is not null THEN fill_rate * closing_stocks\n",
    "                  WHEN closing_stocks > opening_stocks\n",
    "                  AND in_stocks IS NOT NULL THEN opening_stocks + in_stocks\n",
    "                  ELSE opening_stocks\n",
    "                END,\n",
    "                0\n",
    "              ) AS day_stocks,\n",
    "            FROM\n",
    "              (\n",
    "                SELECT\n",
    "                  x.*,\n",
    "                  coalesce(wfr.fill_rate, 0) AS fill_rate,\n",
    "                  wac_p,\n",
    "                  pin.in_stocks\n",
    "                FROM\n",
    "                  (\n",
    "                    SELECT\n",
    "                      *,\n",
    "                      lag(closing_stocks) over (\n",
    "                        PARTITION BY\n",
    "                          product_id,\n",
    "                          region\n",
    "                        ORDER BY\n",
    "                          DATE\n",
    "                      ) AS opening_stocks\n",
    "                    FROM\n",
    "                      (\n",
    "                        SELECT\n",
    "                          sdc.timestamp::DATE AS DATE,\n",
    "                          sdc.product_id,\n",
    "                          c.name_ar AS cat,\n",
    "                          b.name_ar AS brand,\n",
    "                          whs.region,\n",
    "                          sum(sdc.AVAILABLE_STOCK) AS closing_stocks\n",
    "                        FROM\n",
    "                          MATERIALIZED_VIEWS.STOCK_DAY_CLOSE sdc\n",
    "                          JOIN whs ON whs.warehouse_id = sdc.warehouse_id\n",
    "                          JOIN products p ON p.id = sdc.product_id\n",
    "                          JOIN brands b ON b.id = p.BRAND_ID\n",
    "                          JOIN categories c ON c.id = p.category_id\n",
    "                        WHERE\n",
    "                          timestamp::DATE  BETWEEN date_trunc('month',CURRENT_DATE - interval '3 months')  AND CURRENT_DATE - 1\n",
    "                        GROUP BY\n",
    "                          ALL\n",
    "                      )\n",
    "                    ORDER BY\n",
    "                      DATE\n",
    "                  ) x\n",
    "                  LEFT JOIN weighted_fill_rate wfr ON wfr.product_id = x.product_id\n",
    "                  AND x.date = wfr.day\n",
    "                  AND x.region = wfr.region\n",
    "                  LEFT JOIN finance.all_cogs f ON f.product_id = x.product_id\n",
    "                  AND f.from_date::DATE <= x.date\n",
    "                  AND f.to_date::DATE > x.date\n",
    "                  LEFT JOIN prs_in pin ON pin.product_id = x.product_id\n",
    "                  AND pin.region = x.region\n",
    "                  AND pin.pr_date = x.date\n",
    "              )\n",
    "          ) z\n",
    "        WHERE\n",
    "          DATE BETWEEN date_trunc('month',CURRENT_DATE - interval '3 months')  AND CURRENT_DATE - 1\n",
    "),\n",
    "sales AS (\n",
    "  select * \n",
    "  from (\n",
    "  select s.*,  day_stocks,\n",
    "  PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY qty) OVER (partition by s.region,s.product_id ) AS q1,\n",
    "  PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY qty) OVER (partition by s.region,s.product_id ) AS q3,\n",
    "  q3+(1.2*(q3-q1)) as max,\n",
    "\tq1-(1.2*(q3-q1)) as min\n",
    "  from (\n",
    "    SELECT DISTINCT\n",
    "\tcase when regions.id = 2 then cities.name_en else regions.name_en end as region,\n",
    "      so.created_at::DATE AS date,\n",
    "      pso.product_id,\n",
    "      CONCAT(products.name_ar, ' ', products.size, ' ', product_units.name_ar) AS sku,\n",
    "      brands.name_ar AS brand,\n",
    "      categories.name_ar AS cat,\n",
    "      SUM(pso.total_price) AS nmv,\n",
    "      SUM(pso.purchased_item_count * basic_unit_count) AS qty\n",
    "\t  \n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    JOIN products ON products.id = pso.product_id\n",
    "    JOIN brands ON products.brand_id = brands.id\n",
    "    JOIN categories ON products.category_id = categories.id\n",
    "\tJOIN    materialized_views.retailer_polygon poly ON poly.retailer_id = so.retailer_id\n",
    "\tJOIN    districts ON districts.id = poly.district_id\n",
    "\tJOIN    cities ON cities.id = districts.city_id\n",
    "\tJOIN    states ON states.id = cities.STATE_ID\n",
    "\tJOIN    regions ON regions.id = states.region_id\n",
    "    JOIN finance.all_cogs f ON f.product_id = pso.product_id\n",
    "      AND f.from_date::DATE <= so.created_at::DATE\n",
    "      AND f.to_date::DATE > pso.created_at::DATE\n",
    "    JOIN product_units ON product_units.id = products.unit_id\n",
    "    WHERE so.created_at::DATE BETWEEN date_trunc('month',CURRENT_DATE - interval '3 months')  AND CURRENT_DATE - 1\n",
    "      AND so.sales_order_status_id NOT IN (7, 12)\n",
    "      AND so.channel IN ('telesales', 'retailer')\n",
    "      AND pso.purchased_item_count <> 0\n",
    "\t  AND TO_CHAR(so.created_at::date, 'Day') <> 'Fri'\n",
    "    GROUP BY ALL\n",
    "\t)s\n",
    "\tjoin fill_rate fr on fr.product_id = s.product_id and fr.region = s.region and fr.date = s.date\n",
    "\t)\n",
    "\twhere qty between min and max \n",
    "\tand qty <= day_stocks*0.95\n",
    "  ),\n",
    "\n",
    "  cohort_prices AS (\n",
    "    SELECT CASE WHEN cohort_id = 700 THEN 'Cairo'\n",
    "                             WHEN cohort_id = 701 THEN 'Giza'\n",
    "                             WHEN cohort_id = 702 THEN 'Alexandria'\n",
    "                             WHEN cohort_id = 703 THEN 'Delta West'\n",
    "                             WHEN cohort_id = 704 THEN 'Delta East'\n",
    "                             WHEN cohort_id = 696 THEN 'Upper Egypt'\n",
    "                        ELSE cohort_id::varchar END as region,\n",
    "      pup.product_id,\n",
    "      cpc.price,\n",
    "      cpc.created_at AS change_date,\n",
    "      COALESCE(\n",
    "        LEAD(cpc.created_at) OVER (PARTITION BY cohort_id, pup.product_id ORDER BY cpc.created_at),\n",
    "        CURRENT_TIMESTAMP\n",
    "      ) AS next_change\n",
    "    FROM cohort_pricing_changes cpc\n",
    "    LEFT JOIN packing_unit_products pup ON pup.id = cpc.product_packing_unit_id\n",
    "    WHERE pup.is_basic_unit = 1\n",
    "      AND cpc.created_at::DATE BETWEEN date_trunc('month',CURRENT_DATE - interval '4 months')  AND CURRENT_DATE - 1\n",
    "\t  and cpc.cohort_id in (700,701,702,703,704,696)\n",
    "  )\n",
    "  \n",
    "  SELECT\n",
    "    region,\n",
    "    product_id,\n",
    "    sku,\n",
    "    cat,\n",
    "    brand,\n",
    "\tsum(nmv) as nmv,\n",
    "    SUM(elasticty * qty_cntrb) AS elas\n",
    "  FROM (\n",
    "      SELECT *,\n",
    "        qty / SUM(qty) OVER (PARTITION BY region, product_id) AS qty_cntrb\n",
    "      FROM (\n",
    "        SELECT *,\n",
    "          CASE\n",
    "            WHEN price_change <> 0 THEN qty_change / price_change\n",
    "            ELSE 0\n",
    "          END AS elasticty\n",
    "        FROM (\n",
    "          SELECT *,\n",
    "            (qty - old_qty) / old_qty AS qty_change,\n",
    "            (price - old_price) / old_price AS price_change\n",
    "          FROM (\n",
    "            SELECT *,\n",
    "              LAG(qty) OVER (PARTITION BY product_id, region ORDER BY price) AS old_qty,\n",
    "              LAG(price) OVER (PARTITION BY product_id, region ORDER BY price) AS old_price\n",
    "            FROM (\n",
    "  \t\t\tselect region ,product_id,sku,brand,cat,price,avg(nmv) as nmv,avg(qty) as qty\n",
    "\t\t\t  from(\n",
    "              SELECT s.*, cp.price\n",
    "              FROM sales s\n",
    "              JOIN cohort_prices cp ON cp.region = s.region\n",
    "                AND s.product_id = cp.product_id\n",
    "                AND s.date >= cp.change_date\n",
    "                AND s.date < cp.next_change\n",
    "\t\t\t\t \n",
    "\t\t\t\t)\n",
    "\t\t\t\tgroup by all \n",
    "\t\t\t\torder by price\n",
    "            )\n",
    "            QUALIFY old_qty IS NOT NULL\n",
    "          )\n",
    "          WHERE (\n",
    "            (price_change > 0 AND qty_change < 0) OR\n",
    "            (price_change < 0 AND qty_change > 0)\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "  GROUP BY ALL\n",
    "  order by nmv desc\n",
    "\n",
    "),\n",
    "ops as (\n",
    "select region,product_id,cat,brand,case when nmv <> 0  then ops_cost/nmv else 0 end as ops_perc\n",
    "from (\n",
    "select region,product_id,cat.name_ar as cat,b.name_ar as brand, sum(NMV_EX_VAT) as nmv,sum(lm_cost+wh_cost+mm_cost) as ops_cost,\n",
    "from finance.sku_costs c \n",
    "join products p on p.id = c.product_id \n",
    "join brands b on b.id = p.brand_id \n",
    "join CATEGORies cat on cat.id = p.category_id\n",
    "where month between  date_trunc('month',current_date - interval '3 month') and date_trunc('month',current_date)-1\n",
    "group by all \n",
    ")\n",
    "group by all \n",
    ")\n",
    "select region,product_id,packing_unit_id,sku,cat,brand,tier_1,tier_2,price,wac,margin,ops_perc,elas,t1_change,t2_change,\n",
    "\n",
    "least(Greatest(COALESCE((ROUND(discount_1 / 0.0005) * 0.0005),0.15*margin),0.0035),0.015) as discount_1_final,\n",
    "least(Greatest(COALESCE((ROUND(discount_2 / 0.0005) * 0.0005),0.25*margin),0.005,discount_1_final+0.005),0.02) as discount_2_final\n",
    "\n",
    "from (\n",
    "select * , \n",
    "(tier_1-region_median)/region_median as t1_change,(tier_2-region_median)/region_median as t2_change,COALESCE(t1_change/(elas*-1),0.15*margin) as discount_1 , COALESCE(t2_change/(elas*-1),0.25*margin) as discount_2\n",
    "from (\n",
    "select fd.*,price,wac_p * basic_unit_count as wac,(price-wac)/price as margin ,elas,o.ops_perc\n",
    "from final_data fd \n",
    "join prices p on p.region = fd.region and p.product_id = fd.product_id and p.packing_unit_id = fd.packing_unit_id\n",
    "join finance.all_cogs f on f.product_id = fd.product_id and CURRENT_TIMESTAMP between from_date and to_date \n",
    "left join elast e on e.product_id = fd.product_id and e.region = fd.region\n",
    "join ops o on o.product_id = fd.product_id and o.region = case when fd.region in ('Cairo','Giza') then 'Greater Cairo' when fd.region like '%Delta%' then 'Delta' else fd.region end \n",
    "where margin > 0 \n",
    ")\n",
    ") \n",
    "'''\n",
    "quantity_disc_data = query_snowflake(command_string, columns = ['region','product_id','packing_unit_id','sku','cat','brand','tier_1','tier_2','price','wac','margin','ops_perc','elas','t1_change','t2_change','discount_1_final','discount_2_final'])\n",
    "quantity_disc_data.product_id = pd.to_numeric(quantity_disc_data.product_id)\n",
    "quantity_disc_data.packing_unit_id = pd.to_numeric(quantity_disc_data.packing_unit_id)\n",
    "quantity_disc_data.tier_1 = pd.to_numeric(quantity_disc_data.tier_1)\n",
    "quantity_disc_data.tier_2 = pd.to_numeric(quantity_disc_data.tier_2)\n",
    "\n",
    "quantity_disc_data.price = pd.to_numeric(quantity_disc_data.price)\n",
    "quantity_disc_data.wac = pd.to_numeric(quantity_disc_data.wac)\n",
    "quantity_disc_data.margin = pd.to_numeric(quantity_disc_data.margin)\n",
    "\n",
    "quantity_disc_data.ops_perc = pd.to_numeric(quantity_disc_data.ops_perc)\n",
    "quantity_disc_data.elas = pd.to_numeric(quantity_disc_data.elas)\n",
    "quantity_disc_data.t1_change = pd.to_numeric(quantity_disc_data.t1_change)\n",
    "quantity_disc_data.t2_change = pd.to_numeric(quantity_disc_data.t2_change)\n",
    "\n",
    "quantity_disc_data.discount_1_final = pd.to_numeric(quantity_disc_data.discount_1_final)\n",
    "quantity_disc_data.discount_2_final = pd.to_numeric(quantity_disc_data.discount_2_final)\n",
    "\n",
    "quantity_disc_data = quantity_disc_data[~quantity_disc_data['cat'].isin(['كروت شحن','مياه معدنيه','مقرمشات','شيبسي'])]\n",
    "quantity_disc_data.loc[quantity_disc_data['cat']== 'شوكولاتة','ops_perc'] = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c08569-d3ab-4e5c-9a13-4c2d64bf6a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "\n",
    "SELECT  DISTINCT\n",
    "\t\tcase when regions.id = 2 then states.name_en else regions.name_en end as region,\n",
    "\t\tpso.product_id,\n",
    "        sum(pso.total_price) as nmv\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id\n",
    "JOIN categories ON products.category_id = categories.id and categories.name_ar not like '%سايب%'\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "JOIN cities on cities.id=districts.city_id\n",
    "join states on states.id=cities.state_id\n",
    "join regions on regions.id=states.region_id               \n",
    "\n",
    "WHERE   so.created_at ::date between date_trunc('month',current_date - interval '2 months') and current_date -1 \n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\n",
    "GROUP BY ALL\n",
    "'''\n",
    "sales  = query_snowflake(query, columns = ['region','product_id','nmv'])\n",
    "sales.product_id = pd.to_numeric(sales.product_id)\n",
    "sales.nmv = pd.to_numeric(sales.nmv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee47a6-83de-48e6-b5f7-30a264f4c4c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "cond = [(quantity_disc_data['margin'] - quantity_disc_data['ops_perc'])<0,\n",
    "        ((quantity_disc_data['margin'] - quantity_disc_data['ops_perc']) > 0) &\n",
    "    ((quantity_disc_data['margin'] - quantity_disc_data['ops_perc'] - quantity_disc_data['discount_1_final']) < 0.01)\n",
    "       ]\n",
    "cho_1= [np.minimum(quantity_disc_data['discount_1_final'],quantity_disc_data['margin']*0.15),\n",
    "        np.minimum(quantity_disc_data['discount_1_final'],quantity_disc_data['margin']*0.25)\n",
    "       ]\n",
    "\n",
    "cho_2 =[np.minimum(quantity_disc_data['discount_2_final'],quantity_disc_data['margin']*0.25),\n",
    "        np.minimum(quantity_disc_data['discount_2_final'],quantity_disc_data['margin']*0.35)\n",
    "       ]\n",
    "\n",
    "quantity_disc_data['discount_1'] = np.select(cond,cho_1,default=quantity_disc_data['discount_1_final'])\n",
    "quantity_disc_data['discount_2'] = np.select(cond,cho_2,default=quantity_disc_data['discount_2_final'])\n",
    "quantity_disc_data['discount_1']=np.maximum(quantity_disc_data['discount_1'],0.0035)\n",
    "quantity_disc_data['discount_2']=np.maximum(quantity_disc_data['discount_2'],0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f98445-bde6-4bb9-b85e-58b952acdad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantity_disc_data['median'] = quantity_disc_data['tier_1']/(quantity_disc_data['t1_change']+1)\n",
    "quantity_disc_data['profit_median'] = quantity_disc_data['median'] *quantity_disc_data['price'] * quantity_disc_data['margin']\n",
    "quantity_disc_data['profit_t1'] = quantity_disc_data['tier_1'] *quantity_disc_data['price'] * (quantity_disc_data['margin']-quantity_disc_data['discount_1'])\n",
    "quantity_disc_data['profit_t2'] = quantity_disc_data['tier_2'] *quantity_disc_data['price'] * (quantity_disc_data['margin']-quantity_disc_data['discount_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6b0057-5686-4a34-a9e9-1143de5c0761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantity_disc_data = quantity_disc_data[(quantity_disc_data['profit_median']<quantity_disc_data['profit_t1'])&(quantity_disc_data['profit_t1']<quantity_disc_data['profit_t2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d7439-adc4-4d92-b2d9-16e4ffe95fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantity_disc_data = quantity_disc_data[quantity_disc_data['margin'] - quantity_disc_data['ops_perc']>-0.015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a9f60-f8f5-43b5-b7d7-9f642ae5d9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantity_disc_data = quantity_disc_data.merge(sales,on = ['region','product_id'])\n",
    "quantity_disc_data= quantity_disc_data.sort_values(['region', 'nmv'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26722c3-457a-42a9-97dc-c5515ab3d5ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantity_disc_data['row_number'] = quantity_disc_data.groupby('region').cumcount() + 1\n",
    "quantity_disc_data = quantity_disc_data[quantity_disc_data['row_number']<=100]\n",
    "quantity_disc_data.to_excel('quantity_disc_sku_list.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b9f97-a51f-4e66-ae3c-a3fbfa9e87a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_quantity_discount = pd.DataFrame(columns =['region','Discounts Group 1','Discounts Group 2','Description'])\n",
    "for reg in quantity_disc_data.region.unique():\n",
    "    region_data = quantity_disc_data[quantity_disc_data['region']== reg]\n",
    "    for i,r in region_data.iterrows():\n",
    "        region = r['region']\n",
    "        product_id = r['product_id']\n",
    "        packing_unit_id = r['packing_unit_id']\n",
    "        q_1 = int(r['tier_1'])\n",
    "        q_2 = int(r['tier_2'])\n",
    "        d_1 = round(r['discount_1']*100,2)\n",
    "        d_2 = round(r['discount_2']*100,2)\n",
    "        a_1 = [product_id]+[packing_unit_id]+[q_1]+[d_1]\n",
    "        a_2 = [product_id]+[packing_unit_id]+[q_2]+[d_2]\n",
    "        new_row = {'region':region ,'Discounts Group 1':a_1,'Discounts Group 2':a_2,'Description':f'{reg}_QD'}\n",
    "        new_row_df = pd.DataFrame([new_row]) \n",
    "        final_quantity_discount = pd.concat([final_quantity_discount, new_row_df], ignore_index=True)\n",
    "final_quantity_discount    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb05267-8d58-47d3-9f8f-77c6a4d7beb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Tag_def = {\n",
    "    'region': ['Cairo', 'Giza', 'Alexandria', 'Upper Egypt', 'Delta East', 'Delta West'],\n",
    "    'Tag ID': [2807, 2808, 2809, 2810, 2811, 2812]\n",
    "}\n",
    "\n",
    "Tag_map = pd.DataFrame(Tag_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612bf9e-38e7-46ed-8abe-f54473f764d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz  # install with: pip install pytz\n",
    "\n",
    "# Replace 'Africa/Cairo' with your local timezone\n",
    "local_tz = pytz.timezone('Africa/Cairo')\n",
    "\n",
    "time_plus_10 = (datetime.now(local_tz) + timedelta(minutes=10)).strftime('%d/%m/%Y %H:%M')\n",
    "time_plus_1_week = (datetime.now(local_tz) + timedelta(days=2)+ timedelta(minutes=10)).strftime('%d/%m/%Y %H:%M')\n",
    "\n",
    "final_quantity_discount = final_quantity_discount.merge(Tag_map,on='region')\n",
    "final_quantity_discount['Start Date/Time']= time_plus_10\n",
    "final_quantity_discount['End Date/Time']= time_plus_1_week\n",
    "\n",
    "final_quantity_discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9ad44-c8b7-4d34-980d-027652da8b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data = final_quantity_discount.groupby(['Tag ID','Description', 'Start Date/Time', 'End Date/Time'], as_index=False).agg({\n",
    "    'Discounts Group 1': list ,\n",
    "    'Discounts Group 2' : list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f27619f-e7f8-4a6e-8183-c396ee34c009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a688a038-0c68-4c41-a863-3f8d263eb992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data.to_excel('QD_upload.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c0f8f62-b358-43cc-8b82-cf72f3791d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48616453-a519-446f-a98d-33281b51c002",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qd_new = pd.read_excel('qd_data.xlsx')\n",
    "qd_new.columns = qd_new.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bd37257-912f-4252-b5a8-35748ab114be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select  id as cohort_id,dynamic_tag_id\n",
    "from cohorts \n",
    "where is_active='true'\n",
    "and id in (700,702,702,703,704,1123,1124,1125,1126)\n",
    "'''\n",
    "cohort_data  = query_snowflake(query, columns = ['cohort_id','Tag_id'])\n",
    "cohort_data.cohort_id = pd.to_numeric(cohort_data.cohort_id)\n",
    "cohort_data.Tag_id = pd.to_numeric(cohort_data.Tag_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad2d21f3-8611-473b-b451-a47b4ea6fc0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cohort_id', 'cohort_name', 'product_id', 'sku', 'cat', 'brand',\n",
       "       'packing_unit_id', 'tier_1', 'tier_2', 'discount_1', 'discount_2',\n",
       "       'Tag_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_new = qd_new.merge(cohort_data,on=['cohort_id'])\n",
    "qd_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "326d22ae-e098-4e51-808d-c4c15a163cea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final_quantity_discount = pd.DataFrame(columns =['Tag ID','Discounts Group 1','Discounts Group 2','Description'])\n",
    "for tag in qd_new.Tag_id.unique():\n",
    "    region_data = qd_new[qd_new['Tag_id']== tag]\n",
    "    for i,r in region_data.iterrows():\n",
    "        tag = r['Tag_id']\n",
    "        product_id = r['product_id']\n",
    "        packing_unit_id = r['packing_unit_id']\n",
    "        q_1 = int(r['tier_1'])\n",
    "        q_2 = int(r['tier_2'])\n",
    "        d_1 = round(r['discount_1']*100,2)\n",
    "        d_2 = round(r['discount_2']*100,2)\n",
    "        a_1 = [product_id]+[packing_unit_id]+[q_1]+[d_1]\n",
    "        a_2 = [product_id]+[packing_unit_id]+[q_2]+[d_2]\n",
    "        new_row = {'Tag ID':tag ,'Discounts Group 1':a_1,'Discounts Group 2':a_2,'Description':f'pepsi_{tag}_QD'}\n",
    "        new_row_df = pd.DataFrame([new_row]) \n",
    "        final_quantity_discount = pd.concat([final_quantity_discount, new_row_df], ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad07c1a2-5cca-4fb3-b4a8-8c10e5f620f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag ID</th>\n",
       "      <th>Discounts Group 1</th>\n",
       "      <th>Discounts Group 2</th>\n",
       "      <th>Description</th>\n",
       "      <th>Start Date/Time</th>\n",
       "      <th>End Date/Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>272</td>\n",
       "      <td>[435, 2, 3, 0.73]</td>\n",
       "      <td>[435, 2, 5, 2.24]</td>\n",
       "      <td>pepsi_272_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272</td>\n",
       "      <td>[434, 2, 4, 0.73]</td>\n",
       "      <td>[434, 2, 6, 2.24]</td>\n",
       "      <td>pepsi_272_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>272</td>\n",
       "      <td>[126, 2, 3, 0.93]</td>\n",
       "      <td>[126, 2, 4, 2.86]</td>\n",
       "      <td>pepsi_272_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>272</td>\n",
       "      <td>[8915, 2, 5, 0.97]</td>\n",
       "      <td>[8915, 2, 7, 3.0]</td>\n",
       "      <td>pepsi_272_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>271</td>\n",
       "      <td>[140, 2, 3, 0.93]</td>\n",
       "      <td>[140, 2, 4, 2.86]</td>\n",
       "      <td>pepsi_271_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>271</td>\n",
       "      <td>[434, 2, 3, 0.73]</td>\n",
       "      <td>[434, 2, 5, 2.24]</td>\n",
       "      <td>pepsi_271_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>271</td>\n",
       "      <td>[589, 2, 4, 0.26]</td>\n",
       "      <td>[589, 2, 6, 1.06]</td>\n",
       "      <td>pepsi_271_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>271</td>\n",
       "      <td>[326, 2, 3, 0.93]</td>\n",
       "      <td>[326, 2, 5, 2.86]</td>\n",
       "      <td>pepsi_271_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>271</td>\n",
       "      <td>[126, 2, 3, 0.93]</td>\n",
       "      <td>[126, 2, 4, 2.86]</td>\n",
       "      <td>pepsi_271_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>269</td>\n",
       "      <td>[126, 2, 3, 0.93]</td>\n",
       "      <td>[126, 2, 5, 2.86]</td>\n",
       "      <td>pepsi_269_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2825</td>\n",
       "      <td>[434, 2, 4, 0.73]</td>\n",
       "      <td>[434, 2, 6, 2.24]</td>\n",
       "      <td>pepsi_2825_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2824</td>\n",
       "      <td>[434, 2, 4, 0.73]</td>\n",
       "      <td>[434, 2, 6, 2.24]</td>\n",
       "      <td>pepsi_2824_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2824</td>\n",
       "      <td>[589, 2, 4, 0.26]</td>\n",
       "      <td>[589, 2, 7, 1.06]</td>\n",
       "      <td>pepsi_2824_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2824</td>\n",
       "      <td>[326, 2, 4, 0.93]</td>\n",
       "      <td>[326, 2, 6, 2.86]</td>\n",
       "      <td>pepsi_2824_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2824</td>\n",
       "      <td>[126, 2, 3, 0.93]</td>\n",
       "      <td>[126, 2, 4, 2.86]</td>\n",
       "      <td>pepsi_2824_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2824</td>\n",
       "      <td>[8915, 2, 4, 0.97]</td>\n",
       "      <td>[8915, 2, 7, 3.0]</td>\n",
       "      <td>pepsi_2824_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2823</td>\n",
       "      <td>[140, 2, 3, 0.93]</td>\n",
       "      <td>[140, 2, 4, 2.86]</td>\n",
       "      <td>pepsi_2823_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2823</td>\n",
       "      <td>[126, 2, 3, 0.93]</td>\n",
       "      <td>[126, 2, 5, 2.86]</td>\n",
       "      <td>pepsi_2823_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2823</td>\n",
       "      <td>[589, 2, 4, 0.26]</td>\n",
       "      <td>[589, 2, 6, 1.06]</td>\n",
       "      <td>pepsi_2823_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2823</td>\n",
       "      <td>[434, 2, 4, 0.73]</td>\n",
       "      <td>[434, 2, 6, 2.24]</td>\n",
       "      <td>pepsi_2823_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2823</td>\n",
       "      <td>[8915, 2, 4, 0.97]</td>\n",
       "      <td>[8915, 2, 6, 3.0]</td>\n",
       "      <td>pepsi_2823_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2822</td>\n",
       "      <td>[8915, 2, 4, 0.97]</td>\n",
       "      <td>[8915, 2, 6, 3.0]</td>\n",
       "      <td>pepsi_2822_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2822</td>\n",
       "      <td>[434, 2, 4, 0.73]</td>\n",
       "      <td>[434, 2, 6, 2.24]</td>\n",
       "      <td>pepsi_2822_QD</td>\n",
       "      <td>26/08/2025 12:07</td>\n",
       "      <td>31/08/2025 20:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Tag ID   Discounts Group 1  Discounts Group 2    Description  \\\n",
       "0     272   [435, 2, 3, 0.73]  [435, 2, 5, 2.24]   pepsi_272_QD   \n",
       "1     272   [434, 2, 4, 0.73]  [434, 2, 6, 2.24]   pepsi_272_QD   \n",
       "2     272   [126, 2, 3, 0.93]  [126, 2, 4, 2.86]   pepsi_272_QD   \n",
       "3     272  [8915, 2, 5, 0.97]  [8915, 2, 7, 3.0]   pepsi_272_QD   \n",
       "4     271   [140, 2, 3, 0.93]  [140, 2, 4, 2.86]   pepsi_271_QD   \n",
       "5     271   [434, 2, 3, 0.73]  [434, 2, 5, 2.24]   pepsi_271_QD   \n",
       "6     271   [589, 2, 4, 0.26]  [589, 2, 6, 1.06]   pepsi_271_QD   \n",
       "7     271   [326, 2, 3, 0.93]  [326, 2, 5, 2.86]   pepsi_271_QD   \n",
       "8     271   [126, 2, 3, 0.93]  [126, 2, 4, 2.86]   pepsi_271_QD   \n",
       "9     269   [126, 2, 3, 0.93]  [126, 2, 5, 2.86]   pepsi_269_QD   \n",
       "10   2825   [434, 2, 4, 0.73]  [434, 2, 6, 2.24]  pepsi_2825_QD   \n",
       "11   2824   [434, 2, 4, 0.73]  [434, 2, 6, 2.24]  pepsi_2824_QD   \n",
       "12   2824   [589, 2, 4, 0.26]  [589, 2, 7, 1.06]  pepsi_2824_QD   \n",
       "13   2824   [326, 2, 4, 0.93]  [326, 2, 6, 2.86]  pepsi_2824_QD   \n",
       "14   2824   [126, 2, 3, 0.93]  [126, 2, 4, 2.86]  pepsi_2824_QD   \n",
       "15   2824  [8915, 2, 4, 0.97]  [8915, 2, 7, 3.0]  pepsi_2824_QD   \n",
       "16   2823   [140, 2, 3, 0.93]  [140, 2, 4, 2.86]  pepsi_2823_QD   \n",
       "17   2823   [126, 2, 3, 0.93]  [126, 2, 5, 2.86]  pepsi_2823_QD   \n",
       "18   2823   [589, 2, 4, 0.26]  [589, 2, 6, 1.06]  pepsi_2823_QD   \n",
       "19   2823   [434, 2, 4, 0.73]  [434, 2, 6, 2.24]  pepsi_2823_QD   \n",
       "20   2823  [8915, 2, 4, 0.97]  [8915, 2, 6, 3.0]  pepsi_2823_QD   \n",
       "21   2822  [8915, 2, 4, 0.97]  [8915, 2, 6, 3.0]  pepsi_2822_QD   \n",
       "22   2822   [434, 2, 4, 0.73]  [434, 2, 6, 2.24]  pepsi_2822_QD   \n",
       "\n",
       "     Start Date/Time     End Date/Time  \n",
       "0   26/08/2025 12:07  31/08/2025 20:57  \n",
       "1   26/08/2025 12:07  31/08/2025 20:57  \n",
       "2   26/08/2025 12:07  31/08/2025 20:57  \n",
       "3   26/08/2025 12:07  31/08/2025 20:57  \n",
       "4   26/08/2025 12:07  31/08/2025 20:57  \n",
       "5   26/08/2025 12:07  31/08/2025 20:57  \n",
       "6   26/08/2025 12:07  31/08/2025 20:57  \n",
       "7   26/08/2025 12:07  31/08/2025 20:57  \n",
       "8   26/08/2025 12:07  31/08/2025 20:57  \n",
       "9   26/08/2025 12:07  31/08/2025 20:57  \n",
       "10  26/08/2025 12:07  31/08/2025 20:57  \n",
       "11  26/08/2025 12:07  31/08/2025 20:57  \n",
       "12  26/08/2025 12:07  31/08/2025 20:57  \n",
       "13  26/08/2025 12:07  31/08/2025 20:57  \n",
       "14  26/08/2025 12:07  31/08/2025 20:57  \n",
       "15  26/08/2025 12:07  31/08/2025 20:57  \n",
       "16  26/08/2025 12:07  31/08/2025 20:57  \n",
       "17  26/08/2025 12:07  31/08/2025 20:57  \n",
       "18  26/08/2025 12:07  31/08/2025 20:57  \n",
       "19  26/08/2025 12:07  31/08/2025 20:57  \n",
       "20  26/08/2025 12:07  31/08/2025 20:57  \n",
       "21  26/08/2025 12:07  31/08/2025 20:57  \n",
       "22  26/08/2025 12:07  31/08/2025 20:57  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pytz  # install with: pip install pytz\n",
    "\n",
    "# Replace 'Africa/Cairo' with your local timezone\n",
    "local_tz = pytz.timezone('Africa/Cairo')\n",
    "\n",
    "time_plus_10 = (datetime.now(local_tz) + timedelta(minutes=10)).strftime('%d/%m/%Y %H:%M')\n",
    "time_plus_1_week = (datetime.now(local_tz) + timedelta(days=5)+ timedelta(hours=9)).strftime('%d/%m/%Y %H:%M')\n",
    "\n",
    "final_quantity_discount['Start Date/Time']= time_plus_10\n",
    "final_quantity_discount['End Date/Time']= time_plus_1_week\n",
    "\n",
    "final_quantity_discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fce7239-99c4-4311-8093-b0ec0488ed85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data = final_quantity_discount.groupby(['Tag ID','Description', 'Start Date/Time', 'End Date/Time'], as_index=False).agg({\n",
    "    'Discounts Group 1': list ,\n",
    "    'Discounts Group 2' : list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c73bcca-21c6-4e76-ac9b-b77373f5f025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data.to_excel(\"Pepsi_QD.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc6638-7d56-4015-884a-e04163bd9962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
