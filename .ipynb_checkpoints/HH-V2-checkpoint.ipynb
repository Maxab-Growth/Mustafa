{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371c6017-a418-42a9-9fa7-1eef1ce8cfc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# Connectivity\n",
    "!pip install psycopg2-binary  # PostgreSQL adapter\n",
    "# !pip install snowflake-connector-python  # Snowflake connector\n",
    "!pip install snowflake-connector-python==3.15.0 # Snowflake connector Older Version\n",
    "!pip install snowflake-sqlalchemy  # Snowflake SQLAlchemy connector\n",
    "!pip install warnings # Warnings management\n",
    "# !pip install pyarrow # Serialization\n",
    "!pip install keyring==23.11.0 # Key management\n",
    "!pip install sqlalchemy==1.4.46 # SQLAlchemy\n",
    "!pip install requests # HTTP requests\n",
    "!pip install boto3 # AWS SDK\n",
    "# !pip install slackclient # Slack API\n",
    "!pip install oauth2client # Google Sheets API\n",
    "!pip install gspread==5.9.0 # Google Sheets API\n",
    "!pip install gspread_dataframe # Google Sheets API\n",
    "!pip install google.cloud # Google Cloud\n",
    "# Data manipulation and analysis\n",
    "!pip install polars\n",
    "!pip install pandas==2.2.1\n",
    "!pip install numpy\n",
    "# !pip install fastparquet\n",
    "!pip install openpyxl # Excel file handling\n",
    "!pip install xlsxwriter # Excel file handling\n",
    "# Linear programming\n",
    "!pip install pulp\n",
    "# Date and time handling\n",
    "!pip install --upgrade datetime\n",
    "!pip install python-time\n",
    "!pip install --upgrade pytz\n",
    "# Progress bar\n",
    "!pip install tqdm\n",
    "# Database data types\n",
    "!pip install db-dtypes\n",
    "# Geospatial data handling\n",
    "# !pip install geopandas\n",
    "# !pip install shapely\n",
    "# !pip install fiona\n",
    "# !pip install haversine\n",
    "# Plotting\n",
    "\n",
    "# Modeling\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn\n",
    "\n",
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007e8be5-f084-46b8-9ab9-e6dcec8662a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n",
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import setup_environment_2\n",
    "import importlib\n",
    "import import_ipynb\n",
    "import warnings\n",
    "import demand_sku_cntrb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(setup_environment_2)\n",
    "setup_environment_2.initialize_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "679f4f80-f08b-4d58-bd57-1766cb5ab876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb66a52-0c84-4afd-8b8a-5fb1fecc2ab4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "today = datetime.today()- timedelta(days=4)\n",
    "month_start = today.replace(day=1)\n",
    "first_part = (today - month_start).days\n",
    "\n",
    "last_day = calendar.monthrange(today.year, today.month)[1]\n",
    "second_part = (last_day - today.day)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95799e78-611c-4a58-873e-de86b15e2cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_snowflake(query, columns=[]):\n",
    "    import os\n",
    "    import snowflake.connector\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    con = snowflake.connector.connect(\n",
    "        user =  os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account= os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password= os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database =os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        if len(columns) == 0:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()))\n",
    "        else:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()),columns=columns)\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4995eba-902b-42d6-9f9b-59aab8007f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'America/Los_Angeles'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SHOW PARAMETERS LIKE 'TIMEZONE'\n",
    "'''\n",
    "x  = query_snowflake(query)\n",
    "zone_to_use = x[1].values[0]\n",
    "zone_to_use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f35f29-f58b-401a-a201-c3aa6fdc12c4",
   "metadata": {},
   "source": [
    "## Prodcut Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c3b4fe-f7f8-4e8c-8ecb-87cd3536059a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "command_string = f'''\n",
    "with last_update as (\n",
    "select  DATE_PART('hour', max_date) * 60 + DATE_PART('minute', max_date) AS total_minutes\n",
    "from (\n",
    "select max(created_at) as max_date from sales_orders\n",
    ")\n",
    "\n",
    "),\n",
    " predicted_rr  as (\n",
    "select product_id,warehouse_id,rr,date\n",
    "from Finance.PREDICTED_RUNNING_RATES\n",
    "where date >= CURRENT_DATE\n",
    "qualify date = max(date)over(partition by product_id,warehouse_id)\n",
    "),\n",
    "days_stocks as (\n",
    "select timestamp::date as date ,product_id,warehouse_id,avg(in_stock) as in_stock_perc,avg(case when date_part('hour',timestamp) =date_part('hour',current_timestamp)-1 then  in_stock end) as last_hour_stocks\n",
    "from (\n",
    "select timestamp,product_id,warehouse_id,case when AVAILABLE_STOCK > 0 then 1 else 0 end as in_stock\n",
    "from materialized_views.STOCK_SNAP_SHOTS_RECENT sss\n",
    "where sss.timestamp::date >= date_trunc('month',current_date - 60)\n",
    "and date_part('hour',sss.timestamp)<date_part('hour',CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())) \n",
    "and warehouse_id in (1,8,170,236,337,339,401,501,632,703,797,962)\n",
    ")\n",
    "group by all \n",
    "),\n",
    "base as (\n",
    "select *, row_number()over(partition by retailer_id order by priority) as rnk \n",
    "from (\n",
    "select x.*,TAGGABLE_ID as retailer_id \n",
    "from (\n",
    "select id as cohort_id,name as cohort_name,priority,dynamic_tag_id \n",
    "from cohorts \n",
    "where is_active = 'true'\n",
    "and id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    ") x \n",
    "join DYNAMIC_TAGgables dt on x.dynamic_tag_id = dt.dynamic_tag_id\n",
    ")\n",
    "qualify rnk = 1 \n",
    "),\n",
    "sales_data as (\n",
    "SELECT  DISTINCT\n",
    "\t\tso.created_at::date as date,\n",
    "\t\tpso.warehouse_id as warehouse_id,\n",
    "\t\tpso.product_id,\n",
    "\t\tCONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\n",
    "        sum(pso.total_price) as all_day_nmv,\n",
    "\t\tsum(case when (date_part('hour',so.created_at)*60 + DATE_PART('minute', so.created_at))< (select * from last_update) then pso.total_price end) as uth_nmv,\n",
    "\t\tsum(case when (date_part('hour',so.created_at)*60 + DATE_PART('minute', so.created_at))\n",
    "\t\tbetween (select * from last_update) -60 \n",
    "\t\tand (select * from last_update)\n",
    "\t\tthen pso.total_price end) as last_hour_nmv,\n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN finance.all_cogs f  ON f.product_id = pso.product_id\n",
    "                        AND f.from_date::date <= so.created_at ::date\n",
    "                        AND f.to_date::date > so.created_at ::date\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "JOIN cities on cities.id=districts.city_id\n",
    "join states on states.id=cities.state_id\n",
    "join regions on regions.id=states.region_id  \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at ::date >= date_trunc('month',current_date - 60)\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\n",
    "GROUP BY ALL\n",
    "order by date desc\n",
    "),\n",
    "data as (\n",
    "select * , 1/nullif((0.3*week_distance+0.1*month_distance+0.6*day_distance),0) as distance\n",
    "from (\n",
    "select * ,\n",
    "floor((DATE_PART('day', date) - 1) / 7 + 1) AS week_of_month,\n",
    "DATE_PART('month', date) as month,\n",
    "DATE_PART('DOW', date) AS day_number,\n",
    "\n",
    "abs(floor((DATE_PART('day', current_date) - 1) / 7 + 1) - week_of_month)  as week_distance ,\n",
    "abs(DATE_PART('month', current_date)- month) as month_distance,\n",
    "abs(DATE_PART('DOW', current_date)- day_number) as day_distance\n",
    "from (\n",
    "select *, max(case when date = CURRENT_DATE then last_hour_stocks end) over(partition by product_id,warehouse_id) as current_stocks \n",
    "from (\n",
    "select ds.*, all_day_nmv,\n",
    "uth_nmv,\n",
    "last_hour_nmv\n",
    "from days_stocks ds\n",
    "left join sales_data sd  on ds.product_id = sd.product_id and ds.warehouse_id = sd.warehouse_id and ds.date= sd.date\n",
    ")\n",
    ")\n",
    "where current_stocks <> 0 \n",
    "and (in_stock_perc = 1 or date = CURRENT_DATE)\n",
    ")\n",
    "),\n",
    "current_state as (\n",
    "select product_id,warehouse_id,AVAILABLE_STOCK,activation\n",
    "from PRODUCT_WAREHOUSE\n",
    "where IS_BASIC_UNIT = 1\n",
    ")\n",
    "select x.*,\n",
    "cs.AVAILABLE_STOCK,\n",
    "cs.activation,\n",
    "coalesce(prr.rr,0) as rr,\n",
    "case when coalesce(prr.rr,0) <>0 then cs.AVAILABLE_STOCK/coalesce(prr.rr,0) else cs.AVAILABLE_STOCK end  as doh ,\n",
    "cs.AVAILABLE_STOCK*f.wac1  as stock_value\n",
    " from (\n",
    "select product_id,warehouse_id,\n",
    "coalesce(max(case when state = 'prev' then all_day_nmv end),0) as prev_all_day,\n",
    "coalesce(max(case when state = 'prev' then uth_nmv end),0)  as prev_uth,\n",
    "coalesce(max(case when state = 'prev' then last_hour_nmv end),0)  as prev_last_hour,\n",
    "\n",
    "coalesce(max(case when state = 'current' then all_day_nmv end),0)  as current_all_day,\n",
    "coalesce(max(case when state = 'current' then uth_nmv end),0)  as current_uth,\n",
    "coalesce(max(case when state = 'current' then last_hour_nmv end),0)  as current_last_hour\n",
    "\n",
    "from (\n",
    "select 'current' as state,product_id,warehouse_id,all_day_nmv,uth_nmv,last_hour_nmv\n",
    "from data\n",
    "where date = CURRENT_DATE\n",
    "union all \n",
    "(\n",
    "select state,product_id,warehouse_id,\n",
    "sum(all_day_nmv*distance)/sum(distance) as all_day_nmv,\n",
    "sum(uth_nmv*distance)/sum(distance) as uth_nmv,\n",
    "sum(last_hour_nmv*distance)/sum(distance) as last_hour_nmv\n",
    "from(\n",
    "select 'prev' as state,product_id,warehouse_id,all_day_nmv,uth_nmv,last_hour_nmv,distance\n",
    "from data \n",
    "where date <> CURRENT_DATE\n",
    ")\n",
    "group by all \n",
    ")\n",
    ")\n",
    "group by all \n",
    ")x \n",
    "join current_state cs on x.product_id = cs.product_id and x.warehouse_id = cs.warehouse_id\n",
    "left join predicted_rr prr on x.product_id = prr.product_id and x.warehouse_id = prr.warehouse_id \n",
    "join products p on p.id = x.product_id\n",
    "join finance.all_cogs f on f.product_id = x.product_id and CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp()) between f.from_date and f.to_date \n",
    "where doh > 1 \n",
    "and p.activation ='true'\n",
    "and cs.activation = 'true'\n",
    "and cs.AVAILABLE_STOCK * f.wac1 >= 1000\n",
    "and prev_uth > 0\n",
    "'''\n",
    "product_data = query_snowflake(command_string, columns = ['product_id','warehouse_id','prev_all_day','prev_uth','prev_last_hour','current_all_day','current_uth','current_last_hour','available_stock','activation','rr','doh','stock_value'])\n",
    "product_data.product_id = pd.to_numeric(product_data.product_id)\n",
    "product_data.warehouse_id = pd.to_numeric(product_data.warehouse_id)\n",
    "product_data.prev_all_day = pd.to_numeric(product_data.prev_all_day)\n",
    "product_data.prev_uth = pd.to_numeric(product_data.prev_uth)\n",
    "product_data.prev_last_hour = pd.to_numeric(product_data.prev_last_hour)\n",
    "product_data.current_all_day = pd.to_numeric(product_data.current_all_day)\n",
    "product_data.current_uth = pd.to_numeric(product_data.current_uth)\n",
    "product_data.current_last_hour = pd.to_numeric(product_data.current_last_hour)\n",
    "product_data.available_stock = pd.to_numeric(product_data.available_stock)\n",
    "product_data.rr = pd.to_numeric(product_data.rr)\n",
    "product_data.doh = pd.to_numeric(product_data.doh)\n",
    "product_data.stock_value = pd.to_numeric(product_data.stock_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89169236-0e28-4be4-8800-96377ec58584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "with last_update as (\n",
    "select  DATE_PART('hour', max_date) * 60 + DATE_PART('minute', max_date) AS total_minutes\n",
    "from (\n",
    "select max(created_at) as max_date from sales_orders\n",
    ")\n",
    "),\n",
    "base as (\n",
    "select *, row_number()over(partition by retailer_id order by priority) as rnk \n",
    "from (\n",
    "select x.*,TAGGABLE_ID as retailer_id \n",
    "from (\n",
    "select id as cohort_id,name as cohort_name,priority,dynamic_tag_id \n",
    "from cohorts \n",
    "where is_active = 'true'\n",
    "and id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    ") x \n",
    "join DYNAMIC_TAGgables dt on x.dynamic_tag_id = dt.dynamic_tag_id\n",
    ")\n",
    "qualify rnk = 1 \n",
    "),\n",
    "sales as (\n",
    "SELECT \n",
    "\t\tso.created_at::date as date,\n",
    "\t\tpso.warehouse_id as warehouse_id,\n",
    "        sum(pso.total_price) as all_day_nmv,\n",
    "\t\tsum(case when (date_part('hour',so.created_at)*60 + DATE_PART('minute', so.created_at))< (select * from last_update) then pso.total_price end) as uth_nmv,\n",
    "\t\tsum(case when (date_part('hour',so.created_at)*60 + DATE_PART('minute', so.created_at))\n",
    "\t\tbetween (select * from last_update) -60 \n",
    "\t\tand (select * from last_update)\n",
    "\t\tthen pso.total_price end) as last_hour_nmv,\n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN finance.all_cogs f  ON f.product_id = pso.product_id\n",
    "                        AND f.from_date::date <= so.created_at ::date\n",
    "                        AND f.to_date::date > so.created_at ::date\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "JOIN cities on cities.id=districts.city_id\n",
    "join states on states.id=cities.state_id\n",
    "join regions on regions.id=states.region_id  \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at ::date between date_trunc('month',current_date - 60) and current_date -1 \n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\n",
    "GROUP BY ALL\n",
    "order by date desc\n",
    ")\n",
    "select warehouse_id,sum(uth_cntrb*distance)/sum(distance) as uth_cntrb\n",
    "from (\n",
    "select *, 1/nullif((0.3*week_distance+0.1*month_distance+0.6*day_distance),0) as distance\n",
    "from(\n",
    "select * ,uth_nmv/all_day_nmv as uth_cntrb,\n",
    "floor((DATE_PART('day', date) - 1) / 7 + 1) AS week_of_month,\n",
    "DATE_PART('month', date) as month,\n",
    "DATE_PART('DOW', date) AS day_number,\n",
    "abs(floor((DATE_PART('day', current_date) - 1) / 7 + 1) - week_of_month)  as week_distance ,\n",
    "abs(DATE_PART('month', current_date)- month) as month_distance,\n",
    "abs(DATE_PART('DOW', current_date)- day_number) as day_distance\n",
    "\n",
    "from sales \n",
    ")\n",
    ")\n",
    "group by all \n",
    "'''\n",
    "uth_cntrb = query_snowflake(query, columns = ['warehouse_id','uth_cntrb'])\n",
    "uth_cntrb.warehouse_id = pd.to_numeric(uth_cntrb.warehouse_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17bfde16-bbc0-4c0d-9c6c-2569a5dddf3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "WITH whs as (SELECT *\n",
    "             FROM   (values\n",
    "                            ('Cairo', 'El-Marg', 38,700),\n",
    "                            ('Cairo', 'Mostorod', 1,700),\n",
    "                            ('Giza', 'Barageel', 236,701),\n",
    "                            ('Delta West', 'El-Mahala', 337,703),\n",
    "                            ('Delta West', 'Tanta', 8,703),\n",
    "                            ('Delta East', 'Mansoura FC', 339,704),\n",
    "                            ('Delta East', 'Sharqya', 170,704),\n",
    "                            ('Upper Egypt', 'Assiut FC', 501,1124),\n",
    "                            ('Upper Egypt', 'Bani sweif', 401,1126),\n",
    "                            ('Upper Egypt', 'Menya Samalot', 703,1123),\n",
    "                            ('Upper Egypt', 'Sohag', 632,1125),\n",
    "                            ('Alexandria', 'Khorshed Alex', 797,702),\n",
    "\t\t\t\t\t\t\t('Giza', 'Sakkarah', 962,701)\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t)\n",
    "                    x(region, wh, warehouse_id,cohort_id)),\n",
    "\n",
    "\n",
    "local_prices as (\n",
    "SELECT  case when cpu.cohort_id in (700,695) then 'Cairo'\n",
    "             when cpu.cohort_id in (701) then 'Giza'\n",
    "             when cpu.cohort_id in (704,698) then 'Delta East'\n",
    "             when cpu.cohort_id in (703,697) then 'Delta West'\n",
    "             when cpu.cohort_id in (696,1123,1124,1125,1126) then 'Upper Egypt'\n",
    "             when cpu.cohort_id in (702,699) then 'Alexandria'\n",
    "        end as region,\n",
    "\t\tcohort_id,\n",
    "        pu.product_id,\n",
    "\t\tpu.packing_unit_id as packing_unit_id,\n",
    "\t\tpu.basic_unit_count,\n",
    "        avg(cpu.price) as price\n",
    "FROM    cohort_product_packing_units cpu\n",
    "join    PACKING_UNIT_PRODUCTS pu on pu.id = cpu.product_packing_unit_id\n",
    "WHERE   cpu.cohort_id in (700,701,702,703,704,696,695,698,697,699,1123,1124,1125,1126)\n",
    "    and cpu.created_at::date<>'2023-07-31'\n",
    "    and cpu.is_customized = true\n",
    "\tgroup by all \n",
    "),\n",
    "live_prices as (\n",
    "select region,cohort_id,product_id,pu_id as packing_unit_id,buc as basic_unit_count,NEW_PRICE as price\n",
    "from materialized_views.DBDP_PRICES\n",
    "where created_at = current_date\n",
    "and DATE_PART('hour',CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())) BETWEEN SPLIT_PART(time_slot, '-', 1)::int AND SPLIT_PART(time_slot, '-', 2)::int\n",
    "and cohort_id in (700,701,702,703,704,696,695,698,697,699,1123,1124,1125,1126)\n",
    "),\n",
    "prices as (\n",
    "select *\n",
    "from (\n",
    "    SELECT *, 1 AS priority FROM live_prices\n",
    "    UNION ALL\n",
    "    SELECT *, 2 AS priority FROM local_prices\n",
    ")\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY region,cohort_id,product_id,packing_unit_id ORDER BY priority) = 1\n",
    ")\n",
    "select warehouse_id,product_id,price \n",
    "from prices \n",
    "join whs on prices.cohort_id = whs.cohort_id\n",
    "and basic_unit_count = 1 \n",
    "'''\n",
    "product_warehouse_price = query_snowflake(query, columns = ['warehouse_id','product_id','price'])\n",
    "product_warehouse_price.warehouse_id = pd.to_numeric(product_warehouse_price.warehouse_id)\n",
    "product_warehouse_price.product_id = pd.to_numeric(product_warehouse_price.product_id)\n",
    "product_warehouse_price.price = pd.to_numeric(product_warehouse_price.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f15810cc-6e26-4f5a-93a8-3f60efb52644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "WITH whs as (SELECT *\n",
    "             FROM   (values\n",
    "                            ('Cairo', 'El-Marg', 38,700),\n",
    "                            ('Cairo', 'Mostorod', 1,700),\n",
    "                            ('Giza', 'Barageel', 236,701),\n",
    "                            ('Delta West', 'El-Mahala', 337,703),\n",
    "                            ('Delta West', 'Tanta', 8,703),\n",
    "                            ('Delta East', 'Mansoura FC', 339,704),\n",
    "                            ('Delta East', 'Sharqya', 170,704),\n",
    "                            ('Upper Egypt', 'Assiut FC', 501,1124),\n",
    "                            ('Upper Egypt', 'Bani sweif', 401,1126),\n",
    "                            ('Upper Egypt', 'Menya Samalot', 703,1123),\n",
    "                            ('Upper Egypt', 'Sohag', 632,1125),\n",
    "                            ('Alexandria', 'Khorshed Alex', 797,702),\n",
    "\t\t\t\t\t\t\t('Giza', 'Sakkarah', 962,701)\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t)\n",
    "                    x(region, wh, warehouse_id,cohort_id)),\n",
    "full_data as (\n",
    "select products.id as product_id, region,warehouse_id\n",
    "from products , whs \n",
    "where activation = 'true'\n",
    "),\t\t\t\t\n",
    "\n",
    "MP as (\n",
    "select region,product_id,\n",
    "min(min_price) as min_price,\n",
    "min(max_price) as max_price,\n",
    "min(mod_price) as mod_price,\n",
    "min(true_min) as true_min,\n",
    "min(true_max) as true_max\n",
    "\n",
    "from (\n",
    "select mp.region,mp.product_id,mp.pu_id,\n",
    "min_price/BASIC_UNIT_COUNT as min_price,\n",
    "max_price/BASIC_UNIT_COUNT as max_price,\n",
    "mod_price/BASIC_UNIT_COUNT as mod_price,\n",
    "TRUE_MIN_PRICE/BASIC_UNIT_COUNT as true_min,\n",
    "TRUE_MAX_PRICE/BASIC_UNIT_COUNT as true_max\n",
    "from materialized_views.marketplace_prices mp \n",
    "join packing_unit_products pup on pup.product_id = mp.product_id and pup.packing_unit_id = mp.pu_id\n",
    ")\n",
    "group by all \n",
    "),\n",
    "region_mapping AS (\n",
    "    SELECT * \n",
    "\tFROM \n",
    "\t(\tVALUES\n",
    "        ('Delta East', 'Delta West'),\n",
    "        ('Delta West', 'Delta East'),\n",
    "        ('Alexandria', 'Cairo'),\n",
    "        ('Alexandria', 'Giza'),\n",
    "        ('Upper Egypt', 'Cairo'),\n",
    "        ('Upper Egypt', 'Giza'),\n",
    "\t\t('Cairo','Giza'),\n",
    "\t\t('Giza','Cairo'),\n",
    "\t\t('Delta West', 'Cairo'),\n",
    "\t\t('Delta East', 'Cairo'),\n",
    "\t\t('Delta West', 'Giza'),\n",
    "\t\t('Delta East', 'Giza')\n",
    "\t\t)\n",
    "    AS region_mapping(region, fallback_region)\n",
    ")\n",
    "\n",
    "\n",
    "select region,warehouse_id,product_id,\n",
    "min(final_min_price) as final_min_price,\n",
    "min(final_max_price) as final_max_price,\n",
    "min(final_mod_price) as final_mod_price,\n",
    "min(final_true_min) as final_true_min,\n",
    "min(final_true_max) as final_true_max\n",
    "\n",
    "from (\n",
    "SELECT\n",
    "distinct \n",
    "\tw.region,\n",
    "    w.warehouse_id,\n",
    "\tw.product_id,\n",
    "    COALESCE(m1.min_price, m2.min_price) AS final_min_price,\n",
    "    COALESCE(m1.max_price, m2.max_price) AS final_max_price,\n",
    "    COALESCE(m1.mod_price, m2.mod_price) AS final_mod_price,\n",
    "\tCOALESCE(m1.true_min, m2.true_min) AS final_true_min,\n",
    "\tCOALESCE(m1.true_max, m2.true_max) AS final_true_max,\n",
    "FROM full_data w\n",
    "LEFT JOIN MP m1\n",
    "    ON w.region = m1.region and w.product_id = m1.product_id\n",
    "JOIN region_mapping rm\n",
    "    ON w.region = rm.region\n",
    "LEFT JOIN MP m2\n",
    "    ON rm.fallback_region = m2.region\n",
    "   AND w.product_id = m2.product_id\n",
    ")\n",
    "where final_min_price is not null \n",
    "group by all \n",
    "'''\n",
    "marketplace = query_snowflake(query, columns = ['REGION','WAREHOUSE_ID','PRODUCT_ID','FINAL_MIN_PRICE','FINAL_MAX_PRICE','FINAL_MOD_PRICE','FINAL_TRUE_MIN','FINAL_TRUE_MAX'])\n",
    "marketplace.columns = marketplace.columns.str.lower()\n",
    "for col in marketplace.columns:\n",
    "    marketplace[col] = pd.to_numeric(marketplace[col], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de23bc1f-2b20-4b28-9132-a9fa6a125f93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select product_id,min(ben_soliman_basic_price) as ben_soliman_price\n",
    "from (\n",
    "select MAXAB_PRODUCT_ID as product_id,\n",
    "MAXAB_BASIC_UNIT_COUNT as buc,\n",
    "FINAL_PRICE_AFTER_CONVERSION as ben_soliman_price,\n",
    "ben_soliman_price/buc as ben_soliman_basic_price,\n",
    "max(INJECTION_DATE) OVER(PARTITION by product_id) as max_date\n",
    "from materialized_views.savvy_mapping\n",
    "where FINAL_PRICE_AFTER_CONVERSION is not null \n",
    "QUALIFY INJECTION_DATE = max_date\n",
    ")\n",
    "group by all \n",
    "'''\n",
    "\n",
    "bensoliman = query_snowflake(query, columns = ['product_id','ben_soliman_basic_price'])\n",
    "bensoliman.columns = bensoliman.columns.str.lower()\n",
    "for col in bensoliman.columns:\n",
    "    bensoliman[col] = pd.to_numeric(bensoliman[col], errors='ignore')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbba3668-3267-4142-a7c2-3666cef3226d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select region,product_id,optimal_bm,MIN_BOUNDARY,MAX_BOUNDARY,MEDIAN_BM\n",
    "from (\n",
    "select region,product_id,target_bm,optimal_bm,MIN_BOUNDARY,MAX_BOUNDARY,MEDIAN_BM,max(created_at) over(partition by product_id,region) as max_date,created_at\n",
    "from materialized_views.PRODUCT_STATISTICS\n",
    "where created_at::date >= date_trunc('month',current_date - 60)\n",
    "qualify max_date = created_at\n",
    ")\n",
    "\n",
    "'''\n",
    " \n",
    "stats = query_snowflake(query, columns = ['region','product_id','optimal_bm','MIN_BOUNDARY','MAX_BOUNDARY','MEDIAN_BM'])\n",
    "stats.columns = stats.columns.str.lower()\n",
    "for col in stats.columns:\n",
    "    stats[col] = pd.to_numeric(stats[col], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1329532-37a0-47a8-8835-813a3c9cfadf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select warehouse_id,region\n",
    "from (\n",
    "select * ,row_number()over(partition by warehouse_id order by nmv desc) as rnk \n",
    "from (\n",
    "SELECT case when regions.id = 2 then cities.name_en else regions.name_en end as region,\n",
    "\t   pso.warehouse_id,\n",
    "        sum(pso.total_price) as nmv\n",
    "\n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "JOIN cities on cities.id=districts.city_id\n",
    "join states on states.id=cities.state_id\n",
    "join regions on regions.id=states.region_id             \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at ::date between current_date-31 and CURRENT_DATE-1\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\n",
    "GROUP BY ALL\n",
    ")\n",
    "qualify rnk = 1 \n",
    ")\n",
    "'''\n",
    "warehouse_region = query_snowflake(query, columns = ['warehouse_id','region'])\n",
    "warehouse_region.columns = warehouse_region.columns.str.lower()\n",
    "for col in warehouse_region.columns:\n",
    "    warehouse_region[col] = pd.to_numeric(warehouse_region[col], errors='ignore')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e94e1fbe-ccb3-45b8-9f1e-dde8ba79d5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "SELECT DISTINCT cat, brand, margin as target_bm\n",
    "FROM    performance.commercial_targets cplan\n",
    "QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE)OVER()) = DATE_TRUNC('month', CURRENT_DATE) THEN DATE_TRUNC('month', CURRENT_DATE)\n",
    "ELSE DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    "'''\n",
    "brand_cat_target  = query_snowflake(query, columns = ['cat','brand','target_bm'])\n",
    "brand_cat_target.target_bm=pd.to_numeric(brand_cat_target.target_bm)\n",
    "\n",
    "query = f'''\n",
    "select cat,sum(target_bm *(target_nmv/cat_total)) as cat_target_margin\n",
    "from (\n",
    "select *,sum(target_nmv)over(partition by cat) as cat_total\n",
    "from (\n",
    "select cat,brand,avg(target_bm) as target_bm , sum(target_nmv) as target_nmv\n",
    "from (\n",
    "SELECT DISTINCT date,city as region,cat, brand, margin as target_bm,nmv as target_nmv\n",
    "FROM    performance.commercial_targets cplan\n",
    "QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE)OVER()) = DATE_TRUNC('month', CURRENT_DATE) THEN DATE_TRUNC('month', CURRENT_DATE)\n",
    "ELSE DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    ")\n",
    "group by all\n",
    ")\n",
    ")\n",
    "group by all \n",
    "'''\n",
    "cat_target  = query_snowflake(query, columns = ['cat','cat_target_margin'])\n",
    "cat_target.cat_target_margin=pd.to_numeric(cat_target.cat_target_margin)\n",
    "\n",
    "query = f'''\n",
    "SELECT  DIStinct  \n",
    "\t\tproducts.id as product_id,\n",
    "\t\tCONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\n",
    "\t\tf.wac_p\n",
    "from products \n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN finance.all_cogs f  ON f.product_id = products.id and CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp()) between f.from_date and f.to_date \n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "'''\n",
    "sku_info  = query_snowflake(query, columns = ['product_id','sku','brand','cat','wac_p'])\n",
    "sku_info.product_id=pd.to_numeric(sku_info.product_id)\n",
    "sku_info.wac_p=pd.to_numeric(sku_info.wac_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15eee617-c545-4efa-be16-da395b05d27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "with last_update as (\n",
    "select  DATE_PART('hour', max_date) * 60 + DATE_PART('minute', max_date) AS total_minutes\n",
    "from (\n",
    "select max(created_at) as max_date from sales_orders\n",
    ")\n",
    ")\n",
    "SELECT  DISTINCT\n",
    "\t\tpso.warehouse_id,\n",
    "\t\tpso.product_id,\n",
    "\t\tcoalesce(sum(case when DATE_PART('hour', so.created_at) * 60 + DATE_PART('minute', so.created_at)  between  (DATE_PART('hour', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())) * 60 + DATE_PART('minute', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())))-120 and (DATE_PART('hour', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())) * 60 + DATE_PART('minute', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())))-60 then pso.total_price end),0) as t_2_nmv,\n",
    "\t\tcoalesce(sum(case when DATE_PART('hour', so.created_at) * 60 + DATE_PART('minute', so.created_at)  >  (DATE_PART('hour', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())) * 60 + DATE_PART('minute', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())))-60 then pso.total_price end),0) as t_1_nmv,\n",
    "\t\tcoalesce(avg(case when (DATE_PART('hour', so.created_at) * 60 + DATE_PART('minute', so.created_at)  between  (DATE_PART('hour', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())) * 60 + DATE_PART('minute', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())))-120 and (DATE_PART('hour', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())) * 60 + DATE_PART('minute', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())))-60) and (item_discount_value <> 0) then (pso.item_price/basic_unit_count) - (pso.item_discount_value/basic_unit_count) end),0) as t_2_price,\n",
    "\t\tcoalesce(avg(case when (DATE_PART('hour', so.created_at) * 60 + DATE_PART('minute', so.created_at)  >  (DATE_PART('hour', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())) * 60 + DATE_PART('minute', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())))-60) and (item_discount_value <> 0) then  (pso.item_price/basic_unit_count) - (pso.item_discount_value/basic_unit_count) end),0) as t_1_price\n",
    "\n",
    "\n",
    "\n",
    "FROM product_sales_order pso \n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id          \n",
    "\n",
    "WHERE so.created_at::date = current_date \n",
    "and DATE_PART('hour', so.created_at) * 60 + DATE_PART('minute', so.created_at)  >=  (DATE_PART('hour', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())) * 60 + DATE_PART('minute', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())))-120\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "GROUP BY ALL\n",
    "'''\n",
    "last_two_hours =  query_snowflake(query, columns = ['warehouse_id','product_id','t_2_nmv','t_1_nmv','t_2_price','t_1_price'])\n",
    "last_two_hours.columns = last_two_hours.columns.str.lower()\n",
    "for col in last_two_hours.columns:\n",
    "    last_two_hours[col] = pd.to_numeric(last_two_hours[col], errors='ignore')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e9d8f4d-8ec6-4fb3-bd10-8f52c50993be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_data = product_data.merge(product_warehouse_price,on=['product_id','warehouse_id'])\n",
    "product_data = product_data.merge(uth_cntrb[['warehouse_id','uth_cntrb']],on='warehouse_id')\n",
    "product_data['product_UTH_growth'] =(product_data['current_uth'] -product_data['prev_uth'])/product_data['prev_uth']\n",
    "product_data['product_LH_growth'] =(product_data['current_last_hour'] -product_data['prev_last_hour'])/product_data['prev_last_hour']\n",
    "product_data[['product_UTH_growth','product_LH_growth']] =product_data[['product_UTH_growth','product_LH_growth']].fillna(0) \n",
    "product_data = product_data.replace([np.inf, -np.inf], 1)\n",
    "product_data['product_closing_growth'] = (product_data['product_UTH_growth']*product_data['uth_cntrb'])+(product_data['product_LH_growth']*(1-product_data['uth_cntrb']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20e2675c-61d8-4c74-9b8d-3d6508a061c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "warehouse_data = product_data.groupby('warehouse_id')[['prev_all_day', 'prev_uth','prev_last_hour', 'current_all_day', 'current_uth', 'current_last_hour']].sum().reset_index()\n",
    "warehouse_data['UTH_growth'] =(warehouse_data['current_uth'] -warehouse_data['prev_uth'])/warehouse_data['prev_uth']\n",
    "warehouse_data['LH_growth'] =(warehouse_data['current_last_hour'] -warehouse_data['prev_last_hour'])/warehouse_data['prev_last_hour']\n",
    "warehouse_data = warehouse_data.merge(uth_cntrb,on='warehouse_id')\n",
    "warehouse_data['Closing_growth'] = (warehouse_data['UTH_growth']*warehouse_data['uth_cntrb'])+(warehouse_data['LH_growth']*(1-warehouse_data['uth_cntrb']))\n",
    "dropping_whs = warehouse_data[warehouse_data['Closing_growth']<0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fb16c40-bee2-4050-b08d-da0069012b33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "growing_products  = product_data.merge(warehouse_data[['warehouse_id','UTH_growth','LH_growth','Closing_growth']],on='warehouse_id')\n",
    "#needs edit\n",
    "growing_products = growing_products[growing_products['product_closing_growth']>=np.maximum(growing_products['Closing_growth'],0.1)]\n",
    "growing_products['max_closing'] = growing_products.groupby('product_id')['product_closing_growth'].transform(sum)\n",
    "growing_products=growing_products[growing_products['max_closing']==growing_products['product_closing_growth']]\n",
    "growing_products = growing_products.groupby(['product_id'])['price'].mean().reset_index()\n",
    "growing_products.columns = ['product_id','maxab_good_price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea0f1062-ebf9-4006-b727-671c546ab895",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropping_products = product_data.merge(dropping_whs[['warehouse_id','UTH_growth','LH_growth','Closing_growth']],on='warehouse_id')\n",
    "dropping_products = dropping_products[dropping_products['product_closing_growth'] < 0]\n",
    "dropping_products = dropping_products.sort_values(by='prev_all_day',ascending = False)\n",
    "\n",
    "dropping_products = dropping_products.merge(growing_products,on='product_id',how='left')\n",
    "dropping_products = dropping_products.merge(marketplace,on=['product_id','warehouse_id'],how='left')\n",
    "dropping_products = dropping_products.merge(bensoliman[['product_id','ben_soliman_basic_price']],on=['product_id'],how='left')\n",
    "dropping_products = dropping_products.drop(columns = 'region')\n",
    "dropping_products = dropping_products.merge(warehouse_region,on=['warehouse_id'])\n",
    "dropping_products = dropping_products.merge(stats,on=['product_id','region'],how='left')\n",
    "dropping_products = dropping_products.merge(sku_info,on=['product_id'])\n",
    "dropping_products = dropping_products.merge(brand_cat_target,on=['brand','cat'],how='left')\n",
    "dropping_products = dropping_products.merge(cat_target,on=['cat'],how='left')\n",
    "dropping_products['Target_margin'] = dropping_products['target_bm'].fillna(dropping_products['cat_target_margin'])\n",
    "dropping_products = dropping_products[[ 'warehouse_id','product_id','sku','brand','cat', 'prev_all_day', 'prev_uth',\n",
    "       'prev_last_hour', 'current_all_day', 'current_uth', 'current_last_hour','product_UTH_growth', 'product_LH_growth',\n",
    "       'product_closing_growth','doh','wac_p','price','maxab_good_price', 'final_min_price', 'final_max_price',\n",
    "       'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "       'ben_soliman_basic_price','optimal_bm', 'min_boundary',\n",
    "       'max_boundary', 'median_bm','Target_margin']]\n",
    "dropping_products = dropping_products.merge(last_two_hours,on=['product_id','warehouse_id'],how='left')\n",
    "dropping_products[['t_2_nmv','t_1_nmv','t_2_price','t_1_price']] = dropping_products[['t_2_nmv','t_1_nmv','t_2_price','t_1_price']].fillna(0)\n",
    "dropping_products=dropping_products.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39e7ab85-01f8-447a-b214-28dca3e83b3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_price(product_UTH_growth,product_LH_growth,product_closing_growth,remaining_prices,price,wac,Target_margin,min_boundary,optimal_bm,t_1_price):\n",
    "    target_price = 0 \n",
    "    min_price = 0\n",
    "    max_price = 0 \n",
    "    acceptable = []\n",
    "    source = ''\n",
    "    for i in range(len(remaining_prices)-1,-1,-1):\n",
    "        new_price = remaining_prices[i]\n",
    "        diff = (new_price-price)/price\n",
    "        current_margin = (price-wac)/price\n",
    "        new_margin = (new_price-wac)/new_price\n",
    "        if new_margin >= min_boundary and new_margin >= 0.25*Target_margin and new_margin >0  and diff <= -0.0025:\n",
    "            target_price = new_price\n",
    "            source = 'Listed'\n",
    "            break\n",
    "    if target_price == 0:\n",
    "        \n",
    "        for j in range(0,len(remaining_prices)):\n",
    "            new_price = remaining_prices[j]\n",
    "            diff = (new_price-price)/price\n",
    "            current_margin = (price-wac)/price\n",
    "            new_margin = (new_price-wac)/new_price\n",
    "            if new_margin >0 :\n",
    "                acceptable.append(new_price)\n",
    "        if(len(acceptable) > 1):\n",
    "            distance_arr = []\n",
    "            for k in range(0,len(acceptable)):\n",
    "                new_price = acceptable[k]\n",
    "                diff = 1/abs(price-new_price)\n",
    "                distance_arr.append(diff)\n",
    "            \n",
    "            total_array = sum(distance_arr)\n",
    "            normalized = [x / total_array for x in distance_arr]\n",
    "            final_value = 0 \n",
    "            for v in range(0,len(normalized)):\n",
    "                w = normalized[v]\n",
    "                p = acceptable[v]\n",
    "                final_value+= (w*p)\n",
    "            target_price = np.maximum(final_value,wac/(1-(0.3*Target_margin)))\n",
    "            source = 'induced'\n",
    "            \n",
    "        elif (len(acceptable) > 0):\n",
    "            new_price = acceptable[0]\n",
    "            final_value = (0.3*new_price)+(0.7*price)\n",
    "            target_price = np.maximum(final_value,wac/(1-(0.3*Target_margin)))\n",
    "            source = 'induced'\n",
    "                \n",
    "              \n",
    "               \n",
    "    return target_price,source    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa9eeee1-ea7f-429b-8156-8a68a4924ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_final_df = pd.DataFrame(columns = ['warehouse_id', 'product_id', 'sku', 'brand', 'cat', 'prev_all_day',\n",
    "       'prev_uth', 'prev_last_hour', 'current_all_day', 'current_uth',\n",
    "       'current_last_hour', 'product_UTH_growth', 'product_LH_growth',\n",
    "       'product_closing_growth', 'doh', 'wac_p', 'price', 'maxab_good_price',\n",
    "       'final_min_price', 'final_max_price', 'final_mod_price',\n",
    "       'final_true_min', 'final_true_max', 'ben_soliman_basic_price',\n",
    "       'optimal_bm', 'min_boundary', 'max_boundary', 'median_bm',\n",
    "       'Target_margin', 't_2_nmv', 't_1_nmv', 't_2_price', 't_1_price','selected_price','source'])\n",
    "\n",
    "for _,row in dropping_products.iterrows():\n",
    "    wac = row['wac_p']\n",
    "    price = row['price']\n",
    "    maxab_good_price = row['maxab_good_price']\n",
    "    final_min_price = row['final_min_price']\n",
    "    final_max_price = row['final_max_price']\n",
    "    final_mod_price = row['final_mod_price']\n",
    "    final_true_min = row['final_true_min']\n",
    "    final_true_max = row['final_true_max']\n",
    "    ben_soliman_basic_price= row['ben_soliman_basic_price']\n",
    "    optimal_price = wac/(1-row['optimal_bm'])\n",
    "    min_b_price = wac/(1-row['min_boundary'])\n",
    "    max_b_price = wac/(1-row['max_boundary'])\n",
    "    median_price = wac/(1-row['median_bm'])\n",
    "    target_price = wac/(1-row['Target_margin'])\n",
    "    product_UTH_growth = row['product_UTH_growth']\n",
    "    product_LH_growth = row['product_LH_growth']\n",
    "    product_closing_growth=row['product_closing_growth']\n",
    "    t_1_price = row['t_1_price']\n",
    "    prices_list = [maxab_good_price,final_min_price,final_max_price,final_mod_price,final_true_min,final_true_max,ben_soliman_basic_price,optimal_price,min_b_price,max_b_price,median_price,target_price]\n",
    "    cleaned_prices = list({x for x in prices_list if x not in [0, np.nan] and not pd.isna(x)})\n",
    "    if t_1_price>0 and product_UTH_growth<product_LH_growth and product_LH_growth > 0:\n",
    "        row['selected_price'] = t_1_price\n",
    "        row['source'] == 'Prev_disc'\n",
    "    else:\n",
    "        remaining_prices = [x for x in cleaned_prices if (x < price) or (t_1_price > 0 and x <= t_1_price)]\n",
    "        remaining_prices.sort()\n",
    "        new_price,source = select_price(product_UTH_growth,product_LH_growth,product_closing_growth,remaining_prices,price,wac,row['Target_margin'],row['min_boundary'],row['optimal_bm'],t_1_price)\n",
    "        row['selected_price'] = new_price\n",
    "        row['source'] = source\n",
    "        \n",
    "        \n",
    "    product_final_df = pd.concat([product_final_df, row.to_frame().T], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1621a7d-28e5-459c-bf2f-ed32ea7cd170",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_final_df['discount'] = abs((product_final_df['selected_price']-product_final_df['price'])/product_final_df['price'])\n",
    "product_final_df = product_final_df[(product_final_df['discount'] > 0.002)&(product_final_df['selected_price']>0)]\n",
    "product_final_df['discount'] = np.minimum(product_final_df['discount'],0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c02aedc7-0bf2-43ea-a23e-71c580ded71e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "product_final_df['tuple'] = product_final_df[[\"product_id\",'warehouse_id']].apply(tuple, axis=1)\n",
    "selected_skus_tuple = str(list(product_final_df['tuple']))[1:-1]\n",
    "product_final_df=product_final_df.drop(columns = 'tuple')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffcb5e8-eb24-42df-bb3b-00944d7a0267",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retailers Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83b73dfe-46b7-4727-bf8a-44bac6c38ed8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retailer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401857</td>\n",
       "      <td>346</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>850133</td>\n",
       "      <td>10719</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>272848</td>\n",
       "      <td>7004</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>362447</td>\n",
       "      <td>2049</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>749222</td>\n",
       "      <td>8915</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>40745</td>\n",
       "      <td>5083</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>108884</td>\n",
       "      <td>2327</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>104784</td>\n",
       "      <td>2912</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>503595</td>\n",
       "      <td>1446</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>94154</td>\n",
       "      <td>12883</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1882 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      retailer_id  product_id  warehouse_id\n",
       "0          401857         346           962\n",
       "1          850133       10719             8\n",
       "2          272848        7004           170\n",
       "3          362447        2049           632\n",
       "4          749222        8915           962\n",
       "...           ...         ...           ...\n",
       "1877        40745        5083           962\n",
       "1878       108884        2327             8\n",
       "1879       104784        2912           337\n",
       "1880       503595        1446           962\n",
       "1881        94154       12883           962\n",
       "\n",
       "[1882 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f'''\n",
    "with selected_prods as (\n",
    "select * \n",
    "from(\n",
    "VALUES\n",
    "{selected_skus_tuple}\n",
    ")x(product_id,warehouse_id)\n",
    "),\n",
    "selected_districts as (\n",
    "select distinct sp.warehouse_id , sp.product_id,dp.district_id  \n",
    "from WAREHOUSE_DISPATCHING_RULES wdr \n",
    "join DISPATCHING_POLYGONS dp on dp.id = wdr.DISPATCHING_POLYGON_ID\n",
    "join selected_prods sp on sp.product_id = wdr.product_id and wdr.warehouse_id = sp.warehouse_id\n",
    "),\n",
    "sales_before as (\n",
    "select retailer_id,product_id,warehouse_id,district_id,avg(nmv) as avg_nmv_before\n",
    "from (\n",
    "SELECT  DISTINCT\n",
    "so.id as order_id ,\n",
    "sd.district_id,\n",
    "sd.warehouse_id as warehouse_id,\n",
    "pso.product_id as product_id,\n",
    "so.retailer_id as retailer_id,\n",
    "sum(pso.total_price) as nmv \n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "join selected_districts sd on sd.product_id = pso.product_id and sd.district_id = districts.id\n",
    "           \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at ::date between current_date - 120 and current_date - 31\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\t\n",
    "GROUP BY ALL\n",
    ")\n",
    "group by all \n",
    "),\n",
    "sales_after as (\n",
    "select retailer_id,product_id,warehouse_id,district_id,avg(nmv) as avg_nmv_after,max(order_date) as last_order\n",
    "from (\n",
    "SELECT  DISTINCT\n",
    "so.id as order_id ,\n",
    "so.created_at::date as order_date,\n",
    "sales_order_status_id, \n",
    "sd.district_id,\n",
    "sd.warehouse_id as warehouse_id,\n",
    "pso.product_id as product_id,\n",
    "so.retailer_id as retailer_id,\n",
    "sum(pso.total_price) as nmv \n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "join selected_districts sd on sd.product_id = pso.product_id and sd.district_id = districts.id\n",
    "           \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at ::date > current_date - 31\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\t\n",
    "GROUP BY ALL\n",
    ")\n",
    "group by all \n",
    "\n",
    "),\n",
    "made_order as (\n",
    "select distinct so.retailer_id\n",
    "\n",
    "\n",
    "FROM  sales_orders so \n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "join selected_districts sd on sd.district_id = districts.id\n",
    "           \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at ::date > current_date - 31\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "\t\n",
    "GROUP BY ALL\n",
    ")\n",
    "\n",
    "select distinct retailer_id , product_id,warehouse_id \n",
    "from (\n",
    "select sb.* , coalesce(avg_nmv_after,0) as nmv_after,(nmv_after-avg_nmv_before)/avg_nmv_before as growth\n",
    "from sales_before sb \n",
    "left join sales_after sa on sb.retailer_id = sa.retailer_id and sb.product_id = sa.product_id\n",
    "left join made_order mo on mo.retailer_id = sa.retailer_id \n",
    "where growth < -0.6\n",
    "and (current_date - last_order >=5 or last_order is null)\n",
    "and mo.retailer_id is not null \n",
    ")\n",
    "'''\n",
    "churned_dropped =  query_snowflake(query, columns = ['retailer_id','product_id','warehouse_id'])\n",
    "churned_dropped.columns = churned_dropped.columns.str.lower()\n",
    "for col in churned_dropped.columns:\n",
    "    churned_dropped[col] = pd.to_numeric(churned_dropped[col], errors='ignore')  \n",
    "churned_dropped    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b96e0-b3f4-4667-8f36-18f7484557e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "with retailer_cohort as (\n",
    "select *, row_number()over(partition by retailer_id order by priority) as rnk \n",
    "from (\n",
    "select x.*,TAGGABLE_ID as retailer_id \n",
    "from (\n",
    "select id as cohort_id,name as cohort_name,priority,dynamic_tag_id \n",
    "from cohorts \n",
    "where is_active = 'true'\n",
    "and id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    ") x \n",
    "join DYNAMIC_TAGgables dt on x.dynamic_tag_id = dt.dynamic_tag_id\n",
    ")\n",
    "qualify rnk = 1 \n",
    "order by cohort_id\n",
    "),\n",
    "vs as (\n",
    "select event_date,event_timestamp,retailer_id,SECTION_ID,s.name_ar as section,GA_SESSION_ID \n",
    "from MAXAB_EVENTS.VIEW_SECTION\n",
    "join sections s on s.id = MAXAB_EVENTS.VIEW_SECTION.section_id \n",
    "where (seller_name in ('maxab','')\n",
    "or flow_type = '')\n",
    "and  event_timestamp::date between date_trunc('month',current_date - interval '18 month') and current_date-1\n",
    "AND country LIKE '%Egypt%'\n",
    "AND user_id LIKE '%EG_retailers_%'\n",
    "),\n",
    "vb as (\n",
    "select \n",
    "event_date,\n",
    "event_timestamp,\n",
    "vb.retailer_id,\n",
    "vb.brand_id,\n",
    "vb.brand_name,\n",
    "s.id as section_id ,\n",
    "s.name_ar as section,\n",
    "c.id as cat_id,\n",
    "c.name_ar as cat,\n",
    "GA_SESSION_ID \n",
    "FROM maxab_events.view_brand vb\n",
    "join CATEGORIES c on c.id = vb.category_id \n",
    "join sections s on s.id = c.section_id\n",
    "WHERE  event_timestamp::date between date_trunc('month',current_date - interval '18 month') and current_date-1\n",
    "AND country LIKE '%Egypt%'\n",
    "AND user_id LIKE '%EG_retailers_%'\n",
    "and brand_id <> 'null'\n",
    "),\n",
    "catbrands as (\n",
    "SELECT  DISTINCT\n",
    "\t\tbrands.id as brand_id, \n",
    "\t\tcategories.id as cat_id\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "           \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at ::date between date_trunc('month',current_date - interval '6 month') and date_trunc('month',current_date)-1\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\n",
    "),\n",
    "sales as (\n",
    "\n",
    "SELECT  DISTINCT\n",
    "\t\tso.created_at::date as date,\n",
    "\t\tso.retailer_id,\n",
    "\t\tbrands.id as brand_id, \n",
    "\t\tcategories.id as cat_id,\n",
    "\t\t1 as purchased,\n",
    "\t\tsum(pso.total_price) as nmv,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "           \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at::date between date_trunc('month',current_date - interval '18 month') and current_date-1\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "group by all \n",
    "\n",
    "),\n",
    "Actual_purchased as (\n",
    "select cohort_id,brand_id,cat_id,\n",
    "PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY case when o_month <> date_trunc('month',current_date - interval '1 month') then  num_rets end)AS Actual_rets_q3,\n",
    "coalesce(avg(case when o_month = date_trunc('month',current_date - interval '1 month') then num_rets end),0) as actual_rets_lm\n",
    "\n",
    "from (\n",
    "select *,\n",
    "PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY case when o_month <> date_trunc('month',current_date - interval '1 month') then  num_rets end) OVER (partition by brand_id,cat_id,cohort_id) AS q1,\n",
    "PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY case when o_month <> date_trunc('month',current_date - interval '1 month') then  num_rets end) OVER (partition by brand_id,cat_id,cohort_id) AS q3,\n",
    "from (\n",
    "select  date_trunc('month',date) as o_month,cohort_id,brand_id,cat_id,count(distinct sales.retailer_id) as num_rets\n",
    "from sales \n",
    "join retailer_cohort rc on rc.retailer_id = sales.retailer_id\n",
    "group by all \n",
    ")\n",
    ")\n",
    "where num_rets >= q1-(1.5*(q3-q1))\n",
    "or o_month = date_trunc('month',current_date - interval '1 month')\n",
    "group by all \n",
    "),\n",
    "oos as (\n",
    "select x.*,b.name_ar as brand ,c.name_ar as cat ,c.id as cat_id \n",
    "from (\n",
    "select \n",
    "event_date,\n",
    "event_timestamp,\n",
    "oos.retailer_id,\n",
    "oos.brand_id,\n",
    "coalesce(oos.item_id,oos.product_id) as product_id,\n",
    "GA_SESSION_ID,\n",
    "1 as no_stocks\n",
    "from maxab_events.out_of_stock oos\n",
    "WHERE  event_timestamp::date between date_trunc('month',current_date - interval '18 month') and current_date-1\n",
    "AND country LIKE '%Egypt%'\n",
    "AND user_id LIKE '%EG_retailers_%'\n",
    "and brand_id <> 'null'\n",
    "and out_type = 'complete'\n",
    ")x \n",
    "join products p on p.id = x.product_id \n",
    "join brands b on b.id = p.brand_id \n",
    "join categories c on c.id = p.category_id\n",
    "),\n",
    "historical_conv as (\n",
    "select brand_id,brand_name,cat_id,cat,cohort_id, \n",
    "PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY total_viewed) as viewed_75,\n",
    "PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY total_purchased) purchased_75,\n",
    "PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY conversion_rate) conv_75,\n",
    "avg(oos_rate) as oos_rate\n",
    "from (\n",
    "select *,total_purchased/total_viewed as conversion_rate,total_oos/total_viewed as oos_rate,\n",
    "PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY conversion_rate) OVER (partition by brand_id,cat_id,cohort_id) AS q1,\n",
    "PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY conversion_rate) OVER (partition by brand_id,cat_id,cohort_id) AS q3,\n",
    "q3-q1 as iqr \n",
    "\n",
    "from (\n",
    "select month,brand_id,brand_name,cat_id,cat,cohort_id,\n",
    "count(distinct retailer_id) as total_viewed,\n",
    "coalesce(count( distinct case when purchased is not null then retailer_id end),0) as total_purchased,\n",
    "coalesce(count(distinct case when oos >=0.3 then retailer_id end),0) as total_oos\n",
    "from (\n",
    "select date_trunc('month',event_date) as month,\n",
    "brand_id,brand_name,\n",
    "cat_id,cat,cohort_id,\n",
    "retailer_id,\n",
    "max(purchased) as purchased,\n",
    "avg(no_stocks) as oos\n",
    "from(\n",
    "\n",
    "select distinct vb.* ,rc.cohort_id,s.purchased,coalesce(oos.no_stocks,0) as no_stocks\n",
    "from vs \n",
    "join vb on vs.section_id = vb.section_id \n",
    "\t\tand vs.GA_SESSION_ID = vb.GA_SESSION_ID \n",
    "\t\tand vs.retailer_id = vb.retailer_id\n",
    "\t\tand vb.event_timestamp >= vs.event_timestamp \n",
    "\t\tand vb.event_date = vs.event_date\n",
    "\t\t\n",
    "left join oos on oos.brand_id = vb.brand_id \n",
    "\t\t\tand oos.GA_SESSION_ID = vb.GA_SESSION_ID \n",
    "\t\t\tand oos.retailer_id = vb.retailer_id\n",
    "\t\t\tand oos.event_timestamp >= vs.event_timestamp \n",
    "\t\t\tand oos.event_date = vs.event_date\n",
    "\t\t\t\n",
    "join retailer_cohort rc on rc.retailer_id = vb.retailer_id\n",
    "join catbrands cb  on cb.brand_id = vb.brand_id and cb.cat_id = vb.cat_id\n",
    "left join sales s on s.retailer_id = vs.retailer_id and s.brand_id = vb.brand_id and vb.cat_id = s.cat_id and s.date >= vb.event_date and s.date <= vb.event_date + 2\n",
    "\n",
    "where vb.event_date::date <  date_trunc('month',current_date - interval '1 month')\n",
    "and vs.event_date::date <  date_trunc('month',current_date - interval '1 month')\n",
    ")\n",
    "group by all\n",
    ")\n",
    "group by all \n",
    ")\n",
    ")\n",
    "where conversion_rate >= q1-(1.5*iqr)\n",
    "group by all \n",
    "),\n",
    "current_conv as (\n",
    "\n",
    "select cohort_id,brand_id,brand_name,cat_id,cat,\n",
    "total_viewed as lm_views,\n",
    "total_purchased as lm_purchases,\n",
    "total_purchased/total_viewed as lm_conversion_rate,\n",
    "total_oos/total_viewed as lm_oos\n",
    "from (\n",
    "select month,brand_id,brand_name,cat_id,cat,cohort_id,\n",
    "count(distinct retailer_id) as total_viewed,\n",
    "coalesce(count( distinct case when purchased is not null then retailer_id end),0) as total_purchased,\n",
    "coalesce(count(distinct case when oos >=0.3 then retailer_id end),0) as total_oos\n",
    "from (\n",
    "select date_trunc('month',event_date) as month,\n",
    "brand_id,brand_name,\n",
    "cat_id,cat,cohort_id,\n",
    "retailer_id,\n",
    "max(purchased) as purchased,\n",
    "avg(no_stocks) as oos\n",
    "from(\n",
    "select distinct vb.* ,rc.cohort_id,s.purchased,coalesce(oos.no_stocks,0) as no_stocks\n",
    "from vs \n",
    "join vb on vs.section_id = vb.section_id \n",
    "\t\tand vs.GA_SESSION_ID = vb.GA_SESSION_ID \n",
    "\t\tand vs.retailer_id = vb.retailer_id\n",
    "\t\tand vb.event_timestamp >= vs.event_timestamp \n",
    "\t\tand vb.event_date = vs.event_date\n",
    "left join oos on oos.brand_id = vb.brand_id \n",
    "\t\t\tand oos.GA_SESSION_ID = vb.GA_SESSION_ID \n",
    "\t\t\tand oos.retailer_id = vb.retailer_id\n",
    "\t\t\tand oos.event_timestamp >= vs.event_timestamp \n",
    "\t\t\tand oos.event_date = vs.event_date\n",
    "\t\t\t\t\t\n",
    "join retailer_cohort rc on rc.retailer_id = vb.retailer_id\n",
    "join catbrands cb  on cb.brand_id = vb.brand_id and cb.cat_id = vb.cat_id\n",
    "left join sales s on s.retailer_id = vs.retailer_id and s.brand_id = vb.brand_id and vb.cat_id = s.cat_id and s.date >= vb.event_date and s.date <= vb.event_date+2\n",
    "\n",
    "where vb.event_date::date between  date_trunc('month',current_date - interval '1 month')  and date_trunc('month',current_date)-1\n",
    "and vs.event_date::date between  date_trunc('month',current_date - interval '1 month')  and date_trunc('month',current_date)-1\n",
    ")\n",
    "group by all\n",
    ")\n",
    "group by all \n",
    ")\n",
    "),\n",
    "avg_ret_nmv as (\n",
    "select cohort_id,brand_id,cat_id,avg(nmv) as avg_nmv\n",
    "from (\n",
    "select date_trunc('month',date) as date,brand_id,cat_id,sales.retailer_id,cohort_id,sum(nmv) as nmv\n",
    "from sales \n",
    "join retailer_cohort rc on rc.retailer_id = sales.retailer_id\n",
    "where date between date_trunc('month',current_date - interval '4 month') and date_trunc('month',current_date)-1\n",
    "group by all \n",
    ")\n",
    "group by all \n",
    "),\n",
    "final as (\n",
    "select a.*,\n",
    "case when views_growth between -0.05 and 0.05 and conv_growth between -0.05 and 0.05 then 'Stable'\n",
    "when views_growth between -0.05 and 0.05 and conv_growth < -0.05 then 'Price or stocks'\n",
    "when views_growth between -0.05 and 0.05 and conv_growth >  0.05 then 'Growing'\n",
    "\n",
    "when views_growth < -0.05  and conv_growth between -0.05 and 0.05 then 'App retailers Droping' \n",
    "when views_growth < -0.05  and conv_growth < -0.05 then 'Price-stocks-appRetention'\n",
    "when views_growth < -0.05  and conv_growth > 0.05 then 'Needs more views'\n",
    "\n",
    "when views_growth > 0.05  and conv_growth between -0.05 and 0.05 then 'stable' \n",
    "when views_growth > 0.05  and conv_growth < -0.05 then 'Price or stocks'\n",
    "when views_growth > 0.05  and conv_growth > 0.05 then 'Spike'\n",
    "end as status,\n",
    "arn.avg_nmv,\n",
    "case when status like '%Price%'then ceil(((1+(conv_growth/2))*conv_75)*lm_views) else lm_purchases end  as new_rets_to_purchase,\n",
    "new_rets_to_purchase*coalesce(arn.avg_nmv,0) as target_nmv\n",
    "\n",
    "from (\n",
    "select *,\n",
    "case when viewed_75 <>0 then  (lm_views - viewed_75)/viewed_75 else 0 end as views_growth,\n",
    "case when purchased_75 <> 0 then (lm_purchases - purchased_75)/purchased_75 else 0 end  as purchases_growth,\n",
    "case when conv_75 <> 0 then (lm_conversion_rate - conv_75)/conv_75 else 0 end as conv_growth\n",
    "from (\n",
    "select cohort_id,brand_id,brand_name,cat_id,cat,\n",
    "case when purchased_75 <>0 then least(greatest((Actual_rets_q3/purchased_75),1),4)*viewed_75 else viewed_75 end as viewed_75,\n",
    "Actual_rets_q3 as purchased_75,\n",
    "case when viewed_75 > 0 then purchased_75/viewed_75 else 0 end as conv_75,\n",
    "oos_rate,\n",
    "case when lm_purchases <> 0 then least(greatest((actual_rets_lm/lm_purchases),1),4)*lm_views else lm_views end as lm_views,\n",
    "actual_rets_lm as lm_purchases,\n",
    "case when lm_views <> 0 then lm_purchases/lm_views else 0 end as lm_conversion_rate,\n",
    "lm_oos\n",
    "from(\n",
    "select hc.*,\n",
    "coalesce(Actual_rets_q3,0) as Actual_rets_q3,\n",
    "coalesce(Actual_rets_lm,0) as Actual_rets_lm ,\n",
    "\n",
    "coalesce(lm_views,0) as lm_views,\n",
    "coalesce(lm_purchases,0) as lm_purchases ,\n",
    "coalesce(lm_conversion_rate,0) as lm_conversion_rate,\n",
    "coalesce(lm_oos,0) as lm_oos\n",
    "\n",
    "from historical_conv hc \n",
    "left join Actual_purchased ap on hc.cohort_id = ap.cohort_id \n",
    "\t\t\t\t\t\t and hc.brand_id = ap.brand_id \n",
    "\t\t\t\t\t\t and hc.cat_id = ap.cat_id \n",
    "\t\t\t\t\t\t  \n",
    "left join current_conv cc on hc.cohort_id = cc.cohort_id \n",
    "\t\t\t\t\t\t  and hc.brand_id = cc.brand_id \n",
    "\t\t\t\t\t\t  and hc.cat_id = cc.cat_id\n",
    "where conv_75 > 0 \t\t\t\t\t\t  \n",
    ")\n",
    "where conv_75 > 0 \n",
    ")\n",
    "\n",
    ")a \n",
    "left join avg_ret_nmv arn on arn.cat_id = a.cat_id and arn.brand_id = a.brand_id and a.cohort_id = arn.cohort_id\n",
    "),\n",
    "current_month as (\n",
    "select brand_id,cat_id,cohort_id,\n",
    "count(distinct retailer_id) as cm_viewed,\n",
    "coalesce(count(distinct case when purchased is not null then retailer_id end),0) as cm_purchased,\n",
    "coalesce(count(distinct case when oos >=0.3 then retailer_id end),0) as cm_oos,\n",
    "cm_purchased/cm_viewed as cm_conv,\n",
    "cm_oos/cm_viewed as oos_perc\n",
    "from (\n",
    "select date_trunc('month',event_date) as month,\n",
    "brand_id,\n",
    "cat_id,cohort_id,\n",
    "retailer_id,\n",
    "max(purchased) as purchased,\n",
    "avg(no_stocks) as oos\n",
    "from(\n",
    "select distinct vb.* ,rc.cohort_id,s.purchased,coalesce(oos.no_stocks,0) as no_stocks,\n",
    "max(date_part('hour',vb.event_timestamp))over(partition by vb.event_date) as max_hour\n",
    "from vs \n",
    "join vb on vs.section_id = vb.section_id \n",
    "\t\tand vs.GA_SESSION_ID = vb.GA_SESSION_ID \n",
    "\t\tand vs.retailer_id = vb.retailer_id\n",
    "\t\tand vb.event_timestamp >= vs.event_timestamp \n",
    "\t\tand vb.event_date = vs.event_date\n",
    "left join oos on oos.brand_id = vb.brand_id \n",
    "\t\t\tand oos.GA_SESSION_ID = vb.GA_SESSION_ID \n",
    "\t\t\tand oos.retailer_id = vb.retailer_id\n",
    "\t\t\tand oos.event_timestamp >= vs.event_timestamp \n",
    "\t\t\tand oos.event_date = vs.event_date\n",
    "\t\t\t\n",
    "join retailer_cohort rc on rc.retailer_id = vb.retailer_id\n",
    "join catbrands cb  on cb.brand_id = vb.brand_id and cb.cat_id = vb.cat_id\n",
    "left join sales s on s.retailer_id = vs.retailer_id and s.brand_id = vb.brand_id and vb.cat_id = s.cat_id and s.date >= vb.event_date and s.date <= vb.event_date+2\n",
    "\n",
    "where vb.event_date::date >= date_trunc('month',current_date)\n",
    "and vs.event_date::date >= date_trunc('month',current_date)\n",
    "qualify max_hour = 23\n",
    ")\n",
    "group by all \n",
    ")\n",
    " \n",
    "group by all \n",
    ") \n",
    "\n",
    "select f.*,cm_viewed,cm_purchased, cm_conv,oos_perc as cm_oos_perc\n",
    "from final f \n",
    "left join current_month cm on f.cohort_id = cm.cohort_id and cm.brand_id = f.brand_id and cm.cat_id = f.cat_id\n",
    "order by target_nmv desc\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3001e6e-e55b-49dc-bf92-6053b4b75403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "with selected_prods as (\n",
    "select * \n",
    "from(\n",
    "VALUES\n",
    "{selected_skus_tuple}\n",
    ")x(product_id,warehouse_id)\n",
    "),\n",
    "selected_districts as (\n",
    "select distinct sp.warehouse_id , sp.product_id,dp.district_id ,c.name_ar as cat ,b.name_ar as brand\n",
    "from WAREHOUSE_DISPATCHING_RULES wdr \n",
    "join DISPATCHING_POLYGONS dp on dp.id = wdr.DISPATCHING_POLYGON_ID\n",
    "join selected_prods sp on sp.product_id = wdr.product_id and wdr.warehouse_id = sp.warehouse_id\n",
    "join products p on p.id = sp.product_id\n",
    "join brands b on b.id = p.brand_id \n",
    "join categories c on c.id = p.category_id \n",
    "),\n",
    "\n",
    "buy_cat as (\n",
    "SELECT  DISTINCT\n",
    "sd.district_id,\n",
    "sd.warehouse_id as warehouse_id,\n",
    "so.retailer_id as retailer_id,\n",
    "c.name_ar as cat,\n",
    "sd.product_id\n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "join products p on p.id = pso.product_id\n",
    "join brands b on b.id = p.brand_id \n",
    "join categories c on c.id = p.category_id \n",
    "join selected_districts sd on sd.cat = c.name_ar and sd.district_id = districts.id and b.name_ar = sd.brand\n",
    "           \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at::date >= current_date - 60\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\t\n",
    "\n",
    "),\n",
    "buy_product as (\n",
    "SELECT  DISTINCT\n",
    "sd.district_id,\n",
    "sd.warehouse_id as warehouse_id,\n",
    "so.retailer_id as retailer_id,\n",
    "pso.product_id,\n",
    "c.name_ar as cat\n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "join products p on p.id = pso.product_id\n",
    "join brands b on b.id = p.brand_id \n",
    "join categories c on c.id = p.category_id \n",
    "join selected_districts sd on sd.product_id = pso.product_id and sd.district_id = districts.id\n",
    "           \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at::date >= current_date - 60\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\n",
    ")\n",
    "\n",
    "select distinct bc.retailer_id,bc.product_id,bc.warehouse_id\n",
    "from buy_cat bc \n",
    "left join buy_product bp  on bc.retailer_id = bp.retailer_id and bc.cat = bp.cat and bc.product_id = bp.product_id\n",
    "where bp.product_id is null \n",
    "'''\n",
    "cat_not_product =  query_snowflake(query, columns = ['retailer_id','product_id','warehouse_id'])\n",
    "cat_not_product.columns = cat_not_product.columns.str.lower()\n",
    "for col in cat_not_product.columns:\n",
    "    cat_not_product[col] = pd.to_numeric(cat_not_product[col], errors='ignore') \n",
    "cat_not_product    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb235fb7-ae1a-4ef5-9051-343bad49fa91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select retailer_id\n",
    "from (\n",
    "SELECT  DISTINCT\n",
    "retailer_id,\n",
    "sales_order_status_id,\n",
    "created_at::date as o_date ,\n",
    "max(o_date)over(partition by retailer_id) as last_order\n",
    "from sales_orders so \n",
    "WHERE  so.created_at ::date >= current_date - 120\n",
    "AND so.sales_order_status_id not in (7,12)\n",
    "AND so.channel IN ('telesales','retailer')\n",
    "qualify o_date = last_order\n",
    ")\n",
    "where sales_order_status_id <> 6 \n",
    "\n",
    "union all \n",
    "\n",
    "select id as retailer_id \n",
    "from retailers \n",
    "where activation = 'false'\n",
    "'''\n",
    "exec_rets =  query_snowflake(query, columns = ['retailer_id'])\n",
    "exec_rets.columns = exec_rets.columns.str.lower()\n",
    "for col in exec_rets.columns:\n",
    "    exec_rets[col] = pd.to_numeric(exec_rets[col], errors='ignore') \n",
    "exec_rets =  exec_rets.retailer_id.unique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa5f5a-d837-4199-b51e-5104a50c66e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_retailers  = pd.concat([cat_not_product, churned_dropped]).drop_duplicates().reset_index(drop=True)\n",
    "all_retailers = all_retailers[~all_retailers['retailer_id'].isin(exec_rets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a0150-0259-41e8-ae02-e718471e17b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df = product_final_df.merge(all_retailers,on=['warehouse_id','product_id'])\n",
    "final_df['SKU_arr'] = final_df.apply(lambda x: [x['product_id'], 1, x['discount']], axis=1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16fdf1b-8cc0-4ec5-8d50-b93fb0d2cff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
