{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353eed4b-fed6-4ddb-930f-0d1c581aaf2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# Connectivity\n",
    "!pip install psycopg2-binary  # PostgreSQL adapter\n",
    "# !pip install snowflake-connector-python  # Snowflake connector\n",
    "!pip install snowflake-connector-python==3.15.0 # Snowflake connector Older Version\n",
    "!pip install snowflake-sqlalchemy  # Snowflake SQLAlchemy connector\n",
    "!pip install warnings # Warnings management\n",
    "# !pip install pyarrow # Serialization\n",
    "!pip install keyring==23.11.0 # Key management\n",
    "!pip install sqlalchemy==1.4.46 # SQLAlchemy\n",
    "!pip install requests # HTTP requests\n",
    "!pip install boto3 # AWS SDK\n",
    "# !pip install slackclient # Slack API\n",
    "!pip install oauth2client # Google Sheets API\n",
    "!pip install gspread==5.9.0 # Google Sheets API\n",
    "!pip install gspread_dataframe # Google Sheets API\n",
    "!pip install google.cloud # Google Cloud\n",
    "# Data manipulation and analysis\n",
    "!pip install polars\n",
    "!pip install pandas==2.2.1\n",
    "!pip install numpy\n",
    "# !pip install fastparquet\n",
    "!pip install openpyxl # Excel file handling\n",
    "!pip install xlsxwriter # Excel file handling\n",
    "# Linear programming\n",
    "!pip install pulp\n",
    "# Date and time handling\n",
    "!pip install --upgrade datetime\n",
    "!pip install python-time\n",
    "!pip install --upgrade pytz\n",
    "# Progress bar\n",
    "!pip install tqdm\n",
    "# Database data types\n",
    "!pip install db-dtypes\n",
    "# Geospatial data handling\n",
    "# !pip install geopandas\n",
    "# !pip install shapely\n",
    "# !pip install fiona\n",
    "# !pip install haversine\n",
    "# Plotting\n",
    "\n",
    "# Modeling\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn\n",
    "\n",
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64355078-99bc-436e-b5a9-69fbc4f983fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/snowflake/connector/options.py:104: UserWarning: You have an incompatible version of 'pyarrow' installed (21.0.0), please install a version that adheres to: 'pyarrow<19.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import setup_environment_2\n",
    "import importlib\n",
    "import import_ipynb\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import pytz  \n",
    "import os\n",
    "import snowflake.connector\n",
    "import boto3\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(setup_environment_2)\n",
    "setup_environment_2.initialize_env()\n",
    "import base64\n",
    "from botocore.exceptions import ClientError\n",
    "from requests import get\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import time\n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b5cdc8b-89b2-4b8a-a04e-9e70a9a878f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_snowflake(query, columns=[]):\n",
    "    import os\n",
    "    import snowflake.connector\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    con = snowflake.connector.connect(\n",
    "        user =  os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account= os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password= os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database =os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        if len(columns) == 0:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()))\n",
    "        else:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()),columns=columns)\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b5dbea5-e97b-40bc-ba43-9a1ab1848622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scope = [\"https://spreadsheets.google.com/feeds\",\n",
    "         'https://www.googleapis.com/auth/spreadsheets',\n",
    "         \"https://www.googleapis.com/auth/drive.file\",\n",
    "         \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_dict(json.loads(setup_environment_2.get_secret(\"prod/maxab-sheets\")), scope)\n",
    "client = gspread.authorize(creds)\n",
    "force_brands = client.open('QD_brands').worksheet('Include_brands')\n",
    "force_brands_df = pd.DataFrame(force_brands.get_all_records())\n",
    "if(force_brands_df.empty):\n",
    "    force_brands_df = pd.DataFrame(columns=['brand'])\n",
    "    brand_filter = \"\"\n",
    "else:\n",
    "    brand_filter = f\"OR brand IN ({','.join([repr(b) for b in list(force_brands_df.brand.unique())])})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3a02939-f4ba-445d-bc88-940f233ae3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#changed\n",
    "command_string = f'''\n",
    "with rr as (\n",
    "\n",
    "select product_id,warehouse_id,rr\n",
    "from (\n",
    "select * ,max(date)over(partition by product_id,warehouse_id) as max_date\n",
    "from finance.PREDICTED_RUNNING_RATES\n",
    "qualify date = max_date\n",
    "and date::date >= current_date - 14 \n",
    ")\n",
    "\n",
    "),\n",
    "stocks as (\n",
    "WITH whs as (SELECT *\n",
    "             FROM   (values\n",
    "                            ('Cairo', 'El-Marg', 38,700),\n",
    "                            ('Cairo', 'Mostorod', 1,700),\n",
    "                            ('Giza', 'Barageel', 236,701),\n",
    "                            ('Delta West', 'El-Mahala', 337,703),\n",
    "                            ('Delta West', 'Tanta', 8,703),\n",
    "                            ('Delta East', 'Mansoura FC', 339,704),\n",
    "                            ('Delta East', 'Sharqya', 170,704),\n",
    "                            ('Upper Egypt', 'Assiut FC', 501,1124),\n",
    "                            ('Upper Egypt', 'Bani sweif', 401,1126),\n",
    "                            ('Upper Egypt', 'Menya Samalot', 703,1123),\n",
    "                            ('Upper Egypt', 'Sohag', 632,1125),\n",
    "                            ('Alexandria', 'Khorshed Alex', 797,702),\n",
    "\t\t\t\t\t\t\t('Giza', 'Sakkarah', 962,701)\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t)\n",
    "                    x(region, wh, warehouse_id,cohort_id))\n",
    "select cohort_id,product_id,sum(stocks) as stocks ,case when sum(rr) > 0 then SUM(stocks)/sum(rr) else SUM(stocks) end  as doh\n",
    "from (\n",
    "\t\tSELECT DISTINCT whs.region,\n",
    "\t\t\t\tcohort_id,\t\n",
    "                whs.wh,\n",
    "                product_warehouse.product_id,\n",
    "                (product_warehouse.available_stock)::integer as stocks,\n",
    "\t\t\t\tcoalesce(rr.rr,0) as rr \n",
    "        from whs\n",
    "        JOIN product_warehouse ON product_warehouse.warehouse_id = whs.warehouse_id\n",
    "        JOIN products on product_warehouse.product_id = products.id\n",
    "        JOIN product_units ON products.unit_id = product_units.id\n",
    "\t\tleft join rr on rr.product_id= products.id and rr.warehouse_id = whs.warehouse_id\n",
    "\n",
    "        where   product_warehouse.warehouse_id not in (6,9,10)\n",
    "            AND product_warehouse.is_basic_unit = 1\n",
    "\t\t\tand product_warehouse.available_stock > 0 \n",
    "\n",
    ")\n",
    "group by all\n",
    "HAVING doh > 1 \n",
    "),\n",
    "base as (\n",
    "select *, row_number()over(partition by retailer_id order by priority) as rnk \n",
    "from (\n",
    "select x.*,TAGGABLE_ID as retailer_id \n",
    "from (\n",
    "select id as cohort_id,name as cohort_name,priority,dynamic_tag_id \n",
    "from cohorts \n",
    "where is_active = 'true'\n",
    "and id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    ") x \n",
    "join DYNAMIC_TAGgables dt on x.dynamic_tag_id = dt.dynamic_tag_id\n",
    ")\n",
    "qualify rnk = 1 \n",
    "order by cohort_id\n",
    "),\n",
    "selected_skus as (\n",
    "select *\n",
    "from (\n",
    "select cohort_id,cohort_name,product_id,cat,brand,row_number()over(partition by cohort_id,cat order by cntrb) as num_skus\n",
    "from (\n",
    "select *,min(case when cumulative_sum > 0.4 then cumulative_sum end) over(partition by cat, cohort_id) as thres\n",
    "from (\n",
    "select *,SUM(cntrb) OVER (partition by cat, cohort_id ORDER BY cntrb desc ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_sum\n",
    "from (\n",
    "select *, num_order/sum(num_order)over(partition by cat,cohort_id) as cntrb\n",
    "from (\n",
    "SELECT  DISTINCT\n",
    "\t\tbase.cohort_id,\n",
    "\t\tbase.cohort_name,\n",
    "\t\tpso.product_id,\n",
    "\t\tCONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\n",
    "\t\tcount(distinct parent_sales_order_id) as num_order ,\n",
    "        sum(pso.total_price) as nmv,\n",
    "       sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs,\n",
    "\t   (nmv-cogs)/nmv as bm \n",
    "\t\t\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "join base on base.retailer_id = so.retailer_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id\n",
    "JOIN categories ON products.category_id = categories.id and categories.name_ar not like '%سايب%'\n",
    "JOIN finance.all_cogs f  ON f.product_id = pso.product_id\n",
    "                        AND f.from_date::date <= so.created_at::date\n",
    "                        AND f.to_date::date > so.created_at::date\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "join stocks s on s.product_id = pso.product_id and s.cohort_id = base.cohort_id\n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at::date between date_trunc('month',current_date - interval '2 months') and CURRENT_date-1\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "    and products.activation = 'true'\n",
    "\n",
    "GROUP BY ALL\n",
    ")\n",
    ")\n",
    ")\n",
    ")\n",
    "where cumulative_sum <= thres \n",
    "{brand_filter}\n",
    ")\n",
    "where  num_skus <= 10 \n",
    "{brand_filter}\n",
    "),\n",
    "\n",
    "main as (\n",
    "select * ,max(rets) over(partition by cohort_id) as max_rets \n",
    "from(\n",
    "select *,count(distinct retailer_id) over(partition by region,cohort_id) as rets \n",
    "from (\n",
    "SELECT  DISTINCT\n",
    "\t\tso.created_at::date as date,\n",
    "\t\tparent_sales_order_id,\n",
    "\t\tso.retailer_id,\n",
    "\t\tbase.cohort_id,\n",
    "\t\tbase.cohort_name,\n",
    "\t\tcase when regions.id = 2 then states.name_en else regions.name_en end as region,\n",
    "\t\tpso.product_id,\n",
    "\t\tCONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "\t\tpacking_unit_id,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\n",
    "\t\tsum(pso.purchased_item_count) as qty,\n",
    "        sum(pso.total_price) as nmv,\n",
    "       sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs,\n",
    "\t   (nmv-cogs)/nmv as bm \n",
    "\t\t\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "join base on base.retailer_id = so.retailer_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id\n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN finance.all_cogs f  ON f.product_id = pso.product_id\n",
    "                        AND f.from_date::date <= so.created_at::date\n",
    "                        AND f.to_date::date > so.created_at::date\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "JOIN cities on cities.id=districts.city_id\n",
    "join states on states.id=cities.state_id\n",
    "join regions on regions.id=states.region_id\n",
    "join selected_skus ss on ss.product_id = pso.product_id and ss.cohort_id = base.cohort_id\n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at::date between date_trunc('month',current_date - interval '2 months') and CURRENT_date-1\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "    and products.activation = 'true'\n",
    "\n",
    "GROUP BY ALL\n",
    ")\n",
    ")\n",
    "qualify rets = max_rets\n",
    "),\n",
    "cohort_data as (\n",
    "select region,cohort_id,cohort_name,product_id,sku,brand,cat,packing_unit_id,\n",
    "PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY qty) AS region_q1,\n",
    "MEDIAN(qty) as region_median,\n",
    "PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY qty) AS region_q3,\n",
    "PERCENTILE_CONT(0.85) WITHIN GROUP (ORDER BY qty) AS region_85,\n",
    "STDDEV_POP(qty) as std\n",
    "from main\n",
    "group by all \n",
    "),\n",
    "recent_cohort_data as (\n",
    "select cohort_id,cohort_name,product_id,sku,brand,cat,packing_unit_id,\n",
    "MEDIAN(qty) as recent_region_median,\n",
    "PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY qty) AS recent_region_q3,\n",
    "STDDEV_POP(qty) as recent_std\n",
    "from main\n",
    "where date between current_date - 8 and current_date - 1 \n",
    "group by all \n",
    "),\n",
    " freq_table AS (\n",
    "  SELECT\n",
    "  \t cohort_id,cohort_name,\n",
    "    PRODUCT_ID,sku,brand,cat,\n",
    "\tpacking_unit_id,\n",
    "    qty,\n",
    "    COUNT(distinct parent_sales_order_id) AS freq\n",
    "  FROM main\n",
    "  GROUP BY all\n",
    "),\n",
    "lag_lead AS (\n",
    "  SELECT\n",
    "   cohort_id,cohort_name,\n",
    "    PRODUCT_ID,sku,brand,cat,\n",
    "\tpacking_unit_id,\n",
    "    qty,\n",
    "    freq,\n",
    "    LAG(freq) OVER (PARTITION BY cohort_id,PRODUCT_ID,packing_unit_id ORDER BY qty) AS prev_freq,\n",
    "    LEAD(freq) OVER (PARTITION BY cohort_id,PRODUCT_ID,packing_unit_id ORDER BY qty) AS next_freq\n",
    "  FROM freq_table\n",
    "),\n",
    "most_freq as (\n",
    "select * \n",
    "from (\n",
    "select *,max(cntrb)over(partition by product_id,packing_unit_id,cohort_id) as max_cntrb\n",
    "from (\n",
    "SELECT *, freq/sum(freq) over(partition by product_id,packing_unit_id,cohort_id) as cntrb\n",
    "FROM lag_lead ll \n",
    "WHERE (freq > COALESCE(prev_freq, -1))\n",
    "  AND (freq > COALESCE(next_freq, -1))\n",
    "  )\n",
    "  )\n",
    "  where cntrb >= max_cntrb- 0.05\n",
    "  order by product_id\n",
    "),\n",
    "most_qty as (\n",
    "select cohort_id,cohort_name,product_id,sku,cat,brand,packing_unit_id,ceil(sum(freq_cntrb*qty)) as final_qty \n",
    "from (\n",
    "select *,freq/sum(freq)over(partition by  product_id,packing_unit_id,cohort_id) as freq_cntrb\n",
    "from most_freq \n",
    ")\n",
    "group by all \n",
    "),\n",
    "final_data as (\n",
    "select *,\n",
    "ceil(\n",
    "least(\n",
    "GREATEST(\n",
    "      recent_region_median + 0.75 * recent_std,\n",
    "      final_qty,\n",
    "\t  region_median+0.75*std,\n",
    "\t  region_median+2,\n",
    "\t  2\n",
    "    ),\n",
    "\tGREATEST(region_median+2,region_median*1.5)\n",
    "\t)\n",
    "\t\n",
    "\t) as tier_1,\n",
    " ceil(\n",
    " least(\n",
    " GREATEST(\n",
    "      final_qty + 1 * std,\n",
    "      region_q3 + 1 * std,\n",
    "\t  region_85 + 0.5 * std,\n",
    "      recent_region_q3 + 1 * recent_std,\n",
    "\t  tier_1*1.4\n",
    "    ),\n",
    "\ttier_1*3\n",
    "\t)\n",
    "\t) as tier_2\n",
    "from (\n",
    "select  rd.region,mq.*,region_q1,\n",
    "region_median,\n",
    "region_q3,\n",
    "region_85,\n",
    "std,\n",
    "COALESCE(recent_region_median,0) as recent_region_median,\n",
    "COALESCE(recent_region_q3,0) as recent_region_q3,\n",
    "COALESCE(recent_std,0) as recent_std\n",
    "from cohort_data rd \n",
    "join most_qty mq on rd.cohort_id =mq.cohort_id\n",
    "and rd.product_id =  mq.product_id\n",
    "and rd.packing_unit_id = mq.packing_unit_id \n",
    "left join recent_cohort_data rrd on rrd.cohort_id =mq.cohort_id\n",
    "and rrd.product_id =  mq.product_id\n",
    "and rrd.packing_unit_id = mq.packing_unit_id \n",
    ")\n",
    "),\n",
    "local_prices as (\n",
    "SELECT  case when cpu.cohort_id in (700,695) then 'Cairo'\n",
    "             when cpu.cohort_id in (701) then 'Giza'\n",
    "             when cpu.cohort_id in (704,698) then 'Delta East'\n",
    "             when cpu.cohort_id in (703,697) then 'Delta West'\n",
    "             when cpu.cohort_id in (696,1123,1124,1125,1126) then 'Upper Egypt'\n",
    "             when cpu.cohort_id in (702,699) then 'Alexandria'\n",
    "        end as region,\n",
    "\t\tcohort_id,\n",
    "        pu.product_id,\n",
    "\t\tpu.packing_unit_id as packing_unit_id,\n",
    "\t\tpu.basic_unit_count,\n",
    "        avg(cpu.price) as price\n",
    "FROM    cohort_product_packing_units cpu\n",
    "join    PACKING_UNIT_PRODUCTS pu on pu.id = cpu.product_packing_unit_id\n",
    "WHERE   cpu.cohort_id in (700,701,702,703,704,696,695,698,697,699,1123,1124,1125,1126)\n",
    "    and cpu.created_at::date<>'2023-07-31'\n",
    "    and cpu.is_customized = true\n",
    "\tgroup by all \n",
    "),\n",
    "live_prices as (\n",
    "select region,cohort_id,product_id,pu_id as packing_unit_id,buc as basic_unit_count,NEW_PRICE as price\n",
    "from materialized_views.DBDP_PRICES\n",
    "where created_at = current_date\n",
    "and DATE_PART('hour',CURRENT_TIME) BETWEEN SPLIT_PART(time_slot, '-', 1)::int AND SPLIT_PART(time_slot, '-', 2)::int\n",
    "and cohort_id in (700,701,702,703,704,696,695,698,697,699,1123,1124,1125,1126)\n",
    "),\n",
    "prices as (\n",
    "select *\n",
    "from (\n",
    "    SELECT *, 1 AS priority FROM live_prices\n",
    "    UNION ALL\n",
    "    SELECT *, 2 AS priority FROM local_prices\n",
    ")\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY region,cohort_id,product_id,packing_unit_id ORDER BY priority) = 1\n",
    "),\n",
    "region_prices as (\n",
    "select region,product_id,packing_unit_id,basic_unit_count,avg(price) as region_price\n",
    "from prices \n",
    "where price is not null \n",
    "group by all\n",
    "\n",
    "),\n",
    "finalized as (\n",
    "select fd.*,COALESCE(p.basic_unit_count,rp.basic_unit_count) as basic_unit_count,COALESCE(p.price,rp.region_price) as price\n",
    "from final_data fd \n",
    "left join prices p on fd.cohort_id = p.cohort_id and p.product_id = fd.product_id and p.packing_unit_id = fd.packing_unit_id\n",
    "left join region_prices rp on case when fd.region = 'Giza' then 'Cairo' else fd.region end = rp.region and rp.product_id = fd.product_id and rp.packing_unit_id = fd.packing_unit_id\n",
    "),\n",
    "cntrbs as (\n",
    "select main.product_id,main.cohort_id,main.packing_unit_id,\n",
    "count(distinct case when qty < tier_1 then retailer_id end ) as ret_below_t1,\n",
    "count(distinct case when qty >= tier_1  and qty <tier_2 then retailer_id end ) as ret_t1,\n",
    "count(distinct case when qty >= tier_2  then retailer_id end )as ret_t2 \n",
    "from main\n",
    "join finalized f on main.product_id = f.product_id and main.cohort_id = f.cohort_id and f.packing_unit_id = main.packing_unit_id \n",
    "group by all \n",
    ")\n",
    "select f.region,f.cohort_id,f.cohort_name,f.product_id,f.sku,f.cat,f.brand,f.packing_unit_id,TIER_1,tier_2,price, c.ret_below_t1,ret_t1,ret_t2,wac_p*BASIC_UNIT_COUNT as wac,f.region_median,f.RECENT_REGION_MEDIAN\n",
    "from finalized f\n",
    "join cntrbs c on c.product_id = f.product_id and c.cohort_id = f.cohort_id and f.packing_unit_id = c.packing_unit_id\n",
    "join finance.all_cogs cogs on cogs.product_id = f.product_id and CURRENT_TIMESTAMP between cogs.from_date and cogs.to_date\n",
    "where price is not null\n",
    "'''\n",
    "quantity_disc_data = query_snowflake(command_string, columns = ['REGION','COHORT_ID','COHORT_NAME','PRODUCT_ID','SKU','CAT','BRAND','PACKING_UNIT_ID','TIER_1','TIER_2','PRICE','RET_BELOW_T1','RET_T1','RET_T2','WAC_P','region_median','RECENT_REGION_MEDIAN'])\n",
    "quantity_disc_data.columns = quantity_disc_data.columns.str.lower()\n",
    "quantity_disc_data.product_id = pd.to_numeric(quantity_disc_data.product_id)\n",
    "quantity_disc_data.packing_unit_id = pd.to_numeric(quantity_disc_data.packing_unit_id)\n",
    "quantity_disc_data.tier_1 = pd.to_numeric(quantity_disc_data.tier_1)\n",
    "quantity_disc_data.tier_2 = pd.to_numeric(quantity_disc_data.tier_2)\n",
    "\n",
    "quantity_disc_data.price = pd.to_numeric(quantity_disc_data.price)\n",
    "quantity_disc_data.wac_p = pd.to_numeric(quantity_disc_data.wac_p)\n",
    "quantity_disc_data.ret_below_t1 = pd.to_numeric(quantity_disc_data.ret_below_t1)\n",
    "\n",
    "quantity_disc_data.ret_t1 = pd.to_numeric(quantity_disc_data.ret_t1)\n",
    "quantity_disc_data.ret_t2 = pd.to_numeric(quantity_disc_data.ret_t2)\n",
    "\n",
    "quantity_disc_data.region_median = pd.to_numeric(quantity_disc_data.region_median)\n",
    "quantity_disc_data.recent_region_median = pd.to_numeric(quantity_disc_data.recent_region_median)\n",
    "\n",
    "\n",
    "quantity_disc_data = quantity_disc_data[~quantity_disc_data['cat'].isin(['سكر','كروت شحن','مياه معدنيه','مقرمشات','شيبسي'])]\n",
    "quantity_disc_data = quantity_disc_data[~quantity_disc_data['brand'].isin(['ريد بل','بيرل','ترافل','جليد','جيليت لندن بريدج','رايد','سندة ارز','شاي الورردة','فل','كمارا','أجين','فيوري'])]\n",
    "quantity_disc_data['bm'] = (quantity_disc_data['price']-quantity_disc_data['wac_p']) / quantity_disc_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2fbf2f79-a5c9-4583-8b04-5fd434a45b68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>cohort_name</th>\n",
       "      <th>product_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>cat</th>\n",
       "      <th>brand</th>\n",
       "      <th>packing_unit_id</th>\n",
       "      <th>tier_1</th>\n",
       "      <th>tier_2</th>\n",
       "      <th>price</th>\n",
       "      <th>ret_below_t1</th>\n",
       "      <th>ret_t1</th>\n",
       "      <th>ret_t2</th>\n",
       "      <th>wac_p</th>\n",
       "      <th>region_median</th>\n",
       "      <th>recent_region_median</th>\n",
       "      <th>bm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>1124</td>\n",
       "      <td>Assiut_pricing_Cohort</td>\n",
       "      <td>6935</td>\n",
       "      <td>كوكاكولا اكشن - 300 مل</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>كوكا كولا</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>107.75</td>\n",
       "      <td>557</td>\n",
       "      <td>241</td>\n",
       "      <td>122</td>\n",
       "      <td>92.999998</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.136891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delta East</td>\n",
       "      <td>704</td>\n",
       "      <td>Pricing_Model_DE_V2</td>\n",
       "      <td>71</td>\n",
       "      <td>عسل البوادى اسود - 355 جم</td>\n",
       "      <td>عسل</td>\n",
       "      <td>البوادي</td>\n",
       "      <td>10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.303747</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delta West</td>\n",
       "      <td>703</td>\n",
       "      <td>Pricing_Model_DW_V2</td>\n",
       "      <td>66</td>\n",
       "      <td>صلصة هارفست صفيح - 375 جم</td>\n",
       "      <td>صلصة و صوص</td>\n",
       "      <td>هارفست فوودز</td>\n",
       "      <td>16</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>362.50</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>341.722800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.057316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cairo</td>\n",
       "      <td>700</td>\n",
       "      <td>Pricing_Model_Cairo_V2</td>\n",
       "      <td>19583</td>\n",
       "      <td>بسكويت لمبادا دوبل هرم 5 اكس - 5 جنية</td>\n",
       "      <td>ويفر</td>\n",
       "      <td>لمبادا</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>198.75</td>\n",
       "      <td>246</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>184.140000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.073509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cairo</td>\n",
       "      <td>700</td>\n",
       "      <td>Pricing_Model_Cairo_V2</td>\n",
       "      <td>10780</td>\n",
       "      <td>بطارية ريموت افيريدى ازرق - 20 حجر</td>\n",
       "      <td>بطاريات ولمبات</td>\n",
       "      <td>افيريدي</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>80.25</td>\n",
       "      <td>550</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>68.516331</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.146214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>1124</td>\n",
       "      <td>Assiut_pricing_Cohort</td>\n",
       "      <td>335</td>\n",
       "      <td>البوادي حلاوة- 130 جم</td>\n",
       "      <td>حلاوة طحينية</td>\n",
       "      <td>البوادي</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>90</td>\n",
       "      <td>52</td>\n",
       "      <td>16</td>\n",
       "      <td>21.007731</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.045103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2243</th>\n",
       "      <td>Delta East</td>\n",
       "      <td>704</td>\n",
       "      <td>Pricing_Model_DE_V2</td>\n",
       "      <td>624</td>\n",
       "      <td>فانتا برتقال جيب - 240 مل</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>كوكا كولا</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>262.75</td>\n",
       "      <td>952</td>\n",
       "      <td>155</td>\n",
       "      <td>152</td>\n",
       "      <td>249.154204</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>1126</td>\n",
       "      <td>Beni_Suef_Fayoum_pricing_Cohort</td>\n",
       "      <td>615</td>\n",
       "      <td>كوكا كولا جيب - 240 مل</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>كوكا كولا</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>274.75</td>\n",
       "      <td>290</td>\n",
       "      <td>39</td>\n",
       "      <td>47</td>\n",
       "      <td>248.558813</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2245</th>\n",
       "      <td>Delta East</td>\n",
       "      <td>704</td>\n",
       "      <td>Pricing_Model_DE_V2</td>\n",
       "      <td>972</td>\n",
       "      <td>نواعم بسكويت- 5 ج</td>\n",
       "      <td>بسكويت و معمول</td>\n",
       "      <td>نواعم</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>48.50</td>\n",
       "      <td>446</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>46.880100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2246</th>\n",
       "      <td>Delta East</td>\n",
       "      <td>704</td>\n",
       "      <td>Pricing_Model_DE_V2</td>\n",
       "      <td>11633</td>\n",
       "      <td>شاور جيل سوبر كرنفال زهور الربيع - 2 لتر</td>\n",
       "      <td>شامبو و شاور جيل</td>\n",
       "      <td>ليدر</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>321.75</td>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>309.426012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.038303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2107 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           region cohort_id                      cohort_name  product_id  \\\n",
       "0     Upper Egypt      1124            Assiut_pricing_Cohort        6935   \n",
       "1      Delta East       704              Pricing_Model_DE_V2          71   \n",
       "2      Delta West       703              Pricing_Model_DW_V2          66   \n",
       "4           Cairo       700           Pricing_Model_Cairo_V2       19583   \n",
       "5           Cairo       700           Pricing_Model_Cairo_V2       10780   \n",
       "...           ...       ...                              ...         ...   \n",
       "2242  Upper Egypt      1124            Assiut_pricing_Cohort         335   \n",
       "2243   Delta East       704              Pricing_Model_DE_V2         624   \n",
       "2244  Upper Egypt      1126  Beni_Suef_Fayoum_pricing_Cohort         615   \n",
       "2245   Delta East       704              Pricing_Model_DE_V2         972   \n",
       "2246   Delta East       704              Pricing_Model_DE_V2       11633   \n",
       "\n",
       "                                           sku               cat  \\\n",
       "0                       كوكاكولا اكشن - 300 مل        حاجه ساقعه   \n",
       "1                    عسل البوادى اسود - 355 جم               عسل   \n",
       "2                    صلصة هارفست صفيح - 375 جم        صلصة و صوص   \n",
       "4        بسكويت لمبادا دوبل هرم 5 اكس - 5 جنية              ويفر   \n",
       "5           بطارية ريموت افيريدى ازرق - 20 حجر    بطاريات ولمبات   \n",
       "...                                        ...               ...   \n",
       "2242                     البوادي حلاوة- 130 جم      حلاوة طحينية   \n",
       "2243                 فانتا برتقال جيب - 240 مل        حاجه ساقعه   \n",
       "2244                    كوكا كولا جيب - 240 مل        حاجه ساقعه   \n",
       "2245                         نواعم بسكويت- 5 ج    بسكويت و معمول   \n",
       "2246  شاور جيل سوبر كرنفال زهور الربيع - 2 لتر  شامبو و شاور جيل   \n",
       "\n",
       "             brand  packing_unit_id  tier_1  tier_2   price  ret_below_t1  \\\n",
       "0        كوكا كولا                2     8.0    19.0  107.75           557   \n",
       "1          البوادي               10     7.0    10.0   22.00             1   \n",
       "2     هارفست فوودز               16     3.0     5.0  362.50           232   \n",
       "4           لمبادا                1     3.0     5.0  198.75           246   \n",
       "5          افيريدي               10     4.0     6.0   80.25           550   \n",
       "...            ...              ...     ...     ...     ...           ...   \n",
       "2242       البوادي                3     9.0    17.0   22.00            90   \n",
       "2243     كوكا كولا                2     3.0     5.0  262.75           952   \n",
       "2244     كوكا كولا                2     3.0     5.0  274.75           290   \n",
       "2245         نواعم                3     4.0     8.0   48.50           446   \n",
       "2246          ليدر                1     3.0     5.0  321.75            85   \n",
       "\n",
       "      ret_t1  ret_t2       wac_p  region_median  recent_region_median  \\\n",
       "0        241     122   92.999998            5.0                   5.0   \n",
       "1          0       0   20.303747            5.0                   0.0   \n",
       "2          0       2  341.722800            1.0                   1.0   \n",
       "4          4       1  184.140000            1.0                   1.0   \n",
       "5         46       0   68.516331            2.0                   1.0   \n",
       "...      ...     ...         ...            ...                   ...   \n",
       "2242      52      16   21.007731            6.0                   6.0   \n",
       "2243     155     152  249.154204            1.0                   1.0   \n",
       "2244      39      47  248.558813            1.0                   1.0   \n",
       "2245      97       0   46.880100            2.0                   2.0   \n",
       "2246      10       3  309.426012            1.0                   1.0   \n",
       "\n",
       "            bm  \n",
       "0     0.136891  \n",
       "1     0.077102  \n",
       "2     0.057316  \n",
       "4     0.073509  \n",
       "5     0.146214  \n",
       "...        ...  \n",
       "2242  0.045103  \n",
       "2243  0.051744  \n",
       "2244  0.095327  \n",
       "2245  0.033400  \n",
       "2246  0.038303  \n",
       "\n",
       "[2107 rows x 18 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantity_disc_data=quantity_disc_data[~quantity_disc_data['product_id'].isin([21795, 11672,11671])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49c08569-d3ab-4e5c-9a13-4c2d64bf6a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "\n",
    "with base as (\n",
    "select *, row_number()over(partition by retailer_id order by priority) as rnk \n",
    "from (\n",
    "select x.*,TAGGABLE_ID as retailer_id \n",
    "from (\n",
    "select id as cohort_id,name as cohort_name,priority,dynamic_tag_id \n",
    "from cohorts \n",
    "where is_active = 'true'\n",
    "and id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    ") x \n",
    "join DYNAMIC_TAGgables dt on x.dynamic_tag_id = dt.dynamic_tag_id\n",
    ")\n",
    "qualify rnk = 1 \n",
    "order by cohort_id\n",
    ")\n",
    "\n",
    "SELECT  DISTINCT\n",
    "\t\tbase.cohort_id,\n",
    "\t\tpso.product_id,\n",
    "        pso.packing_unit_id,\n",
    "        sum(pso.total_price) as nmv\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id\n",
    "JOIN categories ON products.category_id = categories.id and categories.name_ar not like '%سايب%'\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "JOIN cities on cities.id=districts.city_id\n",
    "join states on states.id=cities.state_id\n",
    "join regions on regions.id=states.region_id\n",
    "join base on base.retailer_id = so.retailer_id\n",
    "\n",
    "WHERE   so.created_at ::date between date_trunc('month',current_date - interval '2 months') and current_date -1 \n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "    and products.activation ='true'\n",
    "\n",
    "GROUP BY ALL\n",
    "'''\n",
    "sales  = query_snowflake(query, columns = ['cohort_id','product_id','packing_unit_id','total_sales'])\n",
    "sales.product_id = pd.to_numeric(sales.product_id)\n",
    "sales.cohort_id = pd.to_numeric(sales.cohort_id)\n",
    "sales.packing_unit_id = pd.to_numeric(sales.packing_unit_id)\n",
    "sales.total_sales = pd.to_numeric(sales.total_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19719c0d-1927-4f52-b293-f10dd14abb85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "with base as (\n",
    "select *, row_number()over(partition by retailer_id order by priority) as rnk \n",
    "from (\n",
    "select x.*,TAGGABLE_ID as retailer_id \n",
    "from (\n",
    "select id as cohort_id,name as cohort_name,priority,dynamic_tag_id \n",
    "from cohorts \n",
    "where is_active = 'true'\n",
    "and id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    ") x \n",
    "join DYNAMIC_TAGgables dt on x.dynamic_tag_id = dt.dynamic_tag_id\n",
    ")\n",
    "qualify rnk = 1 \n",
    "order by cohort_id\n",
    ")\n",
    "select region,cohort_id,product_id,packing_unit_id,\n",
    "avg(num_retailers) as daily_avg_retailers,\n",
    "STDDEV(num_retailers)  as std \n",
    "from (\n",
    "select * \n",
    "from (\n",
    "select *, \n",
    "PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY num_retailers) over(partition by product_id,cohort_id,packing_unit_id)AS q1,\n",
    "PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY num_retailers) over(partition by product_id,cohort_id,packing_unit_id)AS median,\n",
    "PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY num_retailers) over(partition by product_id,cohort_id,packing_unit_id)AS q3,\n",
    "STDDEV(num_retailers) over(partition by product_id,cohort_id,packing_unit_id) as std,\n",
    "q3-q1 as iqr\n",
    "from (\n",
    "select * , dense_rank() over(partition by date,product_id,cohort_id,packing_unit_id order by num_retailers desc ) as rnk \n",
    "from (\n",
    "select date,region,cohort_id,product_id,packing_unit_id,count(distinct retailer_id) as num_retailers\n",
    "from (\n",
    "SELECT  DISTINCT\n",
    "\t\tso.created_at::date as date,\n",
    "\t\tparent_sales_order_id,\n",
    "\t\tso.retailer_id,\n",
    "\t\tbase.cohort_id,\n",
    "\t\tbase.cohort_name,\n",
    "\t\tcase when regions.id = 2 then states.name_en else regions.name_en end as region,\n",
    "\t\tpso.product_id,\n",
    "\t\tCONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "\t\tpacking_unit_id,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\n",
    "\t\tsum(pso.purchased_item_count) as qty,\n",
    "        sum(pso.total_price) as nmv,\n",
    "       sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs,\n",
    "\t   (nmv-cogs)/nmv as bm \n",
    "\t\t\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "join base on base.retailer_id = so.retailer_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id\n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN finance.all_cogs f  ON f.product_id = pso.product_id\n",
    "                        AND f.from_date::date <= so.created_at::date\n",
    "                        AND f.to_date::date > so.created_at::date\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "JOIN materialized_views.retailer_polygon on materialized_views.retailer_polygon.retailer_id=so.retailer_id\n",
    "JOIN districts on districts.id=materialized_views.retailer_polygon.district_id\n",
    "JOIN cities on cities.id=districts.city_id\n",
    "join states on states.id=cities.state_id\n",
    "join regions on regions.id=states.region_id\n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at::date between current_date -30 and  CURRENT_date-1\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "GROUP BY ALL\n",
    ")\n",
    "group by all \n",
    ")\n",
    "qualify rnk = 1 \n",
    ")\n",
    ")\n",
    "WHERE \n",
    "num_retailers >= q1-(1.2*iqr)\n",
    "and num_retailers <= q3+(1.2*iqr)\n",
    "and num_retailers between median and median+std\n",
    ")\n",
    "group by all\n",
    "order by daily_avg_retailers desc\n",
    "'''\n",
    "avg_daily  = query_snowflake(query, columns = ['region','cohort_id','product_id','packing_unit_id','daily_avg_retailers','daily_std'])\n",
    "avg_daily.product_id = pd.to_numeric(avg_daily.product_id)\n",
    "avg_daily.cohort_id = pd.to_numeric(avg_daily.cohort_id)\n",
    "avg_daily.packing_unit_id = pd.to_numeric(avg_daily.packing_unit_id)\n",
    "avg_daily.daily_avg_retailers = pd.to_numeric(avg_daily.daily_avg_retailers)\n",
    "avg_daily['daily_std'] = pd.to_numeric(avg_daily['daily_std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "987a6572-529d-484b-80ab-daeb80cbbe13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT cat, brand, margin as target_bm\n",
    "FROM    performance.commercial_targets cplan\n",
    "QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE)OVER()) = DATE_TRUNC('month', CURRENT_DATE) THEN DATE_TRUNC('month', CURRENT_DATE)\n",
    "ELSE DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    "'''\n",
    "target_margin = query_snowflake(query, columns = ['cat','brand','target_margin']) \n",
    "target_margin.target_margin=pd.to_numeric(target_margin.target_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a90c95f-82c0-4779-9f39-bb4409dd1701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select cppu.cohort_id,product_id,packing_unit_id,basic_unit_count,COALESCE(cppu.MAX_PER_SALES_ORDER,cppu2.MAX_PER_SALES_ORDER) as current_cart_rule\n",
    "from COHORT_PRODUCT_PACKING_UNITS cppu \n",
    "join PACKING_UNIT_PRODUCTS pup on cppu.PRODUCT_PACKING_UNIT_ID = pup.id \n",
    "join cohorts c on c.id = cppu.cohort_id\n",
    "join COHORT_PRODUCT_PACKING_UNITS cppu2 on cppu.PRODUCT_PACKING_UNIT_ID = cppu2.PRODUCT_PACKING_UNIT_ID and cppu2.cohort_id = c.FALLBACK_COHORT_ID \n",
    "where cppu.cohort_id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    "\n",
    "'''\n",
    "live_cart_rules = query_snowflake(query, columns = ['cohort_id','product_id','packing_unit_id','basic_unit_count','current_cart_rule']) \n",
    "live_cart_rules.cohort_id=pd.to_numeric(live_cart_rules.cohort_id)\n",
    "live_cart_rules.product_id=pd.to_numeric(live_cart_rules.product_id)\n",
    "live_cart_rules.packing_unit_id=pd.to_numeric(live_cart_rules.packing_unit_id)\n",
    "live_cart_rules.basic_unit_count=pd.to_numeric(live_cart_rules.basic_unit_count)\n",
    "live_cart_rules.current_cart_rule=pd.to_numeric(live_cart_rules.current_cart_rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f86df56-c1e5-4200-821a-e99eab569d21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#changed\n",
    "quantity_disc_data=quantity_disc_data[~quantity_disc_data['wac_p'].isna()]\n",
    "quantity_disc_data=quantity_disc_data[quantity_disc_data['bm']>0]\n",
    "quantity_disc_data = quantity_disc_data.merge(target_margin,on=['cat','brand'],how='left')\n",
    "quantity_disc_data['min'] = quantity_disc_data['target_margin'] * 0.85 \n",
    "quantity_disc_data['min'] =quantity_disc_data['min'].fillna(0.02)\n",
    "quantity_disc_data=quantity_disc_data[((quantity_disc_data['bm'] >= quantity_disc_data['min'])&(quantity_disc_data['cat']!= 'حاجه ساقعه'))|((quantity_disc_data['bm'] > 0)&(quantity_disc_data['cat']== 'حاجه ساقعه')) ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07ee47a6-83de-48e6-b5f7-30a264f4c4c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#changed\n",
    "main_df = quantity_disc_data.copy()\n",
    "main_df['t0_perc'] = main_df['ret_below_t1']/(main_df['ret_below_t1']+main_df['ret_t1']+main_df['ret_t2'])\n",
    "main_df['t1_perc'] = main_df['ret_t1']/(main_df['ret_below_t1']+main_df['ret_t1']+main_df['ret_t2'])\n",
    "main_df['t2_perc'] = main_df['ret_t2']/(main_df['ret_below_t1']+main_df['ret_t1']+main_df['ret_t2'])\n",
    "\n",
    "main_df['current_median'] =quantity_disc_data.region_median\n",
    "\n",
    "main_df['t0_to_others'] = round(0.25*main_df['ret_below_t1'])\n",
    "main_df['t0_to_t1'] = round(0.4*main_df['t0_to_others'])\n",
    "main_df['t0_to_t2'] = round(0.6*main_df['t0_to_others'])\n",
    "\n",
    "main_df['t0_new_rets'] = main_df['ret_below_t1']-main_df['t0_to_others']\n",
    "main_df['t1_new_rets'] = main_df['ret_t1']+main_df['t0_to_t1']\n",
    "main_df['t2_new_rets'] = main_df['ret_t2']+main_df['t0_to_t2']\n",
    "\n",
    "main_df['t0_new_perc'] = main_df['t0_new_rets']/(main_df['t0_new_rets']+main_df['t1_new_rets']+main_df['t2_new_rets'])\n",
    "main_df['t1_new_perc'] = main_df['t1_new_rets']/(main_df['t0_new_rets']+main_df['t1_new_rets']+main_df['t2_new_rets'])\n",
    "main_df['t2_new_perc'] = main_df['t2_new_rets']/(main_df['t0_new_rets']+main_df['t1_new_rets']+main_df['t2_new_rets'])\n",
    "\n",
    "main_df['new_median'] = (main_df['t0_new_perc']*quantity_disc_data.region_median)+(main_df['t1_new_perc']*main_df['tier_1'] )+(main_df['t2_new_perc']*main_df['tier_2'])\n",
    "\n",
    "main_df['t1_nmv'] = main_df['price']*(main_df['t0_new_rets']+main_df['t1_new_rets']+main_df['t2_new_rets'])*main_df['tier_1']*main_df['t1_new_perc']\n",
    "main_df['t2_nmv'] = main_df['price']*(main_df['t0_new_rets']+main_df['t1_new_rets']+main_df['t2_new_rets'])*main_df['tier_2']*main_df['t2_new_perc']\n",
    "\n",
    "main_df['median_diff'] = main_df['new_median']-main_df['current_median']\n",
    "main_df['OA_increase'] = main_df['median_diff']*main_df['price']*(main_df['t0_new_rets']+main_df['t1_new_rets']+main_df['t2_new_rets'])*main_df['bm']\n",
    "main_df['OA_burn'] = main_df['OA_increase']/(main_df['t1_nmv']+main_df['t2_nmv'])\n",
    "########old######\n",
    "# cond = [main_df['OA_burn']>=0.04 , main_df['OA_burn']<0.04]\n",
    "# cho = [np.minimum(np.maximum((1-((main_df['OA_burn']-0.03)/0.03))-0.33,0.15),0.4),0.4]\n",
    "# main_df['burn_take'] = np.select(cond,cho,default = 0.4)\n",
    "########new######\n",
    "main_df['burn_2'] = 0.02*(main_df['t1_nmv']+main_df['t2_nmv'])\n",
    "main_df['burn_40'] = 0.45*main_df['OA_increase']\n",
    "main_df['Burn_perc_margin'] = (0.3*main_df['bm'])*(main_df['t1_nmv']+main_df['t2_nmv'])\n",
    "main_df['Burn_use']=np.minimum(np.minimum(main_df['burn_2'],main_df['burn_40']),main_df['Burn_perc_margin'])\n",
    "##################\n",
    "main_df['t1_nmv_cntrb'] = main_df['t1_nmv']/(main_df['t1_nmv'] +main_df['t2_nmv']) \n",
    "main_df['t2_nmv_cntrb'] = main_df['t2_nmv']/(main_df['t1_nmv'] +main_df['t2_nmv']) \n",
    "\n",
    "main_df['Tiers_diff'] =  (main_df['tier_2'] - main_df['tier_1'] )/ main_df['tier_1']\n",
    "main_df['Discount_t1'] = ((main_df['Burn_use']/(1+main_df['Tiers_diff']))*main_df['t1_nmv_cntrb'])/main_df['t1_nmv'] \n",
    "main_df['Discount_t2'] = (main_df['Burn_use'] - ((main_df['Burn_use']/(1+main_df['Tiers_diff']))*main_df['t1_nmv_cntrb']))/main_df['t2_nmv'] \n",
    "\n",
    "main_df = main_df[(~main_df['Discount_t1'].isna()) & (~main_df['Discount_t2'].isna())]\n",
    "main_df = main_df[(main_df['t0_new_rets']>0) &(main_df['t1_new_rets']>0) & (main_df['t2_new_rets']>0)]\n",
    "main_df = main_df[(main_df['bm']>0)]\n",
    "main_df = main_df[(main_df['Discount_t1']>0) &(main_df['Discount_t2']>0)]\n",
    "main_df=main_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c1a9f60-f8f5-43b5-b7d7-9f642ae5d9f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_df = main_df.merge(sales,on = ['cohort_id','product_id','packing_unit_id'])\n",
    "main_df = main_df.merge(avg_daily,on = ['region','cohort_id','product_id','packing_unit_id'])\n",
    "main_df= main_df.sort_values(['cohort_id', 'total_sales'], ascending=[True, False])\n",
    "main_df['row_number'] = main_df.groupby('cohort_id').cumcount() + 1\n",
    "main_df = main_df[main_df['row_number']<=100]\n",
    "main_df = main_df[main_df['cohort_id'].isin([700,701,702,703,704,1123])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "592b9f97-a51f-4e66-ae3c-a3fbfa9e87a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_quantity_discount = pd.DataFrame(columns =['region','Discounts Group 1','Discounts Group 2','Description'])\n",
    "for reg in main_df.region.unique():\n",
    "    region_data = main_df[main_df['region']== reg]\n",
    "    for i,r in region_data.iterrows():\n",
    "        region = r['region']\n",
    "        product_id = r['product_id']\n",
    "        packing_unit_id = r['packing_unit_id']\n",
    "        q_1 = int(r['tier_1'])\n",
    "        q_2 = int(r['tier_2'])\n",
    "        d_1 = round(r['Discount_t1']*100,2)\n",
    "        d_2 = round(r['Discount_t2']*100,2)\n",
    "        a_1 = [product_id]+[packing_unit_id]+[q_1]+[d_1]\n",
    "        a_2 = [product_id]+[packing_unit_id]+[q_2]+[d_2]\n",
    "        new_row = {'region':region ,'Discounts Group 1':a_1,'Discounts Group 2':a_2,'Description':f'{reg}QD'}\n",
    "        new_row_df = pd.DataFrame([new_row]) \n",
    "        final_quantity_discount = pd.concat([final_quantity_discount, new_row_df], ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7cb05267-8d58-47d3-9f8f-77c6a4d7beb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Tag_def = {\n",
    "    'region': ['Cairo', 'Giza', 'Alexandria', 'Upper Egypt', 'Delta East', 'Delta West'],\n",
    "    'Tag ID': [2807, 2808, 2809, 2810, 2811, 2812]\n",
    "}\n",
    "\n",
    "Tag_map = pd.DataFrame(Tag_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f08c55a-c51b-4ac4-a2d1-f028d44e8146",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#changed\n",
    "slots = ['0-12','13-17','18-23']\n",
    "local_tz = pytz.timezone('Africa/Cairo')\n",
    "current_hour = datetime.now(local_tz).hour\n",
    "chosen_slot = [np.nan,np.nan]\n",
    "\n",
    "for slot in slots:\n",
    "    parts = slot.split(\"-\")\n",
    "    if(current_hour >= int(parts[0]) and current_hour < int(parts[1])):\n",
    "        chosen_slot[0] = int(parts[0]) \n",
    "        chosen_slot[1] = int(parts[1]) \n",
    "        break\n",
    "    else:\n",
    "        chosen_slot[0] = 0\n",
    "        chosen_slot[1] = 0 \n",
    "        \n",
    "today = datetime.now(local_tz) \n",
    "start_hour = np.maximum(current_hour,chosen_slot[0])\n",
    "if(start_hour==current_hour):\n",
    "    start_mins =  (datetime.now(local_tz).minute) +10\n",
    "else:\n",
    "    start_mins = 30 \n",
    "    \n",
    "    \n",
    "start_date = (today.replace(hour=start_hour, minute=0, second=0, microsecond=0)+ timedelta(minutes=start_mins)).strftime('%d/%m/%Y %H:%M')\n",
    "end_date = (today.replace(hour=chosen_slot[1], minute=59, second=0, microsecond=0)).strftime('%d/%m/%Y %H:%M')\n",
    "final_quantity_discount = final_quantity_discount.merge(Tag_map,on='region')\n",
    "final_quantity_discount['Start Date/Time']= start_date\n",
    "final_quantity_discount['End Date/Time']= end_date\n",
    "main_df['start_date'] = start_date\n",
    "main_df['end_date'] = end_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b505642a-51af-48e0-a964-97a4f0c649ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_df = main_df.merge(Tag_map,on='region')\n",
    "main_df = main_df.rename(columns={'Tag ID':'tag_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "063ea24c-c40d-45c4-ba07-bb32b12119a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cart_rules_data = main_df[['region','product_id','packing_unit_id','tier_2']].copy()\n",
    "cohort_def = {\n",
    "    'region': ['Cairo', 'Giza', 'Alexandria', 'Delta East', 'Delta West','Upper Egypt','Upper Egypt','Upper Egypt','Upper Egypt'],\n",
    "    'cohort_id': [700, 701, 702, 704, 703, 1123,1124,1125,1126]\n",
    "}\n",
    "region_cohort_map = pd.DataFrame(cohort_def)\n",
    "cart_rules_data = cart_rules_data.merge(region_cohort_map,on='region')\n",
    "cart_rules_data = cart_rules_data.merge(live_cart_rules,on=['cohort_id','product_id','packing_unit_id'])\n",
    "cart_rules_data = cart_rules_data[cart_rules_data['tier_2']>cart_rules_data['current_cart_rule']]\n",
    "cart_rules_data=cart_rules_data[['cohort_id','product_id','packing_unit_id','tier_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cc9ad44-c8b7-4d34-980d-027652da8b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data = final_quantity_discount.groupby(['Tag ID','Description', 'Start Date/Time', 'End Date/Time'], as_index=False).agg({\n",
    "    'Discounts Group 1': list ,\n",
    "    'Discounts Group 2' : list\n",
    "})\n",
    "final_data.to_excel('QD_upload.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb654302-6107-4d00-999c-8f644420b5a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # In this sample we only handle the specific exceptions for the 'GetSecretValue' API.\n",
    "    # See https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "    # We rethrow the exception by default.\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            # Secrets Manager can't decrypt the protected secret text using the provided KMS key.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            # An error occurred on the server side.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            # You provided an invalid value for a parameter.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            # You provided a parameter value that is not valid for the current state of the resource.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            # We can't find the resource that you asked for.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "    else:\n",
    "        # Decrypts secret using the associated KMS CMK.\n",
    "        # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            return get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            return base64.b64decode(get_secret_value_response['SecretBinary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aac8cc6-014b-4329-945a-404ff3d88298",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pricing_api_secret = json.loads(get_secret(\"prod/pricing/api/\"))\n",
    "username = pricing_api_secret[\"egypt_username\"]\n",
    "password = pricing_api_secret[\"egypt_password\"]\n",
    "secret = pricing_api_secret[\"egypt_secret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d097975d-4b0f-470e-8b97-1f8433aa714a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_access_token(url, client_id, client_secret):\n",
    "    \"\"\"\n",
    "    get_access_token function takes three parameters and returns a session token\n",
    "    to connect to MaxAB APIs\n",
    "\n",
    "    :param url: production MaxAB token URL\n",
    "    :param client_id: client ID\n",
    "    :param client_secret: client sercret\n",
    "    :return: session token\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        data={\"grant_type\": \"password\",\n",
    "              \"username\": username,\n",
    "              \"password\": password},\n",
    "        auth=(client_id, client_secret),\n",
    "    )\n",
    "    return response.json()[\"access_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2822c781-728c-4878-9f7e-0f9e5559d98f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_QD(file_name):\n",
    "    token = get_access_token('https://sso.maxab.info/auth/realms/maxab/protocol/openid-connect/token',\n",
    "                             'main-system-externals',\n",
    "                             secret)\n",
    "    url = \"https://api.maxab.info/commerce/api/admins/v1/quantity-discounts\"\n",
    "    payload={}\n",
    "    files=[\n",
    "      ('file',(file_name,open(file_name,'rb'),'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'))\n",
    "    ]\n",
    "    headers = {\n",
    "      'Authorization': 'bearer {}'.format(token)}\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload, files=files)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4921ac32-c33d-4891-82d7-a16a8067ac21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def post_cart_rules(id_,file_name):\n",
    "    token = get_access_token('https://sso.maxab.info/auth/realms/maxab/protocol/openid-connect/token',\n",
    "                             'main-system-externals',\n",
    "                             secret)\n",
    "    url = \"https://api.maxab.info/main-system/api/admin-portal/cohorts/{}/cart-rules\".format(id_)\n",
    "    payload={}\n",
    "    files=[\n",
    "      ('sheet',(file_name,open(file_name,'rb'),'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'))\n",
    "    ]\n",
    "    headers = {\n",
    "      'Authorization': 'bearer {}'.format(token)}\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload, files=files)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed94b38e-0cd7-4007-b47c-569de4c0a375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def writer_snowflake_query(query):\n",
    "    import os\n",
    "    import snowflake.connector\n",
    "\n",
    "    config = {\n",
    "        'user': os.environ[\"SNOWFLAKE_SERVICE_USERNAME\"],\n",
    "        'account': os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        'private_key_file': '/tmp/sagemaker_service.p8',\n",
    "        'database': os.environ[\"SNOWFLAKE_DATABASE\"] ,\n",
    "        'role': os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "        'schema': 'PUBLIC'\n",
    "        }\n",
    "\n",
    "    conn = snowflake.connector.connect(**config)\n",
    "\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        return 1\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "    finally:\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "\n",
    "def pandas_dtype_to_snowflake(dtype):\n",
    "    \"\"\"Maps pandas/numpy dtype to Snowflake SQL data type.\"\"\"\n",
    "    if pd.api.types.is_integer_dtype(dtype):\n",
    "        return \"NUMBER,\"\n",
    "    elif pd.api.types.is_float_dtype(dtype):\n",
    "        return \"FLOAT,\"\n",
    "    elif pd.api.types.is_bool_dtype(dtype):\n",
    "        return \"BOOLEAN,\"\n",
    "    elif pd.api.types.is_datetime64_any_dtype(dtype):\n",
    "        return \"TIMESTAMP,\"\n",
    "    elif pd.api.types.is_object_dtype(dtype):\n",
    "        return \"TEXT,\"\n",
    "    elif pd.api.types.is_categorical_dtype(dtype):\n",
    "        return \"TEXT,\"\n",
    "    else:\n",
    "        return \"TEXT,\"  # fallback\n",
    "\n",
    "def dataframe_to_snowflake_columns(df, table_name):\n",
    "    \"\"\"Generates Snowflake-compatible column definitions from a DataFrame.\"\"\"\n",
    "    lines = [f'CREATE TABLE IF NOT EXISTS {table_name} (']\n",
    "    for col in df.columns:\n",
    "        snowflake_type = pandas_dtype_to_snowflake(df[col].dtype)\n",
    "        if col.lower() in ['group', 'section']:\n",
    "            col = f'\"{col}\"'\n",
    "        if col.lower() in ['start_date', 'end_date']:\n",
    "            lines.append(f'{col} TIMESTAMP,')\n",
    "        else:\n",
    "            lines.append(f'{col} {snowflake_type}')\n",
    "    return \"\\n\".join(lines)[:-1] + ');'\n",
    "\n",
    "# create tables if not exist\n",
    "def table_exist_test(df, table_name):\n",
    "    query_string = dataframe_to_snowflake_columns(df, table_name)\n",
    "    writer_snowflake_query(query_string)\n",
    "\n",
    "# Snowflake DB query to write into tables\n",
    "def eg_snowflake_writer(df, table, schema):\n",
    "    import os\n",
    "    import snowflake.connector\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from snowflake.connector.pandas_tools import write_pandas\n",
    "    import os\n",
    "\n",
    "    config = {\n",
    "        'user': os.environ[\"SNOWFLAKE_SERVICE_USERNAME\"],\n",
    "        'account': os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        'private_key_file': '/tmp/sagemaker_service.p8',\n",
    "        'database': os.environ[\"SNOWFLAKE_DATABASE\"] ,\n",
    "        'role': os.environ[\"SNOWFLAKE_ROLE\"],\n",
    "        'schema': 'PUBLIC'\n",
    "    }\n",
    "    conn = snowflake.connector.connect(**config)\n",
    "    success, _, _, _ = write_pandas(conn=conn, df=df, table_name=table, schema=schema)\n",
    "    return success \n",
    "\n",
    "def DatabaseDump(df, path, erase='False'):\n",
    "    # initialize the standard command\n",
    "    command_string = f\"DELETE FROM {path} WHERE True\"\n",
    "    print_string = f\"Succesfuly Removed & Re-Added Data \\n for {path}\"\n",
    "\n",
    "    # if the flag is 'false', erase latest push (day / time_slot)\n",
    "    if erase.lower() == 'false':\n",
    "        if \"start_date\" in df.columns.str.lower():\n",
    "            date_value = main_df.start_date.values[0]\n",
    "            print(date_value)\n",
    "            command_string += f\" AND start_date = TO_TIMESTAMP('{date_value}')\"\n",
    "            print(command_string)\n",
    "            print_string += f\"\\ndate = {df['start_date'].values[0]}\"\n",
    "\n",
    "        if \"cohort_id\" in df.columns.str.lower():\n",
    "            command_string += f\" AND cohort_id IN {tuple(df.cohort_id.unique())}\"\n",
    "            print_string += f\"\\nCohort IDs IN {tuple(df.cohort_id.unique())}\"\n",
    "\n",
    "    # if the flag is 'month', erase current month\n",
    "    if erase.lower() == 'month':\n",
    "        if \"created_at\" in df.columns.str.lower():\n",
    "            command_string += f\" AND DATE_TRUNC('month', created_at) = DATE_TRUNC('month', SYSDATE())\"\n",
    "            print_string += f\"\\ndate = Current month\"\n",
    "        if \"date\" in df.columns.str.lower():\n",
    "            command_string += f\" AND DATE_TRUNC('month', date) = DATE_TRUNC('month', SYSDATE())\"\n",
    "            print_string += f\"\\ndate = Current month\"\n",
    "\n",
    "    # Remove data of the same day, time_slot, etc...\n",
    "    writer_snowflake_query(command_string)\n",
    "\n",
    "    # Push the new data to the table\n",
    "    df.columns = df.columns.str.upper()\n",
    "    eg_snowflake_writer(df, path.split('.')[1].upper(), path.split('.')[0].upper())\n",
    "    print(print_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d64581c9-c3e2-4e93-a1c8-646d40f0e9a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_1126\n",
      "success_1123\n",
      "success_703\n",
      "success_701\n",
      "success_1124\n",
      "success_702\n",
      "success_1125\n",
      "success_700\n",
      "success_704\n"
     ]
    }
   ],
   "source": [
    "for cohort in cart_rules_data.cohort_id.unique():\n",
    "    req_data = cart_rules_data[cart_rules_data['cohort_id']==cohort]\n",
    "    if len(req_data) > 0 :\n",
    "        req_data = req_data[['product_id','packing_unit_id','tier_2']]\n",
    "        req_data.columns = ['Product ID','Packing Unit ID','Cart Rules']\n",
    "        req_data.to_excel(f'CartRules_{cohort}.xlsx', index=False, engine='xlsxwriter')\n",
    "        time.sleep(5)\n",
    "        x =  post_cart_rules(cohort,f'CartRules_{cohort}.xlsx')\n",
    "        if x.ok:\n",
    "            print(f\"success_{cohort}\")\n",
    "        else:\n",
    "            print(f\"ERROR_{cohort}\")\n",
    "            print(x.content)\n",
    "            break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c27a037-7eea-4d3f-997b-28cb2db15bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-21 17:31\n",
      "DELETE FROM materialized_views.qd_targets WHERE True AND start_date = TO_TIMESTAMP('2025-10-21 17:31')\n",
      "Succesfuly Removed & Re-Added Data \n",
      " for materialized_views.qd_targets\n",
      "date = 2025-10-21 17:31\n",
      "Cohort IDs IN (700, 701, 702, 703, 704, 1123)\n"
     ]
    }
   ],
   "source": [
    "#changed\n",
    "response = post_QD('QD_upload.xlsx')\n",
    "if response.ok:\n",
    "    main_df.start_date = pd.to_datetime(main_df.start_date, format=\"%d/%m/%Y %H:%M\").dt.strftime('%Y-%m-%d %H:%M')\n",
    "    main_df.end_date = pd.to_datetime(main_df.end_date, format=\"%d/%m/%Y %H:%M\").dt.strftime('%Y-%m-%d %H:%M')\n",
    "    main_df['cohort_id'] = pd.to_numeric(main_df['cohort_id'])\n",
    "    table_exist_test(main_df, \"materialized_views.qd_targets\")\n",
    "    main_df = main_df.drop(columns=[\"Burn_perc_margin\"])\n",
    "    DatabaseDump(main_df.reset_index(drop=True), \"materialized_views.qd_targets\")\n",
    "    \n",
    "else:\n",
    "    print(\"Failed with status:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b6005be3-cc3c-4a32-a5e4-97bf15df6aee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>cohort_name</th>\n",
       "      <th>product_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>cat</th>\n",
       "      <th>brand</th>\n",
       "      <th>packing_unit_id</th>\n",
       "      <th>tier_1</th>\n",
       "      <th>tier_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Tiers_diff</th>\n",
       "      <th>Discount_t1</th>\n",
       "      <th>Discount_t2</th>\n",
       "      <th>total_sales</th>\n",
       "      <th>daily_avg_retailers</th>\n",
       "      <th>daily_std</th>\n",
       "      <th>row_number</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>tag_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cairo</td>\n",
       "      <td>700</td>\n",
       "      <td>Pricing_Model_Cairo_V2</td>\n",
       "      <td>130</td>\n",
       "      <td>لبن بخيره - 500 مل</td>\n",
       "      <td>ألبان</td>\n",
       "      <td>بخيره</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.006158</td>\n",
       "      <td>0.012822</td>\n",
       "      <td>7.906960e+06</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>6.572086</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-10-21 17:31</td>\n",
       "      <td>2025-10-21 00:59</td>\n",
       "      <td>2807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cairo</td>\n",
       "      <td>700</td>\n",
       "      <td>Pricing_Model_Cairo_V2</td>\n",
       "      <td>6935</td>\n",
       "      <td>كوكاكولا اكشن - 300 مل</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>كوكا كولا</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.008421</td>\n",
       "      <td>0.028825</td>\n",
       "      <td>6.620265e+06</td>\n",
       "      <td>124.555556</td>\n",
       "      <td>16.644151</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-10-21 17:31</td>\n",
       "      <td>2025-10-21 00:59</td>\n",
       "      <td>2807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cairo</td>\n",
       "      <td>700</td>\n",
       "      <td>Pricing_Model_Cairo_V2</td>\n",
       "      <td>3</td>\n",
       "      <td>ارز حبوبة رفيع - 1 كجم</td>\n",
       "      <td>أرز</td>\n",
       "      <td>حبوبة</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.025423</td>\n",
       "      <td>6.223385e+06</td>\n",
       "      <td>114.769231</td>\n",
       "      <td>11.181487</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-10-21 17:31</td>\n",
       "      <td>2025-10-21 00:59</td>\n",
       "      <td>2807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cairo</td>\n",
       "      <td>700</td>\n",
       "      <td>Pricing_Model_Cairo_V2</td>\n",
       "      <td>151</td>\n",
       "      <td>لبن بخيره - 1 لتر</td>\n",
       "      <td>ألبان</td>\n",
       "      <td>بخيره</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>0.017931</td>\n",
       "      <td>5.794120e+06</td>\n",
       "      <td>103.230769</td>\n",
       "      <td>8.709706</td>\n",
       "      <td>4</td>\n",
       "      <td>2025-10-21 17:31</td>\n",
       "      <td>2025-10-21 00:59</td>\n",
       "      <td>2807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cairo</td>\n",
       "      <td>700</td>\n",
       "      <td>Pricing_Model_Cairo_V2</td>\n",
       "      <td>2049</td>\n",
       "      <td>كوفى بريك 2*1 - 11 جم</td>\n",
       "      <td>قهوة</td>\n",
       "      <td>كوفي بريك</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.013337</td>\n",
       "      <td>4.718232e+06</td>\n",
       "      <td>30.461538</td>\n",
       "      <td>3.843076</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-10-21 17:31</td>\n",
       "      <td>2025-10-21 00:59</td>\n",
       "      <td>2807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>1123</td>\n",
       "      <td>El_Minya_pricing_Cohort</td>\n",
       "      <td>12764</td>\n",
       "      <td>صابون دوش عرض خاص - 110 جم</td>\n",
       "      <td>صابون</td>\n",
       "      <td>دوش</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.008714</td>\n",
       "      <td>0.017646</td>\n",
       "      <td>1.724325e+04</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>0.527046</td>\n",
       "      <td>96</td>\n",
       "      <td>2025-10-21 17:31</td>\n",
       "      <td>2025-10-21 00:59</td>\n",
       "      <td>2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>1123</td>\n",
       "      <td>El_Minya_pricing_Cohort</td>\n",
       "      <td>1801</td>\n",
       "      <td>شامبو كلير رجالى ازرق اخضر و اسود - 5 مل</td>\n",
       "      <td>شامبو و شاور جيل</td>\n",
       "      <td>كلير</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>1.610029e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>97</td>\n",
       "      <td>2025-10-21 17:31</td>\n",
       "      <td>2025-10-21 00:59</td>\n",
       "      <td>2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>1123</td>\n",
       "      <td>El_Minya_pricing_Cohort</td>\n",
       "      <td>432</td>\n",
       "      <td>مشروب كادبوري مشروب كاكاو - 30 جم</td>\n",
       "      <td>كاكاو و مبيضات</td>\n",
       "      <td>كادبوري</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>0.022460</td>\n",
       "      <td>1.566675e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98</td>\n",
       "      <td>2025-10-21 17:31</td>\n",
       "      <td>2025-10-21 00:59</td>\n",
       "      <td>2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>1123</td>\n",
       "      <td>El_Minya_pricing_Cohort</td>\n",
       "      <td>8898</td>\n",
       "      <td>كوكيز العبد بقطع الشوكولاتة  - 10 جنية</td>\n",
       "      <td>بسكويت و معمول</td>\n",
       "      <td>العبد</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.022735</td>\n",
       "      <td>1.513775e+04</td>\n",
       "      <td>2.272727</td>\n",
       "      <td>0.467100</td>\n",
       "      <td>99</td>\n",
       "      <td>2025-10-21 17:31</td>\n",
       "      <td>2025-10-21 00:59</td>\n",
       "      <td>2810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>1123</td>\n",
       "      <td>El_Minya_pricing_Cohort</td>\n",
       "      <td>8285</td>\n",
       "      <td>صابون كامى كلاسيك - 115 جم</td>\n",
       "      <td>صابون</td>\n",
       "      <td>كامى</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.010396</td>\n",
       "      <td>0.019252</td>\n",
       "      <td>1.473789e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>2025-10-21 17:31</td>\n",
       "      <td>2025-10-21 00:59</td>\n",
       "      <td>2810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          region  cohort_id              cohort_name  product_id  \\\n",
       "0          Cairo        700   Pricing_Model_Cairo_V2         130   \n",
       "1          Cairo        700   Pricing_Model_Cairo_V2        6935   \n",
       "2          Cairo        700   Pricing_Model_Cairo_V2           3   \n",
       "3          Cairo        700   Pricing_Model_Cairo_V2         151   \n",
       "4          Cairo        700   Pricing_Model_Cairo_V2        2049   \n",
       "..           ...        ...                      ...         ...   \n",
       "595  Upper Egypt       1123  El_Minya_pricing_Cohort       12764   \n",
       "596  Upper Egypt       1123  El_Minya_pricing_Cohort        1801   \n",
       "597  Upper Egypt       1123  El_Minya_pricing_Cohort         432   \n",
       "598  Upper Egypt       1123  El_Minya_pricing_Cohort        8898   \n",
       "599  Upper Egypt       1123  El_Minya_pricing_Cohort        8285   \n",
       "\n",
       "                                          sku               cat      brand  \\\n",
       "0                          لبن بخيره - 500 مل             ألبان      بخيره   \n",
       "1                      كوكاكولا اكشن - 300 مل        حاجه ساقعه  كوكا كولا   \n",
       "2                      ارز حبوبة رفيع - 1 كجم               أرز      حبوبة   \n",
       "3                           لبن بخيره - 1 لتر             ألبان      بخيره   \n",
       "4                       كوفى بريك 2*1 - 11 جم              قهوة  كوفي بريك   \n",
       "..                                        ...               ...        ...   \n",
       "595                صابون دوش عرض خاص - 110 جم             صابون        دوش   \n",
       "596  شامبو كلير رجالى ازرق اخضر و اسود - 5 مل  شامبو و شاور جيل       كلير   \n",
       "597         مشروب كادبوري مشروب كاكاو - 30 جم    كاكاو و مبيضات    كادبوري   \n",
       "598    كوكيز العبد بقطع الشوكولاتة  - 10 جنية    بسكويت و معمول      العبد   \n",
       "599                صابون كامى كلاسيك - 115 جم             صابون       كامى   \n",
       "\n",
       "     packing_unit_id  tier_1  tier_2  ...  Tiers_diff  Discount_t1  \\\n",
       "0                  1     3.0     5.0  ...    0.666667     0.006158   \n",
       "1                  2     8.0    19.0  ...    1.375000     0.008421   \n",
       "2                  2     4.0     7.0  ...    0.750000     0.011429   \n",
       "3                  1     3.0     6.0  ...    1.000000     0.006115   \n",
       "4                  1     3.0     5.0  ...    0.666667     0.006748   \n",
       "..               ...     ...     ...  ...         ...          ...   \n",
       "595                2     5.0     7.0  ...    0.400000     0.008714   \n",
       "596                1     3.0     5.0  ...    0.666667     0.012000   \n",
       "597                3     4.0     6.0  ...    0.500000     0.011672   \n",
       "598                3     4.0     6.0  ...    0.500000     0.013333   \n",
       "599                2     4.0     6.0  ...    0.500000     0.010396   \n",
       "\n",
       "     Discount_t2   total_sales  daily_avg_retailers  daily_std  row_number  \\\n",
       "0       0.012822  7.906960e+06           143.500000   6.572086           1   \n",
       "1       0.028825  6.620265e+06           124.555556  16.644151           2   \n",
       "2       0.025423  6.223385e+06           114.769231  11.181487           3   \n",
       "3       0.017931  5.794120e+06           103.230769   8.709706           4   \n",
       "4       0.013337  4.718232e+06            30.461538   3.843076           5   \n",
       "..           ...           ...                  ...        ...         ...   \n",
       "595     0.017646  1.724325e+04             2.444444   0.527046          96   \n",
       "596     0.024800  1.610029e+04             1.000000   0.000000          97   \n",
       "597     0.022460  1.566675e+04             2.000000   0.000000          98   \n",
       "598     0.022735  1.513775e+04             2.272727   0.467100          99   \n",
       "599     0.019252  1.473789e+04             2.000000   0.000000         100   \n",
       "\n",
       "           start_date          end_date  tag_id  \n",
       "0    2025-10-21 17:31  2025-10-21 00:59    2807  \n",
       "1    2025-10-21 17:31  2025-10-21 00:59    2807  \n",
       "2    2025-10-21 17:31  2025-10-21 00:59    2807  \n",
       "3    2025-10-21 17:31  2025-10-21 00:59    2807  \n",
       "4    2025-10-21 17:31  2025-10-21 00:59    2807  \n",
       "..                ...               ...     ...  \n",
       "595  2025-10-21 17:31  2025-10-21 00:59    2810  \n",
       "596  2025-10-21 17:31  2025-10-21 00:59    2810  \n",
       "597  2025-10-21 17:31  2025-10-21 00:59    2810  \n",
       "598  2025-10-21 17:31  2025-10-21 00:59    2810  \n",
       "599  2025-10-21 17:31  2025-10-21 00:59    2810  \n",
       "\n",
       "[600 rows x 54 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b98a67-9cb6-4d71-91cb-94d7e96f317f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
