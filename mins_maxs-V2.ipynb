{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e32a9-ef1a-474a-a2f7-e291561f6da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# =============================================================================\n",
    "# PACKAGE INSTALLATION\n",
    "# =============================================================================\n",
    "!pip install --upgrade pip\n",
    "\n",
    "# Database Connectivity\n",
    "!pip install psycopg2-binary snowflake-connector-python==3.15.0 snowflake-sqlalchemy\n",
    "\n",
    "# Authentication & Cloud\n",
    "!pip install keyring==23.11.0 sqlalchemy==1.4.46 requests boto3\n",
    "!pip install oauth2client gspread==5.9.0 gspread_dataframe google.cloud\n",
    "\n",
    "# Data Processing\n",
    "!pip install pandas==2.2.1 numpy polars openpyxl xlsxwriter\n",
    "\n",
    "# Utilities\n",
    "!pip install tqdm db-dtypes pytz import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b73aac-2b7a-491b-80f9-674d0b9a67a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS & ENVIRONMENT SETUP\n",
    "# =============================================================================\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import importlib\n",
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import snowflake.connector\n",
    "\n",
    "import setup_environment_2\n",
    "import import_ipynb\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize environment\n",
    "importlib.reload(setup_environment_2)\n",
    "setup_environment_2.initialize_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ec765-6d3d-436f-bd59-76eda7de4e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Pricing status mode: \"min_market\" adjusts tiers down by 1\n",
    "STATUS = \"min_market\"\n",
    "\n",
    "# Google Sheets API scope\n",
    "GSHEETS_SCOPE = [\n",
    "    \"https://spreadsheets.google.com/feeds\",\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\",\n",
    "    \"https://www.googleapis.com/auth/drive.file\",\n",
    "    \"https://www.googleapis.com/auth/drive\"\n",
    "]\n",
    "\n",
    "# Brand/Category pricing rules\n",
    "BELOW_MARKET_BRANDS = ['شويبس', 'كوكا كولا']\n",
    "MIN_PRICE_BRANDS = ['فاميليا', 'مولبد', 'مولفيكس', 'اوكسي', 'جوي', 'ريفولي', 'البوادي', 'هارفست فوودز', 'هاينز', 'بيبسي']\n",
    "AVG_PRICE_BRANDS = ['بخيره', 'جود كير']\n",
    "MAX_PRICE_BRANDS = ['فيوري']\n",
    "MIN_PRICE_CATEGORIES = ['تونة و سمك']\n",
    "\n",
    "# Warehouse mapping\n",
    "WAREHOUSE_CONFIG = pd.DataFrame([\n",
    "    ('Cairo', 'El-Marg', 38, 700),\n",
    "    ('Cairo', 'Mostorod', 1, 700),\n",
    "    ('Giza', 'Barageel', 236, 701),\n",
    "    ('Delta West', 'El-Mahala', 337, 703),\n",
    "    ('Delta West', 'Tanta', 8, 703),\n",
    "    ('Delta East', 'Mansoura FC', 339, 704),\n",
    "    ('Delta East', 'Sharqya', 170, 704),\n",
    "    ('Upper Egypt', 'Assiut FC', 501, 1124),\n",
    "    ('Upper Egypt', 'Bani sweif', 401, 1126),\n",
    "    ('Upper Egypt', 'Menya Samalot', 703, 1123),\n",
    "    ('Upper Egypt', 'Sohag', 632, 1125),\n",
    "    ('Alexandria', 'Khorshed Alex', 797, 702),\n",
    "    ('Giza', 'Sakkarah', 962, 701)\n",
    "], columns=['region', 'warehouse', 'warehouse_id', 'cohort_id'])\n",
    "\n",
    "# Region to cohort mapping\n",
    "REGION_COHORT_MAP = pd.DataFrame({\n",
    "    'region': ['Cairo', 'Giza', 'Delta West', 'Delta East', 'Upper Egypt', \n",
    "               'Upper Egypt', 'Upper Egypt', 'Upper Egypt', 'Alexandria'],\n",
    "    'cohort_id': [700, 701, 703, 704, 1124, 1126, 1123, 1125, 702]\n",
    "})\n",
    "\n",
    "# Products to exclude from TGTG processing\n",
    "TGTG_EXCLUSIONS = pd.DataFrame([\n",
    "    (8673, 401)\n",
    "], columns=['product_id', 'warehouse_id'])\n",
    "TGTG_EXCLUSIONS['remove'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc41c3e-734d-43f3-8964-1c9fd8e676bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def query_snowflake(query, columns=None):\n",
    "    \"\"\"Execute a query on Snowflake and return results as DataFrame.\"\"\"\n",
    "    con = snowflake.connector.connect(\n",
    "        user=os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database=os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        data = cur.fetchall()\n",
    "        return pd.DataFrame(data, columns=columns) if columns else pd.DataFrame(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Snowflake Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()\n",
    "\n",
    "\n",
    "def get_gsheets_client():\n",
    "    \"\"\"Get authenticated Google Sheets client.\"\"\"\n",
    "    creds = ServiceAccountCredentials.from_json_keyfile_dict(\n",
    "        json.loads(setup_environment_2.get_secret(\"prod/maxab-sheets\")), \n",
    "        GSHEETS_SCOPE\n",
    "    )\n",
    "    return gspread.authorize(creds)\n",
    "\n",
    "\n",
    "def to_numeric_columns(df):\n",
    "    \"\"\"Convert all columns to numeric where possible.\"\"\"\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "    return df\n",
    "\n",
    "\n",
    "def assign_tier(cumulative_contribution):\n",
    "    \"\"\"Assign pricing tier based on cumulative NMV contribution.\"\"\"\n",
    "    thresholds = [0.4, 0.6, 0.8, 0.95]\n",
    "    for i, threshold in enumerate(thresholds, 1):\n",
    "        if cumulative_contribution <= threshold:\n",
    "            return i\n",
    "    return 5\n",
    "\n",
    "\n",
    "def price_analysis(row):\n",
    "    \"\"\"Analyze prices and calculate percentiles for a product.\"\"\"\n",
    "    wac = row['wac_p']\n",
    "    avg_margin = row['avg_margin'] if row['avg_margin'] >= 0.01 else row['target_margin']\n",
    "    std = row['std']\n",
    "    \n",
    "    # Collect all price points\n",
    "    price_list = [\n",
    "        row['ben_soliman_price'], row['final_min_price'], row['final_mod_price'],\n",
    "        row['final_max_price'], row['min_scrapped'], row['median_scrapped'], row['max_scrapped']\n",
    "    ]\n",
    "    \n",
    "    # Filter valid prices within acceptable range\n",
    "    valid_prices = sorted({\n",
    "        x for x in price_list \n",
    "        if x and not pd.isna(x) and x != 0 \n",
    "        and wac / (1 - (avg_margin - 2.5 * std)) <= x <= wac / (1 - (avg_margin + 4 * std))\n",
    "        and x >= wac\n",
    "    })\n",
    "    \n",
    "    if not valid_prices:\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    return (\n",
    "        np.min(valid_prices),\n",
    "        np.percentile(valid_prices, 25),\n",
    "        np.percentile(valid_prices, 50),\n",
    "        np.percentile(valid_prices, 75),\n",
    "        np.max(valid_prices)\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_step_bounds(row):\n",
    "    \"\"\"Calculate below/above market bounds based on price steps.\"\"\"\n",
    "    wac = row['wac_p']\n",
    "    std = row['std']\n",
    "    prices = [row['minimum'], row['percentile_25'], row['percentile_50'], row['percentile_75'], row['maximum']]\n",
    "    \n",
    "    # Calculate valid steps between price points\n",
    "    valid_steps = []\n",
    "    for i in range(len(prices) - 1):\n",
    "        step = prices[i + 1] - prices[i]\n",
    "        if (step / wac) <= std * 1.2:\n",
    "            valid_steps.append(step)\n",
    "    \n",
    "    avg_step = np.mean(valid_steps) if valid_steps else min(2 * std, 0.2 * row['target_margin'])\n",
    "    \n",
    "    new_min = prices[0] - avg_step if (prices[0] - avg_step) >= wac else prices[0]\n",
    "    new_max = prices[-1] + avg_step if (prices[-1] + avg_step) >= wac else prices[-1]\n",
    "    \n",
    "    return new_min, new_max\n",
    "\n",
    "\n",
    "def convert_sku_id(row):\n",
    "    \"\"\"Convert SKU string to integer ID.\"\"\"\n",
    "    try:\n",
    "        return int(str(row.SKU).replace(\",\", \"\"))\n",
    "    except:\n",
    "        return row.SKU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4843f389-c610-4185-bec0-0978a722587f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'America/Los_Angeles'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING - Snowflake Timezone & Google Sheets\n",
    "# =============================================================================\n",
    "\n",
    "# Get Snowflake timezone\n",
    "zone_to_use = query_snowflake(\"SHOW PARAMETERS LIKE 'TIMEZONE'\")[1].values[0]\n",
    "print(f\"Snowflake timezone: {zone_to_use}\")\n",
    "\n",
    "# Initialize Google Sheets client\n",
    "client = get_gsheets_client()\n",
    "\n",
    "# Load min_max margin cohort data\n",
    "min_max_sheet = client.open('Demand Based Dynamic Pricing').worksheet('min_max_margin_cohort')\n",
    "min_max_df = to_numeric_columns(pd.DataFrame(min_max_sheet.get_all_records()))\n",
    "min_max_df = min_max_df[min_max_df['min_margin'] > 0.01]\n",
    "\n",
    "# Load Blue FD campaign brands\n",
    "blue_brands_sheet = client.open('Anniversary Campaign 2025 (Final)').worksheet('Suppliers Brands')\n",
    "blue_list = pd.DataFrame(blue_brands_sheet.get_all_records())[['Brands']].drop_duplicates()['Brands'].tolist()\n",
    "\n",
    "print(f\"Loaded {len(min_max_df)} min_max records, {len(blue_list)} blue campaign brands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5198399c-507c-4f5b-b61e-b030873c2694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING - Market Main Data Query\n",
    "# =============================================================================\n",
    "\n",
    "MARKET_DATA_QUERY = f'''\n",
    "WITH whs as (SELECT *\n",
    "             FROM   (values\n",
    "                            ('Cairo', 'El-Marg', 38,700),\n",
    "                            ('Cairo', 'Mostorod', 1,700),\n",
    "                            ('Giza', 'Barageel', 236,701),\n",
    "                            ('Delta West', 'El-Mahala', 337,703),\n",
    "                            ('Delta West', 'Tanta', 8,703),\n",
    "                            ('Delta East', 'Mansoura FC', 339,704),\n",
    "                            ('Delta East', 'Sharqya', 170,704),\n",
    "                            ('Upper Egypt', 'Assiut FC', 501,1124),\n",
    "                            ('Upper Egypt', 'Bani sweif', 401,1126),\n",
    "                            ('Upper Egypt', 'Menya Samalot', 703,1123),\n",
    "                            ('Upper Egypt', 'Sohag', 632,1125),\n",
    "                            ('Alexandria', 'Khorshed Alex', 797,702),\n",
    "                            ('Giza', 'Sakkarah', 962,701))\n",
    "                    x(region, wh, warehouse_id,cohort_id)),\n",
    "\n",
    "full_data as (\n",
    "    select products.id as product_id, region\n",
    "    from products, whs \n",
    "    where activation = 'true'\n",
    "),\n",
    "\n",
    "MP as (\n",
    "    select region, product_id,\n",
    "        min(min_price) as min_price, min(max_price) as max_price,\n",
    "        min(mod_price) as mod_price, min(true_min) as true_min, min(true_max) as true_max\n",
    "    from (\n",
    "        select mp.region, mp.product_id, mp.pu_id,\n",
    "            min_price/BASIC_UNIT_COUNT as min_price,\n",
    "            max_price/BASIC_UNIT_COUNT as max_price,\n",
    "            mod_price/BASIC_UNIT_COUNT as mod_price,\n",
    "            TRUE_MIN_PRICE/BASIC_UNIT_COUNT as true_min,\n",
    "            TRUE_MAX_PRICE/BASIC_UNIT_COUNT as true_max\n",
    "        from materialized_views.marketplace_prices mp \n",
    "        join packing_unit_products pup on pup.product_id = mp.product_id and pup.packing_unit_id = mp.pu_id\n",
    "        join finance.all_cogs f on f.product_id = mp.product_id and CURRENT_TIMESTAMP between f.from_date and f.to_date\n",
    "        where least(min_price, mod_price) between wac_p*0.9 and wac_p*1.3 \n",
    "    )\n",
    "    group by all \n",
    "),\n",
    "\n",
    "region_mapping AS (\n",
    "    SELECT * FROM (VALUES\n",
    "        ('Delta East', 'Delta West'), ('Delta West', 'Delta East'),\n",
    "        ('Alexandria', 'Cairo'), ('Alexandria', 'Giza'),\n",
    "        ('Upper Egypt', 'Cairo'), ('Upper Egypt', 'Giza'),\n",
    "        ('Cairo', 'Giza'), ('Giza', 'Cairo'),\n",
    "        ('Delta West', 'Cairo'), ('Delta East', 'Cairo'),\n",
    "        ('Delta West', 'Giza'), ('Delta East', 'Giza')\n",
    "    ) AS region_mapping(region, fallback_region)\n",
    "),\n",
    "\n",
    "final_mp as (\n",
    "    select region, product_id,\n",
    "        min(final_min_price) as final_min_price, min(final_max_price) as final_max_price,\n",
    "        min(final_mod_price) as final_mod_price, min(final_true_min) as final_true_min,\n",
    "        min(final_true_max) as final_true_max\n",
    "    from (\n",
    "        SELECT distinct w.region, w.product_id,\n",
    "            COALESCE(m1.min_price, m2.min_price) AS final_min_price,\n",
    "            COALESCE(m1.max_price, m2.max_price) AS final_max_price,\n",
    "            COALESCE(m1.mod_price, m2.mod_price) AS final_mod_price,\n",
    "            COALESCE(m1.true_min, m2.true_min) AS final_true_min,\n",
    "            COALESCE(m1.true_max, m2.true_max) AS final_true_max\n",
    "        FROM full_data w\n",
    "        LEFT JOIN MP m1 ON w.region = m1.region and w.product_id = m1.product_id\n",
    "        JOIN region_mapping rm ON w.region = rm.region\n",
    "        LEFT JOIN MP m2 ON rm.fallback_region = m2.region AND w.product_id = m2.product_id\n",
    "    )\n",
    "    where final_min_price is not null \n",
    "    group by all \n",
    "),\n",
    "\n",
    "ben_soliman as (\n",
    "    select z.* from (\n",
    "        select maxab_product_id as product_id, maxab_sku as sku, avg(bs_final_price) as ben_soliman_price\n",
    "        from (\n",
    "            select *, row_number() over(partition by maxab_product_id order by diff) as rnk_2 from (\n",
    "                select *, (bs_final_price-wac_p)/wac_p as diff_2 from (\n",
    "                    select *, bs_price/maxab_basic_unit_count as bs_final_price from (\n",
    "                        select *, row_number() over(partition by maxab_product_id, maxab_pu order by diff) as rnk from (\n",
    "                            select sm.*, max(INJECTION_DATE::date) over(partition by maxab_product_id, maxab_pu) as max_date,\n",
    "                                wac1, wac_p, abs(bs_price-(wac_p*maxab_basic_unit_count))/(wac_p*maxab_basic_unit_count) as diff \n",
    "                            from materialized_views.savvy_mapping sm \n",
    "                            join finance.all_cogs f on f.product_id = sm.maxab_product_id and current_timestamp between f.from_Date and f.to_date\n",
    "                            where bs_price is not null and INJECTION_DATE::date >= CURRENT_DATE - 5\n",
    "                            qualify INJECTION_DATE::date = max_date\n",
    "                        ) qualify rnk = 1 \n",
    "                    )\n",
    "                ) where diff_2 between -0.5 and 0.5 \n",
    "            ) qualify rnk_2 = 1 \n",
    "        ) group by all\n",
    "    ) z \n",
    "    join finance.all_cogs f on f.product_id = z.product_id and current_timestamp between f.from_Date and f.to_date\n",
    "    where ben_soliman_price between f.wac_p*0.7 and f.wac_p*1.3\n",
    "),\n",
    "\n",
    "scrapped_data as (\n",
    "    select product_id, cat, brand, region, max_date,\n",
    "        min(MARKET_PRICE) as min_scrapped, max(MARKET_PRICE) as max_scrapped, median(MARKET_PRICE) as median_scrapped\n",
    "    from (\n",
    "        select MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES.*, max(date) over(partition by region, MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES.product_id, competitor) as max_date\n",
    "        from MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES\n",
    "        join finance.all_cogs f on f.product_id = MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES.product_id and CURRENT_TIMESTAMP between f.from_date and f.to_date \n",
    "        where date >= current_date - 5 and MARKET_PRICE between f.wac_p * 0.7 and wac_p*1.3\n",
    "        qualify date = max_date \n",
    "    ) group by all \n",
    "),\n",
    "\n",
    "local_prices as (\n",
    "    SELECT case when cpu.cohort_id in (700) then 'Cairo'\n",
    "                when cpu.cohort_id in (701) then 'Giza'\n",
    "                when cpu.cohort_id in (704) then 'Delta East'\n",
    "                when cpu.cohort_id in (703) then 'Delta West'\n",
    "                when cpu.cohort_id in (1123,1124,1125,1126) then 'Upper Egypt'\n",
    "                when cpu.cohort_id in (702) then 'Alexandria'\n",
    "           end as region,\n",
    "           cohort_id, pu.product_id, pu.packing_unit_id, pu.basic_unit_count, avg(cpu.price) as price\n",
    "    FROM cohort_product_packing_units cpu\n",
    "    join PACKING_UNIT_PRODUCTS pu on pu.id = cpu.product_packing_unit_id\n",
    "    WHERE cpu.cohort_id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    "        and cpu.created_at::date <> '2023-07-31' and cpu.is_customized = true\n",
    "    group by all \n",
    "),\n",
    "\n",
    "live_prices as (\n",
    "    select region, cohort_id, product_id, pu_id as packing_unit_id, buc as basic_unit_count, NEW_PRICE as price\n",
    "    from materialized_views.DBDP_PRICES\n",
    "    where created_at = Current_timestamp::date\n",
    "        and DATE_PART('hour', Current_timestamp::time) BETWEEN SPLIT_PART(time_slot, '-', 1)::int AND SPLIT_PART(time_slot, '-', 2)::int\n",
    "        and cohort_id in (700,701,702,703,704,696,695,698,697,699,1123,1124,1125,1126)\n",
    "),\n",
    "\n",
    "prices as (\n",
    "    select * from (\n",
    "        SELECT *, 1 AS priority FROM live_prices\n",
    "        UNION ALL\n",
    "        SELECT *, 2 AS priority FROM local_prices\n",
    "    )\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY region, cohort_id, product_id, packing_unit_id ORDER BY priority) = 1\n",
    "),\n",
    "\n",
    "maxab_prices as (\n",
    "    select region, cohort_id, product_id, price from prices where basic_unit_count = 1 \n",
    "),\n",
    "\n",
    "sales as (\n",
    "    SELECT DISTINCT cpc.cohort_id, pso.product_id, sum(pso.total_price) as nmv\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id   \n",
    "    join COHORT_PRICING_CHANGES cpc on cpc.id = pso.cohort_pricing_change_id\n",
    "    WHERE so.created_at::date between date_trunc('month', Current_timestamp::date - 120) and Current_timestamp::date - 1\n",
    "        AND so.sales_order_status_id not in (7,12)\n",
    "        AND so.channel IN ('telesales','retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY ALL\n",
    "),\n",
    "\n",
    "margin_change as (\n",
    "    select product_id, cohort_id, (0.6*product_std) + (0.3*brand_std) + (0.1*cat_std) as std, avg_margin\n",
    "    from (\n",
    "        select product_id, cohort_id, stddev(product_margin) as product_std, stddev(brand_margin) as brand_std,\n",
    "            stddev(cat_margin) as cat_std, avg(product_margin) as avg_margin\n",
    "        from (\n",
    "            select distinct product_id, order_date, cohort_id,\n",
    "                (nmv-cogs_p)/nmv as product_margin, (brand_nmv-brand_cogs)/brand_nmv as brand_margin,\n",
    "                (cat_nmv-cat_cogs)/cat_nmv as cat_margin\n",
    "            from (\n",
    "                SELECT DISTINCT so.created_at::date as order_date, cpc.cohort_id, pso.product_id,\n",
    "                    brands.name_ar as brand, categories.name_ar as cat,\n",
    "                    sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs_p,\n",
    "                    sum(pso.total_price) as nmv,\n",
    "                    sum(nmv) over(partition by order_date, cat, brand) as brand_nmv,\n",
    "                    sum(cogs_p) over(partition by order_date, cat, brand) as brand_cogs,\n",
    "                    sum(nmv) over(partition by order_date, cat) as cat_nmv,\n",
    "                    sum(cogs_p) over(partition by order_date, cat) as cat_cogs\n",
    "                FROM product_sales_order pso\n",
    "                JOIN sales_orders so ON so.id = pso.sales_order_id   \n",
    "                join COHORT_PRICING_CHANGES cpc on cpc.id = pso.cohort_pricing_change_id\n",
    "                JOIN products on products.id=pso.product_id\n",
    "                JOIN brands on products.brand_id = brands.id \n",
    "                JOIN categories ON products.category_id = categories.id\n",
    "                JOIN finance.all_cogs f ON f.product_id = pso.product_id\n",
    "                    AND f.from_date::date <= so.created_at::date AND f.to_date::date > so.created_at::date\n",
    "                WHERE so.created_at::date between date_trunc('month', Current_timestamp::date - 120) and Current_timestamp::date\n",
    "                    AND so.sales_order_status_id not in (7,12)\n",
    "                    AND so.channel IN ('telesales','retailer')\n",
    "                    AND pso.purchased_item_count <> 0\n",
    "                GROUP BY ALL\n",
    "            )\n",
    "        ) group by all \n",
    "    )\n",
    "),\n",
    "\n",
    "cat_brand_target as (\n",
    "    SELECT DISTINCT cat, brand, margin as target_bm\n",
    "    FROM performance.commercial_targets cplan\n",
    "    QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE) OVER()) = DATE_TRUNC('month', Current_timestamp::date) \n",
    "        THEN DATE_TRUNC('month', Current_timestamp::date)\n",
    "        ELSE DATE_TRUNC('month', Current_timestamp::date - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    "),\n",
    "\n",
    "cat_target as (\n",
    "    select cat, sum(target_bm * (target_nmv/cat_total)) as cat_target_margin\n",
    "    from (\n",
    "        select *, sum(target_nmv) over(partition by cat) as cat_total\n",
    "        from (\n",
    "            select cat, brand, avg(target_bm) as target_bm, sum(target_nmv) as target_nmv\n",
    "            from (\n",
    "                SELECT DISTINCT date, city as region, cat, brand, margin as target_bm, nmv as target_nmv\n",
    "                FROM performance.commercial_targets cplan\n",
    "                QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE) OVER()) = DATE_TRUNC('month', Current_timestamp::date) \n",
    "                    THEN DATE_TRUNC('month', Current_timestamp::date)\n",
    "                    ELSE DATE_TRUNC('month', Current_timestamp::date - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    "            ) group by all\n",
    "        )\n",
    "    ) group by all \n",
    ")\n",
    "\n",
    "select distinct maxab.cohort_id, maxab.product_id,\n",
    "    CONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "    brands.name_ar as brand, categories.name_ar as cat, sections.name_ar as section_name,\n",
    "    maxab.price as maxab_price, bs.ben_soliman_price,\n",
    "    final_min_price, final_max_price, final_mod_price,\n",
    "    min_scrapped, median_scrapped, max_scrapped,\n",
    "    wac_p, coalesce(nmv,0) as nmv, coalesce(mc.std,0.01) as std,\n",
    "    coalesce(coalesce(cbt.target_bm, ct.cat_target_margin),0) as target_margin,\n",
    "    coalesce(avg_margin,0) as avg_margin\n",
    "from maxab_prices maxab\n",
    "left join ben_soliman bs on bs.product_id = maxab.product_id\n",
    "left join final_mp fmp on fmp.product_id = maxab.product_id and fmp.region = maxab.region\n",
    "left join sales s on s.product_id = maxab.product_id and s.cohort_id = maxab.cohort_id\n",
    "left join scrapped_data sd on sd.product_id = maxab.product_id and sd.region = maxab.region\n",
    "join finance.all_cogs f on f.product_id = maxab.product_id and CURRENT_TIMESTAMP between f.from_date and f.to_date\n",
    "JOIN products on products.id=maxab.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN sections ON sections.id = categories.section_id\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "left join margin_change mc on mc.product_id = maxab.product_id and mc.cohort_id = maxab.cohort_id\n",
    "left join cat_brand_target cbt on cbt.brand = brands.name_ar and cbt.cat = categories.name_ar \n",
    "left join cat_target ct on ct.cat = categories.name_ar \n",
    "'''\n",
    "\n",
    "market_cols = ['cohort_id', 'product_id', 'sku', 'brand', 'cat', 'section_name', 'maxab_price',\n",
    "               'ben_soliman_price', 'final_min_price', 'final_max_price', 'final_mod_price',\n",
    "               'min_scrapped', 'median_scrapped', 'max_scrapped', 'wac_p', 'nmv', 'std', 'target_margin', 'avg_margin']\n",
    "\n",
    "market_main_data = to_numeric_columns(query_snowflake(MARKET_DATA_QUERY, columns=market_cols))\n",
    "market_main_data = market_main_data[market_cols].drop_duplicates(subset=['cohort_id', 'product_id'])\n",
    "print(f\"Loaded {len(market_main_data)} market data records\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87883b4b-bad9-4d21-9f69-6685e716ea4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING - Additional Queries (Groups, Price Ups, Sales, WAC, Stocks, Stats)\n",
    "# =============================================================================\n",
    "\n",
    "# Product commercial groups from PostgreSQL\n",
    "groups = setup_environment_2.dwh_pg_query(\n",
    "    \"SELECT * FROM materialized_views.sku_commercial_groups\", \n",
    "    columns=['product_id', 'group']\n",
    ")\n",
    "groups.columns = groups.columns.str.lower()\n",
    "groups = to_numeric_columns(groups)\n",
    "\n",
    "# Price ups data\n",
    "price_ups = to_numeric_columns(query_snowflake('''\n",
    "    SELECT region, product_id, new_pp, forecasted_date\n",
    "    FROM materialized_views.DBDP_PRICE_UPS\n",
    "''', columns=['region', 'product_id', 'new_pp', 'forcasted_date']))\n",
    "\n",
    "# Sales data (120-day history)\n",
    "sales = to_numeric_columns(query_snowflake('''\n",
    "    SELECT DISTINCT cpc.cohort_id, pso.product_id,\n",
    "        CONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "        brands.name_ar as brand, categories.name_ar as cat,\n",
    "        sum(pso.total_price) as nmv\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    JOIN COHORT_PRICING_CHANGES cpc ON cpc.id = pso.COHORT_PRICING_CHANGE_id\n",
    "    JOIN products ON products.id = pso.product_id\n",
    "    JOIN brands ON products.brand_id = brands.id \n",
    "    JOIN categories ON products.category_id = categories.id\n",
    "    JOIN product_units ON product_units.id = products.unit_id \n",
    "    WHERE so.created_at::date BETWEEN current_date - 120 AND current_date - 1 \n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "        AND cpc.cohort_id IN (700,701,702,703,704,1123,1124,1125,1126)\n",
    "    GROUP BY ALL\n",
    "''', columns=['cohort_id', 'product_id', 'sku', 'brand', 'cat', 'nmv']))\n",
    "\n",
    "# WAC (Weighted Average Cost) data\n",
    "wacs = to_numeric_columns(query_snowflake(f'''\n",
    "    SELECT product_id, wac_p\n",
    "    FROM finance.all_cogs f \n",
    "    WHERE CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP()) BETWEEN f.from_date AND f.to_date \n",
    "''', columns=['product_id', 'wac_p']))\n",
    "\n",
    "# Current stocks\n",
    "stocks = to_numeric_columns(query_snowflake('''\n",
    "    SELECT DISTINCT product_warehouse.warehouse_id, product_warehouse.product_id,\n",
    "        (product_warehouse.available_stock)::integer as stocks\n",
    "    FROM product_warehouse \n",
    "    JOIN products ON product_warehouse.product_id = products.id\n",
    "    JOIN product_units ON products.unit_id = product_units.id\n",
    "    WHERE product_warehouse.warehouse_id NOT IN (6, 9, 10)\n",
    "        AND product_warehouse.activation = 'true'\n",
    "        AND product_warehouse.is_basic_unit = 1\n",
    "''', columns=['warehouse_id', 'product_id', 'cu_stocks']))\n",
    "\n",
    "# Product statistics\n",
    "stats = to_numeric_columns(query_snowflake('''\n",
    "    SELECT region, product_id, optimal_bm, MIN_BOUNDARY, MAX_BOUNDARY, MEDIAN_BM\n",
    "    FROM (\n",
    "        SELECT region, product_id, target_bm, optimal_bm, MIN_BOUNDARY, MAX_BOUNDARY, MEDIAN_BM,\n",
    "            MAX(created_at) OVER(PARTITION BY product_id, region) as max_date, created_at\n",
    "        FROM materialized_views.PRODUCT_STATISTICS\n",
    "        WHERE created_at::date >= date_trunc('month', current_date - 60)\n",
    "        QUALIFY max_date = created_at\n",
    "    )\n",
    "''', columns=['region', 'product_id', 'optimal_bm', 'min_boundary', 'max_boundary', 'median_bm']))\n",
    "\n",
    "print(f\"Loaded: {len(groups)} groups, {len(price_ups)} price_ups, {len(sales)} sales, {len(wacs)} wacs, {len(stocks)} stocks, {len(stats)} stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade36b5b-e61d-4d32-a310-6f5f610f838b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING - TGTG Aging Monitor (Google Sheets)\n",
    "# =============================================================================\n",
    "\n",
    "# Get current and recent week numbers for sheet lookup\n",
    "week_number = datetime.now().isocalendar()[1]\n",
    "week_candidates = [str(week_number), str(week_number - 1), str(week_number - 2)]\n",
    "\n",
    "# Find the most recent TGTG sheet\n",
    "tgtg_worksheets = client.open('Egypt SKUs Aging Monitor').worksheets()\n",
    "worksheet_names = [ws.title for ws in tgtg_worksheets]\n",
    "\n",
    "sheet_name = None\n",
    "for week_str in week_candidates:\n",
    "    for name in worksheet_names:\n",
    "        if week_str in name:\n",
    "            sheet_name = name\n",
    "            break\n",
    "    if sheet_name:\n",
    "        break\n",
    "\n",
    "# Load TGTG data\n",
    "tgtg_sheet = client.open('Egypt SKUs Aging Monitor').worksheet(sheet_name)\n",
    "tgtg_data = tgtg_sheet.get_all_values()\n",
    "\n",
    "if tgtg_data:\n",
    "    tgtg_df = pd.DataFrame(tgtg_data[2:], columns=tgtg_data[1]).iloc[:, :21]\n",
    "    tgtg_df = to_numeric_columns(tgtg_df)\n",
    "    tgtg_df = tgtg_df[tgtg_df['Fulfillment confirmation'] == 'confirmed']\n",
    "    \n",
    "    # Select relevant warehouse columns\n",
    "    warehouse_cols = ['SKU', 'Sharqya', 'Khorshed Alex', 'Bani sweif', 'Mostorod', 'Barageel', \n",
    "                      'El-Mahala', 'Sohag', 'Mansoura FC', 'Assiut FC', 'Menya Samalot', 'Tanta']\n",
    "    tgtg_df = tgtg_df[warehouse_cols]\n",
    "    \n",
    "    # Melt to long format (SKU x warehouse -> stocks)\n",
    "    tgtg_long = tgtg_df.melt(id_vars=['SKU'], var_name='warehouse', value_name='stocks')\n",
    "    tgtg_long['product_id'] = tgtg_long.apply(convert_sku_id, axis=1)\n",
    "    tgtg_long = tgtg_long.drop(columns='SKU')\n",
    "    tgtg_long = tgtg_long[~tgtg_long['stocks'].isna()]\n",
    "else:\n",
    "    tgtg_long = pd.DataFrame(columns=['warehouse', 'stocks', 'product_id'])\n",
    "\n",
    "print(f\"Loaded TGTG data from sheet '{sheet_name}': {len(tgtg_long)} warehouse-product records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490c145-f6da-49d8-9ab8-bd241f6a0e16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PROCESSING - Sales Tier Assignment\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate NMV contribution and cumulative contribution\n",
    "sales['total_nmv'] = sales.groupby('cohort_id')['nmv'].transform('sum')\n",
    "sales['cntrb_nmv'] = sales['nmv'] / sales['total_nmv']\n",
    "sales = sales.sort_values(['cohort_id', 'nmv'], ascending=[True, False])\n",
    "sales['nmv_cumulative_cntrb'] = sales.groupby('cohort_id')['cntrb_nmv'].cumsum()\n",
    "\n",
    "# Assign base tier from cumulative contribution\n",
    "sales['tier'] = sales['nmv_cumulative_cntrb'].apply(assign_tier)\n",
    "\n",
    "# Apply brand/category tier adjustments\n",
    "sales.loc[sales['cat'].isin(MIN_PRICE_CATEGORIES), 'tier'] = np.maximum(sales['tier'] - 1, 1)\n",
    "sales.loc[sales['brand'].isin(blue_list), 'tier'] = np.maximum(sales['tier'] - 1, 1)\n",
    "sales.loc[sales['brand'].isin(MIN_PRICE_BRANDS), 'tier'] = 1\n",
    "sales.loc[sales['brand'].isin(BELOW_MARKET_BRANDS), 'tier'] = 0\n",
    "sales.loc[sales['brand'].isin(AVG_PRICE_BRANDS), 'tier'] = 3\n",
    "sales.loc[sales['brand'].isin(MAX_PRICE_BRANDS), 'tier'] = 5\n",
    "\n",
    "# Apply status-based adjustment (reduce tier by 1 if \"min\" mode)\n",
    "if 'min' in STATUS:\n",
    "    sales['tier'] = np.maximum(sales['tier'] - 1, 0)\n",
    "\n",
    "print(f\"Tier distribution:\\n{sales['tier'].value_counts().sort_index()}\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a60ce8-9362-4bbd-8d62-e969f2135d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PROCESSING - Market Data with Groups\n",
    "# =============================================================================\n",
    "\n",
    "# Merge market data with product groups\n",
    "market_data = market_main_data.copy()\n",
    "market_data = market_data.merge(groups, on='product_id', how='left')\n",
    "\n",
    "# Calculate group-level aggregated prices for products with group assignments\n",
    "groups_data = market_data[~market_data['group'].isna()].copy()\n",
    "groups_data['group_nmv'] = groups_data.groupby(['group', 'cohort_id'])['nmv'].transform('sum')\n",
    "groups_data['cntrb'] = (groups_data['nmv'] / groups_data['group_nmv']).fillna(1)\n",
    "\n",
    "# Aggregate group prices\n",
    "groups_agg = groups_data.groupby(['group', 'cohort_id']).agg({\n",
    "    'ben_soliman_price': 'median', 'final_min_price': 'median', 'final_max_price': 'median',\n",
    "    'final_mod_price': 'median', 'min_scrapped': 'median', 'median_scrapped': 'median', 'max_scrapped': 'median'\n",
    "}).reset_index()\n",
    "\n",
    "# Fill missing prices with group-level prices\n",
    "merged = market_data.merge(groups_agg, on=['group', 'cohort_id'], how='left', suffixes=('', '_group'))\n",
    "price_cols = ['ben_soliman_price', 'final_min_price', 'final_max_price', 'final_mod_price', \n",
    "              'min_scrapped', 'median_scrapped', 'max_scrapped']\n",
    "for col in price_cols:\n",
    "    merged[col] = merged[col].fillna(merged[f'{col}_group'])\n",
    "\n",
    "market_data = merged.drop(columns=[f'{c}_group' for c in price_cols])\n",
    "\n",
    "print(f\"Market data after group processing: {len(market_data)} records\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e7772-bc1f-4e0c-8165-8fcac88753ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PROCESSING - Price Analysis & Margin Calculation\n",
    "# =============================================================================\n",
    "\n",
    "# Apply price analysis to calculate price percentiles\n",
    "market_data[['minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum']] = \\\n",
    "    market_data.apply(price_analysis, axis=1, result_type='expand')\n",
    "\n",
    "# Filter out records without valid price analysis\n",
    "market_data = market_data[~market_data['minimum'].isna()]\n",
    "\n",
    "# Calculate below/above market bounds\n",
    "market_data[['below_market', 'above_market']] = market_data.apply(calculate_step_bounds, axis=1, result_type='expand')\n",
    "\n",
    "# Calculate margin metrics\n",
    "market_data = market_data[['cohort_id', 'product_id', 'maxab_price', 'wac_p', 'minimum', \n",
    "                           'percentile_25', 'percentile_50', 'percentile_75', 'maximum', \n",
    "                           'below_market', 'above_market']]\n",
    "\n",
    "# Convert prices to margins\n",
    "market_data['below_market'] = (market_data['below_market'] - market_data['wac_p']) / market_data['below_market']\n",
    "market_data['market_min'] = (market_data['minimum'] - market_data['wac_p']) / market_data['minimum']\n",
    "market_data['market_25'] = (market_data['percentile_25'] - market_data['wac_p']) / market_data['percentile_25']\n",
    "market_data['market_50'] = (market_data['percentile_50'] - market_data['wac_p']) / market_data['percentile_50']\n",
    "market_data['market_75'] = (market_data['percentile_75'] - market_data['wac_p']) / market_data['percentile_75']\n",
    "market_data['market_max'] = (market_data['maximum'] - market_data['wac_p']) / market_data['maximum']\n",
    "market_data['above_market'] = (market_data['above_market'] - market_data['wac_p']) / market_data['above_market']\n",
    "market_data['current_margin'] = (market_data['maxab_price'] - market_data['wac_p']) / market_data['maxab_price']\n",
    "\n",
    "market_data = market_data[['cohort_id', 'product_id', 'current_margin', 'below_market', 'market_min', \n",
    "                           'market_25', 'market_50', 'market_75', 'market_max', 'above_market']]\n",
    "\n",
    "print(f\"Market data after price analysis: {len(market_data)} records\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f390dc2b-c772-4d2e-b7cc-bdcc2695a411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PROCESSING - Calculate Min/Max Margins (Found Products)\n",
    "# =============================================================================\n",
    "\n",
    "# Merge with existing min_max constraints and sales tiers\n",
    "found = min_max_df.merge(market_data, on=['cohort_id', 'product_id'])\n",
    "found = found.merge(sales[['cohort_id', 'product_id', 'tier']], on=['cohort_id', 'product_id'])\n",
    "\n",
    "# Select min/max margins based on tier\n",
    "tier_conditions = [found['tier'] == i for i in range(6)]\n",
    "tier_min_choices = [found['below_market'], found['market_min'], found['market_25'], \n",
    "                    found['market_50'], found['market_75'], found['market_max']]\n",
    "tier_max_choices = [found['market_min'], found['market_25'], found['market_50'], \n",
    "                    found['market_75'], found['market_max'], found['market_max'] * 1.2]\n",
    "\n",
    "found['selected_min'] = np.select(tier_conditions, tier_min_choices, default=found['market_min'])\n",
    "found['selected_max'] = np.select(tier_conditions, tier_max_choices, default=found['market_min'])\n",
    "\n",
    "# Filter based on margin difference thresholds\n",
    "found['min_cu_diff'] = (found['selected_min'] - found['current_margin']) / found['current_margin']\n",
    "found['min_min_diff'] = (found['selected_min'] - found['min_margin']) / found['min_margin']\n",
    "found = found[((found['min_cu_diff'].between(-0.55, 0.55)) | (found['min_min_diff'].between(-0.55, 0.55)))]\n",
    "\n",
    "# Calculate final new min/max\n",
    "found['diff'] = (found['max_margin'] - found['min_margin']) / found['min_margin']\n",
    "found['new_min'] = found['selected_min']\n",
    "found['new_max'] = np.minimum(\n",
    "    np.maximum(np.maximum((found['diff'] + 1) * found['selected_min'], found['selected_max']), \n",
    "               found['selected_min'] + 0.01),\n",
    "    found['selected_min'] + 0.04\n",
    ")\n",
    "found = found[['cohort_id', 'product_id', 'new_min', 'new_max']]\n",
    "found['type'] = 'both'\n",
    "\n",
    "print(f\"Found (products with existing min_max): {len(found)} records\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f8918-f784-4364-8b3c-b6fc7c0cc47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PROCESSING - Calculate Min/Max Margins (New Products - MP Only)\n",
    "# =============================================================================\n",
    "\n",
    "# Identify products not in existing min_max\n",
    "min_max_df['flag'] = 1\n",
    "not_found = market_data.merge(min_max_df[['cohort_id', 'product_id', 'flag']], on=['cohort_id', 'product_id'], how='left')\n",
    "not_found = not_found.merge(sales[['cohort_id', 'product_id', 'tier']], on=['cohort_id', 'product_id'])\n",
    "not_found = not_found[not_found['flag'].isna()]\n",
    "\n",
    "# Select margins based on tier\n",
    "tier_conditions = [not_found['tier'] == i for i in range(6)]\n",
    "tier_min_choices = [not_found['below_market'], not_found['market_min'], not_found['market_25'],\n",
    "                    not_found['market_50'], not_found['market_75'], not_found['market_max']]\n",
    "tier_max_choices = [not_found['market_min'], not_found['market_25'], not_found['market_50'],\n",
    "                    not_found['market_75'], not_found['market_max'], not_found['market_max'] * 1.2]\n",
    "\n",
    "not_found['selected_min'] = np.select(tier_conditions, tier_min_choices, default=not_found['market_min'])\n",
    "not_found['selected_max'] = np.select(tier_conditions, tier_max_choices, default=not_found['market_min'])\n",
    "\n",
    "# Filter based on margin difference\n",
    "not_found['min_cu_diff'] = (not_found['selected_min'] - not_found['current_margin']) / not_found['current_margin']\n",
    "not_found = not_found[not_found['min_cu_diff'].between(-2, 2)]\n",
    "\n",
    "# Calculate new min/max\n",
    "not_found['new_min'] = not_found['selected_min']\n",
    "not_found['new_max'] = np.minimum(\n",
    "    np.maximum(not_found['selected_max'], not_found['selected_min'] + 0.01),\n",
    "    not_found['selected_min'] + 0.04\n",
    ")\n",
    "not_found = not_found[['cohort_id', 'product_id', 'new_min', 'new_max']]\n",
    "not_found['type'] = 'MP_only'\n",
    "\n",
    "print(f\"Not found (new products): {len(not_found)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab29e4-c8fc-42d9-a816-616d55f867da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PROCESSING - Combine Results & Add Region Mapping\n",
    "# =============================================================================\n",
    "\n",
    "# Combine found and not_found\n",
    "final_df = pd.concat([found, not_found], axis=0).drop_duplicates()\n",
    "\n",
    "# Add region mapping\n",
    "final_df = final_df.merge(REGION_COHORT_MAP, on='cohort_id')\n",
    "final_df = final_df[['cohort_id', 'product_id', 'new_min', 'new_max', 'type']].drop_duplicates()\n",
    "final_df.columns = ['cohort_id', 'product_id', 'min_margin', 'max_margin', 'type']\n",
    "\n",
    "print(f\"Combined dataframe: {len(final_df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8846fc1c-3e90-484e-8233-5e1b24369d15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PROCESSING - TGTG (Too Good To Go) Products\n",
    "# =============================================================================\n",
    "\n",
    "# Process TGTG aging products with special margin rules\n",
    "tgtg = tgtg_long.merge(wacs, on='product_id')\n",
    "tgtg = tgtg.merge(WAREHOUSE_CONFIG, on='warehouse')\n",
    "tgtg = tgtg.merge(TGTG_EXCLUSIONS, on=['product_id', 'warehouse_id'], how='left')\n",
    "tgtg = tgtg[tgtg['remove'].isna()]\n",
    "tgtg = tgtg.merge(stocks, on=['warehouse_id', 'product_id'])\n",
    "tgtg = tgtg[tgtg['cu_stocks'] > 0]\n",
    "\n",
    "# Calculate stock value and filter\n",
    "tgtg['stock_value'] = tgtg['cu_stocks'] * tgtg['wac_p']\n",
    "tgtg = tgtg.sort_values(by='stock_value', ascending=False)\n",
    "tgtg = tgtg[tgtg['stock_value'] > 100]\n",
    "\n",
    "# Merge with market data and stats\n",
    "tgtg = tgtg.merge(market_data, on=['cohort_id', 'product_id'], how='left')\n",
    "tgtg = tgtg.merge(stats, on=['region', 'product_id'])\n",
    "tgtg = tgtg.merge(market_main_data[['cohort_id', 'product_id', 'target_margin']], on=['cohort_id', 'product_id'], how='left')\n",
    "tgtg = tgtg.fillna(1000)\n",
    "\n",
    "# Calculate aggressive min margins for TGTG products\n",
    "tgtg['min_margin'] = np.minimum(\n",
    "    np.minimum(\n",
    "        np.minimum(tgtg['market_min'] * 0.8, tgtg['target_margin'] / 4),\n",
    "        tgtg['min_boundary'] * 0.9\n",
    "    ),\n",
    "    tgtg['optimal_bm'] * 0.75\n",
    ")\n",
    "tgtg['max_margin'] = tgtg['min_margin']\n",
    "\n",
    "# Save TGTG data for reference\n",
    "tgtg.to_excel(\"Min_max_data/tgtg.xlsx\", index=False)\n",
    "\n",
    "# Aggregate TGTG by cohort/product\n",
    "tgtg = tgtg[['cohort_id', 'product_id', 'min_margin', 'max_margin']]\n",
    "tgtg = tgtg.groupby(['cohort_id', 'product_id']).agg({'min_margin': 'min', 'max_margin': 'min'}).reset_index()\n",
    "tgtg['type'] = 'TGTG'\n",
    "\n",
    "print(f\"TGTG products: {len(tgtg)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f459c984-aff5-484e-9e3c-c61da9f9c290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PROCESSING - Merge TGTG with Final DataFrame\n",
    "# =============================================================================\n",
    "\n",
    "# Remove TGTG products from main final_df to avoid duplicates\n",
    "result = final_df.merge(tgtg[['product_id', 'cohort_id']], on=['product_id', 'cohort_id'], how='left', indicator=True)\n",
    "result = result[result['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "\n",
    "# Add TGTG products to final\n",
    "final_df = pd.concat([result, tgtg], axis=0)\n",
    "\n",
    "print(f\"Final dataframe after TGTG: {len(final_df)} records\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0fe18-8f02-4be7-a0f6-86695bdc957e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA PROCESSING - Price Ups & Final Adjustments\n",
    "# =============================================================================\n",
    "\n",
    "# Merge price_ups with region mapping\n",
    "price_ups = price_ups.merge(REGION_COHORT_MAP, on='region')\n",
    "\n",
    "# Merge with final_df\n",
    "final_df = final_df.merge(price_ups, on=['product_id', 'cohort_id'], how='left')\n",
    "\n",
    "# Adjust max_margin for products with price ups (except TGTG)\n",
    "mask = (~final_df['new_pp'].isna()) & (final_df['type'] != 'TGTG')\n",
    "final_df.loc[mask, 'max_margin'] = np.minimum(\n",
    "    final_df.loc[mask, 'max_margin'] + 0.15, \n",
    "    final_df.loc[mask, 'min_margin'] + 0.2\n",
    ")\n",
    "\n",
    "# Add enforce flag for price_ups products\n",
    "final_df['enforce'] = np.where(~final_df['new_pp'].isna(), 1, np.nan)\n",
    "\n",
    "# Merge with sales for SKU info\n",
    "final_df = final_df.drop_duplicates()\n",
    "final_df = final_df.merge(sales, on=['cohort_id', 'product_id'], how='left')\n",
    "final_df = final_df[['cohort_id', 'product_id', 'sku', 'min_margin', 'max_margin', 'enforce', 'brand', 'type']]\n",
    "\n",
    "# Add comparison with existing min_max\n",
    "final_df = final_df.merge(\n",
    "    min_max_df[['cohort_id', 'product_id', 'min_margin', 'max_margin']].rename(\n",
    "        columns={'min_margin': 'old_min', 'max_margin': 'old_max'}\n",
    "    ),\n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Final dataframe ready: {len(final_df)} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd040b-9e06-49c4-848d-d93627c2da49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OUTPUT - Export Final Results\n",
    "# =============================================================================\n",
    "\n",
    "# Save to Excel\n",
    "output_path = 'Min_max_data/min_max_data.xlsx'\n",
    "final_df.to_excel(output_path, index=False)\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MIN/MAX MARGIN CALCULATION COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(final_df)}\")\n",
    "print(f\"\\nBreakdown by type:\")\n",
    "print(final_df['type'].value_counts())\n",
    "print(f\"\\nOutput saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38447844-b1c3-49bf-b8f0-c0f70242d196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# OPTIONAL - Preview Final Data\n",
    "# =============================================================================\n",
    "\n",
    "# Display sample of final output\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d20302c-606e-4a6d-a00f-07cbfd4fee53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce78a5b2-84a5-40c0-a2ce-559e16307de5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6f910-9114-45ef-895a-2df61a1b9f5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc9aae5-7c74-41c2-a60d-5496eea24009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c394895-f070-4c5f-a9db-408c2c752d35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>new_min</th>\n",
       "      <th>new_max</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.081171</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>701</td>\n",
       "      <td>3</td>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>702</td>\n",
       "      <td>3</td>\n",
       "      <td>0.043734</td>\n",
       "      <td>0.059734</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050679</td>\n",
       "      <td>0.082501</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704</td>\n",
       "      <td>3</td>\n",
       "      <td>0.047987</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10636</th>\n",
       "      <td>1123</td>\n",
       "      <td>2109</td>\n",
       "      <td>0.050446</td>\n",
       "      <td>0.060446</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10665</th>\n",
       "      <td>701</td>\n",
       "      <td>23380</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.068091</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10744</th>\n",
       "      <td>703</td>\n",
       "      <td>10596</td>\n",
       "      <td>0.050042</td>\n",
       "      <td>0.060042</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10771</th>\n",
       "      <td>1123</td>\n",
       "      <td>7182</td>\n",
       "      <td>0.044240</td>\n",
       "      <td>0.056313</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10806</th>\n",
       "      <td>1123</td>\n",
       "      <td>10906</td>\n",
       "      <td>0.074732</td>\n",
       "      <td>0.114732</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10626 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cohort_id  product_id   new_min   new_max     type\n",
       "0            700           3  0.051860  0.081171     both\n",
       "1            701           3  0.041931  0.066391     both\n",
       "2            702           3  0.043734  0.059734     both\n",
       "3            703           3  0.050679  0.082501     both\n",
       "4            704           3  0.047987  0.070307     both\n",
       "...          ...         ...       ...       ...      ...\n",
       "10636       1123        2109  0.050446  0.060446  MP_only\n",
       "10665        701       23380  0.058091  0.068091  MP_only\n",
       "10744        703       10596  0.050042  0.060042  MP_only\n",
       "10771       1123        7182  0.044240  0.056313  MP_only\n",
       "10806       1123       10906  0.074732  0.114732  MP_only\n",
       "\n",
       "[10626 rows x 5 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b3ac9-7f3c-48d0-b4d2-d52c2189de6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>min_margin</th>\n",
       "      <th>max_margin</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051860</td>\n",
       "      <td>0.081171</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>701</td>\n",
       "      <td>3</td>\n",
       "      <td>0.041931</td>\n",
       "      <td>0.066391</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>702</td>\n",
       "      <td>3</td>\n",
       "      <td>0.043734</td>\n",
       "      <td>0.059734</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050679</td>\n",
       "      <td>0.082501</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704</td>\n",
       "      <td>3</td>\n",
       "      <td>0.047987</td>\n",
       "      <td>0.070307</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10621</th>\n",
       "      <td>1123</td>\n",
       "      <td>2109</td>\n",
       "      <td>0.050446</td>\n",
       "      <td>0.060446</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10622</th>\n",
       "      <td>701</td>\n",
       "      <td>23380</td>\n",
       "      <td>0.058091</td>\n",
       "      <td>0.068091</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10623</th>\n",
       "      <td>703</td>\n",
       "      <td>10596</td>\n",
       "      <td>0.050042</td>\n",
       "      <td>0.060042</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10624</th>\n",
       "      <td>1123</td>\n",
       "      <td>7182</td>\n",
       "      <td>0.044240</td>\n",
       "      <td>0.056313</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>1123</td>\n",
       "      <td>10906</td>\n",
       "      <td>0.074732</td>\n",
       "      <td>0.114732</td>\n",
       "      <td>MP_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10626 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cohort_id  product_id  min_margin  max_margin     type\n",
       "0            700           3    0.051860    0.081171     both\n",
       "1            701           3    0.041931    0.066391     both\n",
       "2            702           3    0.043734    0.059734     both\n",
       "3            703           3    0.050679    0.082501     both\n",
       "4            704           3    0.047987    0.070307     both\n",
       "...          ...         ...         ...         ...      ...\n",
       "10621       1123        2109    0.050446    0.060446  MP_only\n",
       "10622        701       23380    0.058091    0.068091  MP_only\n",
       "10623        703       10596    0.050042    0.060042  MP_only\n",
       "10624       1123        7182    0.044240    0.056313  MP_only\n",
       "10625       1123       10906    0.074732    0.114732  MP_only\n",
       "\n",
       "[10626 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de92b0-2384-4b65-8fcd-af42a6f67ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 48 47\n"
     ]
    }
   ],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c94bf1-7de2-478c-964b-6b1360968d67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse</th>\n",
       "      <th>stocks</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>24.0</td>\n",
       "      <td>12345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>37.0</td>\n",
       "      <td>2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>173 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     warehouse  stocks  product_id\n",
       "18     Sharqya    24.0       12345\n",
       "20     Sharqya    27.0        1064\n",
       "21     Sharqya     7.0        8638\n",
       "29     Sharqya    37.0        2270\n",
       "36     Sharqya    11.0       12858\n",
       "...        ...     ...         ...\n",
       "2112     Tanta     1.0        8486\n",
       "2114     Tanta     8.0        9620\n",
       "2125     Tanta     6.0       11295\n",
       "2131     Tanta     5.0        8935\n",
       "2177     Tanta     1.0        5189\n",
       "\n",
       "[173 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d065a5e8-d5cf-4c0f-b69d-7de929b3be34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518e53c-478a-4334-8699-18c1bf089c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23032ae-a99a-45a1-bdf0-3c4e93cea1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee31ff4-c77d-44f2-973a-2072e118a13f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a42817-656e-404b-8d94-a5bf83dc899c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>remove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8673</td>\n",
       "      <td>401</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  warehouse_id  remove\n",
       "0        8673           401       1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb2d42-0520-4e1e-a42f-2c643bb9fe2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>min_margin</th>\n",
       "      <th>max_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>701</td>\n",
       "      <td>1069</td>\n",
       "      <td>0.013468</td>\n",
       "      <td>0.013468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>701</td>\n",
       "      <td>9353</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>0.008440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>701</td>\n",
       "      <td>9570</td>\n",
       "      <td>0.037267</td>\n",
       "      <td>0.037267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>701</td>\n",
       "      <td>10384</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>0.011544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>701</td>\n",
       "      <td>10667</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>0.015649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1126</td>\n",
       "      <td>12031</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>0.024704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1126</td>\n",
       "      <td>12032</td>\n",
       "      <td>0.024704</td>\n",
       "      <td>0.024704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1126</td>\n",
       "      <td>12343</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1126</td>\n",
       "      <td>12533</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.007619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1126</td>\n",
       "      <td>20670</td>\n",
       "      <td>0.009877</td>\n",
       "      <td>0.009877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cohort_id  product_id  min_margin  max_margin\n",
       "0         701        1069    0.013468    0.013468\n",
       "1         701        9353    0.008440    0.008440\n",
       "2         701        9570    0.037267    0.037267\n",
       "3         701       10384    0.011544    0.011544\n",
       "4         701       10667    0.015649    0.015649\n",
       "..        ...         ...         ...         ...\n",
       "91       1126       12031    0.024704    0.024704\n",
       "92       1126       12032    0.024704    0.024704\n",
       "93       1126       12343    0.026500    0.026500\n",
       "94       1126       12533    0.007619    0.007619\n",
       "95       1126       20670    0.009877    0.009877\n",
       "\n",
       "[96 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660e4534-3f0a-4398-870a-64ee3ca84093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfd282-3306-455b-8fbd-b96fc1b8cce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ff707d-7974-4321-9f13-9f1a7c383fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8858cc8-a2a3-4387-b405-91d004786ec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# [DEPRECATED - Code moved to refactored cells above]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45b608-51c2-48d9-ae5f-aa32e2e328d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
