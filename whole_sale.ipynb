{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0aab1c-ca86-4f46-8dac-684b0062f85d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# Connectivity\n",
    "!pip install psycopg2-binary  # PostgreSQL adapter\n",
    "# !pip install snowflake-connector-python  # Snowflake connector\n",
    "!pip install snowflake-connector-python==3.15.0 # Snowflake connector Older Version\n",
    "!pip install snowflake-sqlalchemy  # Snowflake SQLAlchemy connector\n",
    "!pip install warnings # Warnings management\n",
    "# !pip install pyarrow # Serialization\n",
    "!pip install keyring==23.11.0 # Key management\n",
    "!pip install sqlalchemy==1.4.46 # SQLAlchemy\n",
    "!pip install requests # HTTP requests\n",
    "!pip install boto3 # AWS SDK\n",
    "# !pip install slackclient # Slack API\n",
    "!pip install oauth2client # Google Sheets API\n",
    "!pip install gspread==5.9.0 # Google Sheets API\n",
    "!pip install gspread_dataframe # Google Sheets API\n",
    "!pip install google.cloud # Google Cloud\n",
    "# Data manipulation and analysis\n",
    "!pip install polars\n",
    "!pip install pandas==2.2.1\n",
    "!pip install numpy\n",
    "# !pip install fastparquet\n",
    "!pip install openpyxl # Excel file handling\n",
    "!pip install xlsxwriter # Excel file handling\n",
    "# Linear programming\n",
    "!pip install pulp\n",
    "# Date and time handling\n",
    "!pip install --upgrade datetime\n",
    "!pip install python-time\n",
    "!pip install --upgrade pytz\n",
    "# Progress bar\n",
    "!pip install tqdm\n",
    "# Database data types\n",
    "!pip install db-dtypes\n",
    "# Geospatial data handling\n",
    "# !pip install geopandas\n",
    "# !pip install shapely\n",
    "# !pip install fiona\n",
    "# !pip install haversine\n",
    "# Plotting\n",
    "\n",
    "# Modeling\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn\n",
    "\n",
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d174c3-4449-497d-bbdc-d00c2335e221",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n",
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import setup_environment_2\n",
    "import importlib\n",
    "import import_ipynb\n",
    "import warnings\n",
    "import demand_sku_cntrb\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(setup_environment_2)\n",
    "setup_environment_2.initialize_env()\n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89df83b-343f-44e9-96f7-2b7fea6aea82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_snowflake(query, columns=[]):\n",
    "    import os\n",
    "    import snowflake.connector\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    con = snowflake.connector.connect(\n",
    "        user =  os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account= os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password= os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database =os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        if len(columns) == 0:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()))\n",
    "        else:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()),columns=columns)\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8994ad8-b430-4445-9ff3-1425fff31010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SHOW PARAMETERS LIKE 'TIMEZONE'\n",
    "'''\n",
    "x  = query_snowflake(query)\n",
    "zone_to_use = x[1].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b35fc5-07ba-4ee8-915a-19421c73df34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import base64\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "from requests import get\n",
    "from pathlib import Path\n",
    "import requests\n",
    "    \n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    # In this sample we only handle the specific exceptions for the 'GetSecretValue' API.\n",
    "    # See https://docs.aws.amazon.com/secretsmanager/latest/apireference/API_GetSecretValue.html\n",
    "    # We rethrow the exception by default.\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
    "    except ClientError as e:\n",
    "        if e.response['Error']['Code'] == 'DecryptionFailureException':\n",
    "            # Secrets Manager can't decrypt the protected secret text using the provided KMS key.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InternalServiceErrorException':\n",
    "            # An error occurred on the server side.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidParameterException':\n",
    "            # You provided an invalid value for a parameter.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'InvalidRequestException':\n",
    "            # You provided a parameter value that is not valid for the current state of the resource.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "        elif e.response['Error']['Code'] == 'ResourceNotFoundException':\n",
    "            # We can't find the resource that you asked for.\n",
    "            # Deal with the exception here, and/or rethrow at your discretion.\n",
    "            raise e\n",
    "    else:\n",
    "        # Decrypts secret using the associated KMS CMK.\n",
    "        # Depending on whether the secret is a string or binary, one of these fields will be populated.\n",
    "        if 'SecretString' in get_secret_value_response:\n",
    "            return get_secret_value_response['SecretString']\n",
    "        else:\n",
    "            return base64.b64decode(get_secret_value_response['SecretBinary'])\n",
    "\n",
    "        \n",
    "pricing_api_secret = json.loads(get_secret(\"prod/pricing/api/\"))\n",
    "username = pricing_api_secret[\"egypt_username\"]\n",
    "password = pricing_api_secret[\"egypt_password\"]\n",
    "secret = pricing_api_secret[\"egypt_secret\"]\n",
    "\n",
    "# get access token\n",
    "def get_access_token(url, client_id, client_secret):\n",
    "    \"\"\"\n",
    "    get_access_token function takes three parameters and returns a session token\n",
    "    to connect to MaxAB APIs\n",
    "\n",
    "    :param url: production MaxAB token URL\n",
    "    :param client_id: client ID\n",
    "    :param client_secret: client sercret\n",
    "    :return: session token\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        data={\"grant_type\": \"password\",\n",
    "              \"username\": username,\n",
    "              \"password\": password},\n",
    "        auth=(client_id, client_secret),\n",
    "    )\n",
    "    return response.json()[\"access_token\"]\n",
    "\n",
    "\n",
    "def post_prices(id_,file_name):\n",
    "    token = get_access_token('https://sso.maxab.info/auth/realms/maxab/protocol/openid-connect/token',\n",
    "                             'main-system-externals',\n",
    "                             secret)\n",
    "    url = \"https://api.maxab.info/main-system/api/admin-portal/cohorts/{}/pricing\".format(id_)\n",
    "    payload={}\n",
    "    files=[\n",
    "      ('sheet',(file_name,open(file_name,'rb'),'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'))\n",
    "    ]\n",
    "    headers = {\n",
    "      'Authorization': 'bearer {}'.format(token)}\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload, files=files)\n",
    "    return response\n",
    "\n",
    "def post_cart_rules(id_,file_name):\n",
    "    token = get_access_token('https://sso.maxab.info/auth/realms/maxab/protocol/openid-connect/token',\n",
    "                             'main-system-externals',\n",
    "                             secret)\n",
    "    url = \"https://api.maxab.info/main-system/api/admin-portal/cohorts/{}/cart-rules\".format(id_)\n",
    "    payload={}\n",
    "    files=[\n",
    "      ('sheet',(file_name,open(file_name,'rb'),'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'))\n",
    "    ]\n",
    "    headers = {\n",
    "      'Authorization': 'bearer {}'.format(token)}\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload, files=files)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b86c495-a75e-4836-887a-c46fe52f5c97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "with vec_cost_type as(\n",
    "\n",
    "select region,CATEGORY as vehicle_name,COST_PER_VEHICLE_RUN as vehicle_cost\n",
    "from (\n",
    "WITH fms AS (WITH reasons AS (SELECT DISTINCT\n",
    "fleet_cost_mapping.reason_id,\n",
    "logs_reason.reason,\n",
    "CASE WHEN regions.name_en IN ('Delta West','Delta East') THEN 'Delta' ELSE regions.name_en END AS region,\n",
    "cost\n",
    "\n",
    "FROM retool.fleet_cost_mapping\n",
    "\n",
    "INNER JOIN regions ON fleet_cost_mapping.region_id = regions.id\n",
    "LEFT JOIN retool.logs_reason ON fleet_cost_mapping.reason_id = logs_reason.id),\n",
    "\n",
    "vehicles AS (WITH history AS (\n",
    "    SELECT DISTINCT\n",
    "        SUPPLIERS_VEHICLES_history.supplier_id,\n",
    "        supplier.name_en AS supplier_en,\n",
    "        supplier.name_ar AS supplier_ar,\n",
    "        supplier.tax_number,\n",
    "        supplier.tax_name,\n",
    "        SUPPLIERS_VEHICLES_history.VEHICLE_PLATE_NUMBER,\n",
    "        SUPPLIERS_VEHICLES_history.monthly_cost,\n",
    "        SUPPLIERS_VEHICLES_history.created_at AS created_timestamp,\n",
    "        SUPPLIERS_VEHICLES_history.created_at::DATE AS created_at\n",
    "    FROM retool.SUPPLIERS_VEHICLES_history\n",
    "    LEFT JOIN retool.supplier ON SUPPLIERS_VEHICLES_history.supplier_id = supplier.id\n",
    "),\n",
    "history_with_next_update AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        COALESCE(LEAD(created_at) OVER (PARTITION BY VEHICLE_PLATE_NUMBER ORDER BY created_timestamp), CURRENT_DATE + 1) AS next_update \n",
    "    FROM history\n",
    ")\n",
    "SELECT\n",
    "    *,\n",
    "    ROW_NUMBER()OVER(PARTITION BY VEHICLE_PLATE_NUMBER ORDER BY created_at) AS ranks\n",
    "FROM history_with_next_update\n",
    "WHERE created_at <> next_update OR next_update IS NULL)\n",
    "\n",
    "SELECT\n",
    "fleet_tracking.delivery_date::VARCHAR AS date,\n",
    "lh_warehouses.region,\n",
    "warehouses.name AS warehouse,\n",
    "COALESCE(vehicles.supplier_en, V2.supplier_en) AS supplier_en,\n",
    "COALESCE(vehicles.supplier_ar, V2.supplier_ar) AS supplier_ar,\n",
    "COALESCE(vehicles.tax_number, V2.tax_number) AS tax_number,\n",
    "COALESCE(vehicles.tax_name, V2.tax_name) AS tax_name,\n",
    "fleet_tracking.vehicle_plate_number AS plate_number,\n",
    "fleet_tracking.run_sheet_id,\n",
    "vehicle_types.name_en AS category,\n",
    "fleet_tracking_liability.liability,\n",
    "fleet_logs.logs,\n",
    "--fleet_tracking.cost,\n",
    "CASE WHEN fleet_tracking.logs_id IN (1,2) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26.0 ELSE NULL END AS vehicle_cost,\n",
    "--CASE WHEN fleet_tracking.logs_id IN (1,2) THEN COALESCE(history.monthly_cost,0)/26.0 ELSE NULL END AS vehicle_cost,\n",
    "fleet_tracking.ON_DEMAND_COST,\n",
    "extra_reasons.reason AS extra_reason,\n",
    "extra_reasons.cost AS extra_cost,\n",
    "\n",
    "case when fleet_tracking.approved = 'true' then parse_json(fleet_tracking.extra)[0]:amount::INT end  as new_extra_amount_1,\n",
    "case when fleet_tracking.approved = 'true' then extra_reasons_1.reason::VARCHAR end as extra_reasons_1 ,\n",
    "case when fleet_tracking.approved = 'true' then parse_json(fleet_tracking.extra)[1]:amount::INT end as new_extra_amount_2,\n",
    "case when fleet_tracking.approved = 'true' then extra_reasons_2.reason::VARCHAR  end as extra_reasons_2,\n",
    "case when fleet_tracking.approved = 'true' then parse_json(fleet_tracking.extra)[2]:amount::INT end  as new_extra_amount_3,\n",
    "case when fleet_tracking.approved = 'true' then extra_reasons_3.reason::VARCHAR  end as extra_reasons_3,\n",
    "COALESCE(new_extra_amount_1,0) + COALESCE(new_extra_amount_2,0) + COALESCE(new_extra_amount_3,0) + COALESCE(extra_reasonS.cost,0) as total_extra_cost , \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "deduction_reasons.reason AS deduction_reason,\n",
    "deduction_reasons.cost AS deduction_cost,\n",
    "\n",
    "case when fleet_tracking.approved = 'true' then parse_json(fleet_tracking.deduction)[0]:amount::INT end  as new_deduction_amount_1,\n",
    "case when fleet_tracking.approved = 'true' then deduction_reason_1.reason::VARCHAR  end as deduction_reason_1,\n",
    "case when fleet_tracking.approved = 'true' then parse_json(fleet_tracking.deduction)[1]:amount::INT  end as new_deduction_amount_2,\n",
    "case when fleet_tracking.approved = 'true' then deduction_reason_2.reason::VARCHAR end as deduction_reason_2,\n",
    "case when fleet_tracking.approved = 'true' then parse_json(fleet_tracking.deduction)[2]:amount::INT end as new_deduction_amount_3,\n",
    "case when fleet_tracking.approved = 'true' then deduction_reason_3.reason::VARCHAR end as deduction_reason_3,\n",
    "\n",
    "COALESCE(new_deduction_amount_1,0) + COALESCE(new_deduction_amount_2,0) + COALESCE(new_deduction_amount_3,0)  as total_deduction_cost , \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "waiting_reasons.reason AS waiting_reason,\n",
    "\n",
    "CASE WHEN fleet_tracking.logs_id IN (4,5) AND fleet_tracking.waiting_reason_id = 13 THEN vehicles.monthly_cost/26.0 END AS waiting_cost,\n",
    "fleet_tracking.karta_cost,\n",
    "fleet_tracking.adjustment_cost,\n",
    "\n",
    "(COALESCE(CASE WHEN fleet_tracking.logs_id IN (1,2) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26.0 ELSE NULL END, 0) + \n",
    "\n",
    " COALESCE(fleet_tracking.ON_DEMAND_COST,0)+ \n",
    " \n",
    "COALESCE(extra_reasons.cost, 0) + \n",
    "\n",
    "COALESCE((CASE WHEN fleet_tracking.logs_id IN (4,5) AND fleet_tracking.waiting_reason_id = 13 THEN vehicles.monthly_cost/26.0 END), 0)\n",
    "+\n",
    "COALESCE(deduction_reasons.cost, 0)) \n",
    "+ \n",
    "COALESCE(new_extra_amount_1,0) + COALESCE(new_extra_amount_2,0) + COALESCE(new_extra_amount_3,0)\n",
    "-\n",
    "(COALESCE(new_deduction_amount_1,0) + COALESCE(new_deduction_amount_3,0) + COALESCE(new_deduction_amount_3,0))\n",
    "- \n",
    "COALESCE(fleet_tracking.adjustment_cost,0) AS final_cost,\n",
    "fleet_force_delay.REVISED_DELIVERY_DATE::VARCHAR AS new_delivery_date,\n",
    "updated_logs.logs AS updated_logs,\n",
    "CASE WHEN fleet_force_delay.updated_logs_id IN (1,2) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26.0 ELSE NULL END AS updated_vehicle_cost,\n",
    "updated_extra_reasons.reason AS updated_extra_reason,\n",
    "\n",
    "case when fleet_force_delay.approved = 'true' then parse_json(fleet_force_delay.extra)[0]:amount::INT end  as updated_new_extra_amount_1,\n",
    "case when fleet_force_delay.approved = 'true' then extra_reasons_1.reason::VARCHAR end as updated_extra_reasons_1 ,\n",
    "case when fleet_force_delay.approved = 'true' then parse_json(fleet_force_delay.extra)[1]:amount::INT end as updated_new_extra_amount_2,\n",
    "case when fleet_force_delay.approved = 'true' then extra_reasons_2.reason::VARCHAR  end as updated_extra_reasons_2,\n",
    "case when fleet_force_delay.approved = 'true' then parse_json(fleet_force_delay.extra)[2]:amount::INT end  as updated_new_extra_amount_3,\n",
    "case when fleet_force_delay.approved = 'true' then extra_reasons_3.reason::VARCHAR  end as updated_extra_reasons_3,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "updated_extra_reasons.cost AS updated_extra_cost,\n",
    "updated_deduction_reasons.reason AS updated_deduction_reason,\n",
    "updated_deduction_reasons.cost AS updated_deduction_cost,\n",
    "fleet_force_delay.karta_cost AS updated_karta_cost,\n",
    "fleet_force_delay.ON_DEMAND_COST AS UPDATED_ON_DEMAND_COST,\n",
    "COALESCE(CASE WHEN fleet_force_delay.updated_logs_id IN (1,2) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26.0 ELSE NULL END, 0) + \n",
    "COALESCE(updated_extra_reasons.cost, 0) + COALESCE(UPDATED_ON_DEMAND_COST,0) + \n",
    "COALESCE(updated_deduction_reasons.cost, 0) + (COALESCE(updated_new_extra_amount_1,0) + COALESCE(updated_new_extra_amount_2,0) + COALESCE(updated_new_extra_amount_3,0) )  AS force_delay_final_cost,\n",
    "((COALESCE(CASE WHEN fleet_tracking.logs_id IN (1,2) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26.0 ELSE NULL END, 0) + \n",
    "COALESCE(extra_reasons.cost, 0) + \n",
    "COALESCE(UPDATED_ON_DEMAND_COST,0) + \n",
    "COALESCE((CASE WHEN fleet_tracking.logs_id IN (4,5) AND fleet_tracking.waiting_reason_id = 13 THEN vehicles.monthly_cost/26.0 END), 0) +\n",
    "COALESCE(deduction_reasons.cost, 0)) - \n",
    "COALESCE(fleet_tracking.adjustment_cost,0)) + \n",
    "(COALESCE(CASE WHEN fleet_force_delay.updated_logs_id IN (1,2) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26.0 ELSE NULL END, 0) + \n",
    "COALESCE(updated_extra_reasons.cost, 0) + \n",
    "COALESCE(fleet_tracking.ON_DEMAND_COST,0) +\n",
    "COALESCE(updated_deduction_reasons.cost, 0))\n",
    "+\n",
    "total_extra_cost + \n",
    "(COALESCE(updated_new_extra_amount_1,0) + COALESCE(updated_new_extra_amount_2,0) + COALESCE(updated_new_extra_amount_3,0) )\n",
    "- (COALESCE(new_deduction_amount_1,0) + COALESCE(new_deduction_amount_2,0) + COALESCE(new_deduction_amount_3,0) )\n",
    "AS total_amount\n",
    "\n",
    "FROM retool.fleet_tracking\n",
    "\n",
    "LEFT JOIN vehicles ON REPLACE(fleet_tracking.VEHICLE_PLATE_NUMBER, ' ', '') = REPLACE(vehicles.VEHICLE_PLATE_NUMBER, ' ', '') \n",
    "AND fleet_tracking.delivery_date::DATE >= vehicles.created_at AND fleet_tracking.delivery_date::DATE < vehicles.next_update\n",
    "\n",
    "LEFT JOIN vehicles V2 ON REPLACE(fleet_tracking.VEHICLE_PLATE_NUMBER, ' ', '') = REPLACE(v2.VEHICLE_PLATE_NUMBER, ' ', '') \n",
    "AND V2.ranks = 1\n",
    "\n",
    "LEFT JOIN materialized_views.lh_warehouses ON fleet_tracking.warehouse_id = lh_warehouses.id\n",
    "LEFT JOIN retool.suppliers_vehicles ON REPLACE(fleet_tracking.vehicle_plate_number, ' ', '') = suppliers_vehicles.vehicle_plate_number\n",
    "LEFT JOIN retool.supplier ON suppliers_vehicles.supplier_id = supplier.id\n",
    "LEFT JOIN warehouses ON fleet_tracking.warehouse_id = warehouses.id\n",
    "LEFT JOIN drivers ON fleet_tracking.driver_id = drivers.id\n",
    "LEFT JOIN vehicle_types ON fleet_tracking.vehicle_id = vehicle_types.id\n",
    "LEFT JOIN retool.fleet_tracking_liability ON fleet_tracking.liability_id = fleet_tracking_liability.id\n",
    "\n",
    "LEFT JOIN retool.fleet_logs ON fleet_tracking.logs_id = fleet_logs.id\n",
    "LEFT JOIN reasons extra_reasons ON fleet_tracking.extra_reason_id = extra_reasons.reason_id AND extra_reasons.region = lh_warehouses.region\n",
    "LEFT JOIN reasons deduction_reasons ON fleet_tracking.deduction_reason_id = deduction_reasons.reason_id AND deduction_reasons.region = lh_warehouses.region\n",
    "LEFT JOIN retool.logs_reason waiting_reasons ON fleet_tracking.waiting_reason_id = waiting_reasons.id\n",
    "\n",
    "LEFT JOIN retool.fleet_force_delay ON fleet_tracking.run_sheet_id = fleet_force_delay.run_sheet_id\n",
    "LEFT JOIN retool.fleet_logs updated_logs ON fleet_force_delay.updated_logs_id = updated_logs.id\n",
    "LEFT JOIN reasons updated_deduction_reasons ON fleet_force_delay.deduction_reason_id = updated_deduction_reasons.reason_id AND updated_deduction_reasons.region = lh_warehouses.region\n",
    "LEFT JOIN reasons updated_extra_reasons ON fleet_force_delay.extra_reason_id = updated_extra_reasons.reason_id AND updated_extra_reasons.region = lh_warehouses.region\n",
    "\n",
    "\n",
    "LEFT JOIN retool.logs_reason as extra_reasons_1\n",
    "ON extra_reasons_1.ID::INT  = parse_json(fleet_tracking.extra)[0]:extra_reason_id::INT\n",
    "\n",
    "LEFT JOIN retool.logs_reason as deduction_reason_1\n",
    "ON deduction_reason_1.ID::INT  = parse_json(fleet_tracking.deduction)[0]:deduction_reason_id::INT\n",
    "\n",
    "LEFT JOIN retool.logs_reason as extra_reasons_2\n",
    "ON extra_reasons_2.ID::INT  = parse_json(fleet_tracking.extra)[1]:extra_reason_id::INT\n",
    "\n",
    "LEFT JOIN retool.logs_reason as deduction_reason_2\n",
    "ON deduction_reason_2.ID::INT  = parse_json(fleet_tracking.deduction)[1]:deduction_reason_id::INT\n",
    "\n",
    "LEFT JOIN retool.logs_reason as extra_reasons_3\n",
    "ON extra_reasons_3.ID::INT  = parse_json(fleet_tracking.extra)[2]:extra_reason_id::INT\n",
    "\n",
    "LEFT JOIN retool.logs_reason as deduction_reason_3\n",
    "ON deduction_reason_3.ID::INT  = parse_json(fleet_tracking.deduction)[2]:deduction_reason_id::INT\n",
    "\n",
    "\n",
    "\n",
    "WHERE fleet_tracking.delivery_date::DATE BETWEEN date_trunc('month',current_date - interval '1 month' ) and date_trunc('month',current_date)-1 \n",
    "-- and fleet_tracking.run_sheet_id = 1374549\n",
    "\n",
    "\n",
    "UNION\n",
    "\n",
    "SELECT DISTINCT\n",
    "unutilized_vehicle.date::VARCHAR AS date,\n",
    "lh_warehouses.region,\n",
    "warehouses.name AS warehouse,\n",
    "COALESCE(vehicles.supplier_en, V2.supplier_en) AS supplier_en,\n",
    "COALESCE(vehicles.supplier_ar, V2.supplier_ar) AS supplier_ar,\n",
    "COALESCE(vehicles.tax_number, V2.tax_number) AS tax_number,\n",
    "COALESCE(vehicles.tax_name, V2.tax_name) AS tax_name,\n",
    "unutilized_vehicle.vehicle_plate_number AS plate_number,\n",
    "0 AS run_sheet_id,\n",
    "vehicle_types.name_en AS category,\n",
    "'' AS liability,\n",
    "'Unutilized' AS logs,\n",
    "0 AS vehicle_cost,\n",
    "0 as ON_DEMAND_COST,\n",
    "'' AS extra_reason,\n",
    "0 AS extra_cost,\n",
    "\n",
    "0 as new_extra_amount_1,\n",
    "'' AS  extra_reasons_1,\n",
    "0 as new_extra_amount_2,\n",
    "'' as extra_reasons_2,\n",
    "0 as new_extra_amount_3,\n",
    "'' as extra_reasons_3 , \n",
    "0  AS total_extra_cost ,\n",
    "\n",
    "\n",
    "'' AS deduction_reason,\n",
    "0 AS deduction_cost,\n",
    "\n",
    "\n",
    "0 as new_deduction_amount_1 ,\n",
    "'' as deduction_reason_1 ,\n",
    "0 as new_deduction_amount_2 ,\n",
    "'' as deduction_reason_2 , \n",
    "0 as new_deduction_amount_3 ,\n",
    "'' as deduction_reason_3,\n",
    "0 as total_deduction_cost,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'' AS waiting_reason,\n",
    "(CASE WHEN DATE BETWEEN '2024-04-01' AND '2024-04-16' THEN      \n",
    "(\n",
    "CASE WHEN region = 'Greater Cairo' THEN \n",
    "          CASE\n",
    "               WHEN (suppliers_vehicles.vehicle_id IN (67,68,100)) AND (unutilized_vehicle.arrived = true) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26\n",
    "               WHEN (suppliers_vehicles.vehicle_id NOT IN (67,68,100)) AND (unutilized_vehicle.arrived = true) THEN 150 END\n",
    "      ELSE (CASE WHEN (unutilized_vehicle.arrived = true) THEN (COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26)* 0.5 END) END )\n",
    "      ELSE \n",
    "      (\n",
    "      CASE WHEN DATE < '2024-04-01'\n",
    "      THEN \n",
    "      (CASE WHEN (unutilized_vehicle.reason_id IS NOT NULL) AND (suppliers_vehicles.vehicle_id IN (67,68,100)) AND (unutilized_vehicle.arrived = true OR unutilized_vehicle.arrived IS NULL) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26\n",
    "      WHEN (unutilized_vehicle.reason_id IS NOT NULL) AND (suppliers_vehicles.vehicle_id NOT IN (67,68,100)) AND (unutilized_vehicle.arrived = true OR unutilized_vehicle.arrived IS NULL) THEN 150 END)\n",
    "      \n",
    "      ELSE \n",
    "            ROUND(CASE\n",
    "          WHEN region = 'Greater Cairo' THEN \n",
    "              CASE\n",
    "                  WHEN unutilized_vehicle.arrived = true THEN (vehicles.monthly_cost / 26) * unutilized_vehicle.reason_id \n",
    "              END\n",
    "          ELSE \n",
    "              CASE\n",
    "                  WHEN unutilized_vehicle.arrived = true THEN (vehicles.monthly_cost / 26) * 0.5\n",
    "              END\n",
    "      END) END ) END ) AS waiting_cost,\n",
    "0 AS karta_cost,\n",
    "unutilized_vehicle.adjustment_cost,\n",
    "\n",
    " (CASE WHEN DATE BETWEEN '2024-04-01' AND '2024-04-16' THEN      \n",
    "(\n",
    "CASE WHEN region = 'Greater Cairo' THEN \n",
    "          CASE\n",
    "               WHEN (suppliers_vehicles.vehicle_id IN (67,68,100)) AND (unutilized_vehicle.arrived = true) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26\n",
    "               WHEN (suppliers_vehicles.vehicle_id NOT IN (67,68,100)) AND (unutilized_vehicle.arrived = true) THEN 150 END\n",
    "      ELSE (CASE WHEN (unutilized_vehicle.arrived = true) THEN (COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26)* 0.5 END) END )\n",
    "      ELSE \n",
    "      (\n",
    "      CASE WHEN DATE < '2024-04-01'\n",
    "      THEN \n",
    "      (CASE WHEN (unutilized_vehicle.reason_id IS NOT NULL) AND (suppliers_vehicles.vehicle_id IN (67,68,100)) AND (unutilized_vehicle.arrived = true OR unutilized_vehicle.arrived IS NULL) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26\n",
    "      WHEN (unutilized_vehicle.reason_id IS NOT NULL) AND (suppliers_vehicles.vehicle_id NOT IN (67,68,100)) AND (unutilized_vehicle.arrived = true OR unutilized_vehicle.arrived IS NULL) THEN 150 END)\n",
    "      \n",
    "      ELSE \n",
    "            ROUND(CASE\n",
    "          WHEN region = 'Greater Cairo' THEN \n",
    "              CASE\n",
    "                  WHEN unutilized_vehicle.arrived = true THEN (vehicles.monthly_cost / 26) * unutilized_vehicle.reason_id \n",
    "              END\n",
    "          ELSE \n",
    "              CASE\n",
    "                  WHEN unutilized_vehicle.arrived = true THEN (vehicles.monthly_cost / 26) * 0.5\n",
    "              END\n",
    "      END) END ) END )\n",
    "      \n",
    "      \n",
    "-- (CASE WHEN (unutilized_vehicle.reason_id IS NOT NULL) AND (suppliers_vehicles.vehicle_id IN (67,68,100)) AND (unutilized_vehicle.arrived = true OR unutilized_vehicle.arrived IS NULL) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26\n",
    "--       WHEN (unutilized_vehicle.reason_id IS NOT NULL) AND (suppliers_vehicles.vehicle_id NOT IN (67,68,100)) AND (unutilized_vehicle.arrived = true OR unutilized_vehicle.arrived IS NULL) THEN 150 END)\n",
    "      \n",
    "      - \n",
    "COALESCE(unutilized_vehicle.adjustment_cost,0) AS final_cost,\n",
    " ''  AS new_delivery_date,\n",
    "'' AS updated_logs,\n",
    "0 AS updated_vehicle_cost,\n",
    "'' AS updated_extra_reason,\n",
    "\n",
    "0 as updated_new_extra_amount_1,\n",
    "'' AS  updated_extra_reasons_1,\n",
    "0 as updated_new_extra_amount_2,\n",
    "'' as updated_extra_reasons_2,\n",
    "0 as updated_new_extra_amount_3,\n",
    "'' as updated_extra_reasons_3 , \n",
    "\n",
    "0 AS updated_extra_cost,\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'' AS updated_deduction_reason,\n",
    "0 AS updated_deduction_cost,\n",
    "0 AS updated_karta_cost,\n",
    "0 AS UPDATED_ON_DEMAND_COST,\n",
    "0 AS force_delay_final_cost,\n",
    "\n",
    " -- unutilized_vehicle_cost\n",
    "-- (CASE WHEN (unutilized_vehicle.reason_id IS NOT NULL) AND (suppliers_vehicles.vehicle_id IN (67,68,100)) AND (unutilized_vehicle.arrived = true OR unutilized_vehicle.arrived IS NULL) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26\n",
    "--       WHEN (unutilized_vehicle.reason_id IS NOT NULL) AND (suppliers_vehicles.vehicle_id NOT IN (67,68,100)) AND (unutilized_vehicle.arrived = true OR unutilized_vehicle.arrived IS NULL) THEN 150 END) \n",
    " \n",
    "(CASE WHEN DATE BETWEEN '2024-04-01' AND  '2024-04-16' THEN      \n",
    "(\n",
    "CASE WHEN region = 'Greater Cairo' THEN \n",
    "          CASE\n",
    "               WHEN (suppliers_vehicles.vehicle_id IN (67,68,100)) AND (unutilized_vehicle.arrived = true) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26\n",
    "               WHEN (suppliers_vehicles.vehicle_id NOT IN (67,68,100)) AND (unutilized_vehicle.arrived = true) THEN 150 END\n",
    "      ELSE (CASE WHEN (unutilized_vehicle.arrived = true) THEN (COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26)* 0.5 END) END )\n",
    "      ELSE \n",
    "      (\n",
    "      CASE WHEN DATE < '2024-04-01'\n",
    "      THEN \n",
    "      (CASE WHEN (unutilized_vehicle.reason_id IS NOT NULL) AND (suppliers_vehicles.vehicle_id IN (67,68,100)) AND (unutilized_vehicle.arrived = true OR unutilized_vehicle.arrived IS NULL) THEN COALESCE(vehicles.monthly_cost, v2.monthly_cost)/26\n",
    "      WHEN (unutilized_vehicle.reason_id IS NOT NULL) AND (suppliers_vehicles.vehicle_id NOT IN (67,68,100)) AND (unutilized_vehicle.arrived = true OR unutilized_vehicle.arrived IS NULL) THEN 150 END)\n",
    "      \n",
    "      ELSE \n",
    "            ROUND(CASE\n",
    "          WHEN region = 'Greater Cairo' THEN \n",
    "              CASE\n",
    "                  WHEN unutilized_vehicle.arrived = true THEN (vehicles.monthly_cost / 26) * unutilized_vehicle.reason_id \n",
    "              END\n",
    "          ELSE \n",
    "              CASE\n",
    "                  WHEN unutilized_vehicle.arrived = true THEN (vehicles.monthly_cost / 26) * 0.5\n",
    "              END\n",
    "      END) END ) END ) - COALESCE(unutilized_vehicle.adjustment_cost,0) +\n",
    "(COALESCE(new_extra_amount_1,0) + COALESCE(new_extra_amount_2,0) + COALESCE(new_extra_amount_3,0) ) \n",
    "+ \n",
    "(COALESCE(updated_new_extra_amount_1,0) + COALESCE(updated_new_extra_amount_2,0) + COALESCE(updated_new_extra_amount_3,0) ) \n",
    "-\n",
    "(COALESCE(new_deduction_amount_1,0) + COALESCE(new_deduction_amount_2,0) + COALESCE(new_deduction_amount_3,0) )\n",
    "AS total_amount\n",
    "\n",
    "FROM retool.unutilized_vehicle\n",
    "\n",
    "LEFT JOIN (WITH history AS (\n",
    "    SELECT DISTINCT\n",
    "        SUPPLIERS_VEHICLES_history.supplier_id,\n",
    "        supplier.name_en AS supplier_en,\n",
    "        supplier.name_ar AS supplier_ar,\n",
    "        supplier.tax_number,\n",
    "        supplier.tax_name,\n",
    "        SUPPLIERS_VEHICLES_history.VEHICLE_PLATE_NUMBER,\n",
    "        SUPPLIERS_VEHICLES_history.monthly_cost,\n",
    "        SUPPLIERS_VEHICLES_history.created_at AS created_timestamp,\n",
    "        SUPPLIERS_VEHICLES_history.created_at::DATE AS created_at\n",
    "    FROM retool.SUPPLIERS_VEHICLES_history\n",
    "    LEFT JOIN retool.supplier ON SUPPLIERS_VEHICLES_history.supplier_id = supplier.id\n",
    "),\n",
    "history_with_next_update AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        COALESCE(LEAD(created_at) OVER (PARTITION BY VEHICLE_PLATE_NUMBER ORDER BY created_timestamp), CURRENT_DATE + 1) AS next_update \n",
    "    FROM history\n",
    ")\n",
    "SELECT\n",
    "    *\n",
    "FROM history_with_next_update\n",
    "WHERE created_at <> next_update OR next_update IS NULL) vehicles ON REPLACE(unutilized_vehicle.VEHICLE_PLATE_NUMBER, ' ', '') = REPLACE(vehicles.VEHICLE_PLATE_NUMBER, ' ', '') \n",
    "AND unutilized_vehicle.date::DATE >= vehicles.created_at AND unutilized_vehicle.date < vehicles.next_update\n",
    "\n",
    "LEFT JOIN (WITH history AS (\n",
    "    SELECT DISTINCT\n",
    "        SUPPLIERS_VEHICLES_history.supplier_id,\n",
    "        supplier.name_en AS supplier_en,\n",
    "        supplier.name_ar AS supplier_ar,\n",
    "        supplier.tax_number,\n",
    "        supplier.tax_name,\n",
    "        SUPPLIERS_VEHICLES_history.VEHICLE_PLATE_NUMBER,\n",
    "        SUPPLIERS_VEHICLES_history.monthly_cost,\n",
    "        SUPPLIERS_VEHICLES_history.created_at AS created_timestamp,\n",
    "        SUPPLIERS_VEHICLES_history.created_at::DATE AS created_at\n",
    "    FROM retool.SUPPLIERS_VEHICLES_history\n",
    "    LEFT JOIN retool.supplier ON SUPPLIERS_VEHICLES_history.supplier_id = supplier.id\n",
    "),\n",
    "history_with_next_update AS (\n",
    "    SELECT\n",
    "        *,\n",
    "        COALESCE(LEAD(created_at) OVER (PARTITION BY VEHICLE_PLATE_NUMBER ORDER BY created_timestamp), CURRENT_DATE + 1) AS next_update \n",
    "    FROM history\n",
    ")\n",
    "SELECT\n",
    "    *,\n",
    "    ROW_NUMBER()OVER(PARTITION BY VEHICLE_PLATE_NUMBER ORDER BY created_at) AS ranks\n",
    "FROM history_with_next_update\n",
    "WHERE created_at <> next_update OR next_update IS NULL) v2 ON REPLACE(unutilized_vehicle.VEHICLE_PLATE_NUMBER, ' ', '') = REPLACE(v2.VEHICLE_PLATE_NUMBER, ' ', '') \n",
    "AND v2.ranks = 1\n",
    "\n",
    "LEFT JOIN warehouses ON unutilized_vehicle.warehouse_id = warehouses.id\n",
    "LEFT JOIN retool.suppliers_vehicles ON REPLACE(unutilized_vehicle.vehicle_plate_number, ' ', '') = suppliers_vehicles.vehicle_plate_number\n",
    "LEFT JOIN retool.supplier ON suppliers_vehicles.supplier_id = supplier.id\n",
    "LEFT JOIN retool.logs_reason ON unutilized_vehicle.reason_id = logs_reason.id\n",
    "LEFT JOIN vehicle_types ON suppliers_vehicles.vehicle_id = vehicle_types.id\n",
    "LEFT JOIN materialized_views.lh_warehouses ON unutilized_vehicle.warehouse_id = lh_warehouses.id\n",
    "\n",
    "WHERE unutilized_vehicle.date::DATE  BETWEEN date_trunc('month',current_date - interval '1 month' ) and date_trunc('month',current_date)-1 \n",
    "AND (unutilized_vehicle.arrived = true OR unutilized_vehicle.arrived IS NULL)\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "SELECT \n",
    "date_trunc('month',date::date) month,\n",
    " region,\n",
    "category,\n",
    "count(distinct run_sheet_id) vehicles,\n",
    "sum(total_amount) total_amountt,\n",
    "total_amountt/vehicles cost_per_vehicle_run \n",
    "FROM fms\n",
    "where logs in ('first')\n",
    " GROUP BY all\n",
    "order by 1,2,3\n",
    ")\n",
    "\n",
    "),\n",
    "\n",
    "vec as (\n",
    "select vct.region , vt.id as vehicle_id,name_en as vehicle_name,vc.weight as vehicle_weight,vc.cbm as vehicle_cbm,vehicle_cost+300 as vehicle_cost\n",
    "from vec_cost_type vct\n",
    "join VEHICLE_TYPES  vt on vt.name_en = vct.vehicle_name\n",
    "join  RETOOL.VEHICLE_CAPACITIES vc on vc.vehicle_id = vt.id\n",
    "where vehicle_id = 100\n",
    "),\n",
    "products_dim as (\n",
    "select product_id,is_basic_unit,packing_unit_id,(long * width * height)/1000000.00 AS cbm,weight/1000.00 AS weight,\n",
    "from (\n",
    "SELECT DISTINCT\n",
    "product_id, packing_unit_id, long, width, height, weight,is_basic_unit\n",
    "FROM packing_unit_products\n",
    "join products on products.id = packing_unit_products.product_id \n",
    "where  is_basic_unit = 1\n",
    "and products.ACTIVATION = 'true'\n",
    ")\n",
    "),\n",
    "vehicle_cost as (\n",
    "select * ,vehicle_cost/quantity as vehicle_cost_per_unit \n",
    "from (\n",
    "select region,product_id,packing_unit_id,vehicle_name,vehicle_id,cbm,weight,least(cbm_qty,weight_qty) as quantity ,vehicle_cost as vehicle_cost\n",
    "from(\n",
    "select *, floor((vehicle_cbm*0.95)/cbm) as cbm_qty , floor((vehicle_weight*0.9)/weight) as weight_qty  \n",
    "from  products_dim , vec\n",
    ")\n",
    ")\n",
    "),\n",
    "wh_cost as (\n",
    "select product_id,region,sum(wh_cost)/sum(nmv_ex_vat) as wh_cost_perc , sum(lm_cost)/sum(nmv_ex_vat) as LM_cost_perc\n",
    "from finance.sku_costs c \n",
    "where month >= date_trunc('month',current_date - interval '10 months')\n",
    "and WH_COST > 0 \n",
    "and nmv_ex_vat > 0 \n",
    "and lm_cost > 0 \n",
    "group by all \n",
    "),\n",
    "mapping as (\n",
    "SELECT *\n",
    "             FROM   (values\n",
    "                            ('Greater Cairo','Cairo',700),\n",
    "                            ('Greater Cairo','Giza', 701),\n",
    "                            ('Delta','Delta West',703),\n",
    "                            ('Delta','Delta East', 704),\n",
    "                            ('Upper Egypt','Upper Egypt', 1124),\n",
    "                            ('Upper Egypt','Upper Egypt', 1126),\n",
    "                            ('Upper Egypt','Upper Egypt',1123),\n",
    "                            ('Upper Egypt','Upper Egypt',1125),\n",
    "                            ('Alexandria','Alexandria',702))\n",
    "\t\t\t\t\t\t\t\n",
    "                    x(main_region,region,cohort_id)\n",
    "\t\t\t\t\t),\n",
    "\n",
    "skus_prices as (\n",
    "with local_prices as (\n",
    "SELECT  case when cpu.cohort_id in (700,695) then 'Cairo'\n",
    "             when cpu.cohort_id in (701) then 'Giza'\n",
    "             when cpu.cohort_id in (704,698) then 'Delta East'\n",
    "             when cpu.cohort_id in (703,697) then 'Delta West'\n",
    "             when cpu.cohort_id in (696,1123,1124,1125,1126) then 'Upper Egypt'\n",
    "             when cpu.cohort_id in (702,699) then 'Alexandria'\n",
    "        end as region,\n",
    "\t\tcohort_id,\n",
    "        pu.product_id,\n",
    "\t\tpu.packing_unit_id as packing_unit_id,\n",
    "\t\tpu.basic_unit_count,\n",
    "        avg(cpu.price) as price\n",
    "FROM    cohort_product_packing_units cpu\n",
    "join    PACKING_UNIT_PRODUCTS pu on pu.id = cpu.product_packing_unit_id\n",
    "WHERE   cpu.cohort_id in (700,701,702,703,704,696,695,698,697,699,1123,1124,1125,1126)\n",
    "    and cpu.created_at::date<>'2023-07-31'\n",
    "    and cpu.is_customized = true\n",
    "\tgroup by all \n",
    "),\n",
    "live_prices as (\n",
    "select region,cohort_id,product_id,pu_id as packing_unit_id,buc as basic_unit_count,NEW_PRICE as price\n",
    "from materialized_views.DBDP_PRICES\n",
    "where created_at = current_date\n",
    "and DATE_PART('hour',CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp())) BETWEEN SPLIT_PART(time_slot, '-', 1)::int AND SPLIT_PART(time_slot, '-', 2)::int\n",
    "and cohort_id in (700,701,702,703,704,696,695,698,697,699,1123,1124,1125,1126)\n",
    "),\n",
    "prices as (\n",
    "select *\n",
    "from (\n",
    "    SELECT *, 1 AS priority FROM live_prices\n",
    "    UNION ALL\n",
    "    SELECT *, 2 AS priority FROM local_prices\n",
    ")\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY region,cohort_id,product_id,packing_unit_id ORDER BY priority) = 1\n",
    ")\n",
    "select region,cohort_id,product_id,price \n",
    "from prices \n",
    "where basic_unit_count = 1\n",
    "AND (\n",
    "        (product_id = 1309 AND packing_unit_id = 2)\n",
    "        OR (product_id <> 1309)\n",
    "      )\n",
    ")\n",
    "select *,(wac_p + vehicle_cost_per_unit + (wac_p*wh_cost_perc)) as wac_ws,\n",
    "(wac_p + (wac_p*lm_cost_perc) + (wac_p*wh_cost_perc)) as wac_norm,\n",
    "case when price <> 0 then (price-wac_ws)/price else 0 end as cm3_whole_sale,\n",
    "case when price <> 0 then (price-wac_norm)/price else 0 end as cm3_norm\n",
    "from (\n",
    "select m.cohort_id,vc.product_id,CONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,b.name_ar as brand,cat.name_ar as cat,m.region,packing_unit_id,vehicle_name,vehicle_id,vc.quantity,vc.vehicle_cost,vehicle_cost_per_unit,coalesce(wh_cost_perc,0) as wh_cost_perc,coalesce(LM_cost_perc,0) as LM_cost_perc,max(wac1) as wac1,max(wac_p) as wac_p,p.price\n",
    "from vehicle_cost vc  \n",
    "left join wh_cost wc on vc.product_id = wc.product_id and wc.region = vc.region\n",
    "join mapping m on m.main_region = vc.region\n",
    "join finance.all_cogs c on c.product_id = vc.product_id and CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp()) between c.from_date and c.to_date\n",
    "join skus_prices p on p.product_id = vc.product_id and p.cohort_id = m.cohort_id \n",
    "join products  on products.id = vc.product_id \n",
    "join categories cat on cat.id = products.category_id\n",
    "join brands b on b.id = products.brand_id\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "where wac1 > 0 and wac_p > 0 \n",
    "group by all\n",
    ")x\n",
    "\n",
    "where region = 'Cairo'\n",
    "and price > 0\n",
    "'''\n",
    "whole_sale = query_snowflake(query, columns = ['COHORT_ID','PRODUCT_ID','SKU','BRAND','CAT','REGION','PACKING_UNIT_ID','VEHICLE_NAME','VEHICLE_ID','QUANTITY','VEHICLE_COST','VEHICLE_COST_PER_UNIT','WH_COST_PERC','LM_COST_PERC','WAC1','WAC_P','PRICE','WAC_WS','WAC_NORM','CM3_WHOLE_SALE','CM3_NORM'])\n",
    "whole_sale.columns = whole_sale.columns.str.lower()\n",
    "for col in whole_sale.columns:\n",
    "    whole_sale[col] = pd.to_numeric(whole_sale[col], errors='ignore')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f738d2e8-c94b-4bae-8b25-148150672199",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT cat, brand, margin as target_bm\n",
    "FROM    performance.commercial_targets cplan\n",
    "QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE)OVER()) = DATE_TRUNC('month', CURRENT_DATE) THEN DATE_TRUNC('month', CURRENT_DATE)\n",
    "ELSE DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    "'''\n",
    "brand_cat_target  = query_snowflake(query, columns = ['cat','brand','target_bm'])\n",
    "brand_cat_target.target_bm=pd.to_numeric(brand_cat_target.target_bm)\n",
    "\n",
    "query = '''\n",
    "select cat,sum(target_bm *(target_nmv/cat_total)) as cat_target_margin\n",
    "from (\n",
    "select *,sum(target_nmv)over(partition by cat) as cat_total\n",
    "from (\n",
    "select cat,brand,avg(target_bm) as target_bm , sum(target_nmv) as target_nmv\n",
    "from (\n",
    "SELECT DISTINCT date,city as region,cat, brand, margin as target_bm,nmv as target_nmv\n",
    "FROM    performance.commercial_targets cplan\n",
    "QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE)OVER()) = DATE_TRUNC('month', CURRENT_DATE) THEN DATE_TRUNC('month', CURRENT_DATE)\n",
    "ELSE DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    ")\n",
    "group by all\n",
    ")\n",
    ")\n",
    "group by all \n",
    "'''\n",
    "cat_target  = query_snowflake(query, columns = ['cat','cat_target_margin'])\n",
    "cat_target.cat_target_margin=pd.to_numeric(cat_target.cat_target_margin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2999cf-a506-4a97-8bdf-b5c7715d9fe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT  DISTINCT\n",
    "\t\tcpc.cohort_id,  \n",
    "\t\tpso.product_id,\n",
    "        sum(pso.total_price) as nmv,\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "join COHORT_PRICING_CHANGES cpc on cpc.id = pso.COHORT_PRICING_CHANGE_ID\n",
    "WHERE so.created_at::date between date_trunc('month', current_date- interval '3 months') and  date_trunc('month',current_date)-1\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "\n",
    "GROUP BY ALL\n",
    "'''\n",
    "sales  = query_snowflake(query, columns = ['cohort_id','product_id','nmv'])\n",
    "sales.columns = sales.columns.str.lower()\n",
    "for col in sales.columns:\n",
    "    sales[col] = pd.to_numeric(sales[col], errors='ignore')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b51bea60-893e-4efb-922a-7898226d8771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "select * \n",
    "from materialized_views.sku_commercial_groups\n",
    "'''\n",
    "groups  = setup_environment_2.dwh_pg_query(query, columns = ['product_id','group'])\n",
    "groups.columns = groups.columns.str.lower()\n",
    "for col in groups.columns:\n",
    "    groups[col] = pd.to_numeric(groups[col], errors='ignore')      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af468a1-f6e1-41ad-97f5-c88c82a73725",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "\n",
    "WITH whs as (SELECT *\n",
    "             FROM   (values\n",
    "                            ('Cairo', 'Mostorod', 1,700),\n",
    "                            ('Giza', 'Barageel', 236,701),\n",
    "                            ('Delta West', 'El-Mahala', 337,703),\n",
    "                            ('Delta West', 'Tanta', 8,703),\n",
    "                            ('Delta East', 'Mansoura FC', 339,704),\n",
    "                            ('Delta East', 'Sharqya', 170,704),\n",
    "                            ('Upper Egypt', 'Assiut FC', 501,1124),\n",
    "                            ('Upper Egypt', 'Bani sweif', 401,1126),\n",
    "                            ('Upper Egypt', 'Menya Samalot', 703,1123),\n",
    "                            ('Upper Egypt', 'Sohag', 632,1125),\n",
    "                            ('Alexandria', 'Khorshed Alex', 797,702),\n",
    "\t\t\t\t\t\t\t('Giza', 'Sakkarah', 962,701)\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t)\n",
    "                    x(region, wh, warehouse_id,cohort_id))\n",
    "\t\t\t\t\t\n",
    "select cohort_id,product_id,sum(stocks) as stocks \n",
    "from (\n",
    "\t\tSELECT DISTINCT whs.region,\n",
    "\t\t\t\tcohort_id,\t\n",
    "                whs.wh,\n",
    "                product_warehouse.product_id,\n",
    "                (product_warehouse.available_stock)::integer as stocks,\n",
    "\n",
    "        from whs\n",
    "        JOIN product_warehouse ON product_warehouse.warehouse_id = whs.warehouse_id\n",
    "        JOIN products on product_warehouse.product_id = products.id\n",
    "        JOIN product_units ON products.unit_id = product_units.id\n",
    "\n",
    "        where   product_warehouse.warehouse_id not in (6,9,10)\n",
    "            AND product_warehouse.is_basic_unit = 1\n",
    "\t\t\tand product_warehouse.available_stock > 0 \n",
    "\n",
    ")\n",
    "group by all\n",
    "\n",
    "'''\n",
    "stocks  = query_snowflake(query, columns = ['cohort_id','product_id','stocks'])\n",
    "stocks.columns = stocks.columns.str.lower()\n",
    "for col in stocks.columns:\n",
    "    stocks[col] = pd.to_numeric(stocks[col], errors='ignore')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c7ace89-645d-4ee3-9031-f3407acd26bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "command_string = '''\n",
    "select \n",
    "product_id,\n",
    "PACKING_UNIT_id,\n",
    "basic_unit_count,\n",
    "from PACKING_UNIT_PRODUCTS\n",
    "where PACKING_UNIT_PRODUCTS.deleted_at is null\n",
    "order by product_id,basic_unit_count'''\n",
    "pu = query_snowflake(command_string, columns = ['product_id','pu_id', 'buc'])\n",
    "pu.product_id = pd.to_numeric(pu.product_id)\n",
    "pu.pu_id = pd.to_numeric(pu.pu_id)\n",
    "pu.buc = pd.to_numeric(pu.buc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72ebc880-886f-4e6a-9bef-a1a6f04c5a55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query ='''\n",
    "select product_id,new_pp,forecasted_date\n",
    "from materialized_views.DBDP_PRICE_UPS\n",
    "where region = 'Cairo'\n",
    "'''\n",
    "price_ups  = query_snowflake(query, columns = ['product_id','new_pp','forcasted_date'])\n",
    "price_ups.columns = price_ups.columns.str.lower()\n",
    "for col in price_ups.columns:\n",
    "    price_ups[col] = pd.to_numeric(price_ups[col], errors='ignore')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48cb4c4c-8598-4868-b3eb-b219fca0f498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def select_price(x):\n",
    "    old_cm3 = x['cm3_norm']\n",
    "    new_cm3 = x['cm3_whole_sale']\n",
    "    target_margin = x['target_margin']\n",
    "    wac_p = x['wac_p'] \n",
    "    wac_ws = x['wac_ws'] \n",
    "    wac_norm = x['wac_norm']\n",
    "    price = x['price'] \n",
    "    new_pp = x['new_pp']\n",
    "    stocks = x['stocks']\n",
    "    if new_cm3< old_cm3 or new_cm3 < 0:\n",
    "        if(price > wac_p):\n",
    "            return price \n",
    "        else:\n",
    "            return round((wac_p/(1-target_margin))*4)/4\n",
    "    else:\n",
    "        if old_cm3 < 0:\n",
    "            old_cm3=0\n",
    "        distance = (new_cm3-old_cm3)\n",
    "        if pd.isna(new_pp):\n",
    "            return round((wac_ws/(1-(new_cm3-(0.9*distance))))*4)/4\n",
    "        elif (~pd.isna(new_pp)) and stocks > 0:\n",
    "            return round((wac_ws/(1-(new_cm3-(0.5*distance))))*4)/4\n",
    "        else:\n",
    "            return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9158017-ccd2-4f8e-a149-a46fb86ea330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wholesale_data  = whole_sale.merge(brand_cat_target,on =['cat','brand'],how='left')\n",
    "wholesale_data  = wholesale_data.merge(cat_target,on =['cat'],how='left')\n",
    "wholesale_data  = wholesale_data.merge(price_ups,on =['product_id'],how='left')\n",
    "wholesale_data = wholesale_data.merge(stocks,on=['product_id','cohort_id'],how='left')\n",
    "wholesale_data['stocks'] = wholesale_data['stocks'].fillna(0)\n",
    "wholesale_data['target_margin'] = (wholesale_data['target_bm'].fillna(wholesale_data['cat_target_margin'])).fillna(0.04)\n",
    "wholesale_data['selected_price'] =  wholesale_data.apply(select_price,axis=1)\n",
    "wholesale_data['new_margin'] =  (wholesale_data['selected_price']-wholesale_data['wac_p'])/wholesale_data['selected_price']\n",
    "wholesale_data['price_diff'] = (wholesale_data['selected_price']-wholesale_data['price'])/wholesale_data['price']\n",
    "wholesale_data = wholesale_data.merge(sales,on=['product_id','cohort_id'],how='left')\n",
    "wholesale_data['nmv'] = wholesale_data['nmv'].fillna(0)\n",
    "wholesale_data['total_nmv'] = wholesale_data.groupby('cohort_id')['nmv'].transform(sum)\n",
    "wholesale_data['cntrb'] = wholesale_data['nmv']/wholesale_data['total_nmv'] \n",
    "wholesale_data = wholesale_data.merge(groups,on=['product_id'],how='left')\n",
    "wholesale_data['new_group_nmv'] = wholesale_data['nmv']\n",
    "wholesale_data.loc[wholesale_data['stocks'] == 0 ,'new_group_nmv'] = wholesale_data['nmv']*0.1\n",
    "wholesale_data['total_group_nmv'] =wholesale_data.groupby(['cohort_id','group'])['new_group_nmv'].transform(sum)\n",
    "wholesale_data['price_cntrb'] = wholesale_data['selected_price'] * (wholesale_data['new_group_nmv']/wholesale_data['total_group_nmv'])\n",
    "wholesale_data['final_group_price'] = wholesale_data.groupby(['cohort_id','group'])['price_cntrb'].transform(sum) \n",
    "wholesale_data['final_price'] = wholesale_data['final_group_price'].fillna(wholesale_data['selected_price'])\n",
    "wholesale_data['final_price']=round(wholesale_data['final_price']*4)/4\n",
    "wholesale_data.loc[wholesale_data['final_price']==0,'final_price'] = wholesale_data['selected_price']\n",
    "wholesale_data.loc[wholesale_data['final_price']==0,'final_price'] = wholesale_data['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a76c9534-1af2-4a1e-8958-a82dad7956b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scope = [\"https://spreadsheets.google.com/feeds\",\n",
    "         'https://www.googleapis.com/auth/spreadsheets',\n",
    "         \"https://www.googleapis.com/auth/drive.file\",\n",
    "         \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_dict(json.loads(setup_environment_2.get_secret(\"prod/maxab-sheets\")), scope)\n",
    "client = gspread.authorize(creds)\n",
    "force_brands = client.open('Wholesales_exec').worksheet('brands')\n",
    "force_cats = client.open('Wholesales_exec').worksheet('cats')\n",
    "force_brands_df = pd.DataFrame(force_brands.get_all_records())\n",
    "force_cats_df = pd.DataFrame(force_cats.get_all_records())\n",
    "if force_brands_df.empty:\n",
    "    forced_brand_list = []\n",
    "else:    \n",
    "    forced_brand_list = force_brands_df.brand.unique()\n",
    "    \n",
    "if force_cats_df.empty:\n",
    "    forced_cat_list = []  \n",
    "else:    \n",
    "    forced_cat_list = force_cats_df.cat.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2793a600-7980-4b23-99e1-492b6c05f273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wholesale_data.loc[wholesale_data['brand'].isin(forced_brand_list),'final_price'] = wholesale_data['price'] \n",
    "wholesale_data.loc[wholesale_data['cat'].isin(forced_cat_list),'final_price'] = wholesale_data['price'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ef3fb2a-1f63-41f8-aa30-88633be561a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dcfebb5-6bdc-489f-9575-3dbc89ab9888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data = wholesale_data[['cohort_id', 'product_id', 'sku', 'brand', 'cat','final_price']]\n",
    "final_data=final_data.drop_duplicates()\n",
    "final_data = final_data.merge(pu, on='product_id')\n",
    "final_data['new_price'] = final_data['final_price'] * final_data['buc']\n",
    "final_data['ind'] = 1\n",
    "final_data['ind'] = final_data.groupby(['cohort_id', 'product_id']).ind.cumsum()\n",
    "remove_min_pu = pd.read_csv('skus_to_remove_min.csv')\n",
    "remove_min_pu['remove_min'] = 1\n",
    "final_data = final_data.merge(remove_min_pu[['product_id','remove_min']], on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d0a965-4428-473d-b37b-cb1e8d7d9693",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cart_rules_data = final_data.copy()\n",
    "cart_rules_data=cart_rules_data.merge(wholesale_data[['cohort_id','product_id','quantity']],on=['cohort_id','product_id'])\n",
    "cart_rules_data['car_allowed_quantity'] = cart_rules_data['quantity']/(cart_rules_data['buc']*3)\n",
    "cart_rules_data['half_allowed_quantity'] = 15000/(cart_rules_data['new_price'])\n",
    "cart_rules_data['Cart_rules'] = np.ceil(np.minimum(np.minimum(cart_rules_data['half_allowed_quantity'],cart_rules_data['car_allowed_quantity']),100))\n",
    "cart_rules_data.loc[cart_rules_data['brand'].isin(['ريد بل','فيوري']),'Cart_rules']=7\n",
    "cart_rules_data.loc[cart_rules_data['cat'].isin(['حاجه ساقعه']),'Cart_rules']=np.minimum(cart_rules_data['Cart_rules'],50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a166de2d-2db1-427d-bb81-cd34cf8ad98d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_upload = final_data[['product_id','sku','pu_id','new_price','cohort_id','ind','remove_min']]\n",
    "to_upload=to_upload.drop_duplicates()\n",
    "to_upload.dropna(subset=['new_price'], inplace=True)\n",
    "to_upload = to_upload[to_upload.new_price > 0].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b1161f8-c761-41f0-8873-3a487cbe4164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "to_upload['cohort_id'] =1156\n",
    "cart_rules_data['cohort_id'] =1156"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da0953c8-7be9-412d-9a33-c81effc4d299",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cart_rules_data = cart_rules_data[['cohort_id','product_id','pu_id','Cart_rules']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "417f6712-b0db-424e-83e4-481b59bbff47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spliting file into chunks...\n",
      "len chunks = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  4.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading...\n",
      "Prices are upoladed successfuly cohort: 1156, chunk: 1\n",
      "Prices are upoladed successfuly cohort: 1156, chunk: 2\n",
      "Prices are upoladed successfuly cohort: 1156, chunk: 3\n"
     ]
    }
   ],
   "source": [
    "for cohort in to_upload.cohort_id.unique():\n",
    "        upload = to_upload[to_upload['cohort_id']==cohort]\n",
    "        out=upload[['product_id', 'sku', 'pu_id', 'new_price', 'ind', 'remove_min']].copy()\n",
    "        out.columns = ['Product ID','Product Name','Packing Unit ID','Price','ind','remove_min']\n",
    "        out['Visibility (YES/NO)'] = 'YES'\n",
    "        out.loc[(out['ind'] == 1) & (out['remove_min'] == 1), 'Visibility (YES/NO)'] = 'NO'\n",
    "        out.drop(columns=['ind','remove_min'], inplace=True)\n",
    "        out = out.drop_duplicates()\n",
    "        out['Execute At (format:dd/mm/yyyy HH:mm)'] = None\n",
    "        out['Tags'] = None\n",
    "        file_name_ = 'uploads/1_new_{}.xlsx'.format(cohort).replace(' ','_')\n",
    "        out.to_excel(file_name_,index = False,engine = 'xlsxwriter')\n",
    "        time.sleep(5)\n",
    "        ################### Loop to avoid file limit ######################\n",
    "        # split file into chunks\n",
    "        print('Spliting file into chunks...')\n",
    "        if cohort == 61:\n",
    "            chunks = [out[i:i + 2000] for i in range(0, len(out), 2000)]\n",
    "        else:\n",
    "            chunks = [out[i:i + 4000] for i in range(0, len(out), 4000)]\n",
    "        print(f'len chunks = {len(chunks)}')\n",
    "        fileslist = []\n",
    "        for i, chunk in tqdm(enumerate(chunks), total=len(chunks)):\n",
    "            fileslist.append(f'manual/output_{cohort}_chunk_{i + 1}.xlsx')\n",
    "            output_file_path = f'manual/output_{cohort}_chunk_{i + 1}.xlsx'\n",
    "            chunk.to_excel(output_file_path, index=False, engine='xlsxwriter')\n",
    "        # Loop over chunks and upload\n",
    "        print('Uploading...')\n",
    "        for file in fileslist:\n",
    "            chunk = file.split('chunk_')[1].split('.xls')[0]\n",
    "            x = post_prices(cohort, file)\n",
    "            # print(str(x.content))\n",
    "            if ('\"success\":true' in str(x.content).lower()):\n",
    "                print(f\"Prices are upoladed successfuly cohort: {cohort}, chunk: {chunk}\")\n",
    "            else:\n",
    "                print(f\"ERROR cohort: {cohort}, chunk: {chunk}\")\n",
    "                print(x.content)\n",
    "                final_status = False\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12c262d3-a258-4e98-b82f-c65c0e566bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_1156\n"
     ]
    }
   ],
   "source": [
    "for cohort in cart_rules_data.cohort_id.unique():\n",
    "    req_data = cart_rules_data[cart_rules_data['cohort_id']==cohort]\n",
    "    if len(req_data) > 0 :\n",
    "        req_data = req_data[['product_id','pu_id','Cart_rules']]\n",
    "        req_data.columns = ['Product ID','Packing Unit ID','Cart Rules']\n",
    "        req_data.to_excel(f'CartRules_{cohort}.xlsx', index=False, engine='xlsxwriter')\n",
    "        time.sleep(5)\n",
    "        x =  post_cart_rules(cohort,f'CartRules_{cohort}.xlsx')\n",
    "        if x.ok:\n",
    "            print(f\"success_{cohort}\")\n",
    "        else:\n",
    "            print(f\"ERROR_{cohort}\")\n",
    "            print(x.content)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3102cb-4465-4a39-88d8-45585432530c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
