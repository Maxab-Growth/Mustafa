{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treasure Hunt Scheduler\n",
    "\n",
    "This script runs daily at 12 AM to process Treasure Hunt SKUs and push prices to the MaxAB API.\n",
    "\n",
    "## Workflow\n",
    "1. Read 'Treasure Hunt' Google Sheet (Sheet6)\n",
    "2. Process SKUs - determine which are visible today\n",
    "3. Handle duplicates - keep only today's entry for duplicate SKUs\n",
    "4. Set remove_min=1 for SKUs not visible today\n",
    "5. Push prices to cohort 61\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treasure Hunt Scheduler loaded at 2026-02-09 17:40:53 Cairo time\n",
      "Today's date: 2026-02-09\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import base64\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# AWS for secrets management\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# HTTP requests for API calls\n",
    "import requests\n",
    "\n",
    "# Progress bar for chunk uploads\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Google Sheets integration\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "# Import setup_environment_2 for Google Sheets credentials\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import setup_environment_2\n",
    "\n",
    "# Cairo timezone\n",
    "CAIRO_TZ = pytz.timezone('Africa/Cairo')\n",
    "\n",
    "def get_cairo_now():\n",
    "    \"\"\"Get current datetime in Cairo timezone.\"\"\"\n",
    "    return datetime.now(CAIRO_TZ)\n",
    "\n",
    "def get_cairo_today():\n",
    "    \"\"\"Get today's date in Cairo timezone.\"\"\"\n",
    "    return datetime.now(CAIRO_TZ).date()\n",
    "\n",
    "CAIRO_NOW = get_cairo_now()\n",
    "TODAY = get_cairo_today()\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "CHUNK_SIZE_SPECIAL = 2000   # Chunk size for cohort 61\n",
    "UPLOAD_DIR = 'uploads'\n",
    "MANUAL_DIR = 'manual'\n",
    "\n",
    "# Google Sheets configuration\n",
    "TREASURE_HUNT_GSHEET = 'Treasure Hunt'\n",
    "TREASURE_HUNT_SHEET = 'Sheet6'\n",
    "\n",
    "# Fixed cohort for Treasure Hunt\n",
    "TREASURE_HUNT_COHORT = 61\n",
    "\n",
    "print(f\"Treasure Hunt Scheduler loaded at {CAIRO_NOW.strftime('%Y-%m-%d %H:%M:%S')} Cairo time\")\n",
    "print(f\"Today's date: {TODAY}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# AWS & API FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def get_secret(secret_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve a secret from AWS Secrets Manager.\n",
    "    \"\"\"\n",
    "    region_name = \"us-east-1\"\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(service_name='secretsmanager', region_name=region_name)\n",
    "\n",
    "    try:\n",
    "        response = client.get_secret_value(SecretId=secret_name)\n",
    "    except ClientError as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        error_messages = {\n",
    "            'DecryptionFailureException': \"Can't decrypt secret using provided KMS key\",\n",
    "            'InternalServiceErrorException': \"Server-side error occurred\",\n",
    "            'InvalidParameterException': \"Invalid parameter value provided\",\n",
    "            'InvalidRequestException': \"Invalid request for current resource state\",\n",
    "            'ResourceNotFoundException': \"Requested resource not found\"\n",
    "        }\n",
    "        if error_code in error_messages:\n",
    "            print(f\"AWS Error: {error_messages[error_code]}\")\n",
    "        raise e\n",
    "    \n",
    "    if 'SecretString' in response:\n",
    "        return response['SecretString']\n",
    "    return base64.b64decode(response['SecretBinary'])\n",
    "\n",
    "\n",
    "def get_access_token(url: str, client_id: str, client_secret: str) -> str:\n",
    "    \"\"\"\n",
    "    Get OAuth2 access token for MaxAB API authentication.\n",
    "    \"\"\"\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        data={\n",
    "            \"grant_type\": \"password\",\n",
    "            \"username\": API_USERNAME,\n",
    "            \"password\": API_PASSWORD\n",
    "        },\n",
    "        auth=(client_id, client_secret),\n",
    "    )\n",
    "    return response.json()[\"access_token\"]\n",
    "\n",
    "\n",
    "def _get_api_token() -> str:\n",
    "    \"\"\"\n",
    "    Get a fresh API token for MaxAB API requests.\n",
    "    \"\"\"\n",
    "    return get_access_token(\n",
    "        'https://sso.maxab.info/auth/realms/maxab/protocol/openid-connect/token',\n",
    "        'main-system-externals',\n",
    "        API_SECRET\n",
    "    )\n",
    "\n",
    "\n",
    "def post_prices(cohort_id: int, file_name: str) -> requests.Response:\n",
    "    \"\"\"\n",
    "    Upload a pricing Excel sheet to MaxAB API for a specific cohort.\n",
    "    \"\"\"\n",
    "    token = _get_api_token()\n",
    "    url = f\"https://api.maxab.info/main-system/api/admin-portal/cohorts/{cohort_id}/pricing\"\n",
    "    \n",
    "    files = [('sheet', (file_name, open(file_name, 'rb'), \n",
    "              'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'))]\n",
    "    headers = {'Authorization': f'bearer {token}'}\n",
    "    \n",
    "    return requests.post(url, headers=headers, data={}, files=files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì API credentials loaded successfully\n",
      "‚úì Google Sheets client initialized\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# API CREDENTIALS INITIALIZATION\n",
    "# =============================================================================\n",
    "pricing_api_secret = json.loads(get_secret(\"prod/pricing/api/\"))\n",
    "API_USERNAME = pricing_api_secret[\"egypt_username\"]\n",
    "API_PASSWORD = pricing_api_secret[\"egypt_password\"]\n",
    "API_SECRET = pricing_api_secret[\"egypt_secret\"]\n",
    "\n",
    "print(\"‚úì API credentials loaded successfully\")\n",
    "\n",
    "# =============================================================================\n",
    "# GOOGLE SHEETS CLIENT INITIALIZATION\n",
    "# =============================================================================\n",
    "GSHEET_SCOPE = [\n",
    "    \"https://spreadsheets.google.com/feeds\",\n",
    "    'https://www.googleapis.com/auth/spreadsheets',\n",
    "    \"https://www.googleapis.com/auth/drive.file\",\n",
    "    \"https://www.googleapis.com/auth/drive\"\n",
    "]\n",
    "\n",
    "gsheet_creds = ServiceAccountCredentials.from_json_keyfile_dict(\n",
    "    json.loads(setup_environment_2.get_secret(\"prod/maxab-sheets\")), \n",
    "    GSHEET_SCOPE\n",
    ")\n",
    "gsheet_client = gspread.authorize(gsheet_creds)\n",
    "\n",
    "print(\"‚úì Google Sheets client initialized\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "def load_treasure_hunt_data() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load Treasure Hunt data from Google Sheets.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with treasure hunt SKUs and their details\n",
    "    \"\"\"\n",
    "    print(f\"Loading data from '{TREASURE_HUNT_GSHEET}' sheet '{TREASURE_HUNT_SHEET}'...\")\n",
    "    \n",
    "    sheet = gsheet_client.open(TREASURE_HUNT_GSHEET).worksheet(TREASURE_HUNT_SHEET)\n",
    "    df = pd.DataFrame(sheet.get_all_records())\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"  ‚ö†Ô∏è No data in Treasure Hunt sheet\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    print(f\"  ‚úì Loaded {len(df)} rows\")\n",
    "    print(f\"  Columns: {list(df.columns)}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# TREASURE HUNT DATA PROCESSING\n",
    "# =============================================================================\n",
    "\n",
    "def process_treasure_hunt_skus(treasure_skus: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process Treasure Hunt SKUs to determine visibility.\n",
    "    \n",
    "    Logic:\n",
    "    1. Convert created_at to datetime\n",
    "    2. For each SKU, check if it should be visible today\n",
    "    3. If an SKU appears multiple times with different dates:\n",
    "       - Keep only the entry for today (if exists)\n",
    "       - Ignore entries for other dates for this SKU\n",
    "    4. For SKUs not visible today, set remove_min = 1\n",
    "    \n",
    "    Args:\n",
    "        treasure_skus: Raw data from Google Sheet\n",
    "        \n",
    "    Returns:\n",
    "        Processed DataFrame ready for price push\n",
    "    \"\"\"\n",
    "    if treasure_skus.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    df = treasure_skus.copy()\n",
    "    \n",
    "    # Convert created_at to datetime\n",
    "    current_year = get_cairo_today().year\n",
    "    df['created_at'] = pd.to_datetime(df['created_at'].astype(str) + f'-{current_year}', format='%d-%B-%Y', errors='coerce')\n",
    "    df['created_date'] = df['created_at'].dt.date\n",
    "    \n",
    "    # Initialize columns\n",
    "    df['ind'] = 1\n",
    "    df['remove_min'] = np.nan\n",
    "    \n",
    "    # Get fresh Cairo date at execution time\n",
    "    today_cairo = get_cairo_today()\n",
    "    \n",
    "    print(f\"\\nProcessing {len(df)} treasure hunt entries...\")\n",
    "    print(f\"Today (Cairo): {today_cairo}\")\n",
    "    print(f\"Unique SKUs: {df['sku'].nunique()}\")\n",
    "    print(f\"Date range: {df['created_date'].min()} to {df['created_date'].max()}\")\n",
    "    \n",
    "    # Identify SKUs that are visible today (using fresh Cairo date)\n",
    "    df['is_today'] = df['created_date'] == today_cairo\n",
    "    \n",
    "    # Get list of SKUs that have an entry for today\n",
    "    skus_visible_today = df[df['is_today']]['sku'].unique()\n",
    "    print(f\"SKUs visible today: {len(skus_visible_today)}\")\n",
    "    \n",
    "    # For SKUs with today's entry: keep only today's entry\n",
    "    # For SKUs without today's entry: set remove_min = 1\n",
    "    \n",
    "    # Filter: Keep today's entries for SKUs that have today's date\n",
    "    df_today = df[df['is_today']].copy()\n",
    "    \n",
    "    # For SKUs without today's entry, we still need them but with remove_min = 1\n",
    "    skus_not_today = df[~df['sku'].isin(skus_visible_today)]['sku'].unique()\n",
    "    df_not_today = df[df['sku'].isin(skus_not_today)].copy()\n",
    "    \n",
    "    # For non-today SKUs, keep only the most recent entry per SKU\n",
    "    if not df_not_today.empty:\n",
    "        df_not_today = df_not_today.sort_values('created_at', ascending=False)\n",
    "        df_not_today = df_not_today.drop_duplicates(subset=['sku'], keep='first')\n",
    "        df_not_today['remove_min'] = 1\n",
    "    \n",
    "    # Combine the results\n",
    "    result = pd.concat([df_today, df_not_today], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\nAfter processing:\")\n",
    "    print(f\"  Total entries: {len(result)}\")\n",
    "    print(f\"  Visible today (remove_min=NaN): {len(result[result['remove_min'].isna()])}\")\n",
    "    print(f\"  Not visible (remove_min=1): {len(result[result['remove_min'] == 1])}\")\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PUSH PRICES FUNCTION (Simplified for Treasure Hunt)\n",
    "# =============================================================================\n",
    "\n",
    "MODE_TESTING = 'testing'\n",
    "MODE_LIVE = 'live'\n",
    "\n",
    "def push_treasure_hunt_prices(df_prices: pd.DataFrame,\n",
    "                               mode: str = 'testing') -> dict:\n",
    "    \"\"\"\n",
    "    Push Treasure Hunt prices to MaxAB API (cohort 61).\n",
    "    \n",
    "    This is a simplified version of push_prices specifically for Treasure Hunt:\n",
    "    - No packing unit expansion (products are already at correct level)\n",
    "    - Fixed cohort ID = 61\n",
    "    - Visibility based on remove_min flag\n",
    "    \n",
    "    Args:\n",
    "        df_prices: DataFrame with processed treasure hunt data\n",
    "                   Required columns: product_id, sku, Price, packing_unit_id, remove_min\n",
    "        mode: 'testing' or 'live'\n",
    "        \n",
    "    Returns:\n",
    "        dict with upload results\n",
    "    \"\"\"\n",
    "    cohort = TREASURE_HUNT_COHORT\n",
    "    \n",
    "    # Validate mode\n",
    "    if mode not in [MODE_TESTING, MODE_LIVE]:\n",
    "        print(f\"‚ö†Ô∏è Invalid mode '{mode}'. Using 'testing' mode.\")\n",
    "        mode = MODE_TESTING\n",
    "    \n",
    "    print(f\"\\n{'üß™' if mode == MODE_TESTING else 'üöÄ'} MODE: {mode.upper()}\")\n",
    "    if mode == MODE_TESTING:\n",
    "        print(\"   Files will be prepared but NOT uploaded to API\")\n",
    "    else:\n",
    "        print(\"   Files will be prepared AND uploaded to API\")\n",
    "    \n",
    "    # Initialize result tracking\n",
    "    result = {\n",
    "        'total_received': len(df_prices),\n",
    "        'pushed': 0,\n",
    "        'failed': 0,\n",
    "        'timestamp': get_cairo_now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'mode': mode,\n",
    "        'cohort': cohort\n",
    "    }\n",
    "    \n",
    "    if df_prices.empty:\n",
    "        print(\"‚ö†Ô∏è No data to push\")\n",
    "        return result\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"PUSH TREASURE HUNT PRICES - Cohort {cohort}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total entries: {len(df_prices)}\")\n",
    "    \n",
    "    # Ensure output directories exist\n",
    "    os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
    "    os.makedirs(MANUAL_DIR, exist_ok=True)\n",
    "    \n",
    "    # Prepare output DataFrame with API-expected columns\n",
    "    out = df_prices[['product_id', 'sku', 'pu_id', 'new_price', 'ind', 'remove_min']].copy()\n",
    "    out.columns = ['Product ID', 'Product Name', 'Packing Unit ID', 'Price', 'ind', 'remove_min']\n",
    "    \n",
    "    # Set visibility based on remove_min flag\n",
    "    # remove_min = NaN -> Visible (YES)\n",
    "    # remove_min = 1 -> Not visible (NO)\n",
    "    out['Visibility (YES/NO)'] = 'YES'\n",
    "    out.loc[out['remove_min'] == 1, 'Visibility (YES/NO)'] = 'NO'\n",
    "    \n",
    "    # Drop helper columns and duplicates\n",
    "    out = out.drop(columns=['ind', 'remove_min']).drop_duplicates()\n",
    "    \n",
    "    # Add required empty columns for API\n",
    "    out['Execute At (format:dd/mm/yyyy HH:mm)'] = None\n",
    "    out['Tags'] = None\n",
    "    \n",
    "    # Filter out invalid prices\n",
    "    out = out[out['Price'] > 1].reset_index(drop=True)\n",
    "    \n",
    "    if len(out) == 0:\n",
    "        print(\"  No valid prices to push\")\n",
    "        return result\n",
    "    \n",
    "    print(f\"\\nVisibility summary:\")\n",
    "    print(f\"  Visible (YES): {len(out[out['Visibility (YES/NO)'] == 'YES'])}\")\n",
    "    print(f\"  Hidden (NO): {len(out[out['Visibility (YES/NO)'] == 'NO'])}\")\n",
    "    \n",
    "    # Save full file for reference\n",
    "    file_name_ = f'{UPLOAD_DIR}/treasure_hunt_{cohort}.xlsx'\n",
    "    out.to_excel(file_name_, index=False)\n",
    "    print(f\"\\n  Saved: {file_name_} ({len(out)} rows)\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # In testing mode, skip the actual API upload\n",
    "    if mode == MODE_TESTING:\n",
    "        print(f\"  üß™ [TESTING] Would upload {len(out)} prices (skipped)\")\n",
    "        result['pushed'] = len(out)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"üß™ TESTING MODE COMPLETE - NO PRICES WERE UPLOADED\")\n",
    "        print(f\"{'='*60}\")\n",
    "        return result\n",
    "    \n",
    "    # Split into chunks for API upload\n",
    "    chunk_size = CHUNK_SIZE_SPECIAL\n",
    "    chunks = [out[i:i + chunk_size] for i in range(0, len(out), chunk_size)]\n",
    "    print(f\"  Split into {len(chunks)} chunks (size: {chunk_size})\")\n",
    "    \n",
    "    # Save and upload chunks\n",
    "    fileslist = []\n",
    "    for i, chunk in tqdm(enumerate(chunks), total=len(chunks), desc=\"  Saving chunks\"):\n",
    "        output_file = f'{MANUAL_DIR}/treasure_hunt_{cohort}_chunk_{i + 1}.xlsx'\n",
    "        fileslist.append(output_file)\n",
    "        chunk.to_excel(output_file, index=False)\n",
    "    \n",
    "    # Upload each chunk\n",
    "    print(\"  Uploading...\")\n",
    "    total_pushed = 0\n",
    "    total_failed = 0\n",
    "    \n",
    "    for file in fileslist:\n",
    "        chunk_num = file.split('chunk_')[1].split('.xls')[0]\n",
    "        response = post_prices(cohort, file)\n",
    "        \n",
    "        if '\"success\":true' in str(response.content).lower():\n",
    "            print(f\"    ‚úì Chunk {chunk_num} uploaded successfully\")\n",
    "            total_pushed += len(pd.read_excel(file))\n",
    "        else:\n",
    "            print(f\"    ‚úó ERROR chunk {chunk_num}\")\n",
    "            print(f\"      Response: {response.content}\")\n",
    "            total_failed += len(pd.read_excel(file))\n",
    "            break\n",
    "    \n",
    "    result['pushed'] = total_pushed\n",
    "    result['failed'] = total_failed\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"üöÄ UPLOAD COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Mode: {mode}\")\n",
    "    print(f\"Total pushed: {total_pushed}\")\n",
    "    print(f\"Total failed: {total_failed}\")\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MAIN EXECUTION\n",
    "# =============================================================================\n",
    "\n",
    "def run_treasure_hunt_scheduler(mode: str = 'testing'):\n",
    "    \"\"\"\n",
    "    Main entry point for the Treasure Hunt scheduler.\n",
    "    \n",
    "    Args:\n",
    "        mode: 'testing' or 'live'\n",
    "    \"\"\"\n",
    "    # Get fresh Cairo time at execution\n",
    "    cairo_now = get_cairo_now()\n",
    "    cairo_today = get_cairo_today()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"TREASURE HUNT SCHEDULER\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Execution time: {cairo_now.strftime('%Y-%m-%d %H:%M:%S')} Cairo\")\n",
    "    print(f\"Today's date (Cairo): {cairo_today}\")\n",
    "    \n",
    "    # Step 1: Load data from Google Sheet\n",
    "    treasure_data = load_treasure_hunt_data()\n",
    "    \n",
    "    if treasure_data.empty:\n",
    "        print(\"\\n‚ùå No data to process. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Process SKUs\n",
    "    processed_data = process_treasure_hunt_skus(treasure_data)\n",
    "    \n",
    "    if processed_data.empty:\n",
    "        print(\"\\n‚ùå No processed data. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    # Step 3: Push prices\n",
    "    result = push_treasure_hunt_prices(processed_data, mode=mode)\n",
    "    \n",
    "    print(f\"\\n‚úì Scheduler completed\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# Run in testing mode by default\n",
    "# Change to mode='live' to actually push prices\n",
    "# result = run_treasure_hunt_scheduler(mode='testing')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TREASURE HUNT SCHEDULER\n",
      "============================================================\n",
      "Execution time: 2026-02-09 17:51:06 Cairo\n",
      "Today's date (Cairo): 2026-02-09\n",
      "Loading data from 'Treasure Hunt' sheet 'Sheet6'...\n",
      "  ‚úì Loaded 17 rows\n",
      "  Columns: ['product_id', 'sku', 'supplier', 'Cat', 'brand', 'created_at', 'pu', 'pu_id', 'new_price']\n",
      "\n",
      "Processing 17 treasure hunt entries...\n",
      "Today (Cairo): 2026-02-09\n",
      "Unique SKUs: 1\n",
      "Date range: 2026-02-10 to 2026-02-26\n",
      "SKUs visible today: 0\n",
      "\n",
      "After processing:\n",
      "  Total entries: 1\n",
      "  Visible today (remove_min=NaN): 0\n",
      "  Not visible (remove_min=1): 1\n",
      "\n",
      "üß™ MODE: TESTING\n",
      "   Files will be prepared but NOT uploaded to API\n",
      "\n",
      "============================================================\n",
      "PUSH TREASURE HUNT PRICES - Cohort 61\n",
      "============================================================\n",
      "Total entries: 1\n",
      "  No valid prices to push\n",
      "\n",
      "‚úì Scheduler completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_received': 1,\n",
       " 'pushed': 0,\n",
       " 'failed': 0,\n",
       " 'timestamp': '2026-02-09 17:51:07',\n",
       " 'mode': 'testing',\n",
       " 'cohort': 61}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_treasure_hunt_scheduler()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
