{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e32a9-ef1a-474a-a2f7-e291561f6da3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# Connectivity\n",
    "!pip install psycopg2-binary  # PostgreSQL adapter\n",
    "# !pip install snowflake-connector-python  # Snowflake connector\n",
    "!pip install snowflake-connector-python==3.15.0 # Snowflake connector Older Version\n",
    "!pip install snowflake-sqlalchemy  # Snowflake SQLAlchemy connector\n",
    "!pip install warnings # Warnings management\n",
    "# !pip install pyarrow # Serialization\n",
    "!pip install keyring==23.11.0 # Key management\n",
    "!pip install sqlalchemy==1.4.46 # SQLAlchemy\n",
    "!pip install requests # HTTP requests\n",
    "!pip install boto3 # AWS SDK\n",
    "# !pip install slackclient # Slack API\n",
    "!pip install oauth2client # Google Sheets API\n",
    "!pip install gspread==5.9.0 # Google Sheets API\n",
    "!pip install gspread_dataframe # Google Sheets API\n",
    "!pip install google.cloud # Google Cloud\n",
    "# Data manipulation and analysis\n",
    "!pip install polars\n",
    "!pip install pandas==2.2.1\n",
    "!pip install numpy\n",
    "# !pip install fastparquet\n",
    "!pip install openpyxl # Excel file handling\n",
    "!pip install xlsxwriter # Excel file handling\n",
    "# Linear programming\n",
    "!pip install pulp\n",
    "# Date and time handling\n",
    "!pip install --upgrade datetime\n",
    "!pip install python-time\n",
    "!pip install --upgrade pytz\n",
    "# Progress bar\n",
    "!pip install tqdm\n",
    "# Database data types\n",
    "!pip install db-dtypes\n",
    "# Geospatial data handling\n",
    "# !pip install geopandas\n",
    "# !pip install shapely\n",
    "# !pip install fiona\n",
    "# !pip install haversine\n",
    "# Plotting\n",
    "\n",
    "# Modeling\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn\n",
    "\n",
    "!pip install import-ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16b73aac-2b7a-491b-80f9-674d0b9a67a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import setup_environment_2\n",
    "import importlib\n",
    "import import_ipynb\n",
    "import warnings\n",
    "import demand_sku_cntrb\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "importlib.reload(setup_environment_2)\n",
    "setup_environment_2.initialize_env()\n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cc41c3e-734d-43f3-8964-1c9fd8e676bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def query_snowflake(query, columns=[]):\n",
    "    import os\n",
    "    import snowflake.connector\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    con = snowflake.connector.connect(\n",
    "        user =  os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account= os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password= os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database =os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        if len(columns) == 0:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()))\n",
    "        else:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()),columns=columns)\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4843f389-c610-4185-bec0-0978a722587f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'America/Los_Angeles'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = '''\n",
    "SHOW PARAMETERS LIKE 'TIMEZONE'\n",
    "'''\n",
    "x  = query_snowflake(query)\n",
    "zone_to_use = x[1].values[0]\n",
    "zone_to_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5198399c-507c-4f5b-b61e-b030873c2694",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scope = [\"https://spreadsheets.google.com/feeds\",\n",
    "         'https://www.googleapis.com/auth/spreadsheets',\n",
    "         \"https://www.googleapis.com/auth/drive.file\",\n",
    "         \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_dict(json.loads(setup_environment_2.get_secret(\"prod/maxab-sheets\")), scope)\n",
    "client = gspread.authorize(creds)\n",
    "min_max = client.open('Demand Based Dynamic Pricing').worksheet('min_max_margin_cohort')\n",
    "min_max_df = pd.DataFrame(min_max.get_all_records())\n",
    "for col in min_max_df.columns:\n",
    "    min_max_df[col] = pd.to_numeric(min_max_df[col], errors='ignore') \n",
    "min_max_df = min_max_df[min_max_df['min_margin']>0.01]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87883b4b-bad9-4d21-9f69-6685e716ea4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Blue_FD_brands =  client.open('Anniversary Campaign 2025 (Final)').worksheet('Suppliers Brands')\n",
    "Blue_FD_brands_df = pd.DataFrame(Blue_FD_brands.get_all_records())[['Brands']].drop_duplicates()\n",
    "blue_list = [brand  for brand in Blue_FD_brands_df['Brands']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ade36b5b-e61d-4d32-a310-6f5f610f838b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "WITH whs as (SELECT *\n",
    "             FROM   (values\n",
    "                            ('Cairo', 'El-Marg', 38,700),\n",
    "                            ('Cairo', 'Mostorod', 1,700),\n",
    "                            ('Giza', 'Barageel', 236,701),\n",
    "                            ('Delta West', 'El-Mahala', 337,703),\n",
    "                            ('Delta West', 'Tanta', 8,703),\n",
    "                            ('Delta East', 'Mansoura FC', 339,704),\n",
    "                            ('Delta East', 'Sharqya', 170,704),\n",
    "                            ('Upper Egypt', 'Assiut FC', 501,1124),\n",
    "                            ('Upper Egypt', 'Bani sweif', 401,1126),\n",
    "                            ('Upper Egypt', 'Menya Samalot', 703,1123),\n",
    "                            ('Upper Egypt', 'Sohag', 632,1125),\n",
    "                            ('Alexandria', 'Khorshed Alex', 797,702),\n",
    "\t\t\t\t\t\t\t('Giza', 'Sakkarah', 962,701)\n",
    "\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t)\n",
    "                    x(region, wh, warehouse_id,cohort_id)),\n",
    "full_data as (\n",
    "select products.id as product_id, region\n",
    "from products , whs \n",
    "where activation = 'true'\n",
    "),\t\t\t\t\n",
    "\n",
    "MP as (\n",
    "select region,product_id,\n",
    "min(min_price) as min_price,\n",
    "min(max_price) as max_price,\n",
    "min(mod_price) as mod_price,\n",
    "min(true_min) as true_min,\n",
    "min(true_max) as true_max\n",
    "\n",
    "from (\n",
    "select mp.region,mp.product_id,mp.pu_id,\n",
    "min_price/BASIC_UNIT_COUNT as min_price,\n",
    "max_price/BASIC_UNIT_COUNT as max_price,\n",
    "mod_price/BASIC_UNIT_COUNT as mod_price,\n",
    "TRUE_MIN_PRICE/BASIC_UNIT_COUNT as true_min,\n",
    "TRUE_MAX_PRICE/BASIC_UNIT_COUNT as true_max\n",
    "from materialized_views.marketplace_prices mp \n",
    "join packing_unit_products pup on pup.product_id = mp.product_id and pup.packing_unit_id = mp.pu_id\n",
    "join finance.all_cogs f on f.product_id = mp.product_id and CURRENT_TIMESTAMP between f.from_date and f.to_date\n",
    "where  least(min_price,mod_price) between wac_p*0.9 and wac_p*1.3 \n",
    ")\n",
    "group by all \n",
    "),\n",
    "region_mapping AS (\n",
    "    SELECT * \n",
    "\tFROM \n",
    "\t(\tVALUES\n",
    "        ('Delta East', 'Delta West'),\n",
    "        ('Delta West', 'Delta East'),\n",
    "        ('Alexandria', 'Cairo'),\n",
    "        ('Alexandria', 'Giza'),\n",
    "        ('Upper Egypt', 'Cairo'),\n",
    "        ('Upper Egypt', 'Giza'),\n",
    "\t\t('Cairo','Giza'),\n",
    "\t\t('Giza','Cairo'),\n",
    "\t\t('Delta West', 'Cairo'),\n",
    "\t\t('Delta East', 'Cairo'),\n",
    "\t\t('Delta West', 'Giza'),\n",
    "\t\t('Delta East', 'Giza')\n",
    "\t\t)\n",
    "    AS region_mapping(region, fallback_region)\n",
    "),\n",
    "final_mp as (\n",
    "select region,product_id,\n",
    "min(final_min_price) as final_min_price,\n",
    "min(final_max_price) as final_max_price,\n",
    "min(final_mod_price) as final_mod_price,\n",
    "min(final_true_min) as final_true_min,\n",
    "min(final_true_max) as final_true_max\n",
    "\n",
    "from (\n",
    "SELECT\n",
    "distinct \n",
    "\tw.region,\n",
    "\tw.product_id,\n",
    "    COALESCE(m1.min_price, m2.min_price) AS final_min_price,\n",
    "    COALESCE(m1.max_price, m2.max_price) AS final_max_price,\n",
    "    COALESCE(m1.mod_price, m2.mod_price) AS final_mod_price,\n",
    "\tCOALESCE(m1.true_min, m2.true_min) AS final_true_min,\n",
    "\tCOALESCE(m1.true_max, m2.true_max) AS final_true_max,\n",
    "FROM full_data w\n",
    "LEFT JOIN MP m1\n",
    "    ON w.region = m1.region and w.product_id = m1.product_id\n",
    "JOIN region_mapping rm\n",
    "    ON w.region = rm.region\n",
    "LEFT JOIN MP m2\n",
    "    ON rm.fallback_region = m2.region\n",
    "   AND w.product_id = m2.product_id\n",
    ")\n",
    "where final_min_price is not null \n",
    "group by all \n",
    "),\n",
    "ben_soliman as (\n",
    "select z.* \n",
    "from (\n",
    "select maxab_product_id as product_id,maxab_sku as sku,avg(bs_final_price) as ben_soliman_price\n",
    "from (\n",
    "select * , row_number()over(partition by maxab_product_id order by diff) as rnk_2\n",
    "from (\n",
    "select *,(bs_final_price-wac_p)/wac_p as diff_2\n",
    "from (\n",
    "select * ,bs_price/maxab_basic_unit_count as bs_final_price\n",
    "from (\n",
    "select *,row_number()over(partition by maxab_product_id,maxab_pu order by diff) as rnk \n",
    "from (\n",
    "select sm.* ,max(INJECTION_DATE::date)over(partition by maxab_product_id,maxab_pu) as max_date,wac1,wac_p,abs(bs_price-(wac_p*maxab_basic_unit_count))/(wac_p*maxab_basic_unit_count) as diff \n",
    "from materialized_views.savvy_mapping sm \n",
    "join finance.all_cogs f on f.product_id = sm.maxab_product_id and current_timestamp between f.from_Date and f.to_date\n",
    "where bs_price is not null \n",
    "and INJECTION_DATE::date >= CURRENT_DATE- 5\n",
    "qualify INJECTION_DATE::date = max_date\n",
    ")\n",
    "qualify rnk = 1 \n",
    ")\n",
    ")\n",
    "where diff_2 between -0.5 and 0.5 \n",
    ")\n",
    "qualify rnk_2 = 1 \n",
    ")\n",
    "group by all\n",
    ")z \n",
    "join finance.all_cogs f on f.product_id = z.product_id and current_timestamp between f.from_Date and f.to_date\n",
    "\n",
    "where ben_soliman_price between f.wac_p*0.9 and f.wac_p*1.3\n",
    "),\n",
    "scrapped_data as (\n",
    "select product_id,cat,brand,region,max_date,min(MARKET_PRICE) as min_scrapped,max(MARKET_PRICE) as max_scrapped,median(MARKET_PRICE) as median_scrapped\n",
    "from (\n",
    "select MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES.*,max(date)over(partition by region,MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES.product_id,competitor) as max_date\n",
    "from MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES\n",
    "join finance.all_cogs f on f.product_id = MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES.product_id and CURRENT_TIMESTAMP between f.from_date and f.to_date \n",
    "where date>= current_date -5\n",
    "and MARKET_PRICE between f.wac_p * 0.9 and wac_p*1.3\n",
    "qualify date = max_date \n",
    ")\n",
    "group by all \n",
    "),\n",
    "local_prices as (\n",
    "SELECT  case when cpu.cohort_id in (700) then 'Cairo'\n",
    "             when cpu.cohort_id in (701) then 'Giza'\n",
    "             when cpu.cohort_id in (704) then 'Delta East'\n",
    "             when cpu.cohort_id in (703) then 'Delta West'\n",
    "             when cpu.cohort_id in (1123,1124,1125,1126) then 'Upper Egypt'\n",
    "             when cpu.cohort_id in (702) then 'Alexandria'\n",
    "        end as region,\n",
    "\t\tcohort_id,\n",
    "        pu.product_id,\n",
    "\t\tpu.packing_unit_id as packing_unit_id,\n",
    "\t\tpu.basic_unit_count,\n",
    "        avg(cpu.price) as price\n",
    "FROM    cohort_product_packing_units cpu\n",
    "join    PACKING_UNIT_PRODUCTS pu on pu.id = cpu.product_packing_unit_id\n",
    "WHERE   cpu.cohort_id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    "    and cpu.created_at::date<>'2023-07-31'\n",
    "    and cpu.is_customized = true\n",
    "\tgroup by all \n",
    "),\n",
    "live_prices as (\n",
    "select region,cohort_id,product_id,pu_id as packing_unit_id,buc as basic_unit_count,NEW_PRICE as price\n",
    "from materialized_views.DBDP_PRICES\n",
    "where created_at = CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date\n",
    "and DATE_PART('hour', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::time) BETWEEN SPLIT_PART(time_slot, '-', 1)::int AND SPLIT_PART(time_slot, '-', 2)::int\n",
    "and cohort_id in (700,701,702,703,704,696,695,698,697,699,1123,1124,1125,1126)\n",
    "),\n",
    "prices as (\n",
    "select *\n",
    "from (\n",
    "    SELECT *, 1 AS priority FROM live_prices\n",
    "    UNION ALL\n",
    "    SELECT *, 2 AS priority FROM local_prices\n",
    ")\n",
    "QUALIFY ROW_NUMBER() OVER (PARTITION BY region,cohort_id,product_id,packing_unit_id ORDER BY priority) = 1\n",
    "),\n",
    "\n",
    "maxab_prices as (\n",
    "select region,cohort_id,product_id,price \n",
    "from prices \n",
    "where basic_unit_count = 1 \n",
    "),\n",
    "sales as (\n",
    "SELECT  DISTINCT\n",
    "\t\tcpc.cohort_id,\n",
    "\t\tpso.product_id,\n",
    "        sum(pso.total_price) as nmv\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id   \n",
    "join COHORT_PRICING_CHANGES cpc on cpc.id = pso.cohort_pricing_change_id\n",
    "WHERE   True\n",
    "    AND so.created_at::date between date_trunc('month', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 90) and CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 1\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "GROUP BY ALL\n",
    "),\n",
    "margin_change as (\n",
    "select product_id,cohort_id,(0.6*product_std) +(0.3*brand_std) + (0.1*cat_std) as std,avg_margin\n",
    "from (\n",
    "select product_id,cohort_id,stddev(product_margin) as product_std , stddev(brand_margin) as brand_std,stddev(cat_margin) as cat_std,avg(product_margin) as avg_margin\n",
    "from (\n",
    "select distinct product_id,order_date,cohort_id,(nmv-cogs_p)/nmv as product_margin,(brand_nmv-brand_cogs)/brand_nmv as brand_margin,(cat_nmv-cat_cogs)/cat_nmv as cat_margin\n",
    "from(\n",
    "SELECT  DISTINCT\n",
    "\t\tso.created_at::date as order_date,\n",
    "\t\tcpc.cohort_id,\n",
    "\t\tpso.product_id,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\n",
    "       sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs_p,\n",
    "    \tsum(pso.total_price) as nmv,\n",
    "\t\tsum(nmv) over(partition by order_date,cat,brand) as brand_nmv,\n",
    "\t\tsum(cogs_p) over(partition by order_date,cat,brand) as brand_cogs,\n",
    "\t\tsum(nmv) over(partition by order_date,cat) as cat_nmv,\n",
    "\t\tsum(cogs_p) over(partition by order_date,cat) as cat_cogs\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id   \n",
    "join COHORT_PRICING_CHANGES cpc on cpc.id = pso.cohort_pricing_change_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN finance.all_cogs f  ON f.product_id = pso.product_id\n",
    "                        AND f.from_date::date <= so.created_at::date\n",
    "                        AND f.to_date::date > so.created_at::date\n",
    "\t\t\t\t\t\t\n",
    "WHERE  so.created_at::date between date_trunc('month', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 120) and CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date\n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "GROUP BY ALL\n",
    ")\n",
    ")\n",
    "\n",
    "group by all \n",
    ")\n",
    "),\n",
    "cat_brand_target as (\n",
    "SELECT DISTINCT cat, brand, margin as target_bm\n",
    "FROM    performance.commercial_targets cplan\n",
    "QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE)OVER()) = DATE_TRUNC('month', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date) THEN DATE_TRUNC('month', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date)\n",
    "ELSE DATE_TRUNC('month', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    "),\n",
    "cat_target as (\n",
    "\n",
    "select cat,sum(target_bm *(target_nmv/cat_total)) as cat_target_margin\n",
    "from (\n",
    "select *,sum(target_nmv)over(partition by cat) as cat_total\n",
    "from (\n",
    "select cat,brand,avg(target_bm) as target_bm , sum(target_nmv) as target_nmv\n",
    "from (\n",
    "SELECT DISTINCT date,city as region,cat, brand, margin as target_bm,nmv as target_nmv\n",
    "FROM    performance.commercial_targets cplan\n",
    "QUALIFY CASE WHEN DATE_TRUNC('month', MAX(DATE)OVER()) = DATE_TRUNC('month', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date) THEN DATE_TRUNC('month', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date)\n",
    "ELSE DATE_TRUNC('month', CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - INTERVAL '1 month') END = DATE_TRUNC('month', date)\n",
    ")\n",
    "group by all\n",
    ")\n",
    ")\n",
    "group by all \n",
    ")\n",
    "\n",
    "select cohort_id,product_id,sku,cat,brand,\n",
    "case when min_status = 1 and new_min_status = 1 then  min_margin when min_status = 0 and new_min_status = 1 then new_min_margin else min_margin end as min_margin,\n",
    "case when new_min_status = 0 then min_margin else new_min_margin end as new_min_margin,\n",
    "avg_market_margin,\n",
    "new_avg_market_margin,\n",
    "target_margin,\n",
    "current_margin\n",
    "from (\n",
    "select *,\n",
    "(all_mp_mins-wac_p)/all_mp_mins as min_margin,\n",
    "(new_min-wac_p)/new_min as new_min_margin,\n",
    "(average_price-wac_p)/average_price as avg_market_margin,\n",
    "(average_new-wac_p)/average_new as new_avg_market_margin,\n",
    "(maxab_price-wac_p)/maxab_price as current_margin,\n",
    "greatest(least(current_margin - (1.5*std) , avg_margin - (0.5*std),target_margin-(2*std)),0.005) as lower_bound,\n",
    "greatest(current_margin + (3*std) , avg_margin + (4*std),target_margin+(3*std)) as upper_bound,\n",
    "case when min_margin between lower_bound and upper_bound then 1 else 0 end as min_status,\n",
    "case when new_min_margin between lower_bound and upper_bound then 1 else 0 end as new_min_status\n",
    "\n",
    "from (\n",
    "select distinct maxab.cohort_id,\n",
    "maxab.product_id,\n",
    "CONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "brands.name_ar as brand, \n",
    "categories.name_ar as cat,\n",
    "maxab.price as maxab_price,bs.ben_soliman_price,\n",
    "final_min_price,\n",
    "final_max_price,\n",
    "final_mod_price,\n",
    "min_scrapped,\n",
    "median_scrapped,\n",
    "max_scrapped,\n",
    "wac_p,\n",
    "NULLIF(\n",
    "    LEAST(\n",
    "        CASE WHEN final_min_price <> 0 AND final_min_price IS NOT NULL \n",
    "            THEN final_min_price ELSE 999999999 END,\n",
    "        CASE WHEN final_mod_price <> 0 AND final_mod_price IS NOT NULL \n",
    "            THEN final_mod_price ELSE 999999999 END,\n",
    "        CASE WHEN ben_soliman_price <> 0 AND ben_soliman_price IS NOT NULL \n",
    "            THEN ben_soliman_price ELSE 999999999 END,\n",
    "        CASE WHEN min_scrapped <> 0 AND min_scrapped IS NOT NULL \n",
    "            THEN min_scrapped ELSE 999999999 END\n",
    "    ), \n",
    "    999999999\n",
    ") AS all_mp_mins,\n",
    "\n",
    "(\n",
    "    COALESCE(ben_soliman_price, 0) * 0.4 * (CASE WHEN ben_soliman_price IS NOT NULL AND ben_soliman_price <> 0 THEN 1 ELSE 0 END) + \n",
    "    COALESCE(NULLIF(LEAST(\n",
    "        CASE WHEN final_min_price <> 0 AND final_min_price IS NOT NULL \n",
    "            THEN final_min_price ELSE 999999999 END,\n",
    "        CASE WHEN final_mod_price <> 0 AND final_mod_price IS NOT NULL \n",
    "            THEN final_mod_price ELSE 999999999 END\n",
    "    ), 999999999), 0) * 0.25 * (CASE WHEN (final_min_price IS NOT NULL AND final_min_price <> 0) \n",
    "                                          OR (final_mod_price IS NOT NULL AND final_mod_price <> 0) THEN 1 ELSE 0 END) + \n",
    "    COALESCE(min_scrapped, 0) * 0.35 * (CASE WHEN min_scrapped IS NOT NULL AND min_scrapped <> 0 THEN 1 ELSE 0 END)\n",
    ") / NULLIF(\n",
    "    (0.4 * (CASE WHEN ben_soliman_price IS NOT NULL AND ben_soliman_price <> 0 THEN 1 ELSE 0 END) +\n",
    "     0.25 * (CASE WHEN (final_min_price IS NOT NULL AND final_min_price <> 0) \n",
    "                   OR (final_mod_price IS NOT NULL AND final_mod_price <> 0) THEN 1 ELSE 0 END) +\n",
    "     0.35 * (CASE WHEN min_scrapped IS NOT NULL AND min_scrapped <> 0 THEN 1 ELSE 0 END)),\n",
    "    0\n",
    ") AS new_min,\n",
    "\n",
    "    (COALESCE((final_min_price + final_max_price) / 2, 0) + \n",
    "     COALESCE(ben_soliman_price, 0) + \n",
    "     COALESCE(final_mod_price, 0)+\n",
    "\t coalesce(median_scrapped,0)\n",
    "\t ) / \n",
    "    NULLIF(\n",
    "        (CASE WHEN (final_min_price + final_max_price) / 2 IS NOT NULL and final_min_price >0 and final_max_price >0 THEN 1 ELSE 0 END +\n",
    "         CASE WHEN ben_soliman_price IS NOT NULL and ben_soliman_price >0  THEN 1 ELSE 0 END +\n",
    "\t\t CASE WHEN median_scrapped IS NOT NULL and median_scrapped >0  THEN 1 ELSE 0 END +\n",
    "         CASE WHEN final_mod_price IS NOT NULL and final_mod_price > 0 THEN 1 ELSE 0 END), \n",
    "        0\n",
    "    ) AS average_price,\n",
    "\t(\n",
    "    COALESCE((final_min_price + final_max_price) / 2, 0) * 0.25 * \n",
    "        (CASE WHEN final_min_price > 0 AND final_max_price > 0 THEN 1 ELSE 0 END) + \n",
    "    COALESCE(ben_soliman_price, 0) * 0.4 * \n",
    "        (CASE WHEN ben_soliman_price IS NOT NULL AND ben_soliman_price > 0 THEN 1 ELSE 0 END) + \n",
    "    COALESCE(final_mod_price, 0) * 0.25 * \n",
    "        (CASE WHEN final_mod_price IS NOT NULL AND final_mod_price > 0 THEN 1 ELSE 0 END) +\n",
    "    COALESCE(median_scrapped, 0) * 0.1 * \n",
    "        (CASE WHEN median_scrapped IS NOT NULL AND median_scrapped > 0 THEN 1 ELSE 0 END)\n",
    ") / \n",
    "NULLIF(\n",
    "    (0.25 * (CASE WHEN final_min_price > 0 AND final_max_price > 0 THEN 1 ELSE 0 END) +\n",
    "     0.4 * (CASE WHEN ben_soliman_price IS NOT NULL AND ben_soliman_price > 0 THEN 1 ELSE 0 END) +\n",
    "     0.25 * (CASE WHEN final_mod_price IS NOT NULL AND final_mod_price > 0 THEN 1 ELSE 0 END) +\n",
    "     0.1 * (CASE WHEN median_scrapped IS NOT NULL AND median_scrapped > 0 THEN 1 ELSE 0 END)),\n",
    "    0\n",
    ") AS average_new,\n",
    "\t\n",
    "coalesce(nmv,0) as nmv,\n",
    "coalesce(mc.std,0.01) as std,\n",
    "coalesce(coalesce(cbt.target_bm , ct.cat_target_margin),0) as target_margin,\n",
    "coalesce(avg_margin,0) as avg_margin\n",
    "\n",
    "from maxab_prices maxab\n",
    "left join ben_soliman bs on bs.product_id = maxab.product_id\n",
    "left join final_mp fmp on fmp.product_id = maxab.product_id and fmp.region = maxab.region\n",
    "left join sales s on s.product_id = maxab.product_id and s.cohort_id = maxab.cohort_id\n",
    "left join scrapped_data  sd on sd.product_id = maxab.product_id and sd.region = maxab.region\n",
    "join finance.all_cogs f on f.product_id = maxab.product_id and CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_date and f.to_date\n",
    "JOIN products on products.id=maxab.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "left join margin_change mc on mc.product_id = maxab.product_id and mc.cohort_id = maxab.cohort_id\n",
    "left join cat_brand_target cbt on cbt.brand = brands.name_ar and cbt.cat = categories.name_ar \n",
    "left join cat_target ct on ct.cat = categories.name_ar \n",
    ")\n",
    "where all_mp_mins is not null \n",
    "and (min_status = 1 or new_min_status = 1)\n",
    ")\n",
    "order by NMV desc\n",
    "'''\n",
    "market_data   = query_snowflake(query, columns = ['cohort_id','product_id','sku','cat','brand','min_market_margin','new_min_margin','avg_market_margin','new_avg_margin','target_margin','current_margin'])\n",
    "market_data.columns = market_data.columns.str.lower()\n",
    "for col in market_data.columns:\n",
    "    market_data[col] = pd.to_numeric(market_data[col], errors='ignore')   \n",
    "market_data = market_data[['cohort_id','product_id','min_market_margin','new_min_margin','avg_market_margin','new_avg_margin','target_margin','current_margin']]   \n",
    "market_data = market_data[(market_data['min_market_margin'] > 0)&(market_data['avg_market_margin'] > 0) ]\n",
    "market_data=market_data.drop_duplicates(subset=['cohort_id','product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b1a60ce8-9362-4bbd-8d62-e969f2135d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query ='''\n",
    "select region , product_id,new_pp,forecasted_date\n",
    "from materialized_views.DBDP_PRICE_UPS\n",
    "'''\n",
    "price_ups  = query_snowflake(query, columns = ['region','product_id','new_pp','forcasted_date'])\n",
    "price_ups.columns = price_ups.columns.str.lower()\n",
    "for col in price_ups.columns:\n",
    "    price_ups[col] = pd.to_numeric(price_ups[col], errors='ignore')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "986e7772-bc1f-4e0c-8165-8fcac88753ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT  DISTINCT\n",
    "\t\tcpc.cohort_id,  \n",
    "\t\tpso.product_id,\n",
    "\t\tCONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "\t\tbrands.name_ar as brand, \n",
    "\t\tcategories.name_ar as cat,\n",
    "        sum(pso.total_price) as nmv\n",
    "\n",
    "\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "join COHORT_PRICING_CHANGES cpc on cpc.id = pso.COHORT_PRICING_CHANGE_id\n",
    "JOIN products on products.id=pso.product_id\n",
    "JOIN brands on products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "          \n",
    "\n",
    "WHERE   True\n",
    "    AND so.created_at::date between  current_date - 120 and current_date -1 \n",
    "    AND so.sales_order_status_id not in (7,12)\n",
    "    AND so.channel IN ('telesales','retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "    and cpc.cohort_id in (700,701,702,703,704,1123,1124,1125,1126)\n",
    "\n",
    "GROUP BY ALL\n",
    "'''\n",
    "sales  = query_snowflake(query, columns = ['cohort_id','product_id','sku','brand','cat','nmv'])\n",
    "sales.columns = sales.columns.str.lower()\n",
    "for col in sales.columns:\n",
    "    sales[col] = pd.to_numeric(sales[col], errors='ignore')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3406d265-8189-484b-86dd-6d3a9bc775af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'market_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6654/2287834409.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_target_growth'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_market_margin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_margin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_margin'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmarket_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarket_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cohort_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cohort_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmarket_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_target_growth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmarket_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_target_growth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'market_data' is not defined"
     ]
    }
   ],
   "source": [
    "market_data['min_target_growth'] = (market_data['min_market_margin'] - market_data['target_margin'])/market_data['target_margin']\n",
    "market_data = market_data.merge(sales[['cohort_id','product_id']],on=['cohort_id','product_id'])\n",
    "market_data=market_data[market_data['min_target_growth']<2.5]\n",
    "market_data=market_data[market_data['min_target_growth']>-2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4233079-dabc-4bd2-b91b-05c239b6e3b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'market_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6654/4041322240.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m6628\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'market_data' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f390dc2b-c772-4d2e-b7cc-bdcc2695a411",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def assign_tier(cumulative_contribution):\n",
    "    if cumulative_contribution <= 0.6:\n",
    "        return 1\n",
    "    elif cumulative_contribution <= 0.8:\n",
    "        return 2\n",
    "    elif cumulative_contribution <= 0.9:\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc2f8918-f784-4364-8b3c-b6fc7c0cc47a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_brands = ['شويبس','جود كير','بيبسي','فاميليا','مولبد','مولفيكس','اوكسي','جوي','ريفولي','البوادي','هارفست فوودز','هاينز','كوكا كولا']\n",
    "avg_brands = ['بخيره']\n",
    "max_brands =['فيوري']\n",
    "min_cats = ['زيوت','أرز','سكر','دقيق','منظفات','صابون']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6aab29e4-c8fc-42d9-a816-616d55f867da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales['total_nmv'] = sales.groupby('cohort_id')['nmv'].transform(sum)\n",
    "sales['cntrb_nmv'] = sales['nmv']/sales['total_nmv']\n",
    "sales = sales.sort_values(['cohort_id', 'nmv'], ascending=[True, False])\n",
    "sales['nmv_cumulative_cntrb'] = sales.groupby('cohort_id')['cntrb_nmv'].cumsum()\n",
    "sales['tier'] = sales['nmv_cumulative_cntrb'].apply(assign_tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8846fc1c-3e90-484e-8233-5e1b24369d15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sales.loc[sales['brand'].isin(blue_list),'tier']=np.maximum(sales['tier']-1,1)\n",
    "sales.loc[sales['brand'].isin(min_brands),'tier']=1\n",
    "sales.loc[sales['cat'].isin(min_cats),'tier']=1\n",
    "sales.loc[sales['brand'].isin(avg_brands),'tier']=2\n",
    "sales.loc[sales['brand'].isin(max_brands),'tier']=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f98a4fda-c93f-44f0-838d-5e5c2738fa0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "found = min_max_df.merge(market_data,on=['cohort_id','product_id'])\n",
    "found = found.merge(sales[['cohort_id','product_id','tier']],on=['cohort_id','product_id'])\n",
    "found['new_min'] = found['min_market_margin']\n",
    "found['min_change'] = (found['new_min_margin']-found['min_market_margin'])/found['min_market_margin']\n",
    "\n",
    "found.loc[(found['current_margin']>=found['min_market_margin'])&(found['tier'] == 1),'new_min'] = found['min_market_margin']\n",
    "found.loc[(found['current_margin']>=found['min_market_margin'])&(found['tier'] == 2),'new_min'] = found['new_min_margin']\n",
    "found.loc[(found['current_margin']>=found['min_market_margin'])&(found['tier'] == 3),'new_min'] = found['avg_market_margin']\n",
    "found.loc[(found['current_margin']>=found['min_market_margin'])&(found['tier'] == 4),'new_min'] = found['new_avg_margin']\n",
    "\n",
    "found.loc[(found['new_min'] == found['min_market_margin'])&(found['min_change']>=0.5),'new_min']= found.loc[(found['new_min'] == found['min_market_margin'])&(found['min_change'])>=0.5,'new_min_margin']\n",
    "found.loc[found['current_margin']<0,'new_min'] = found['current_margin']\n",
    "\n",
    "found.loc[found['new_min'] < found['min_market_margin'],'new_min'] = found['min_market_margin']\n",
    "\n",
    "found['diff'] = (found['max_margin'] - found['min_margin'])/found['min_margin']\n",
    "\n",
    "found['new_max']= found['new_min'] + np.minimum(np.maximum((found['diff']*found['new_min']),0.01),0.07)\n",
    "\n",
    "found.loc[found['max_margin'].isna(),'new_max'] = np.nan\n",
    "\n",
    "found=found[['cohort_id','product_id','new_min','new_max']]\n",
    "found['type'] = 'both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ead04dca-cb4f-46bc-825d-372eee1b1d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_max_df['flag']=1\n",
    "not_found = market_data.merge(min_max_df[['cohort_id','product_id','flag']],on=['cohort_id','product_id'],how='left')\n",
    "not_found = not_found.merge(sales[['cohort_id','product_id','tier']],on=['cohort_id','product_id'])\n",
    "not_found = not_found[not_found['flag'].isna()]\n",
    "\n",
    "not_found['new_min'] = not_found['min_market_margin']\n",
    "not_found['min_change'] = (not_found['new_min_margin']-not_found['min_market_margin'])/not_found['min_market_margin']\n",
    "\n",
    "not_found.loc[(not_found['current_margin']>=not_found['min_market_margin'])&(not_found['tier'] == 1),'new_min'] = not_found['min_market_margin']\n",
    "not_found.loc[(not_found['current_margin']>=not_found['min_market_margin'])&(not_found['tier'] == 2),'new_min'] = not_found['new_min_margin']\n",
    "not_found.loc[(not_found['current_margin']>=not_found['min_market_margin'])&(not_found['tier'] == 3),'new_min'] = not_found['avg_market_margin']\n",
    "not_found.loc[(not_found['current_margin']>=not_found['min_market_margin'])&(not_found['tier'] == 4),'new_min'] = not_found['new_avg_margin']\n",
    "\n",
    "not_found.loc[(not_found['new_min'] == not_found['min_market_margin'])&(not_found['min_change'])>=0.5,'new_min']=not_found['new_min_margin']\n",
    "\n",
    "not_found['diff'] = np.minimum(np.maximum(0.3*not_found['target_margin'],0.01),0.04)\n",
    "not_found['new_max'] = not_found['new_min']+not_found['diff'] \n",
    "not_found=not_found[['cohort_id','product_id','new_min','new_max']]\n",
    "not_found['type'] = 'MP_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2a07a63-cf1f-490e-b6ce-004595e2973c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "market_data['flag_2'] = 1 \n",
    "main_found = min_max_df.merge(market_data,on=['cohort_id','product_id'],how='left')\n",
    "main_found=main_found[main_found['flag_2'].isna()]\n",
    "main_found = main_found[['cohort_id','product_id','min_margin','max_margin','enforce']]\n",
    "main_found['type'] = 'sheet_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "283b3ac9-7f3c-48d0-b4d2-d52c2189de6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df = pd.concat([found,not_found],axis=0)\n",
    "final_df=final_df.drop_duplicates()\n",
    "regions = pd.DataFrame({\n",
    "    'region': ['Cairo', 'Giza', 'Delta West', 'Delta East', 'Upper Egypt', \n",
    "               'Upper Egypt', 'Upper Egypt', 'Upper Egypt', 'Alexandria'],\n",
    "    'cohort_id': [700, 701, 703, 704, 1124, 1126, 1123, 1125, 702]\n",
    "})\n",
    "final_df=final_df.merge(regions,on=['cohort_id'])\n",
    "final_df=final_df[['cohort_id','product_id','new_min','new_max','type']]\n",
    "final_df=final_df.drop_duplicates()\n",
    "final_df.columns = ['cohort_id','product_id','min_margin','max_margin','type']\n",
    "#final_df = pd.concat([final_df,main_found[['cohort_id','product_id','min_margin','max_margin','type']]],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71de92b0-2384-4b65-8fcd-af42a6f67ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "week_number = datetime.now().isocalendar()[1]\n",
    "week_number_c = str(week_number-1)\n",
    "week_number_p = str(week_number-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b5c94bf1-7de2-478c-964b-6b1360968d67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse</th>\n",
       "      <th>stocks</th>\n",
       "      <th>product_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>45.0</td>\n",
       "      <td>12352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>53.0</td>\n",
       "      <td>12350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sharqya</td>\n",
       "      <td>47.0</td>\n",
       "      <td>12343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>Tanta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     warehouse  stocks  product_id\n",
       "1      Sharqya    45.0       12352\n",
       "2      Sharqya    53.0       12350\n",
       "3      Sharqya    14.0       10587\n",
       "8      Sharqya     2.0       12026\n",
       "9      Sharqya    47.0       12343\n",
       "...        ...     ...         ...\n",
       "1113     Tanta     4.0        6684\n",
       "1120     Tanta     2.0       12867\n",
       "1136     Tanta     1.0       23442\n",
       "1138     Tanta     1.0        3546\n",
       "1139     Tanta     1.0       19982\n",
       "\n",
       "[137 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scope = [\"https://spreadsheets.google.com/feeds\",\n",
    "         'https://www.googleapis.com/auth/spreadsheets',\n",
    "         \"https://www.googleapis.com/auth/drive.file\",\n",
    "         \"https://www.googleapis.com/auth/drive\"]\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_dict(json.loads(setup_environment_2.get_secret(\"prod/maxab-sheets\")), scope)\n",
    "client = gspread.authorize(creds)\n",
    "tgto = client.open('Egypt SKUs Aging Monitor').worksheets()\n",
    "worksheet_names = [ws.title for ws in tgto]\n",
    "sheet_name = \"\"\n",
    "for name in worksheet_names:\n",
    "    if week_number_c in name:\n",
    "        sheet_name = name\n",
    "        break\n",
    "    elif week_number_p in name:\n",
    "        sheet_name = name \n",
    "tgto = client.open('Egypt SKUs Aging Monitor').worksheet(f'{sheet_name}')\n",
    "\n",
    "data = tgto.get_all_values()\n",
    "\n",
    "# Convert to DataFrame\n",
    "if data:\n",
    "    tgto_df = pd.DataFrame(data[2:], columns=data[1])\n",
    "    print(\"ok\")\n",
    "else:\n",
    "    tgto_df = pd.DataFrame()\n",
    "for col in tgto_df.columns:\n",
    "    tgto_df[col] = pd.to_numeric(tgto_df[col], errors='ignore')   \n",
    "tgto_df = tgto_df[tgto_df['Fulfillment confirmation']=='confirmed']\n",
    "\n",
    "\n",
    "tgto_df=tgto_df[['SKU', 'Sharqya', 'Khorshed Alex', 'Bani sweif',\n",
    "       'Mostorod', 'Barageel', 'El-Mahala', 'Sohag', 'Mansoura FC',\n",
    "       'Assiut FC', 'Menya Samalot', 'Tanta']]    \n",
    "def convert_string(x):\n",
    "    id_ = x.SKU\n",
    "    try:\n",
    "        id_ = id_.replace(\",\", \"\")\n",
    "        id_ = int(id_)\n",
    "    except:\n",
    "        pass\n",
    "    return id_\n",
    "df_long = tgto_df.melt(\n",
    "    id_vars=['SKU'], \n",
    "    var_name='warehouse', \n",
    "    value_name='stocks'\n",
    ")\n",
    "df_long['product_id'] = df_long.apply(convert_string,axis=1)\n",
    "df_long = df_long.drop(columns = 'SKU')\n",
    "df_long = df_long[~df_long['stocks'].isna()]\n",
    "df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d065a5e8-d5cf-4c0f-b69d-7de929b3be34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select product_id,wac_p\n",
    "from finance.all_cogs f \n",
    "where CONVERT_TIMEZONE('{zone_to_use}', 'Africa/Cairo', CURRENT_TIMEstamp()) between f.from_date and f.to_date \n",
    "'''\n",
    "wacs   = query_snowflake(query, columns = ['product_id','wac_p'])\n",
    "wacs.columns = wacs.columns.str.lower()\n",
    "for col in wacs.columns:\n",
    "    wacs[col] = pd.to_numeric(wacs[col], errors='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7518e53c-478a-4334-8699-18c1bf089c21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "whs = pd.DataFrame([\n",
    "    ('Cairo', 'El-Marg', 38, 700),\n",
    "    ('Cairo', 'Mostorod', 1, 700),\n",
    "    ('Giza', 'Barageel', 236, 701),\n",
    "    ('Delta West', 'El-Mahala', 337, 703),\n",
    "    ('Delta West', 'Tanta', 8, 703),\n",
    "    ('Delta East', 'Mansoura FC', 339, 704),\n",
    "    ('Delta East', 'Sharqya', 170, 704),\n",
    "    ('Upper Egypt', 'Assiut FC', 501, 1124),\n",
    "    ('Upper Egypt', 'Bani sweif', 401, 1126),\n",
    "    ('Upper Egypt', 'Menya Samalot', 703, 1123),\n",
    "    ('Upper Egypt', 'Sohag', 632, 1125),\n",
    "    ('Alexandria', 'Khorshed Alex', 797, 702),\n",
    "    ('Giza', 'Sakkarah', 962, 701)\n",
    "], columns=['region', 'warehouse', 'warehouse_id', 'cohort_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c23032ae-a99a-45a1-bdf0-3c4e93cea1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT product_warehouse.warehouse_id,\n",
    "                product_warehouse.product_id,\n",
    "                (product_warehouse.available_stock)::integer as stocks,\n",
    "        from  product_warehouse \n",
    "        JOIN products on product_warehouse.product_id = products.id\n",
    "        JOIN product_units ON products.unit_id = product_units.id\n",
    "        where   product_warehouse.warehouse_id not in (6,9,10)\n",
    "            AND product_warehouse.activation = 'true'\n",
    "            AND product_warehouse.is_basic_unit = 1\n",
    "'''\n",
    "stocks   = query_snowflake(query, columns = ['warehouse_id','product_id','cu_stocks'])\n",
    "stocks.columns = stocks.columns.str.lower()\n",
    "for col in stocks.columns:\n",
    "    stocks[col] = pd.to_numeric(stocks[col], errors='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7ee31ff4-c77d-44f2-973a-2072e118a13f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = f'''\n",
    "select region,product_id,optimal_bm,MIN_BOUNDARY,MAX_BOUNDARY,MEDIAN_BM\n",
    "from (\n",
    "select region,product_id,target_bm,optimal_bm,MIN_BOUNDARY,MAX_BOUNDARY,MEDIAN_BM,max(created_at) over(partition by product_id,region) as max_date,created_at\n",
    "from materialized_views.PRODUCT_STATISTICS\n",
    "where created_at::date >= date_trunc('month',current_date - 60)\n",
    "qualify max_date = created_at\n",
    ")\n",
    "\n",
    "'''\n",
    " \n",
    "stats = query_snowflake(query, columns = ['region','product_id','optimal_bm','MIN_BOUNDARY','MAX_BOUNDARY','MEDIAN_BM'])\n",
    "stats.columns = stats.columns.str.lower()\n",
    "for col in stats.columns:\n",
    "    stats[col] = pd.to_numeric(stats[col], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "58a42817-656e-404b-8d94-a5bf83dc899c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>remove</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  warehouse_id  remove\n",
       "0        -999          -999       1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_remove = pd.DataFrame([\n",
    "(-999,-999)\n",
    "], columns=['product_id', 'warehouse_id'])\n",
    "to_remove['remove'] =1 \n",
    "to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c6cb2d42-0520-4e1e-a42f-2c643bb9fe2c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>min_margin</th>\n",
       "      <th>max_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>703</td>\n",
       "      <td>3915</td>\n",
       "      <td>0.016301</td>\n",
       "      <td>0.016301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703</td>\n",
       "      <td>4719</td>\n",
       "      <td>0.020454</td>\n",
       "      <td>0.020454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>703</td>\n",
       "      <td>11046</td>\n",
       "      <td>0.024276</td>\n",
       "      <td>0.024276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703</td>\n",
       "      <td>11226</td>\n",
       "      <td>0.032549</td>\n",
       "      <td>0.032549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>703</td>\n",
       "      <td>11295</td>\n",
       "      <td>0.028570</td>\n",
       "      <td>0.028570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>704</td>\n",
       "      <td>11044</td>\n",
       "      <td>0.040360</td>\n",
       "      <td>0.040360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1123</td>\n",
       "      <td>109</td>\n",
       "      <td>0.021489</td>\n",
       "      <td>0.021489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1124</td>\n",
       "      <td>11226</td>\n",
       "      <td>0.029884</td>\n",
       "      <td>0.029884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1124</td>\n",
       "      <td>11735</td>\n",
       "      <td>0.049356</td>\n",
       "      <td>0.049356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1124</td>\n",
       "      <td>20262</td>\n",
       "      <td>0.032968</td>\n",
       "      <td>0.032968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1126</td>\n",
       "      <td>1088</td>\n",
       "      <td>0.017599</td>\n",
       "      <td>0.017599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cohort_id  product_id  min_margin  max_margin\n",
       "0         703        3915    0.016301    0.016301\n",
       "1         703        4719    0.020454    0.020454\n",
       "2         703       11046    0.024276    0.024276\n",
       "3         703       11226    0.032549    0.032549\n",
       "4         703       11295    0.028570    0.028570\n",
       "5         704       11044    0.040360    0.040360\n",
       "6        1123         109    0.021489    0.021489\n",
       "7        1124       11226    0.029884    0.029884\n",
       "8        1124       11735    0.049356    0.049356\n",
       "9        1124       20262    0.032968    0.032968\n",
       "10       1126        1088    0.017599    0.017599"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tgtg = df_long.merge(wacs,on='product_id')\n",
    "tgtg = tgtg.merge(whs,on='warehouse')\n",
    "tgtg=tgtg.merge(to_remove,on=['product_id','warehouse_id'],how='left')\n",
    "tgtg=tgtg[tgtg['remove'].isna()]\n",
    "tgtg = tgtg.merge(stocks,on=['warehouse_id','product_id'])\n",
    "tgtg =tgtg[tgtg['cu_stocks']>0] \n",
    "tgtg['stock_value'] = tgtg['cu_stocks'] * tgtg['wac_p']\n",
    "tgtg =tgtg.sort_values(by ='stock_value',ascending = False) \n",
    "tgtg = tgtg[tgtg['stock_value']>5000]\n",
    "tgtg = tgtg.merge(market_data,on=['cohort_id','product_id'],how='left')\n",
    "tgtg = tgtg.merge(stats,on=['region','product_id'])\n",
    "tgtg=tgtg.fillna(1000)\n",
    "tgtg['min_margin'] = np.minimum(np.minimum(np.minimum(tgtg['min_market_margin']*0.8,tgtg['target_margin']/2),tgtg['min_boundary']*0.9),tgtg['optimal_bm']*0.75)\n",
    "tgtg['max_margin'] = tgtg['min_margin']\n",
    "tgtg.to_excel(\"Min_max_data/tgtg.xlsx\")\n",
    "tgtg = tgtg[['cohort_id', 'product_id','min_margin', 'max_margin']]\n",
    "tgtg = tgtg.groupby(['cohort_id', 'product_id']).agg({'min_margin':min,'max_margin':min}).reset_index()\n",
    "tgtg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "660e4534-3f0a-4398-870a-64ee3ca84093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tgtg['type'] = 'TGTG'\n",
    "result = final_df.merge(tgtg[['product_id', 'cohort_id']], \n",
    "                   on=['product_id', 'cohort_id'], \n",
    "                   how='left', indicator=True)\n",
    "\n",
    "result = result[result['_merge'] == 'left_only'].drop(columns=['_merge'])\n",
    "final_df = pd.concat([result,tgtg],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6dfd282-3306-455b-8fbd-b96fc1b8cce0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "price_ups=price_ups.merge(regions,on=['region'])\n",
    "final_df=final_df.merge(price_ups,on=['product_id','cohort_id'],how='left')\n",
    "final_df.loc[(~final_df['new_pp'].isna())&(final_df['type']=='Normal'),'max_margin'] = np.minimum(final_df['max_margin']+0.15,final_df['min_margin']+0.2)\n",
    "final_df['enforce'] = np.nan\n",
    "final_df.loc[~final_df['new_pp'].isna(),'enforce']= 1  \n",
    "final_df=final_df.drop_duplicates()\n",
    "final_df = final_df.merge(sales,on=['cohort_id','product_id'],how='left')\n",
    "final_df = final_df[['cohort_id', 'product_id','sku', 'min_margin', 'max_margin', 'enforce','brand','type']]\n",
    "final_df = final_df.merge(min_max_df[['cohort_id', 'product_id','min_margin', 'max_margin']].rename(columns = {'min_margin':'old_min','max_margin':'old_max'}),on=['cohort_id', 'product_id'],how='left')\n",
    "final_df.to_excel('Min_max_data/min_max_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8858cc8-a2a3-4387-b405-91d004786ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
