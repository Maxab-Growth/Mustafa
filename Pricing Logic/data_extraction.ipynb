{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction Module for Pricing & Offers System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/snowflake/connector/options.py:104: UserWarning: You have an incompatible version of 'pyarrow' installed (22.0.0), please install a version that adheres to: 'pyarrow<19.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import setup_environment_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region\n",
    "REGION = \"Egypt\"\n",
    "\n",
    "# Snowflake Warehouse\n",
    "WAREHOUSE = \"COMPUTE_WH\"\n",
    "\n",
    "# Date Variables\n",
    "from datetime import datetime, timedelta\n",
    "TODAY = datetime.now().date()\n",
    "YESTERDAY = TODAY - timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "setup_environment_2.initialize_env()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warehouse & Cohort Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warehouse Mapping: (region, warehouse_name, warehouse_id, cohort_id)\n",
    "WAREHOUSE_MAPPING = [\n",
    "    ('Cairo', 'Mostorod', 1, 700),\n",
    "    ('Giza', 'Barageel', 236, 701),\n",
    "    ('Giza', 'Sakkarah', 962, 701),\n",
    "    ('Delta West', 'El-Mahala', 337, 703),\n",
    "    ('Delta West', 'Tanta', 8, 703),\n",
    "    ('Delta East', 'Mansoura FC', 339, 704),\n",
    "    ('Delta East', 'Sharqya', 170, 704),\n",
    "    ('Upper Egypt', 'Assiut FC', 501, 1124),\n",
    "    ('Upper Egypt', 'Bani sweif', 401, 1126),\n",
    "    ('Upper Egypt', 'Menya Samalot', 703, 1123),\n",
    "    ('Upper Egypt', 'Sohag', 632, 1125),\n",
    "    ('Alexandria', 'Khorshed Alex', 797, 702),\n",
    "]\n",
    "\n",
    "# Region to Cohort Mapping\n",
    "REGION_COHORT_MAPPING = {\n",
    "    'Cairo': 700,\n",
    "    'Giza': 701,\n",
    "    'Delta West': 703,\n",
    "    'Delta East': 704,\n",
    "    'Upper Egypt': 1124,\n",
    "    'Alexandria': 702,\n",
    "}\n",
    "\n",
    "# All Cohort IDs\n",
    "COHORT_IDS = [700, 701, 702, 703, 704, 1123, 1124, 1125, 1126]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowflake Query Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_snowflake(query):\n",
    "    \"\"\"Execute a query on Snowflake and return results as DataFrame.\"\"\"\n",
    "    con = snowflake.connector.connect(\n",
    "        user=os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database=os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        data = cur.fetchall()\n",
    "        columns = [desc[0].lower() for desc in cur.description]  # Get column names from cursor\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "    except Exception as e:\n",
    "        print(f\"Snowflake Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snowflake_timezone():\n",
    "    \"\"\"Get the current timezone from Snowflake.\"\"\"\n",
    "    query = \"SHOW PARAMETERS LIKE 'TIMEZONE'\"\n",
    "    result = query_snowflake(query)\n",
    "    return result.value[0] if len(result) > 0 else \"UTC\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warehouse_df():\n",
    "    \"\"\"Get warehouse mapping as DataFrame.\"\"\"\n",
    "    return pd.DataFrame(\n",
    "        WAREHOUSE_MAPPING,\n",
    "        columns=['region', 'warehouse', 'warehouse_id', 'cohort_id']\n",
    "    )\n",
    "\n",
    "\n",
    "def get_cohort_by_region(region):\n",
    "    \"\"\"Get cohort ID for a given region.\"\"\"\n",
    "    return REGION_COHORT_MAPPING.get(region)\n",
    "\n",
    "\n",
    "def convert_to_numeric(df):\n",
    "    \"\"\"Convert DataFrame columns to numeric where possible.\"\"\"\n",
    "    df.columns = df.columns.str.lower()\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Snowflake Timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake timezone: America/Los_Angeles\n"
     ]
    }
   ],
   "source": [
    "TIMEZONE = get_snowflake_timezone()\n",
    "print(f\"Snowflake timezone: {TIMEZONE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Prices Extraction Queries\n",
    "Queries for external market price data:\n",
    "1. **Ben Soliman Prices** - Competitor reference prices\n",
    "2. **Marketplace Prices** - Min, Max, Mod prices from marketplace\n",
    "3. **Scrapped Data** - Competitor prices from scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. BEN SOLIMAN PRICES QUERY\n",
    "# =============================================================================\n",
    "BEN_SOLIMAN_QUERY = f'''\n",
    "WITH lower as (\n",
    "    select distinct product_id, sku, new_d*bs_price as ben_soliman_price, INJECTION_DATE\n",
    "    from (\n",
    "        select maxab_product_id as product_id, maxab_sku as sku, INJECTION_DATE, wac1, wac_p,\n",
    "            (bs_price/bs_unit_count) as bs_price, diff, cu_price,\n",
    "            case when p1 > 1 then child_quantity else 0 end as scheck,\n",
    "            round(p1/2)*2 as p1, p2,\n",
    "            case when (ROUND(p1 / scheck) * scheck) = 0 then p1 else (ROUND(p1 / scheck) * scheck) end as new_d\n",
    "        from (\n",
    "            select sm.*, wac1, wac_p, \n",
    "                abs((bs_price/bs_unit_count)-(wac_p*maxab_basic_unit_count))/(wac_p*maxab_basic_unit_count) as diff,\n",
    "                cpc.price as cu_price, pup.child_quantity,\n",
    "                round((cu_price/(bs_price/bs_unit_count))) as p1, \n",
    "                round(((bs_price/bs_unit_count)/cu_price)) as p2\n",
    "            from materialized_views.savvy_mapping sm \n",
    "            join finance.all_cogs f on f.product_id = sm.maxab_product_id \n",
    "                and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "            join PACKING_UNIT_PRODUCTS pu on pu.product_id = sm.maxab_product_id and pu.IS_BASIC_UNIT = 1 \n",
    "            join cohort_product_packing_units cpc on cpc.PRODUCT_PACKING_UNIT_ID = pu.id and cohort_id = 700 \n",
    "            join packing_unit_products pup on pup.product_id = sm.maxab_product_id and pup.is_basic_unit = 1  \n",
    "            where bs_price is not null \n",
    "                and INJECTION_DATE::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 5 \n",
    "                and diff > 0.3 and p1 > 1\n",
    "        )\n",
    "    )\n",
    "    qualify max(INJECTION_DATE) over(partition by product_id) = INJECTION_DATE\n",
    "),\n",
    "\n",
    "m_bs as (\n",
    "    select z.* from (\n",
    "        select maxab_product_id as product_id, maxab_sku as sku, avg(bs_final_price) as ben_soliman_price, INJECTION_DATE\n",
    "        from (\n",
    "            select *, row_number() over(partition by maxab_product_id order by diff) as rnk_2 \n",
    "            from (\n",
    "                select *, (bs_final_price-wac_p)/wac_p as diff_2 \n",
    "                from (\n",
    "                    select *, bs_price/maxab_basic_unit_count as bs_final_price \n",
    "                    from (\n",
    "                        select *, row_number() over(partition by maxab_product_id, maxab_pu order by diff) as rnk \n",
    "                        from (\n",
    "                            select *, max(INJECTION_DATE::date) over(partition by maxab_product_id, maxab_pu) as max_date\n",
    "                            from (\n",
    "                                select sm.*, wac1, wac_p, \n",
    "                                    abs(bs_price-(wac_p*maxab_basic_unit_count))/(wac_p*maxab_basic_unit_count) as diff \n",
    "                                from materialized_views.savvy_mapping sm \n",
    "                                join finance.all_cogs f on f.product_id = sm.maxab_product_id \n",
    "                                    and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "                                where bs_price is not null \n",
    "                                    and INJECTION_DATE::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 5 \n",
    "                                    and diff < 0.3\n",
    "                            )\n",
    "                            qualify max_date = INJECTION_DATE\n",
    "                        ) qualify rnk = 1 \n",
    "                    )\n",
    "                ) where diff_2 between -0.5 and 0.5 \n",
    "            ) qualify rnk_2 = 1 \n",
    "        ) group by all\n",
    "    ) z \n",
    "    join finance.all_cogs f on f.product_id = z.product_id \n",
    "        and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "    where ben_soliman_price between f.wac_p*0.8 and f.wac_p*1.3\n",
    ")\n",
    "\n",
    "select product_id, avg(ben_soliman_price) as ben_soliman_price\n",
    "from (\n",
    "    select * from (\n",
    "        select * from m_bs \n",
    "        union all\n",
    "        select * from lower\n",
    "    )\n",
    "    qualify max(INJECTION_DATE) over(partition by product_id) = INJECTION_DATE\n",
    ")\n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. MARKETPLACE PRICES QUERY (with region fallback)\n",
    "# =============================================================================\n",
    "MARKETPLACE_PRICES_QUERY = f'''\n",
    "WITH MP as (\n",
    "    select region, product_id,\n",
    "        min(min_price) as min_price, min(max_price) as max_price,\n",
    "        min(mod_price) as mod_price, min(true_min) as true_min, min(true_max) as true_max\n",
    "    from (\n",
    "        select mp.region, mp.product_id, mp.pu_id,\n",
    "            min_price/BASIC_UNIT_COUNT as min_price,\n",
    "            max_price/BASIC_UNIT_COUNT as max_price,\n",
    "            mod_price/BASIC_UNIT_COUNT as mod_price,\n",
    "            TRUE_MIN_PRICE/BASIC_UNIT_COUNT as true_min,\n",
    "            TRUE_MAX_PRICE/BASIC_UNIT_COUNT as true_max\n",
    "        from materialized_views.marketplace_prices mp \n",
    "        join packing_unit_products pup on pup.product_id = mp.product_id and pup.packing_unit_id = mp.pu_id\n",
    "        join finance.all_cogs f on f.product_id = mp.product_id \n",
    "            and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_date and f.to_date\n",
    "        where least(min_price, mod_price) between wac_p*0.9 and wac_p*1.3 \n",
    "    )\n",
    "    group by all \n",
    "),\n",
    "\n",
    "region_mapping AS (\n",
    "    SELECT * FROM (VALUES\n",
    "        ('Delta East', 'Delta West'), ('Delta West', 'Delta East'),\n",
    "        ('Alexandria', 'Cairo'), ('Alexandria', 'Giza'),\n",
    "        ('Upper Egypt', 'Cairo'), ('Upper Egypt', 'Giza'),\n",
    "        ('Cairo', 'Giza'), ('Giza', 'Cairo'),\n",
    "        ('Delta West', 'Cairo'), ('Delta East', 'Cairo'),\n",
    "        ('Delta West', 'Giza'), ('Delta East', 'Giza')\n",
    "    ) AS region_mapping(region, fallback_region)\n",
    "),\n",
    "\n",
    "all_regions as (\n",
    "    SELECT * FROM (VALUES\n",
    "        ('Cairo'), ('Giza'), ('Delta West'), ('Delta East'), ('Upper Egypt'), ('Alexandria')\n",
    "    ) AS x(region)\n",
    "),\n",
    "\n",
    "full_data as (\n",
    "    select products.id as product_id, ar.region\n",
    "    from products, all_regions ar\n",
    "    where activation = 'true'\n",
    ")\n",
    "\n",
    "select region, product_id,\n",
    "    min(final_min_price) as final_min_price, \n",
    "    min(final_max_price) as final_max_price,\n",
    "    min(final_mod_price) as final_mod_price, \n",
    "    min(final_true_min) as final_true_min,\n",
    "    min(final_true_max) as final_true_max\n",
    "from (\n",
    "    SELECT distinct w.region, w.product_id,\n",
    "        COALESCE(m1.min_price, m2.min_price) AS final_min_price,\n",
    "        COALESCE(m1.max_price, m2.max_price) AS final_max_price,\n",
    "        COALESCE(m1.mod_price, m2.mod_price) AS final_mod_price,\n",
    "        COALESCE(m1.true_min, m2.true_min) AS final_true_min,\n",
    "        COALESCE(m1.true_max, m2.true_max) AS final_true_max\n",
    "    FROM full_data w\n",
    "    LEFT JOIN MP m1 ON w.region = m1.region and w.product_id = m1.product_id\n",
    "    LEFT JOIN region_mapping rm ON w.region = rm.region\n",
    "    LEFT JOIN MP m2 ON rm.fallback_region = m2.region AND w.product_id = m2.product_id\n",
    ")\n",
    "where final_min_price is not null \n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. SCRAPPED DATA QUERY (Competitor prices from scraping)\n",
    "# =============================================================================\n",
    "SCRAPPED_DATA_QUERY = f'''\n",
    "select product_id, region,\n",
    "    MIN(market_price) AS min_scrapped,\n",
    "    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY market_price) AS scrapped25,\n",
    "    PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY market_price) AS scrapped50,\n",
    "    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY market_price) AS scrapped75,\n",
    "    MAX(market_price) AS max_scrapped\n",
    "from (\n",
    "    select distinct cmp.*, max(date) over(partition by region, cmp.product_id, competitor) as max_date\n",
    "    from MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES cmp\n",
    "    join finance.all_cogs f on f.product_id = cmp.product_id \n",
    "        and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_date and f.to_date \n",
    "    where date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 7 \n",
    "        and MARKET_PRICE between f.wac_p * 0.8 and wac_p * 1.3\n",
    "    qualify date = max_date \n",
    ")\n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional Data Queries (Sales, Groups, WAC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. PRODUCT BASE DATA QUERY (product_id, sku, brand, cat, wac1, wac_p, current_price)\n",
    "# =============================================================================\n",
    "PRODUCT_BASE_QUERY = f'''\n",
    "WITH skus_prices AS (\n",
    "    WITH local_prices AS (\n",
    "        SELECT  \n",
    "            CASE \n",
    "                WHEN cpu.cohort_id IN (700, 695) THEN 'Cairo'\n",
    "                WHEN cpu.cohort_id IN (701) THEN 'Giza'\n",
    "                WHEN cpu.cohort_id IN (704, 698) THEN 'Delta East'\n",
    "                WHEN cpu.cohort_id IN (703, 697) THEN 'Delta West'\n",
    "                WHEN cpu.cohort_id IN (696, 1123, 1124, 1125, 1126) THEN 'Upper Egypt'\n",
    "                WHEN cpu.cohort_id IN (702, 699) THEN 'Alexandria'\n",
    "            END AS region,\n",
    "            cohort_id,\n",
    "            pu.product_id,\n",
    "            pu.packing_unit_id,\n",
    "            pu.basic_unit_count,\n",
    "            AVG(cpu.price) AS price\n",
    "        FROM cohort_product_packing_units cpu\n",
    "        JOIN PACKING_UNIT_PRODUCTS pu ON pu.id = cpu.product_packing_unit_id\n",
    "        WHERE cpu.cohort_id IN (700,701,702,703,704,695,696,697,698,699,1123,1124,1125,1126)\n",
    "            AND cpu.created_at::date <> '2023-07-31'\n",
    "            AND cpu.is_customized = TRUE\n",
    "        GROUP BY ALL\n",
    "    ),\n",
    "    \n",
    "    live_prices AS (\n",
    "        SELECT \n",
    "            region, cohort_id, product_id, \n",
    "            pu_id AS packing_unit_id, \n",
    "            buc AS basic_unit_count, \n",
    "            NEW_PRICE AS price\n",
    "        FROM materialized_views.DBDP_PRICES\n",
    "        WHERE created_at = CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date\n",
    "            AND DATE_PART('hour', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::time) \n",
    "                BETWEEN SPLIT_PART(time_slot, '-', 1)::int AND (SPLIT_PART(time_slot, '-', 1)::int) + 1\n",
    "            AND cohort_id IN (700,701,702,703,704,695,696,697,698,699,1123,1124,1125,1126)\n",
    "    ),\n",
    "    \n",
    "    prices AS (\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT *, 1 AS priority FROM live_prices\n",
    "            UNION ALL\n",
    "            SELECT *, 2 AS priority FROM local_prices\n",
    "        )\n",
    "        QUALIFY ROW_NUMBER() OVER (PARTITION BY region, cohort_id, product_id, packing_unit_id ORDER BY priority) = 1\n",
    "    )\n",
    "    \n",
    "    SELECT region, cohort_id, product_id, price\n",
    "    FROM prices\n",
    "    WHERE basic_unit_count = 1\n",
    "        AND ((product_id = 1309 AND packing_unit_id = 2) OR (product_id <> 1309))\n",
    ")\n",
    "\n",
    "SELECT distinct\n",
    "    region, cohort_id, p.product_id,\n",
    "    CONCAT(products.name_ar, ' ', products.size, ' ', product_units.name_ar) AS sku,\n",
    "    b.name_ar AS brand,\n",
    "    cat.name_ar AS cat,\n",
    "    wac1, wac_p, p.price as current_price\n",
    "FROM skus_prices p\n",
    "JOIN finance.all_cogs c ON c.product_id = p.product_id \n",
    "    AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) BETWEEN c.from_date AND c.to_date\n",
    "JOIN products ON products.id = p.product_id\n",
    "JOIN categories cat ON cat.id = products.category_id\n",
    "JOIN brands b ON b.id = products.brand_id\n",
    "JOIN product_units ON product_units.id = products.unit_id\n",
    "WHERE wac1 > 0 AND wac_p > 0\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 5. SALES DATA QUERY (120-day NMV by cohort/product)\n",
    "# =============================================================================\n",
    "SALES_QUERY = f'''\n",
    "SELECT DISTINCT cpc.cohort_id, pso.product_id,\n",
    "    CONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "    brands.name_ar as brand, categories.name_ar as cat,\n",
    "    sum(pso.total_price) as nmv\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN COHORT_PRICING_CHANGES cpc ON cpc.id = pso.COHORT_PRICING_CHANGE_id\n",
    "JOIN products ON products.id = pso.product_id\n",
    "JOIN brands ON products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "WHERE so.created_at::date BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 120 \n",
    "    AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 1 \n",
    "    AND so.sales_order_status_id NOT IN (7, 12)\n",
    "    AND so.channel IN ('telesales', 'retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "    AND cpc.cohort_id IN (700,701,702,703,704,1123,1124,1125,1126)\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 6. MARGIN STATS QUERY (STD and average margins)  \n",
    "# =============================================================================\n",
    "MARGIN_STATS_QUERY = f'''\n",
    "select product_id, cohort_id, \n",
    "    (0.6*product_std) + (0.3*brand_std) + (0.1*cat_std) as std, \n",
    "    avg_margin\n",
    "from (\n",
    "    select product_id, cohort_id, \n",
    "        stddev(product_margin) as product_std, \n",
    "        stddev(brand_margin) as brand_std,\n",
    "        stddev(cat_margin) as cat_std, \n",
    "        avg(product_margin) as avg_margin\n",
    "    from (\n",
    "        select distinct product_id, order_date, cohort_id,\n",
    "            (nmv-cogs_p)/nmv as product_margin, \n",
    "            (brand_nmv-brand_cogs)/brand_nmv as brand_margin,\n",
    "            (cat_nmv-cat_cogs)/cat_nmv as cat_margin\n",
    "        from (\n",
    "            SELECT DISTINCT so.created_at::date as order_date, cpc.cohort_id, pso.product_id,\n",
    "                brands.name_ar as brand, categories.name_ar as cat,\n",
    "                sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs_p,\n",
    "                sum(pso.total_price) as nmv,\n",
    "                sum(nmv) over(partition by order_date, cat, brand) as brand_nmv,\n",
    "                sum(cogs_p) over(partition by order_date, cat, brand) as brand_cogs,\n",
    "                sum(nmv) over(partition by order_date, cat) as cat_nmv,\n",
    "                sum(cogs_p) over(partition by order_date, cat) as cat_cogs\n",
    "            FROM product_sales_order pso\n",
    "            JOIN sales_orders so ON so.id = pso.sales_order_id   \n",
    "            JOIN COHORT_PRICING_CHANGES cpc on cpc.id = pso.cohort_pricing_change_id\n",
    "            JOIN products on products.id = pso.product_id\n",
    "            JOIN brands on products.brand_id = brands.id \n",
    "            JOIN categories ON products.category_id = categories.id\n",
    "            JOIN finance.all_cogs f ON f.product_id = pso.product_id\n",
    "                AND f.from_date::date <= so.created_at::date AND f.to_date::date > so.created_at::date\n",
    "            WHERE so.created_at::date between \n",
    "                date_trunc('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 120) \n",
    "                and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date\n",
    "                AND so.sales_order_status_id not in (7,12)\n",
    "                AND so.channel IN ('telesales','retailer')\n",
    "                AND pso.purchased_item_count <> 0\n",
    "            GROUP BY ALL\n",
    "        )\n",
    "    ) group by all \n",
    ")\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 7. TARGET MARGINS QUERY\n",
    "# =============================================================================\n",
    "TARGET_MARGINS_QUERY = f'''\n",
    "WITH cat_brand_target as (\n",
    "    SELECT DISTINCT cat, brand, margin as target_bm\n",
    "    FROM performance.commercial_targets cplan\n",
    "    QUALIFY CASE \n",
    "        WHEN DATE_TRUNC('month', MAX(DATE) OVER()) = DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date) \n",
    "        THEN DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date)\n",
    "        ELSE DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - INTERVAL '1 month') \n",
    "    END = DATE_TRUNC('month', date)\n",
    "),\n",
    "cat_target as (\n",
    "    select cat, sum(target_bm * (target_nmv/cat_total)) as cat_target_margin\n",
    "    from (\n",
    "        select *, sum(target_nmv) over(partition by cat) as cat_total\n",
    "        from (\n",
    "            select cat, brand, avg(target_bm) as target_bm, sum(target_nmv) as target_nmv\n",
    "            from (\n",
    "                SELECT DISTINCT date, city as region, cat, brand, margin as target_bm, nmv as target_nmv\n",
    "                FROM performance.commercial_targets cplan\n",
    "                QUALIFY CASE \n",
    "                    WHEN DATE_TRUNC('month', MAX(DATE) OVER()) = DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date) \n",
    "                    THEN DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date)\n",
    "                    ELSE DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - INTERVAL '1 month') \n",
    "                END = DATE_TRUNC('month', date)\n",
    "            ) group by all\n",
    "        )\n",
    "    ) group by all \n",
    ")\n",
    "SELECT DISTINCT cbt.cat, cbt.brand, cbt.target_bm, ct.cat_target_margin\n",
    "FROM cat_brand_target cbt\n",
    "LEFT JOIN cat_target ct ON ct.cat = cbt.cat\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute All Queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Snowflake...\n",
      "  1. Loading Ben Soliman prices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 1600 Ben Soliman price records\n",
      "  2. Loading marketplace prices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 11404 marketplace price records\n",
      "  3. Loading scrapped data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 5189 scrapped price records\n",
      "  4. Loading product base data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 101742 product base records\n",
      "  5. Loading sales data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 20617 sales records\n",
      "  6. Loading margin stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 28648 margin stat records\n",
      "  7. Loading target margins...\n",
      "     Loaded 478 target margin records\n",
      "  8. Loading product groups...\n",
      "     Loaded 1576 group records\n",
      "\n",
      "All queries completed!\n",
      "\n",
      "============================================================\n",
      "df_product_base DataFrame available with columns:\n",
      "  - region, cohort_id, product_id, sku, brand, cat, wac1, wac_p, current_price\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n",
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Execute all queries\n",
    "# =============================================================================\n",
    "print(\"Loading data from Snowflake...\")\n",
    "\n",
    "# 1. Ben Soliman Prices\n",
    "print(\"  1. Loading Ben Soliman prices...\")\n",
    "df_ben_soliman = query_snowflake(BEN_SOLIMAN_QUERY)\n",
    "df_ben_soliman = convert_to_numeric(df_ben_soliman)\n",
    "print(f\"     Loaded {len(df_ben_soliman)} Ben Soliman price records\")\n",
    "\n",
    "# 2. Marketplace Prices\n",
    "print(\"  2. Loading marketplace prices...\")\n",
    "df_marketplace = query_snowflake(MARKETPLACE_PRICES_QUERY)\n",
    "df_marketplace = convert_to_numeric(df_marketplace)\n",
    "print(f\"     Loaded {len(df_marketplace)} marketplace price records\")\n",
    "\n",
    "# 3. Scrapped Data\n",
    "print(\"  3. Loading scrapped data...\")\n",
    "df_scrapped = query_snowflake(SCRAPPED_DATA_QUERY)\n",
    "df_scrapped = convert_to_numeric(df_scrapped)\n",
    "print(f\"     Loaded {len(df_scrapped)} scrapped price records\")\n",
    "\n",
    "# 4. Product Base Data (product_id, sku, brand, cat, wac1, wac_p, current_price)\n",
    "print(\"  4. Loading product base data...\")\n",
    "df_product_base = query_snowflake(PRODUCT_BASE_QUERY)\n",
    "df_product_base = convert_to_numeric(df_product_base)\n",
    "print(f\"     Loaded {len(df_product_base)} product base records\")\n",
    "\n",
    "# 5. Sales Data\n",
    "print(\"  5. Loading sales data...\")\n",
    "df_sales = query_snowflake(SALES_QUERY)\n",
    "df_sales = convert_to_numeric(df_sales)\n",
    "print(f\"     Loaded {len(df_sales)} sales records\")\n",
    "\n",
    "# 6. Margin Stats\n",
    "print(\"  6. Loading margin stats...\")\n",
    "df_margin_stats = query_snowflake(MARGIN_STATS_QUERY)\n",
    "df_margin_stats = convert_to_numeric(df_margin_stats)\n",
    "print(f\"     Loaded {len(df_margin_stats)} margin stat records\")\n",
    "\n",
    "# 7. Target Margins\n",
    "print(\"  7. Loading target margins...\")\n",
    "df_targets = query_snowflake(TARGET_MARGINS_QUERY)\n",
    "df_targets = convert_to_numeric(df_targets)\n",
    "print(f\"     Loaded {len(df_targets)} target margin records\")\n",
    "\n",
    "# 8. Product Groups (from PostgreSQL)\n",
    "print(\"  8. Loading product groups...\")\n",
    "df_groups = setup_environment_2.dwh_pg_query(\n",
    "    \"SELECT * FROM materialized_views.sku_commercial_groups\", \n",
    "    columns=['product_id', 'group']\n",
    ")\n",
    "df_groups.columns = df_groups.columns.str.lower()\n",
    "df_groups = convert_to_numeric(df_groups)\n",
    "print(f\"     Loaded {len(df_groups)} group records\")\n",
    "\n",
    "print(\"\\nAll queries completed!\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"df_product_base DataFrame available with columns:\")\n",
    "print(\"  - region, cohort_id, product_id, sku, brand, cat, wac1, wac_p, current_price\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building market_data DataFrame (market prices only)...\n",
      "  Step 1: Joining all market price sources (outer join)...\n",
      "     Market prices base: 16306 records\n",
      "  Step 2: Adding cohort IDs and supporting data for processing...\n",
      "\n",
      "============================================================\n",
      "MARKET DATA BASE READY FOR PROCESSING\n",
      "============================================================\n",
      "Total records: 24076\n",
      "  - With marketplace prices: 16747\n",
      "  - With scrapped prices: 7694\n",
      "  - With Ben Soliman prices: 14400\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PART A: Build market_data DataFrame - Process market prices SEPARATELY\n",
    "# =============================================================================\n",
    "print(\"Building market_data DataFrame (market prices only)...\")\n",
    "\n",
    "# Create region-cohort mapping\n",
    "REGION_COHORT_DF = pd.DataFrame({\n",
    "    'region': ['Cairo', 'Giza', 'Delta West', 'Delta East', \n",
    "               'Upper Egypt', 'Upper Egypt', 'Upper Egypt', 'Upper Egypt', 'Alexandria'],\n",
    "    'cohort_id': [700, 701, 703, 704, 1124, 1126, 1123, 1125, 702]\n",
    "})\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Outer join all market price sources\n",
    "# =============================================================================\n",
    "print(\"  Step 1: Joining all market price sources (outer join)...\")\n",
    "\n",
    "# Start with marketplace prices (has region + product_id)\n",
    "market_data = df_marketplace.copy()\n",
    "\n",
    "# Outer join with scrapped data (by region + product_id)\n",
    "market_data = market_data.merge(df_scrapped, on=['region', 'product_id'], how='outer')\n",
    "\n",
    "# Outer join with Ben Soliman prices (by product_id only - expand to all regions)\n",
    "all_regions = pd.DataFrame({'region': ['Cairo', 'Giza', 'Delta West', 'Delta East', 'Upper Egypt', 'Alexandria']})\n",
    "df_ben_soliman_expanded = df_ben_soliman.merge(all_regions, how='cross')\n",
    "\n",
    "# Outer join with Ben Soliman\n",
    "market_data = market_data.merge(df_ben_soliman_expanded, on=['region', 'product_id'], how='outer')\n",
    "\n",
    "print(f\"     Market prices base: {len(market_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Add cohort_id and supporting data for market processing\n",
    "# =============================================================================\n",
    "print(\"  Step 2: Adding cohort IDs and supporting data for processing...\")\n",
    "market_data = market_data.merge(REGION_COHORT_DF, on='region')\n",
    "\n",
    "# Need sales data for group processing (weighted median)\n",
    "market_data = market_data.merge(\n",
    "    df_sales[['cohort_id', 'product_id', 'nmv']], \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "market_data['nmv'] = market_data['nmv'].fillna(0)\n",
    "\n",
    "# Need margin stats for price analysis\n",
    "market_data = market_data.merge(df_margin_stats, on=['cohort_id', 'product_id'], how='left')\n",
    "\n",
    "# Need WAC for price analysis - get from product base\n",
    "market_data = market_data.merge(\n",
    "    df_product_base[['cohort_id', 'product_id', 'wac_p', 'brand', 'cat']].drop_duplicates(), \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Need target margins for price analysis\n",
    "market_data = market_data.merge(df_targets, on=['brand', 'cat'], how='left')\n",
    "market_data['target_margin'] = market_data['target_bm'].fillna(market_data['cat_target_margin']).fillna(0)\n",
    "market_data = market_data.drop(columns=['target_bm', 'cat_target_margin'], errors='ignore')\n",
    "\n",
    "# Fill NaN values with defaults\n",
    "market_data['std'] = market_data['std'].fillna(0.01)\n",
    "market_data['avg_margin'] = market_data['avg_margin'].fillna(0)\n",
    "\n",
    "# Merge product groups for group processing\n",
    "market_data = market_data.merge(df_groups, on='product_id', how='left')\n",
    "\n",
    "# Remove duplicates\n",
    "market_data = market_data.drop_duplicates(subset=['cohort_id', 'product_id'])\n",
    "\n",
    "# Filter out records without WAC (can't process prices without cost)\n",
    "market_data = market_data[~market_data['wac_p'].isna()]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MARKET DATA BASE READY FOR PROCESSING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(market_data)}\")\n",
    "print(f\"  - With marketplace prices: {len(market_data[~market_data['final_min_price'].isna()])}\")\n",
    "print(f\"  - With scrapped prices: {len(market_data[~market_data['min_scrapped'].isna()])}\")\n",
    "print(f\"  - With Ben Soliman prices: {len(market_data[~market_data['ben_soliman_price'].isna()])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART A: Market Data Processing\n",
    "Process market prices separately (group fill, coverage filter, price analysis, margin tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after group processing: 24076 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/2745197058.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Group Processing - Calculate group-level aggregated prices (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate group-level aggregated prices for products with group assignments\n",
    "groups_data = market_data[~market_data['group'].isna()].copy()\n",
    "groups_data['group_nmv'] = groups_data.groupby(['group', 'cohort_id'])['nmv'].transform('sum')\n",
    "groups_data['cntrb'] = (groups_data['nmv'] / groups_data['group_nmv']).fillna(1)\n",
    "\n",
    "# Flag if any price/scrapped column is non-NaN\n",
    "price_cols = [\n",
    "    'ben_soliman_price', 'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped'\n",
    "]\n",
    "groups_data['flag_non_nan'] = groups_data[price_cols].notna().any(axis=1).astype(int)\n",
    "\n",
    "# Weighted Median Function\n",
    "def weighted_median(series, weights):\n",
    "    valid = ~series.isna() & ~weights.isna()\n",
    "    s = series[valid]\n",
    "    w = weights[valid]\n",
    "    if len(s) == 0:\n",
    "        return np.nan\n",
    "    order = np.argsort(s)\n",
    "    s, w = s.iloc[order], w.iloc[order]\n",
    "    return s.iloc[np.searchsorted(np.cumsum(w), w.sum() / 2)]\n",
    "\n",
    "# Perform Weighted Aggregation\n",
    "groups_agg = (\n",
    "    groups_data[groups_data['flag_non_nan'] == 1]\n",
    "    .groupby(['group', 'cohort_id'])\n",
    "    .apply(lambda g: pd.Series({\n",
    "        col: weighted_median(g[col], g['cntrb']) for col in price_cols\n",
    "    }))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Fill missing prices with group-level prices\n",
    "merged = market_data.merge(groups_agg, on=['group', 'cohort_id'], how='left', suffixes=('', '_group'))\n",
    "for col in price_cols:\n",
    "    merged[col] = merged[col].fillna(merged[f'{col}_group'])\n",
    "\n",
    "market_data = merged.drop(columns=[f'{c}_group' for c in price_cols])\n",
    "\n",
    "print(f\"Market data after group processing: {len(market_data)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Coverage Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after price coverage filtering: 13000 records\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Price Coverage Filtering - Filter products with sufficient price data (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Score price coverage\n",
    "market_data['ben'] = 0\n",
    "market_data['MP'] = 0\n",
    "market_data['sp'] = 0\n",
    "\n",
    "# Ben Soliman: 1 point if present\n",
    "market_data.loc[~market_data['ben_soliman_price'].isna(), 'ben'] = 1\n",
    "\n",
    "# Marketplace: 1 point if single price, 3 points if range\n",
    "market_data.loc[(market_data['final_min_price'] == market_data['final_max_price']) & \n",
    "                (~market_data['final_min_price'].isna()), 'MP'] = 1\n",
    "market_data.loc[(market_data['final_min_price'] != market_data['final_max_price']) & \n",
    "                (~market_data['final_min_price'].isna()), 'MP'] = 3\n",
    "\n",
    "# Scrapped: 1 point if single price, 5 points if range\n",
    "market_data.loc[(market_data['min_scrapped'] == market_data['max_scrapped']) & \n",
    "                (~market_data['min_scrapped'].isna()), 'sp'] = 1\n",
    "market_data.loc[(market_data['min_scrapped'] != market_data['max_scrapped']) & \n",
    "                (~market_data['min_scrapped'].isna()), 'sp'] = 5\n",
    "\n",
    "# Total price coverage score\n",
    "market_data['total_p'] = market_data['ben'] + market_data['MP'] + market_data['sp']\n",
    "\n",
    "# Filter: keep only products with total_p > 2\n",
    "market_data = market_data[market_data['total_p'] > 2]\n",
    "\n",
    "print(f\"Market data after price coverage filtering: {len(market_data)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Analysis & Margin Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Price Analysis Functions\n",
    "# =============================================================================\n",
    "\n",
    "def price_analysis(row):\n",
    "    \"\"\"Analyze prices and calculate percentiles for a product.\"\"\"\n",
    "    wac = row['wac_p']\n",
    "    avg_margin = row['avg_margin'] if row['avg_margin'] >= 0.01 else row['target_margin']\n",
    "    std = np.maximum(row['std'], 0.0025)\n",
    "    target_margin = row['target_margin']\n",
    "    max_marg = np.maximum(avg_margin, target_margin)\n",
    "    \n",
    "    # Collect all price points\n",
    "    price_list = [\n",
    "        row['ben_soliman_price'], row['final_min_price'], row['final_mod_price'],\n",
    "        row['final_max_price'], row['final_true_min'], row['final_true_max'],\n",
    "        row['min_scrapped'], row['scrapped25'], row['scrapped50'], row['scrapped75'], row['max_scrapped']\n",
    "    ]\n",
    "    \n",
    "    # Filter valid prices within acceptable range\n",
    "    valid_prices = sorted({\n",
    "        x for x in price_list \n",
    "        if x and not pd.isna(x) and x != 0 \n",
    "        and wac / (1 - (avg_margin - (10 * std))) <= x <= wac / (1 - (max_marg + 10 * std))\n",
    "        and x >= wac * 0.9\n",
    "    })\n",
    "    \n",
    "    if not valid_prices:\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    return (\n",
    "        np.min(valid_prices),\n",
    "        np.percentile(valid_prices, 25),\n",
    "        np.percentile(valid_prices, 50),\n",
    "        np.percentile(valid_prices, 75),\n",
    "        np.max(valid_prices)\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_step_bounds(row):\n",
    "    \"\"\"Calculate below/above market bounds based on price steps.\"\"\"\n",
    "    wac = row['wac_p']\n",
    "    std = row['std']\n",
    "    prices = [row['minimum'], row['percentile_25'], row['percentile_50'], row['percentile_75'], row['maximum']]\n",
    "    \n",
    "    # Calculate valid steps between price points\n",
    "    valid_steps = []\n",
    "    for i in range(len(prices) - 1):\n",
    "        step = prices[i + 1] - prices[i]\n",
    "        if (step / wac) <= std * 1.2:\n",
    "            valid_steps.append(step)\n",
    "    \n",
    "    avg_step = np.mean(valid_steps) if valid_steps else min(2 * std, 0.2 * row['target_margin'])\n",
    "    \n",
    "    new_min = prices[0] - avg_step if (prices[0] - avg_step) >= wac else prices[0]\n",
    "    new_max = prices[-1] + avg_step if (prices[-1] + avg_step) >= wac else prices[-1]\n",
    "    \n",
    "    return new_min, new_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after price analysis: 12329 records\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Apply Price Analysis & Margin Calculation (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Apply price analysis to calculate price percentiles\n",
    "market_data[['minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum']] = \\\n",
    "    market_data.apply(price_analysis, axis=1, result_type='expand')\n",
    "\n",
    "# Filter out records without valid price analysis\n",
    "market_data = market_data[~market_data['minimum'].isna()]\n",
    "\n",
    "# Calculate below/above market bounds\n",
    "market_data[['below_market', 'above_market']] = market_data.apply(calculate_step_bounds, axis=1, result_type='expand')\n",
    "\n",
    "print(f\"Market data after price analysis: {len(market_data)} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MARKET DATA PROCESSING COMPLETE\n",
      "============================================================\n",
      "Total processed market records: 12329\n",
      "\n",
      "Market data columns:\n",
      "  - Price columns: ben_soliman_price, final_min_price, final_max_price, etc.\n",
      "  - Percentiles: minimum, percentile_25, percentile_50, percentile_75, maximum\n",
      "  - Margin tiers: below_market, market_min, market_25, market_50, market_75, market_max, above_market\n",
      "\n",
      "Sample processed market data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>ben_soliman_price</th>\n",
       "      <th>final_min_price</th>\n",
       "      <th>final_max_price</th>\n",
       "      <th>final_mod_price</th>\n",
       "      <th>final_true_min</th>\n",
       "      <th>final_true_max</th>\n",
       "      <th>min_scrapped</th>\n",
       "      <th>scrapped25</th>\n",
       "      <th>...</th>\n",
       "      <th>percentile_50</th>\n",
       "      <th>percentile_75</th>\n",
       "      <th>maximum</th>\n",
       "      <th>below_market</th>\n",
       "      <th>market_min</th>\n",
       "      <th>market_25</th>\n",
       "      <th>market_50</th>\n",
       "      <th>market_75</th>\n",
       "      <th>market_max</th>\n",
       "      <th>above_market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>702</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.5</td>\n",
       "      <td>255.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>254.630005</td>\n",
       "      <td>254.957504</td>\n",
       "      <td>...</td>\n",
       "      <td>255.448753</td>\n",
       "      <td>256.580002</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.050898</td>\n",
       "      <td>0.053320</td>\n",
       "      <td>0.054655</td>\n",
       "      <td>0.056355</td>\n",
       "      <td>0.060515</td>\n",
       "      <td>0.136011</td>\n",
       "      <td>0.138019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>702</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>835.4</td>\n",
       "      <td>838.6</td>\n",
       "      <td>835.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>837.000000</td>\n",
       "      <td>838.700000</td>\n",
       "      <td>839.0</td>\n",
       "      <td>0.018123</td>\n",
       "      <td>0.019299</td>\n",
       "      <td>0.019651</td>\n",
       "      <td>0.021643</td>\n",
       "      <td>0.023626</td>\n",
       "      <td>0.023975</td>\n",
       "      <td>0.025137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>702</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>288.500000</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.025238</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.036009</td>\n",
       "      <td>0.065273</td>\n",
       "      <td>0.092812</td>\n",
       "      <td>0.097505</td>\n",
       "      <td>0.102149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>702</td>\n",
       "      <td>14.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>461.5</td>\n",
       "      <td>477.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>463.250000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>477.0</td>\n",
       "      <td>0.022650</td>\n",
       "      <td>0.028316</td>\n",
       "      <td>0.030687</td>\n",
       "      <td>0.035133</td>\n",
       "      <td>0.044926</td>\n",
       "      <td>0.062946</td>\n",
       "      <td>0.068156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>702</td>\n",
       "      <td>17.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>596.5</td>\n",
       "      <td>603.5</td>\n",
       "      <td>600.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>598.500000</td>\n",
       "      <td>598.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>603.750000</td>\n",
       "      <td>605.0</td>\n",
       "      <td>0.018424</td>\n",
       "      <td>0.022548</td>\n",
       "      <td>0.026638</td>\n",
       "      <td>0.030693</td>\n",
       "      <td>0.036714</td>\n",
       "      <td>0.038704</td>\n",
       "      <td>0.042660</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_id  product_id  ben_soliman_price  final_min_price  final_max_price  \\\n",
       "0        702         3.0              258.5            255.0            279.0   \n",
       "1        702         9.0                NaN            835.4            838.6   \n",
       "2        702        10.0                NaN            272.0            288.0   \n",
       "4        702        14.0              465.0            461.5            477.0   \n",
       "5        702        17.0              604.0            596.5            603.5   \n",
       "\n",
       "   final_mod_price  final_true_min  final_true_max  min_scrapped  scrapped25  \\\n",
       "0            255.0           255.0           300.0    254.630005  254.957504   \n",
       "1            835.0           835.0           839.0           NaN         NaN   \n",
       "2            270.0           270.0           290.0           NaN         NaN   \n",
       "4            477.0           460.0           477.0           NaN         NaN   \n",
       "5            600.0           595.0           605.0    598.500000  598.500000   \n",
       "\n",
       "   ...  percentile_50  percentile_75  maximum  below_market  market_min  \\\n",
       "0  ...     255.448753     256.580002    279.0      0.050898    0.053320   \n",
       "1  ...     837.000000     838.700000    839.0      0.018123    0.019299   \n",
       "2  ...     280.000000     288.500000    290.0      0.025238    0.030653   \n",
       "4  ...     463.250000     468.000000    477.0      0.022650    0.028316   \n",
       "5  ...     600.000000     603.750000    605.0      0.018424    0.022548   \n",
       "\n",
       "   market_25  market_50  market_75  market_max  above_market  \n",
       "0   0.054655   0.056355   0.060515    0.136011      0.138019  \n",
       "1   0.019651   0.021643   0.023626    0.023975      0.025137  \n",
       "2   0.036009   0.065273   0.092812    0.097505      0.102149  \n",
       "4   0.030687   0.035133   0.044926    0.062946      0.068156  \n",
       "5   0.026638   0.030693   0.036714    0.038704      0.042660  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Convert prices to margins (on market_data) - FINALIZE market_data processing\n",
    "# =============================================================================\n",
    "\n",
    "market_data['below_market'] = (market_data['below_market'] - market_data['wac_p']) / market_data['below_market']\n",
    "market_data['market_min'] = (market_data['minimum'] - market_data['wac_p']) / market_data['minimum']\n",
    "market_data['market_25'] = (market_data['percentile_25'] - market_data['wac_p']) / market_data['percentile_25']\n",
    "market_data['market_50'] = (market_data['percentile_50'] - market_data['wac_p']) / market_data['percentile_50']\n",
    "market_data['market_75'] = (market_data['percentile_75'] - market_data['wac_p']) / market_data['percentile_75']\n",
    "market_data['market_max'] = (market_data['maximum'] - market_data['wac_p']) / market_data['maximum']\n",
    "market_data['above_market'] = (market_data['above_market'] - market_data['wac_p']) / market_data['above_market']\n",
    "\n",
    "# Select only the market-related columns to merge later\n",
    "market_columns = [\n",
    "    'cohort_id', 'product_id',\n",
    "    # Market Prices (raw)\n",
    "    'ben_soliman_price', \n",
    "    'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped',\n",
    "    # Price Percentiles\n",
    "    'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum',\n",
    "    # Margin Tiers\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market'\n",
    "]\n",
    "market_data = market_data[[c for c in market_columns if c in market_data.columns]]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MARKET DATA PROCESSING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total processed market records: {len(market_data)}\")\n",
    "print(f\"\\nMarket data columns:\")\n",
    "print(\"  - Price columns: ben_soliman_price, final_min_price, final_max_price, etc.\")\n",
    "print(\"  - Percentiles: minimum, percentile_25, percentile_50, percentile_75, maximum\")\n",
    "print(\"  - Margin tiers: below_market, market_min, market_25, market_50, market_75, market_max, above_market\")\n",
    "print(f\"\\nSample processed market data:\")\n",
    "market_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART B: Build Main pricing_data DataFrame\n",
    "Start with df_product_base (all our SKUs) and LEFT JOIN the processed market_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building main pricing_data DataFrame...\n",
      "  Step 1: Starting with product base (all SKUs)...\n",
      "     Product base: 101742 records\n",
      "  Step 2: Adding warehouse mapping...\n",
      "     After warehouse mapping: 85906 records\n",
      "  Step 3: Left joining processed market data...\n",
      "     After market data join: 85906 records\n",
      "  Step 4: Left joining supporting data...\n",
      "\n",
      "============================================================\n",
      "PRICING DATA COMPLETE\n",
      "============================================================\n",
      "Total records: 64409\n",
      "\n",
      "Records with market data: 12329\n",
      "Records without market data: 52080\n",
      "\n",
      "Records with sales (nmv > 0): 20612\n",
      "Records without sales (nmv = 0): 43797\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>region</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>sku</th>\n",
       "      <th>brand</th>\n",
       "      <th>cat</th>\n",
       "      <th>wac1</th>\n",
       "      <th>wac_p</th>\n",
       "      <th>...</th>\n",
       "      <th>market_min</th>\n",
       "      <th>market_25</th>\n",
       "      <th>market_50</th>\n",
       "      <th>market_75</th>\n",
       "      <th>market_max</th>\n",
       "      <th>above_market</th>\n",
       "      <th>std</th>\n",
       "      <th>avg_margin</th>\n",
       "      <th>target_margin</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>700</td>\n",
       "      <td>146</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>1</td>\n",
       "      <td>Mostorod</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td> </td>\n",
       "      <td></td>\n",
       "      <td>196.985811</td>\n",
       "      <td>178.938909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031454</td>\n",
       "      <td>0.063637</td>\n",
       "      <td>0.090527</td>\n",
       "      <td>0.121772</td>\n",
       "      <td>0.147910</td>\n",
       "      <td>0.147957</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.057592</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703</td>\n",
       "      <td>10459</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>337</td>\n",
       "      <td>El-Mahala</td>\n",
       "      <td>HD-     - 7 </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>47.500000</td>\n",
       "      <td>46.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.056460</td>\n",
       "      <td>0.060052</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>700</td>\n",
       "      <td>75</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>1</td>\n",
       "      <td>Mostorod</td>\n",
       "      <td>  - 1 </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>192.500001</td>\n",
       "      <td>188.650001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054386</td>\n",
       "      <td>0.061443</td>\n",
       "      <td>0.070666</td>\n",
       "      <td>0.088647</td>\n",
       "      <td>0.101667</td>\n",
       "      <td>0.101717</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>0.054424</td>\n",
       "      <td>0.059104</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>702</td>\n",
       "      <td>7708</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>797</td>\n",
       "      <td>Khorshed Alex</td>\n",
       "      <td>   - 350 </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>164.363523</td>\n",
       "      <td>154.286761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.070562</td>\n",
       "      <td>0.071121</td>\n",
       "      <td>0.075574</td>\n",
       "      <td>0.076127</td>\n",
       "      <td>0.079618</td>\n",
       "      <td>0.015011</td>\n",
       "      <td>0.054188</td>\n",
       "      <td>0.063424</td>\n",
       "      <td>381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>704</td>\n",
       "      <td>23994</td>\n",
       "      <td>Delta East</td>\n",
       "      <td>339</td>\n",
       "      <td>Mansoura FC</td>\n",
       "      <td>     5 - 72 </td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "      <td>398.629030</td>\n",
       "      <td>367.006982</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.054346</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>506.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_id  product_id      region  warehouse_id      warehouse  \\\n",
       "0        700         146       Cairo             1       Mostorod   \n",
       "1        703       10459  Delta West           337      El-Mahala   \n",
       "3        700          75       Cairo             1       Mostorod   \n",
       "4        702        7708  Alexandria           797  Khorshed Alex   \n",
       "5        704       23994  Delta East           339    Mansoura FC   \n",
       "\n",
       "                                             sku       brand           cat  \\\n",
       "0                         - 235                \n",
       "1  HD-     - 7                  \n",
       "3                               - 1                     \n",
       "4                      - 350                   \n",
       "5                5 - 72               \n",
       "\n",
       "         wac1       wac_p  ...  market_min  market_25  market_50  market_75  \\\n",
       "0  196.985811  178.938909  ...    0.031454   0.063637   0.090527   0.121772   \n",
       "1   47.500000   46.075000  ...         NaN        NaN        NaN        NaN   \n",
       "3  192.500001  188.650001  ...    0.054386   0.061443   0.070666   0.088647   \n",
       "4  164.363523  154.286761  ...    0.061896   0.070562   0.071121   0.075574   \n",
       "5  398.629030  367.006982  ...         NaN        NaN        NaN        NaN   \n",
       "\n",
       "   market_max  above_market       std  avg_margin  target_margin  group  \n",
       "0    0.147910      0.147957  0.010679    0.057592       0.058000  445.0  \n",
       "1         NaN           NaN  0.010724    0.056460       0.060052  107.0  \n",
       "3    0.101667      0.101717  0.006324    0.054424       0.059104    NaN  \n",
       "4    0.076127      0.079618  0.015011    0.054188       0.063424  381.0  \n",
       "5         NaN           NaN  0.005394    0.054346       0.070000  506.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PART B: Build Main pricing_data DataFrame from df_product_base\n",
    "# =============================================================================\n",
    "print(\"Building main pricing_data DataFrame...\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Start with df_product_base as the MAIN dataframe (all our SKUs)\n",
    "# =============================================================================\n",
    "print(\"  Step 1: Starting with product base (all SKUs)...\")\n",
    "pricing_data = df_product_base.copy()\n",
    "print(f\"     Product base: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Add warehouse mapping (warehouse_id and warehouse name)\n",
    "# =============================================================================\n",
    "print(\"  Step 2: Adding warehouse mapping...\")\n",
    "warehouse_df = get_warehouse_df()\n",
    "pricing_data = pricing_data.merge(\n",
    "    warehouse_df[['cohort_id', 'warehouse_id', 'warehouse']], \n",
    "    on='cohort_id'\n",
    ")\n",
    "print(f\"     After warehouse mapping: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 3: LEFT JOIN processed market_data\n",
    "# =============================================================================\n",
    "print(\"  Step 3: Left joining processed market data...\")\n",
    "pricing_data = pricing_data.merge(\n",
    "    market_data, \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "print(f\"     After market data join: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 4: LEFT JOIN supporting data (sales, margins, targets, groups)\n",
    "# =============================================================================\n",
    "print(\"  Step 4: Left joining supporting data...\")\n",
    "\n",
    "# Merge sales data (nmv only)\n",
    "pricing_data = pricing_data.merge(\n",
    "    df_sales[['cohort_id', 'product_id', 'nmv']], \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "pricing_data['nmv'] = pricing_data['nmv'].fillna(0)\n",
    "\n",
    "# Merge margin statistics (by cohort_id + product_id)\n",
    "pricing_data = pricing_data.merge(df_margin_stats, on=['cohort_id', 'product_id'], how='left')\n",
    "\n",
    "# Merge target margins (by brand + cat)\n",
    "pricing_data = pricing_data.merge(df_targets, on=['brand', 'cat'], how='left')\n",
    "pricing_data['target_margin'] = pricing_data['target_bm'].fillna(pricing_data['cat_target_margin']).fillna(0)\n",
    "pricing_data = pricing_data.drop(columns=['target_bm', 'cat_target_margin'], errors='ignore')\n",
    "\n",
    "# Fill NaN values with defaults\n",
    "pricing_data['std'] = pricing_data['std'].fillna(0.01)\n",
    "pricing_data['avg_margin'] = pricing_data['avg_margin'].fillna(0)\n",
    "\n",
    "# Merge product groups\n",
    "pricing_data = pricing_data.merge(df_groups, on='product_id', how='left')\n",
    "\n",
    "# =============================================================================\n",
    "# Step 5: Calculate current margin\n",
    "# =============================================================================\n",
    "pricing_data['current_margin'] = (pricing_data['current_price'] - pricing_data['wac_p']) / pricing_data['current_price']\n",
    "\n",
    "# Remove duplicates\n",
    "pricing_data = pricing_data.drop_duplicates(subset=['cohort_id', 'product_id'])\n",
    "\n",
    "# =============================================================================\n",
    "# Reorder columns\n",
    "# =============================================================================\n",
    "final_columns = [\n",
    "    # Product Base Info\n",
    "    'cohort_id', 'product_id', 'region', 'warehouse_id', 'warehouse', 'sku', 'brand', 'cat',\n",
    "    # Cost & Price\n",
    "    'wac1', 'wac_p', 'current_price', 'current_margin',\n",
    "    # Sales\n",
    "    'nmv',\n",
    "    # Market Prices (raw)\n",
    "    'ben_soliman_price', \n",
    "    'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped',\n",
    "    # Price Percentiles\n",
    "    'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum',\n",
    "    # Margin Tiers\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market',\n",
    "    # Supporting Data\n",
    "    'std', 'avg_margin', 'target_margin', 'group'\n",
    "]\n",
    "pricing_data = pricing_data[[c for c in final_columns if c in pricing_data.columns]]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICING DATA COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(pricing_data)}\")\n",
    "print(f\"\\nRecords with market data: {len(pricing_data[~pricing_data['minimum'].isna()])}\")\n",
    "print(f\"Records without market data: {len(pricing_data[pricing_data['minimum'].isna()])}\")\n",
    "print(f\"\\nRecords with sales (nmv > 0): {len(pricing_data[pricing_data['nmv'] > 0])}\")\n",
    "print(f\"Records without sales (nmv = 0): {len(pricing_data[pricing_data['nmv'] == 0])}\")\n",
    "print(f\"\\nSample data:\")\n",
    "pricing_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discount Analysis - Price & Margin After Discount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading discount data...\n",
      "Loaded 11370 discount records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Discount Query - Get discount percentage by warehouse and product\n",
    "# =============================================================================\n",
    "DISCOUNT_QUERY = f'''\n",
    "SELECT warehouse_id, product_id, total_discount/total_nmv AS discount_perc\n",
    "FROM (\n",
    "    SELECT  \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        SUM(pso.total_price) AS total_nmv,\n",
    "        SUM((ITEM_QUANTITY_DISCOUNT_VALUE * pso.purchased_item_count) + \n",
    "            (ITEM_DISCOUNT_VALUE * pso.purchased_item_count)) AS total_discount\n",
    "    FROM product_sales_order pso \n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1 \n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY ALL\n",
    ")\n",
    "WHERE total_nmv > 0\n",
    "'''\n",
    "\n",
    "# Execute discount query\n",
    "print(\"Loading discount data...\")\n",
    "df_discount = query_snowflake(DISCOUNT_QUERY)\n",
    "df_discount = convert_to_numeric(df_discount)\n",
    "print(f\"Loaded {len(df_discount)} discount records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pricing_with_discount DataFrame...\n",
      "\n",
      "============================================================\n",
      "PRICING WITH DISCOUNT DATA COMPLETE\n",
      "============================================================\n",
      "Total records: 64409\n",
      "Records with discount (discount_perc > 0): 3273\n",
      "Records without discount: 61136\n",
      "\n",
      "New columns added:\n",
      "  - discount_perc: discount percentage from sales\n",
      "  - price_after_discount: current_price * (1 - discount_perc)\n",
      "  - margin_after_discount: (price_after_discount - wac_p) / price_after_discount\n",
      "\n",
      "Sample data with discounts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>current_price</th>\n",
       "      <th>current_margin</th>\n",
       "      <th>discount_perc</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>margin_after_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>190.00</td>\n",
       "      <td>0.058216</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>189.929576</td>\n",
       "      <td>0.057867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>201.00</td>\n",
       "      <td>0.061443</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>199.884731</td>\n",
       "      <td>0.056206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2879</td>\n",
       "      <td>797</td>\n",
       "      <td>809.00</td>\n",
       "      <td>0.066121</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>803.822400</td>\n",
       "      <td>0.060106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13498</td>\n",
       "      <td>236</td>\n",
       "      <td>48.50</td>\n",
       "      <td>0.091937</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>48.197219</td>\n",
       "      <td>0.086233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6494</td>\n",
       "      <td>236</td>\n",
       "      <td>570.75</td>\n",
       "      <td>0.046584</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>569.780761</td>\n",
       "      <td>0.044962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3258</td>\n",
       "      <td>1</td>\n",
       "      <td>148.50</td>\n",
       "      <td>0.052897</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>148.181441</td>\n",
       "      <td>0.050860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>470</td>\n",
       "      <td>236</td>\n",
       "      <td>843.25</td>\n",
       "      <td>0.013112</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>842.490673</td>\n",
       "      <td>0.012222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1163</td>\n",
       "      <td>797</td>\n",
       "      <td>86.75</td>\n",
       "      <td>0.048238</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>85.249200</td>\n",
       "      <td>0.031483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8926</td>\n",
       "      <td>1</td>\n",
       "      <td>466.50</td>\n",
       "      <td>0.054963</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>465.930589</td>\n",
       "      <td>0.053808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2424</td>\n",
       "      <td>703</td>\n",
       "      <td>172.50</td>\n",
       "      <td>0.045483</td>\n",
       "      <td>0.002331</td>\n",
       "      <td>172.097898</td>\n",
       "      <td>0.043253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  current_price  current_margin  discount_perc  \\\n",
       "0          146             1         190.00        0.058216       0.000371   \n",
       "2           75             1         201.00        0.061443       0.005549   \n",
       "5         2879           797         809.00        0.066121       0.006400   \n",
       "6        13498           236          48.50        0.091937       0.006243   \n",
       "8         6494           236         570.75        0.046584       0.001698   \n",
       "15        3258             1         148.50        0.052897       0.002145   \n",
       "18         470           236         843.25        0.013112       0.000900   \n",
       "19        1163           797          86.75        0.048238       0.017300   \n",
       "26        8926             1         466.50        0.054963       0.001221   \n",
       "27        2424           703         172.50        0.045483       0.002331   \n",
       "\n",
       "    price_after_discount  margin_after_discount  \n",
       "0             189.929576               0.057867  \n",
       "2             199.884731               0.056206  \n",
       "5             803.822400               0.060106  \n",
       "6              48.197219               0.086233  \n",
       "8             569.780761               0.044962  \n",
       "15            148.181441               0.050860  \n",
       "18            842.490673               0.012222  \n",
       "19             85.249200               0.031483  \n",
       "26            465.930589               0.053808  \n",
       "27            172.097898               0.043253  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Create pricing_with_discount DataFrame\n",
    "# =============================================================================\n",
    "print(\"Creating pricing_with_discount DataFrame...\")\n",
    "\n",
    "# Copy pricing_data\n",
    "pricing_with_discount = pricing_data.copy()\n",
    "\n",
    "# Merge discount data (by warehouse_id + product_id)\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_discount[['warehouse_id', 'product_id', 'discount_perc']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing discount_perc with 0 (no discount)\n",
    "pricing_with_discount['discount_perc'] = pricing_with_discount['discount_perc'].fillna(0)\n",
    "\n",
    "# =============================================================================\n",
    "# Calculate price and margin after discount\n",
    "# =============================================================================\n",
    "# Price after discount = current_price * (1 - discount_perc)\n",
    "pricing_with_discount['price_after_discount'] = (\n",
    "    pricing_with_discount['current_price'] * (1 - pricing_with_discount['discount_perc'])\n",
    ")\n",
    "\n",
    "# Margin after discount = (price_after_discount - wac_p) / price_after_discount\n",
    "pricing_with_discount['margin_after_discount'] = (\n",
    "    (pricing_with_discount['price_after_discount'] - pricing_with_discount['wac_p']) / \n",
    "    pricing_with_discount['price_after_discount']\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICING WITH DISCOUNT DATA COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(pricing_with_discount)}\")\n",
    "print(f\"Records with discount (discount_perc > 0): {len(pricing_with_discount[pricing_with_discount['discount_perc'] > 0])}\")\n",
    "print(f\"Records without discount: {len(pricing_with_discount[pricing_with_discount['discount_perc'] == 0])}\")\n",
    "print(f\"\\nNew columns added:\")\n",
    "print(\"  - discount_perc: discount percentage from sales\")\n",
    "print(\"  - price_after_discount: current_price * (1 - discount_perc)\")\n",
    "print(\"  - margin_after_discount: (price_after_discount - wac_p) / price_after_discount\")\n",
    "print(f\"\\nSample data with discounts:\")\n",
    "pricing_with_discount[pricing_with_discount['discount_perc'] > 0][\n",
    "    ['product_id', 'warehouse_id', 'current_price', 'current_margin', \n",
    "     'discount_perc', 'price_after_discount', 'margin_after_discount']\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PRICE POSITION ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Price Position Distribution:\n",
      "price_position\n",
      "No Market Data    52080\n",
      "At 50th            2511\n",
      "At 75th            2000\n",
      "At Max             1887\n",
      "At 25th            1841\n",
      "Below Market       1422\n",
      "At Min             1275\n",
      "Above Market       1241\n",
      "Below Min           152\n",
      "\n",
      "Price Position Percentages:\n",
      "price_position\n",
      "No Market Data    80.86%\n",
      "At 50th             3.9%\n",
      "At 75th            3.11%\n",
      "At Max             2.93%\n",
      "At 25th            2.86%\n",
      "Below Market       2.21%\n",
      "At Min             1.98%\n",
      "Above Market       1.93%\n",
      "Below Min          0.24%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Sample data with price position:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>current_price</th>\n",
       "      <th>discount_perc</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>price_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>190.00</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>189.929576</td>\n",
       "      <td>184.750000</td>\n",
       "      <td>210.00</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10459</td>\n",
       "      <td>337</td>\n",
       "      <td>HD-     - 7 </td>\n",
       "      <td>48.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>  - 1 </td>\n",
       "      <td>201.00</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>199.884731</td>\n",
       "      <td>199.500000</td>\n",
       "      <td>210.00</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7708</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 350 </td>\n",
       "      <td>167.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>164.466667</td>\n",
       "      <td>167.00</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23994</td>\n",
       "      <td>339</td>\n",
       "      <td>     5 - 72 </td>\n",
       "      <td>389.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>389.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2879</td>\n",
       "      <td>797</td>\n",
       "      <td>    4  - 2.2 </td>\n",
       "      <td>809.00</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>803.822400</td>\n",
       "      <td>779.422748</td>\n",
       "      <td>840.00</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13498</td>\n",
       "      <td>236</td>\n",
       "      <td>      4 ...</td>\n",
       "      <td>48.50</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>48.197219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3979</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 50 </td>\n",
       "      <td>37.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6494</td>\n",
       "      <td>236</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>570.75</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>569.780761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24378</td>\n",
       "      <td>337</td>\n",
       "      <td>   750  750 </td>\n",
       "      <td>149.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>149.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12142</td>\n",
       "      <td>236</td>\n",
       "      <td>    - 650 </td>\n",
       "      <td>390.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>390.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6266</td>\n",
       "      <td>797</td>\n",
       "      <td>    - 125 </td>\n",
       "      <td>47.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.250000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>48.00</td>\n",
       "      <td>At 25th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3976</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 20 </td>\n",
       "      <td>18.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7120</td>\n",
       "      <td>632</td>\n",
       "      <td>   12  - 14 </td>\n",
       "      <td>102.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>101.850000</td>\n",
       "      <td>103.12</td>\n",
       "      <td>At 50th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11081</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 70 </td>\n",
       "      <td>84.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>84.750000</td>\n",
       "      <td>73.518968</td>\n",
       "      <td>85.00</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "0          146             1   \n",
       "1        10459           337   \n",
       "2           75             1   \n",
       "3         7708           797   \n",
       "4        23994           339   \n",
       "5         2879           797   \n",
       "6        13498           236   \n",
       "7         3979           797   \n",
       "8         6494           236   \n",
       "9        24378           337   \n",
       "10       12142           236   \n",
       "11        6266           797   \n",
       "12        3976           797   \n",
       "13        7120           632   \n",
       "14       11081           339   \n",
       "\n",
       "                                                  sku  current_price  \\\n",
       "0                              - 235          190.00   \n",
       "1       HD-     - 7           48.00   \n",
       "2                                    - 1          201.00   \n",
       "3                           - 350          167.00   \n",
       "4                     5 - 72          389.50   \n",
       "5                4  - 2.2          809.00   \n",
       "6         4 ...          48.50   \n",
       "7                            - 50           37.25   \n",
       "8                                 - 700          570.75   \n",
       "9                       750  750          149.25   \n",
       "10                          - 650          390.50   \n",
       "11                            - 125           47.25   \n",
       "12                           - 20           18.00   \n",
       "13                 12  - 14          102.50   \n",
       "14                       - 70           84.75   \n",
       "\n",
       "    discount_perc  price_after_discount     minimum  maximum  price_position  \n",
       "0        0.000371            189.929576  184.750000   210.00          At Min  \n",
       "1        0.000000             48.000000         NaN      NaN  No Market Data  \n",
       "2        0.005549            199.884731  199.500000   210.00          At Min  \n",
       "3        0.000000            167.000000  164.466667   167.00          At Max  \n",
       "4        0.000000            389.500000         NaN      NaN  No Market Data  \n",
       "5        0.006400            803.822400  779.422748   840.00          At Min  \n",
       "6        0.006243             48.197219         NaN      NaN  No Market Data  \n",
       "7        0.000000             37.250000         NaN      NaN  No Market Data  \n",
       "8        0.001698            569.780761         NaN      NaN  No Market Data  \n",
       "9        0.000000            149.250000         NaN      NaN  No Market Data  \n",
       "10       0.000000            390.500000         NaN      NaN  No Market Data  \n",
       "11       0.000000             47.250000   47.000000    48.00         At 25th  \n",
       "12       0.000000             18.000000         NaN      NaN  No Market Data  \n",
       "13       0.000000            102.500000  101.850000   103.12         At 50th  \n",
       "14       0.000000             84.750000   73.518968    85.00         At 75th  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Price Position - Determine where price_after_discount falls in market tiers\n",
    "# =============================================================================\n",
    "\n",
    "def get_price_position(row):\n",
    "    \"\"\"Determine the price position relative to market price tiers.\"\"\"\n",
    "    price = row['price_after_discount']\n",
    "    wac = row['wac_p']\n",
    "    \n",
    "    # Check if we have market data (minimum price exists)\n",
    "    if pd.isna(row['minimum']) or pd.isna(price):\n",
    "        return \"No Market Data\"\n",
    "    \n",
    "    # Get price tiers\n",
    "    min_price = row['minimum']\n",
    "    p25 = row['percentile_25']\n",
    "    p50 = row['percentile_50']\n",
    "    p75 = row['percentile_75']\n",
    "    max_price = row['maximum']\n",
    "    \n",
    "    # Calculate below_market and above_market prices from margins\n",
    "    # margin = (price - wac) / price  =>  price = wac / (1 - margin)\n",
    "    below_market_margin = row['below_market']\n",
    "    above_market_margin = row['above_market']\n",
    "    \n",
    "    below_market_price = wac / (1 - below_market_margin) if below_market_margin < 1 else min_price\n",
    "    above_market_price = wac / (1 - above_market_margin) if above_market_margin < 1 else max_price\n",
    "    \n",
    "    # Determine position based on price tiers\n",
    "    if price < below_market_price:\n",
    "        return \"Below Market\"\n",
    "    elif price < min_price:\n",
    "        return \"Below Min\"\n",
    "    elif price < p25:\n",
    "        return \"At Min\"\n",
    "    elif price < p50:\n",
    "        return \"At 25th\"\n",
    "    elif price < p75:\n",
    "        return \"At 50th\"\n",
    "    elif price < max_price:\n",
    "        return \"At 75th\"\n",
    "    elif price < above_market_price:\n",
    "        return \"At Max\"\n",
    "    else:\n",
    "        return \"Above Market\"\n",
    "\n",
    "# Apply price position function\n",
    "pricing_with_discount['price_position'] = pricing_with_discount.apply(get_price_position, axis=1)\n",
    "\n",
    "# Summary of price positions\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICE POSITION ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nPrice Position Distribution:\")\n",
    "print(pricing_with_discount['price_position'].value_counts().to_string())\n",
    "print(f\"\\nPrice Position Percentages:\")\n",
    "print((pricing_with_discount['price_position'].value_counts(normalize=True) * 100).round(2).astype(str) + '%')\n",
    "\n",
    "# Sample data showing price position\n",
    "print(f\"\\nSample data with price position:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'current_price', 'discount_perc', \n",
    "     'price_after_discount', 'minimum', 'maximum', 'price_position']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stock data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1830778 stock records\n",
      "\n",
      "Stock data merged!\n",
      "Records with stock (stocks > 0): 13592\n",
      "Records without stock (stocks = 0): 50817\n",
      "\n",
      "Sample data with stocks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>stocks</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>price_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>1075</td>\n",
       "      <td>189.929576</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10459</td>\n",
       "      <td>337</td>\n",
       "      <td>HD-     - 7 </td>\n",
       "      <td>20</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>  - 1 </td>\n",
       "      <td>933</td>\n",
       "      <td>199.884731</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7708</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 350 </td>\n",
       "      <td>32</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23994</td>\n",
       "      <td>339</td>\n",
       "      <td>     5 - 72 </td>\n",
       "      <td>15</td>\n",
       "      <td>389.500000</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2879</td>\n",
       "      <td>797</td>\n",
       "      <td>    4  - 2.2 </td>\n",
       "      <td>24</td>\n",
       "      <td>803.822400</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13498</td>\n",
       "      <td>236</td>\n",
       "      <td>      4 ...</td>\n",
       "      <td>40</td>\n",
       "      <td>48.197219</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3979</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 50 </td>\n",
       "      <td>97</td>\n",
       "      <td>37.250000</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6494</td>\n",
       "      <td>236</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>96</td>\n",
       "      <td>569.780761</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24378</td>\n",
       "      <td>337</td>\n",
       "      <td>   750  750 </td>\n",
       "      <td>16</td>\n",
       "      <td>149.250000</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  warehouse_id  \\\n",
       "0         146             1   \n",
       "1       10459           337   \n",
       "2          75             1   \n",
       "3        7708           797   \n",
       "4       23994           339   \n",
       "5        2879           797   \n",
       "6       13498           236   \n",
       "7        3979           797   \n",
       "8        6494           236   \n",
       "9       24378           337   \n",
       "\n",
       "                                                 sku  stocks  \\\n",
       "0                             - 235     1075   \n",
       "1      HD-     - 7       20   \n",
       "2                                   - 1      933   \n",
       "3                          - 350       32   \n",
       "4                    5 - 72       15   \n",
       "5               4  - 2.2       24   \n",
       "6        4 ...      40   \n",
       "7                           - 50       97   \n",
       "8                                - 700       96   \n",
       "9                      750  750       16   \n",
       "\n",
       "   price_after_discount  price_position  \n",
       "0            189.929576          At Min  \n",
       "1             48.000000  No Market Data  \n",
       "2            199.884731          At Min  \n",
       "3            167.000000          At Max  \n",
       "4            389.500000  No Market Data  \n",
       "5            803.822400          At Min  \n",
       "6             48.197219  No Market Data  \n",
       "7             37.250000  No Market Data  \n",
       "8            569.780761  No Market Data  \n",
       "9            149.250000  No Market Data  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Stock Query - Get available stock by warehouse and product\n",
    "# =============================================================================\n",
    "STOCK_QUERY = '''\n",
    "SELECT \n",
    "    pw.warehouse_id,\n",
    "    pw.product_id,\n",
    "    pw.available_stock::INTEGER AS stocks\n",
    "FROM product_warehouse pw\n",
    "WHERE pw.warehouse_id NOT IN (6, 9, 10)\n",
    "    AND pw.is_basic_unit = 1\n",
    "'''\n",
    "\n",
    "# Execute stock query\n",
    "print(\"Loading stock data...\")\n",
    "df_stocks = query_snowflake(STOCK_QUERY)\n",
    "df_stocks = convert_to_numeric(df_stocks)\n",
    "print(f\"Loaded {len(df_stocks)} stock records\")\n",
    "\n",
    "# Merge stock data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_stocks[['warehouse_id', 'product_id', 'stocks']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing stocks with 0\n",
    "pricing_with_discount['stocks'] = pricing_with_discount['stocks'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"\\nStock data merged!\")\n",
    "print(f\"Records with stock (stocks > 0): {len(pricing_with_discount[pricing_with_discount['stocks'] > 0])}\")\n",
    "print(f\"Records without stock (stocks = 0): {len(pricing_with_discount[pricing_with_discount['stocks'] == 0])}\")\n",
    "print(f\"\\nSample data with stocks:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'stocks', 'price_after_discount', 'price_position']\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading zero demand SKUs...\n",
      "Loaded 4095 zero demand SKU records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Zero Demand Query - Identify SKUs with zero/low demand\n",
    "# =============================================================================\n",
    "ZERO_DEMAND_QUERY = f'''\n",
    "WITH last_oss AS (\n",
    "    SELECT product_id, warehouse_id, TIMESTAMP AS last_in_stock_day\n",
    "    FROM (\n",
    "        SELECT *, ROW_NUMBER() OVER(PARTITION BY product_id, warehouse_id ORDER BY TIMESTAMP DESC) AS rnk \n",
    "        FROM materialized_views.STOCK_DAY_CLOSE\n",
    "        WHERE AVAILABLE_STOCK = 0 \n",
    "            AND TIMESTAMP >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "        QUALIFY rnk = 1 \n",
    "    )\n",
    "),\n",
    "\n",
    "current_stocks AS (\n",
    "    SELECT product_id, warehouse_id, AVAILABLE_STOCK, activation\n",
    "    FROM PRODUCT_WAREHOUSE\n",
    "    WHERE IS_BASIC_UNIT = 1\n",
    "        AND CASE WHEN product_id = 1309 THEN packing_unit_id <> 23 ELSE TRUE END\n",
    "),\n",
    "\n",
    "prs AS (\n",
    "    SELECT DISTINCT \n",
    "        product_purchased_receipts.product_id,\n",
    "        purchased_receipts.warehouse_id,\n",
    "        purchased_receipts.date::DATE AS date,\n",
    "        product_purchased_receipts.purchased_item_count * product_purchased_receipts.basic_unit_count AS purchase_min_count\n",
    "    FROM product_purchased_receipts\n",
    "    JOIN purchased_receipts ON purchased_receipts.id = product_purchased_receipts.purchased_receipt_id\n",
    "    JOIN last_oss lo ON product_purchased_receipts.product_id = lo.product_id \n",
    "        AND lo.warehouse_id = purchased_receipts.warehouse_id \n",
    "        AND purchased_receipts.date > lo.last_in_stock_day \n",
    "    WHERE product_purchased_receipts.purchased_item_count <> 0\n",
    "        AND purchased_receipts.purchased_receipt_status_id IN (4, 5, 7)\n",
    "        AND purchased_receipts.date::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "),\n",
    "\n",
    "main AS (\n",
    "    SELECT \n",
    "        prs.product_id, \n",
    "        prs.warehouse_id, \n",
    "        MIN(date) AS first_order_date, \n",
    "        SUM(purchase_min_count) AS total_recieved, \n",
    "        cs.AVAILABLE_STOCK, \n",
    "        cs.activation\n",
    "    FROM prs \n",
    "    JOIN current_stocks cs ON cs.product_id = prs.product_id AND prs.warehouse_id = cs.warehouse_id\n",
    "    GROUP BY prs.product_id, prs.warehouse_id, cs.AVAILABLE_STOCK, cs.activation\n",
    "),\n",
    "\n",
    "sold_days AS (\n",
    "    SELECT product_id, warehouse_id, COUNT(DISTINCT o_date) AS sales_days\n",
    "    FROM (\n",
    "        SELECT DISTINCT\n",
    "            so.created_at::DATE AS o_date,\n",
    "            pso.warehouse_id,\n",
    "            pso.product_id,\n",
    "            SUM(pso.purchased_item_count * basic_unit_count) AS daily_qty\n",
    "        FROM product_sales_order pso\n",
    "        JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "        JOIN main m ON m.product_id = pso.product_id \n",
    "            AND m.warehouse_id = pso.warehouse_id \n",
    "            AND so.created_at::DATE >= m.first_order_date\n",
    "        WHERE so.created_at::DATE BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120 \n",
    "            AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "            AND so.sales_order_status_id NOT IN (7, 12)\n",
    "            AND so.channel IN ('telesales', 'retailer')\n",
    "            AND pso.purchased_item_count <> 0\n",
    "        GROUP BY o_date, pso.warehouse_id, pso.product_id\n",
    "    )\n",
    "    GROUP BY product_id, warehouse_id\n",
    ")\n",
    "\n",
    "SELECT DISTINCT warehouse_id, product_id\n",
    "FROM (\n",
    "    SELECT m.product_id, m.warehouse_id, m.first_order_date, m.activation,\n",
    "        COALESCE(sd.sales_days, 0) AS sales_days,\n",
    "        COALESCE(sd.sales_days, 0)::FLOAT / NULLIF((CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1) - m.first_order_date, 0) AS perc_days\n",
    "    FROM main m \n",
    "    LEFT JOIN sold_days sd ON sd.product_id = m.product_id AND sd.warehouse_id = m.warehouse_id\n",
    "    WHERE m.first_order_date < CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 10\n",
    ")\n",
    "WHERE perc_days <= 0.3\n",
    "    AND activation = 'true'\n",
    "'''\n",
    "\n",
    "# Execute zero demand query\n",
    "print(\"Loading zero demand SKUs...\")\n",
    "df_zero_demand = query_snowflake(ZERO_DEMAND_QUERY)\n",
    "df_zero_demand = convert_to_numeric(df_zero_demand)\n",
    "print(f\"Loaded {len(df_zero_demand)} zero demand SKU records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero demand flag added!\n",
      "SKUs flagged as zero demand: 2885\n",
      "SKUs with normal demand: 61524\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Zero Demand Flag to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Add a marker column to identify zero demand SKUs\n",
    "df_zero_demand['zero_demand'] = 1\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_zero_demand[['warehouse_id', 'product_id', 'zero_demand']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values with 0 (not zero demand)\n",
    "pricing_with_discount['zero_demand'] = pricing_with_discount['zero_demand'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"Zero demand flag added!\")\n",
    "print(f\"SKUs flagged as zero demand: {len(pricing_with_discount[pricing_with_discount['zero_demand'] == 1])}\")\n",
    "print(f\"SKUs with normal demand: {len(pricing_with_discount[pricing_with_discount['zero_demand'] == 0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OOS yesterday data...\n",
      "Loaded 1881253 OOS yesterday records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OOS Yesterday Query - Identify SKUs out of stock yesterday\n",
    "# =============================================================================\n",
    "OOS_YESTERDAY_QUERY = f'''\n",
    "SELECT DISTINCT product_id, warehouse_id,\n",
    "    CASE WHEN opening_stocks = 0 AND closing_stocks = 0 THEN 1\n",
    "         ELSE 0 \n",
    "    END AS oos_yesterday\n",
    "FROM (\n",
    "    SELECT \n",
    "        timestamp,\n",
    "        product_id,\n",
    "        warehouse_id, \n",
    "        AVAILABLE_STOCK AS closing_stocks,\n",
    "        LAG(AVAILABLE_STOCK) OVER (PARTITION BY product_id, warehouse_id ORDER BY TIMESTAMP) AS opening_stocks\n",
    "    FROM materialized_views.stock_day_close\n",
    "    WHERE timestamp::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 2\n",
    "    QUALIFY opening_stocks IS NOT NULL\n",
    ")\n",
    "WHERE oos_yesterday = 1\n",
    "'''\n",
    "\n",
    "# Execute OOS yesterday query\n",
    "print(\"Loading OOS yesterday data...\")\n",
    "df_oos_yesterday = query_snowflake(OOS_YESTERDAY_QUERY)\n",
    "df_oos_yesterday = convert_to_numeric(df_oos_yesterday)\n",
    "print(f\"Loaded {len(df_oos_yesterday)} OOS yesterday records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS yesterday flag added!\n",
      "SKUs out of stock yesterday: 50667\n",
      "SKUs in stock yesterday: 13742\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add OOS Yesterday Flag to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_oos_yesterday[['warehouse_id', 'product_id', 'oos_yesterday']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values with 0 (not OOS yesterday)\n",
    "pricing_with_discount['oos_yesterday'] = pricing_with_discount['oos_yesterday'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"OOS yesterday flag added!\")\n",
    "print(f\"SKUs out of stock yesterday: {len(pricing_with_discount[pricing_with_discount['oos_yesterday'] == 1])}\")\n",
    "print(f\"SKUs in stock yesterday: {len(pricing_with_discount[pricing_with_discount['oos_yesterday'] == 0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading running rate data (this may take a moment)...\n",
      "Loaded 22246 running rate records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Running Rate Query - Get in-stock running rate by warehouse and product\n",
    "# =============================================================================\n",
    "RUNNING_RATE_QUERY = f'''\n",
    "WITH params AS (\n",
    "    SELECT\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE AS run_date,\n",
    "        DATEADD(month, -3, CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE) AS history_start\n",
    "),\n",
    "\n",
    "-- Daily sales aggregation\n",
    "sales_base AS (\n",
    "    SELECT\n",
    "        pso.product_id,\n",
    "        pso.warehouse_id,\n",
    "        DATE_TRUNC('day', pso.created_at)::DATE AS date,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count) AS sold_units,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count * pso.item_price)\n",
    "            / NULLIF(SUM(pso.purchased_item_count * pso.basic_unit_count), 0) AS avg_selling_price,\n",
    "        COUNT(DISTINCT so.retailer_id) AS retailer_count\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON pso.sales_order_id = so.id\n",
    "    WHERE DATE_TRUNC('day', pso.created_at)::DATE >= (SELECT history_start FROM params)\n",
    "    GROUP BY 1, 2, 3\n",
    "),\n",
    "\n",
    "-- Stock daily metrics\n",
    "stock_daily AS (\n",
    "    SELECT\n",
    "        product_id,\n",
    "        warehouse_id,\n",
    "        DATE_TRUNC('day', TIMESTAMP)::DATE AS date,\n",
    "        MAX_BY(available_stock, TIMESTAMP) AS stock_closing,\n",
    "        24 * SUM(CASE WHEN activation = FALSE OR available_stock = 0 THEN 1 ELSE 0 END)::FLOAT \n",
    "            / NULLIF(COUNT(*), 0) AS oos_hours,\n",
    "        MAX(CASE WHEN activation = TRUE AND available_stock > 0 THEN 1 ELSE 0 END) AS in_stock_flag\n",
    "    FROM materialized_views.STOCK_SNAP_SHOTS_RECENT\n",
    "    WHERE product_id IS NOT NULL\n",
    "    GROUP BY product_id, warehouse_id, date\n",
    "),\n",
    "\n",
    "-- Join sales + stock + WAC (only in-stock days)\n",
    "base_data AS (\n",
    "    SELECT\n",
    "        sb.product_id,\n",
    "        sb.warehouse_id,\n",
    "        sb.date,\n",
    "        sb.sold_units,\n",
    "        sb.avg_selling_price,\n",
    "        sb.retailer_count,\n",
    "        sd.oos_hours,\n",
    "        sd.in_stock_flag,\n",
    "        ac.wac_p AS wac,\n",
    "        CASE WHEN DAYOFWEEKISO(sb.date) IN (5, 6) THEN 1 ELSE 0 END AS is_weekend\n",
    "    FROM sales_base sb\n",
    "    LEFT JOIN stock_daily sd ON sb.product_id = sd.product_id \n",
    "        AND sb.warehouse_id = sd.warehouse_id AND sb.date = sd.date\n",
    "    LEFT JOIN finance.ALL_COGS ac ON sb.product_id = ac.product_id \n",
    "        AND sb.date BETWEEN ac.from_date AND ac.to_date\n",
    "    WHERE sd.in_stock_flag = 1\n",
    "),\n",
    "\n",
    "-- Stats per SKU x Warehouse\n",
    "sku_wh_stats AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY sold_units) AS med_units,\n",
    "        PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY sold_units) AS pct95_units,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY retailer_count) AS med_retailers,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY \n",
    "            CASE WHEN avg_selling_price IS NULL OR avg_selling_price = 0 THEN 0 \n",
    "            ELSE (avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0) END\n",
    "        ) AS med_margin\n",
    "    FROM base_data\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Cap outliers and adjust for retailer spikes\n",
    "adjusted AS (\n",
    "    SELECT\n",
    "        b.product_id, b.warehouse_id, b.date, b.in_stock_flag, b.oos_hours, b.is_weekend,\n",
    "        b.avg_selling_price, b.wac, s.med_margin,\n",
    "        CASE \n",
    "            WHEN b.retailer_count > GREATEST(2, s.med_retailers * 2) \n",
    "                AND b.retailer_count > 0 AND s.med_retailers IS NOT NULL\n",
    "            THEN ROUND(LEAST(b.sold_units, s.pct95_units) * (s.med_retailers::FLOAT / NULLIF(b.retailer_count::FLOAT, 0)), 0)\n",
    "            ELSE LEAST(b.sold_units, s.pct95_units)\n",
    "        END AS units_adjusted\n",
    "    FROM base_data b\n",
    "    LEFT JOIN sku_wh_stats s ON b.product_id = s.product_id AND b.warehouse_id = s.warehouse_id\n",
    "),\n",
    "\n",
    "-- Apply weights (recency, stock availability, weekend, margin)\n",
    "weighted AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id, date, units_adjusted,\n",
    "        (\n",
    "            -- Recency weight\n",
    "            CASE WHEN date >= DATEADD(day, -21, (SELECT run_date FROM params)) THEN 1.5\n",
    "                 WHEN date >= DATEADD(day, -90, (SELECT run_date FROM params)) THEN 1.0\n",
    "                 ELSE 0.5 END\n",
    "            -- In-stock weight\n",
    "            * CASE WHEN in_stock_flag = 1 AND COALESCE(oos_hours, 0) < 12 THEN 1.4\n",
    "                   WHEN in_stock_flag = 1 AND COALESCE(oos_hours, 0) >= 12 THEN 0.9\n",
    "                   ELSE 0.6 END\n",
    "            -- Weekend weight\n",
    "            * CASE WHEN is_weekend = 1 THEN 0.7 ELSE 1.0 END\n",
    "            -- Margin weight\n",
    "            * CASE WHEN avg_selling_price IS NULL OR avg_selling_price = 0 OR med_margin IS NULL THEN 1.0\n",
    "                   WHEN ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) < med_margin\n",
    "                   THEN 1.0 + LEAST((med_margin - ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0))) * 2.0, 0.6)\n",
    "                   WHEN ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) > med_margin\n",
    "                   THEN 1.0 - LEAST((((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) - med_margin) * 2.0, 0.4)\n",
    "                   ELSE 1.0 END\n",
    "        ) AS final_weight\n",
    "    FROM adjusted\n",
    "    WHERE units_adjusted IS NOT NULL\n",
    "),\n",
    "\n",
    "-- Weighted average forecast\n",
    "forecast_base AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id,\n",
    "        SUM(units_adjusted * final_weight) / NULLIF(SUM(final_weight), 0) AS weighted_avg_units\n",
    "    FROM weighted\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Zero-sales last 4 days (with stock) exclusion flag\n",
    "last4_flag AS (\n",
    "    SELECT product_id, warehouse_id,\n",
    "        CASE WHEN COUNT(*) = 4 \n",
    "             AND SUM(CASE WHEN COALESCE(sold_units, 0) = 0 AND in_stock_flag = 1 THEN 1 ELSE 0 END) = 4\n",
    "        THEN 1 ELSE 0 END AS exclude_flag\n",
    "    FROM base_data\n",
    "    WHERE date >= DATEADD(day, -4, (SELECT run_date FROM params)) \n",
    "        AND date < (SELECT run_date FROM params)\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Zero sales excluded (in stock but no sales)\n",
    "zero_sales_excluded AS (\n",
    "    SELECT DISTINCT s.warehouse_id, s.product_id\n",
    "    FROM (\n",
    "        SELECT pw.warehouse_id, pw.product_id, SUM(pw.available_stock)::INT AS stocks\n",
    "        FROM product_warehouse pw\n",
    "        WHERE pw.warehouse_id NOT IN (6, 9, 10) AND pw.is_basic_unit = 1 AND pw.available_stock > 0\n",
    "        GROUP BY pw.warehouse_id, pw.product_id\n",
    "    ) s\n",
    "    LEFT JOIN (\n",
    "        SELECT pso.product_id, pso.warehouse_id, SUM(pso.total_price) AS nmv\n",
    "        FROM product_sales_order pso\n",
    "        JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "        WHERE so.created_at::date BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 5 \n",
    "            AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1\n",
    "            AND so.sales_order_status_id NOT IN (7, 12) AND so.channel IN ('telesales', 'retailer')\n",
    "            AND pso.purchased_item_count <> 0\n",
    "        GROUP BY pso.product_id, pso.warehouse_id\n",
    "    ) md ON md.product_id = s.product_id AND md.warehouse_id = s.warehouse_id\n",
    "    LEFT JOIN finance.all_cogs f ON f.product_id = s.product_id\n",
    "        AND f.from_date::date <= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "        AND f.to_date::date > CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "    LEFT JOIN (\n",
    "        SELECT pr.warehouse_id, ppr.product_id, SUM(ppr.final_price) AS total_prs\n",
    "        FROM product_purchased_receipts ppr\n",
    "        JOIN purchased_receipts pr ON pr.id = ppr.purchased_receipt_id\n",
    "        WHERE pr.date::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 4\n",
    "            AND pr.is_actual = 'true' AND pr.purchased_receipt_status_id IN (4, 5, 7)\n",
    "            AND ppr.purchased_item_count <> 0\n",
    "        GROUP BY pr.warehouse_id, ppr.product_id\n",
    "    ) prs ON prs.product_id = s.product_id AND prs.warehouse_id = s.warehouse_id\n",
    "    WHERE COALESCE(md.nmv, 0) = 0 \n",
    "        AND COALESCE(prs.total_prs, 0) < 0.7 * (COALESCE(f.wac_p, 0) * s.stocks)\n",
    "),\n",
    "\n",
    "-- First sale date for new products\n",
    "first_sale AS (\n",
    "    SELECT product_id, warehouse_id, MIN(date) AS first_sale_date\n",
    "    FROM base_data WHERE sold_units > 0\n",
    "    GROUP BY product_id, warehouse_id\n",
    ")\n",
    "\n",
    "-- Final output: running rate per warehouse/product\n",
    "SELECT\n",
    "    fb.warehouse_id,\n",
    "    fb.product_id,\n",
    "    CASE\n",
    "        WHEN l4.exclude_flag = 1 THEN 0\n",
    "        WHEN fs.first_sale_date >= DATEADD(day, -2, (SELECT run_date FROM params))\n",
    "        THEN GREATEST(CEIL(fb.weighted_avg_units), 1)\n",
    "        ELSE CEIL(fb.weighted_avg_units)\n",
    "    END AS In_stock_rr\n",
    "FROM forecast_base fb\n",
    "LEFT JOIN last4_flag l4 ON fb.product_id = l4.product_id AND fb.warehouse_id = l4.warehouse_id\n",
    "LEFT JOIN first_sale fs ON fb.product_id = fs.product_id AND fb.warehouse_id = fs.warehouse_id\n",
    "LEFT JOIN zero_sales_excluded zse ON fb.product_id = zse.product_id AND fb.warehouse_id = zse.warehouse_id\n",
    "WHERE zse.product_id IS NULL\n",
    "'''\n",
    "\n",
    "# Execute running rate query\n",
    "print(\"Loading running rate data (this may take a moment)...\")\n",
    "df_running_rate = query_snowflake(RUNNING_RATE_QUERY)\n",
    "df_running_rate = convert_to_numeric(df_running_rate)\n",
    "print(f\"Loaded {len(df_running_rate)} running rate records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Merge Running Rate and Calculate DOH (Days on Hand)\n",
    "# =============================================================================\n",
    "\n",
    "# Merge running rate data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_running_rate[['warehouse_id', 'product_id', 'in_stock_rr']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing running rate with 0\n",
    "pricing_with_discount['in_stock_rr'] = pricing_with_discount['in_stock_rr'].fillna(0)\n",
    "\n",
    "# Calculate DOH (Days on Hand) = stocks / in_stock_rr\n",
    "# Handle division by zero - if running rate is 0, DOH is infinite (use 999)\n",
    "pricing_with_discount['doh'] = np.select(\n",
    "    [\n",
    "        (pricing_with_discount['in_stock_rr'] > 0) & (pricing_with_discount['stocks'] > 0),\n",
    "        pricing_with_discount['stocks'] == 0\n",
    "    ],\n",
    "    [\n",
    "        pricing_with_discount['stocks'] / pricing_with_discount['in_stock_rr'],\n",
    "        0\n",
    "    ],\n",
    "    default=999\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading product classification data...\n",
      "Loaded 27454 product classification records\n",
      "\n",
      "Classification distribution:\n",
      "abc_class\n",
      "C    20788\n",
      "B     5505\n",
      "A     1161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Product Classification Query - ABC Classification based on order contribution\n",
    "# =============================================================================\n",
    "PRODUCT_CLASSIFICATION_QUERY = f'''\n",
    "WITH order_counts AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        COUNT(DISTINCT pso.sales_order_id) AS order_count\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 90\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id\n",
    "),\n",
    "\n",
    "warehouse_totals AS (\n",
    "    SELECT \n",
    "        warehouse_id,\n",
    "        SUM(order_count) AS total_orders\n",
    "    FROM order_counts\n",
    "    GROUP BY warehouse_id\n",
    "),\n",
    "\n",
    "ranked_products AS (\n",
    "    SELECT \n",
    "        oc.warehouse_id,\n",
    "        oc.product_id,\n",
    "        oc.order_count,\n",
    "        wt.total_orders,\n",
    "        oc.order_count::FLOAT / NULLIF(wt.total_orders, 0) AS contribution,\n",
    "        SUM(oc.order_count::FLOAT / NULLIF(wt.total_orders, 0)) \n",
    "            OVER (PARTITION BY oc.warehouse_id ORDER BY oc.order_count DESC \n",
    "                  ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_contribution\n",
    "    FROM order_counts oc\n",
    "    JOIN warehouse_totals wt ON oc.warehouse_id = wt.warehouse_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    warehouse_id,\n",
    "    product_id,\n",
    "    order_count,\n",
    "    contribution,\n",
    "    cumulative_contribution,\n",
    "    CASE \n",
    "        WHEN cumulative_contribution <= 0.4 THEN 'A'\n",
    "        WHEN cumulative_contribution <= 0.8 THEN 'B'\n",
    "        ELSE 'C'\n",
    "    END AS abc_class\n",
    "FROM ranked_products\n",
    "'''\n",
    "\n",
    "# Execute product classification query\n",
    "print(\"Loading product classification data...\")\n",
    "df_classification = query_snowflake(PRODUCT_CLASSIFICATION_QUERY)\n",
    "df_classification = convert_to_numeric(df_classification)\n",
    "print(f\"Loaded {len(df_classification)} product classification records\")\n",
    "print(f\"\\nClassification distribution:\")\n",
    "print(df_classification['abc_class'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC Classification added!\n",
      "\n",
      "Classification in pricing_with_discount:\n",
      "abc_class\n",
      "C    59925\n",
      "B     3708\n",
      "A      776\n",
      "\n",
      "Sample data with classification:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>order_count</th>\n",
       "      <th>contribution</th>\n",
       "      <th>abc_class</th>\n",
       "      <th>stocks</th>\n",
       "      <th>doh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>4319</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>A</td>\n",
       "      <td>1075</td>\n",
       "      <td>6.980519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10459</td>\n",
       "      <td>337</td>\n",
       "      <td>HD-     - 7 </td>\n",
       "      <td>84</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>  - 1 </td>\n",
       "      <td>6219</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>A</td>\n",
       "      <td>933</td>\n",
       "      <td>5.759259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7708</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 350 </td>\n",
       "      <td>89</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>B</td>\n",
       "      <td>32</td>\n",
       "      <td>10.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23994</td>\n",
       "      <td>339</td>\n",
       "      <td>     5 - 72 </td>\n",
       "      <td>17</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>C</td>\n",
       "      <td>15</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2879</td>\n",
       "      <td>797</td>\n",
       "      <td>    4  - 2.2 </td>\n",
       "      <td>61</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>C</td>\n",
       "      <td>24</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13498</td>\n",
       "      <td>236</td>\n",
       "      <td>      4 ...</td>\n",
       "      <td>257</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>B</td>\n",
       "      <td>40</td>\n",
       "      <td>4.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3979</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 50 </td>\n",
       "      <td>24</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>C</td>\n",
       "      <td>97</td>\n",
       "      <td>24.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6494</td>\n",
       "      <td>236</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>375</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>B</td>\n",
       "      <td>96</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24378</td>\n",
       "      <td>337</td>\n",
       "      <td>   750  750 </td>\n",
       "      <td>31</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>C</td>\n",
       "      <td>16</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12142</td>\n",
       "      <td>236</td>\n",
       "      <td>    - 650 </td>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6266</td>\n",
       "      <td>797</td>\n",
       "      <td>    - 125 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3976</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 20 </td>\n",
       "      <td>32</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>C</td>\n",
       "      <td>180</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7120</td>\n",
       "      <td>632</td>\n",
       "      <td>   12  - 14 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11081</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 70 </td>\n",
       "      <td>28</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>C</td>\n",
       "      <td>94</td>\n",
       "      <td>11.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "0          146             1   \n",
       "1        10459           337   \n",
       "2           75             1   \n",
       "3         7708           797   \n",
       "4        23994           339   \n",
       "5         2879           797   \n",
       "6        13498           236   \n",
       "7         3979           797   \n",
       "8         6494           236   \n",
       "9        24378           337   \n",
       "10       12142           236   \n",
       "11        6266           797   \n",
       "12        3976           797   \n",
       "13        7120           632   \n",
       "14       11081           339   \n",
       "\n",
       "                                                  sku  order_count  \\\n",
       "0                              - 235          4319   \n",
       "1       HD-     - 7            84   \n",
       "2                                    - 1          6219   \n",
       "3                           - 350            89   \n",
       "4                     5 - 72            17   \n",
       "5                4  - 2.2            61   \n",
       "6         4 ...          257   \n",
       "7                            - 50            24   \n",
       "8                                 - 700           375   \n",
       "9                       750  750            31   \n",
       "10                          - 650             1   \n",
       "11                            - 125             0   \n",
       "12                           - 20            32   \n",
       "13                 12  - 14             0   \n",
       "14                       - 70            28   \n",
       "\n",
       "    contribution abc_class  stocks         doh  \n",
       "0       0.004774         A    1075    6.980519  \n",
       "1       0.000383         B      20    5.000000  \n",
       "2       0.006874         A     933    5.759259  \n",
       "3       0.000559         B      32   10.666667  \n",
       "4       0.000064         C      15    5.000000  \n",
       "5       0.000383         C      24   12.000000  \n",
       "6       0.000470         B      40    4.444444  \n",
       "7       0.000151         C      97   24.250000  \n",
       "8       0.000686         B      96   16.000000  \n",
       "9       0.000141         C      16    8.000000  \n",
       "10      0.000002         C       0    0.000000  \n",
       "11      0.000000         C       0    0.000000  \n",
       "12      0.000201         C     180  999.000000  \n",
       "13      0.000000         C       0    0.000000  \n",
       "14      0.000106         C      94   11.750000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add ABC Classification to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge classification data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_classification[['warehouse_id', 'product_id', 'order_count', 'contribution', 'abc_class']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values - products without orders in last 3 months get class 'C'\n",
    "pricing_with_discount['order_count'] = pricing_with_discount['order_count'].fillna(0).astype(int)\n",
    "pricing_with_discount['contribution'] = pricing_with_discount['contribution'].fillna(0)\n",
    "pricing_with_discount['abc_class'] = pricing_with_discount['abc_class'].fillna('C')\n",
    "\n",
    "print(f\"ABC Classification added!\")\n",
    "print(f\"\\nClassification in pricing_with_discount:\")\n",
    "print(pricing_with_discount['abc_class'].value_counts().to_string())\n",
    "print(f\"\\nSample data with classification:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'order_count', 'contribution', 'abc_class', 'stocks', 'doh']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PO data...\n",
      "Loaded 15966 PO records\n",
      "\n",
      "Confirmation status distribution:\n",
      "confirmation_status\n",
      "yes    11782\n",
      "no      3778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PO (Purchase Order) Data Query - Last PO status and rejection count\n",
    "# =============================================================================\n",
    "PO_DATA_QUERY = '''\n",
    "WITH last_data AS (\n",
    "    SELECT product_id, warehouse_id, confirmation_status, PO_date::DATE AS last_po_date, ordered_qty\n",
    "    FROM (\n",
    "        SELECT \n",
    "            product_id,\n",
    "            Target_WAREHOUSE_ID AS warehouse_id,\n",
    "            confirmation_status,\n",
    "            created_at AS PO_date,\n",
    "            MIN_QUANTITY AS ordered_qty,\n",
    "            reason,\n",
    "            MAX(created_at) OVER (PARTITION BY product_id, Target_WAREHOUSE_ID) AS last_po\n",
    "        FROM retool.PO_INITIAL_PLAN\n",
    "        WHERE created_at::DATE >= CURRENT_DATE - 15 \n",
    "    ) x\n",
    "    WHERE last_po = PO_date\n",
    "),\n",
    "\n",
    "last_15_data AS (\n",
    "    SELECT \n",
    "        product_id,\n",
    "        target_WAREHOUSE_ID AS warehouse_id,\n",
    "        COUNT(DISTINCT CASE WHEN confirmation_status <> 'yes' THEN created_at END) AS no_last_15\n",
    "    FROM retool.PO_INITIAL_PLAN\n",
    "    WHERE created_at::DATE >= CURRENT_DATE - 15 \n",
    "    GROUP BY 1, 2\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    ld.product_id,\n",
    "    ld.warehouse_id,\n",
    "    ld.confirmation_status,\n",
    "    ld.last_po_date,\n",
    "    ld.ordered_qty,\n",
    "    COALESCE(lfd.no_last_15, 0) AS no_last_15\n",
    "FROM last_data ld \n",
    "LEFT JOIN last_15_data lfd \n",
    "    ON lfd.product_id = ld.product_id \n",
    "    AND lfd.warehouse_id = ld.warehouse_id\n",
    "'''\n",
    "\n",
    "# Execute PO data query using dwh_pg_query\n",
    "print(\"Loading PO data...\")\n",
    "df_po_data = setup_environment_2.dwh_pg_query(\n",
    "    PO_DATA_QUERY, \n",
    "    columns=['product_id', 'warehouse_id', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']\n",
    ")\n",
    "df_po_data.columns = df_po_data.columns.str.lower()\n",
    "df_po_data = convert_to_numeric(df_po_data)\n",
    "print(f\"Loaded {len(df_po_data)} PO records\")\n",
    "print(f\"\\nConfirmation status distribution:\")\n",
    "print(df_po_data['confirmation_status'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO data added!\n",
      "\n",
      "Records with PO data: 10422\n",
      "Records without PO data: 53987\n",
      "\n",
      "Sample data with PO info:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>confirmation_status</th>\n",
       "      <th>last_po_date</th>\n",
       "      <th>ordered_qty</th>\n",
       "      <th>no_last_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>252.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10459</td>\n",
       "      <td>337</td>\n",
       "      <td>HD-     - 7 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>  - 1 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>352.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7708</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 350 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23994</td>\n",
       "      <td>339</td>\n",
       "      <td>     5 - 72 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13498</td>\n",
       "      <td>236</td>\n",
       "      <td>      4 ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24378</td>\n",
       "      <td>337</td>\n",
       "      <td>   750  750 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>12142</td>\n",
       "      <td>236</td>\n",
       "      <td>    - 650 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11081</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 70 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3258</td>\n",
       "      <td>1</td>\n",
       "      <td>    - 5 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>470</td>\n",
       "      <td>236</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>990</td>\n",
       "      <td>401</td>\n",
       "      <td>     - 1 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9113</td>\n",
       "      <td>337</td>\n",
       "      <td>    20 + 4   ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6098</td>\n",
       "      <td>236</td>\n",
       "      <td>    4 - 100 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8926</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 540 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "0          146             1   \n",
       "1        10459           337   \n",
       "2           75             1   \n",
       "3         7708           797   \n",
       "4        23994           339   \n",
       "6        13498           236   \n",
       "9        24378           337   \n",
       "10       12142           236   \n",
       "14       11081           339   \n",
       "15        3258             1   \n",
       "18         470           236   \n",
       "21         990           401   \n",
       "22        9113           337   \n",
       "23        6098           236   \n",
       "26        8926             1   \n",
       "\n",
       "                                                  sku confirmation_status  \\\n",
       "0                              - 235                  yes   \n",
       "1       HD-     - 7                  yes   \n",
       "2                                    - 1                  yes   \n",
       "3                           - 350                   no   \n",
       "4                     5 - 72                   no   \n",
       "6         4 ...                 yes   \n",
       "9                       750  750                  yes   \n",
       "10                          - 650                   no   \n",
       "14                       - 70                  yes   \n",
       "15                           - 5                  yes   \n",
       "18                                 - 1                  yes   \n",
       "21                    - 1                  yes   \n",
       "22      20 + 4   ...                 yes   \n",
       "23                      4 - 100                  yes   \n",
       "26                               - 540                  yes   \n",
       "\n",
       "   last_po_date  ordered_qty  no_last_15  \n",
       "0    2026-01-11        252.0           1  \n",
       "1    2026-01-11         12.0           0  \n",
       "2    2026-01-11        352.0           0  \n",
       "3    2026-01-11          3.0           4  \n",
       "4    2026-01-11          6.0           3  \n",
       "6    2026-01-11         12.0           0  \n",
       "9    2026-01-06          3.0           0  \n",
       "10   2026-01-11          7.0           4  \n",
       "14   2026-01-05         96.0           0  \n",
       "15   2026-01-11         55.0           0  \n",
       "18   2026-01-11          2.0           0  \n",
       "21   2026-01-10          5.0           1  \n",
       "22   2026-01-11         12.0           1  \n",
       "23   2026-01-11         14.0           0  \n",
       "26   2026-01-08          3.0           0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add PO Data to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge PO data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_po_data[['warehouse_id', 'product_id', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values\n",
    "pricing_with_discount['ordered_qty'] = pricing_with_discount['ordered_qty'].fillna(0)\n",
    "pricing_with_discount['no_last_15'] = pricing_with_discount['no_last_15'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"PO data added!\")\n",
    "print(f\"\\nRecords with PO data: {len(pricing_with_discount[~pricing_with_discount['confirmation_status'].isna()])}\")\n",
    "print(f\"Records without PO data: {len(pricing_with_discount[pricing_with_discount['confirmation_status'].isna()])}\")\n",
    "print(f\"\\nSample data with PO info:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']\n",
    "].dropna(subset=['confirmation_status']).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
