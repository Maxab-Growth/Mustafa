{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction Module for Pricing & Offers System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import setup_environment_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region\n",
    "REGION = \"Egypt\"\n",
    "\n",
    "# Snowflake Warehouse\n",
    "WAREHOUSE = \"COMPUTE_WH\"\n",
    "\n",
    "# Date Variables\n",
    "from datetime import datetime, timedelta\n",
    "TODAY = datetime.now().date()\n",
    "YESTERDAY = TODAY - timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "setup_environment_2.initialize_env()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warehouse & Cohort Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warehouse Mapping: (region, warehouse_name, warehouse_id, cohort_id)\n",
    "WAREHOUSE_MAPPING = [\n",
    "    ('Cairo', 'Mostorod', 1, 700),\n",
    "    ('Giza', 'Barageel', 236, 701),\n",
    "    ('Giza', 'Sakkarah', 962, 701),\n",
    "    ('Delta West', 'El-Mahala', 337, 703),\n",
    "    ('Delta West', 'Tanta', 8, 703),\n",
    "    ('Delta East', 'Mansoura FC', 339, 704),\n",
    "    ('Delta East', 'Sharqya', 170, 704),\n",
    "    ('Upper Egypt', 'Assiut FC', 501, 1124),\n",
    "    ('Upper Egypt', 'Bani sweif', 401, 1126),\n",
    "    ('Upper Egypt', 'Menya Samalot', 703, 1123),\n",
    "    ('Upper Egypt', 'Sohag', 632, 1125),\n",
    "    ('Alexandria', 'Khorshed Alex', 797, 702),\n",
    "]\n",
    "\n",
    "# Region to Cohort Mapping\n",
    "REGION_COHORT_MAPPING = {\n",
    "    'Cairo': 700,\n",
    "    'Giza': 701,\n",
    "    'Delta West': 703,\n",
    "    'Delta East': 704,\n",
    "    'Upper Egypt': 1124,\n",
    "    'Alexandria': 702,\n",
    "}\n",
    "\n",
    "# All Cohort IDs\n",
    "COHORT_IDS = [700, 701, 702, 703, 704, 1123, 1124, 1125, 1126]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowflake Query Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_snowflake(query):\n",
    "    \"\"\"Execute a query on Snowflake and return results as DataFrame.\"\"\"\n",
    "    con = snowflake.connector.connect(\n",
    "        user=os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database=os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        data = cur.fetchall()\n",
    "        columns = [desc[0].lower() for desc in cur.description]  # Get column names from cursor\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "    except Exception as e:\n",
    "        print(f\"Snowflake Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snowflake_timezone():\n",
    "    \"\"\"Get the current timezone from Snowflake.\"\"\"\n",
    "    query = \"SHOW PARAMETERS LIKE 'TIMEZONE'\"\n",
    "    result = query_snowflake(query)\n",
    "    return result.value[0] if len(result) > 0 else \"UTC\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warehouse_df():\n",
    "    \"\"\"Get warehouse mapping as DataFrame.\"\"\"\n",
    "    return pd.DataFrame(\n",
    "        WAREHOUSE_MAPPING,\n",
    "        columns=['region', 'warehouse', 'warehouse_id', 'cohort_id']\n",
    "    )\n",
    "\n",
    "\n",
    "def get_cohort_by_region(region):\n",
    "    \"\"\"Get cohort ID for a given region.\"\"\"\n",
    "    return REGION_COHORT_MAPPING.get(region)\n",
    "\n",
    "\n",
    "def convert_to_numeric(df):\n",
    "    \"\"\"Convert DataFrame columns to numeric where possible.\"\"\"\n",
    "    df.columns = df.columns.str.lower()\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Snowflake Timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake timezone: America/Los_Angeles\n"
     ]
    }
   ],
   "source": [
    "TIMEZONE = get_snowflake_timezone()\n",
    "print(f\"Snowflake timezone: {TIMEZONE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Prices Extraction Queries\n",
    "Queries for external market price data:\n",
    "1. **Ben Soliman Prices** - Competitor reference prices\n",
    "2. **Marketplace Prices** - Min, Max, Mod prices from marketplace\n",
    "3. **Scrapped Data** - Competitor prices from scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. BEN SOLIMAN PRICES QUERY\n",
    "# =============================================================================\n",
    "BEN_SOLIMAN_QUERY = f'''\n",
    "WITH lower as (\n",
    "    select distinct product_id, sku, new_d*bs_price as ben_soliman_price, INJECTION_DATE\n",
    "    from (\n",
    "        select maxab_product_id as product_id, maxab_sku as sku, INJECTION_DATE, wac1, wac_p,\n",
    "            (bs_price/bs_unit_count) as bs_price, diff, cu_price,\n",
    "            case when p1 > 1 then child_quantity else 0 end as scheck,\n",
    "            round(p1/2)*2 as p1, p2,\n",
    "            case when (ROUND(p1 / scheck) * scheck) = 0 then p1 else (ROUND(p1 / scheck) * scheck) end as new_d\n",
    "        from (\n",
    "            select sm.*, wac1, wac_p, \n",
    "                abs((bs_price/bs_unit_count)-(wac_p*maxab_basic_unit_count))/(wac_p*maxab_basic_unit_count) as diff,\n",
    "                cpc.price as cu_price, pup.child_quantity,\n",
    "                round((cu_price/(bs_price/bs_unit_count))) as p1, \n",
    "                round(((bs_price/bs_unit_count)/cu_price)) as p2\n",
    "            from materialized_views.savvy_mapping sm \n",
    "            join finance.all_cogs f on f.product_id = sm.maxab_product_id \n",
    "                and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "            join PACKING_UNIT_PRODUCTS pu on pu.product_id = sm.maxab_product_id and pu.IS_BASIC_UNIT = 1 \n",
    "            join cohort_product_packing_units cpc on cpc.PRODUCT_PACKING_UNIT_ID = pu.id and cohort_id = 700 \n",
    "            join packing_unit_products pup on pup.product_id = sm.maxab_product_id and pup.is_basic_unit = 1  \n",
    "            where bs_price is not null \n",
    "                and INJECTION_DATE::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 5 \n",
    "                and diff > 0.3 and p1 > 1\n",
    "        )\n",
    "    )\n",
    "    qualify max(INJECTION_DATE) over(partition by product_id) = INJECTION_DATE\n",
    "),\n",
    "\n",
    "m_bs as (\n",
    "    select z.* from (\n",
    "        select maxab_product_id as product_id, maxab_sku as sku, avg(bs_final_price) as ben_soliman_price, INJECTION_DATE\n",
    "        from (\n",
    "            select *, row_number() over(partition by maxab_product_id order by diff) as rnk_2 \n",
    "            from (\n",
    "                select *, (bs_final_price-wac_p)/wac_p as diff_2 \n",
    "                from (\n",
    "                    select *, bs_price/maxab_basic_unit_count as bs_final_price \n",
    "                    from (\n",
    "                        select *, row_number() over(partition by maxab_product_id, maxab_pu order by diff) as rnk \n",
    "                        from (\n",
    "                            select *, max(INJECTION_DATE::date) over(partition by maxab_product_id, maxab_pu) as max_date\n",
    "                            from (\n",
    "                                select sm.*, wac1, wac_p, \n",
    "                                    abs(bs_price-(wac_p*maxab_basic_unit_count))/(wac_p*maxab_basic_unit_count) as diff \n",
    "                                from materialized_views.savvy_mapping sm \n",
    "                                join finance.all_cogs f on f.product_id = sm.maxab_product_id \n",
    "                                    and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "                                where bs_price is not null \n",
    "                                    and INJECTION_DATE::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 5 \n",
    "                                    and diff < 0.3\n",
    "                            )\n",
    "                            qualify max_date = INJECTION_DATE\n",
    "                        ) qualify rnk = 1 \n",
    "                    )\n",
    "                ) where diff_2 between -0.5 and 0.5 \n",
    "            ) qualify rnk_2 = 1 \n",
    "        ) group by all\n",
    "    ) z \n",
    "    join finance.all_cogs f on f.product_id = z.product_id \n",
    "        and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "    where ben_soliman_price between f.wac_p*0.8 and f.wac_p*1.3\n",
    ")\n",
    "\n",
    "select product_id, avg(ben_soliman_price) as ben_soliman_price\n",
    "from (\n",
    "    select * from (\n",
    "        select * from m_bs \n",
    "        union all\n",
    "        select * from lower\n",
    "    )\n",
    "    qualify max(INJECTION_DATE) over(partition by product_id) = INJECTION_DATE\n",
    ")\n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. MARKETPLACE PRICES QUERY (with region fallback)\n",
    "# =============================================================================\n",
    "MARKETPLACE_PRICES_QUERY = f'''\n",
    "WITH MP as (\n",
    "    select region, product_id,\n",
    "        min(min_price) as min_price, min(max_price) as max_price,\n",
    "        min(mod_price) as mod_price, min(true_min) as true_min, min(true_max) as true_max\n",
    "    from (\n",
    "        select mp.region, mp.product_id, mp.pu_id,\n",
    "            min_price/BASIC_UNIT_COUNT as min_price,\n",
    "            max_price/BASIC_UNIT_COUNT as max_price,\n",
    "            mod_price/BASIC_UNIT_COUNT as mod_price,\n",
    "            TRUE_MIN_PRICE/BASIC_UNIT_COUNT as true_min,\n",
    "            TRUE_MAX_PRICE/BASIC_UNIT_COUNT as true_max\n",
    "        from materialized_views.marketplace_prices mp \n",
    "        join packing_unit_products pup on pup.product_id = mp.product_id and pup.packing_unit_id = mp.pu_id\n",
    "        join finance.all_cogs f on f.product_id = mp.product_id \n",
    "            and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_date and f.to_date\n",
    "        where least(min_price, mod_price) between wac_p*0.9 and wac_p*1.3 \n",
    "    )\n",
    "    group by all \n",
    "),\n",
    "\n",
    "region_mapping AS (\n",
    "    SELECT * FROM (VALUES\n",
    "        ('Delta East', 'Delta West'), ('Delta West', 'Delta East'),\n",
    "        ('Alexandria', 'Cairo'), ('Alexandria', 'Giza'),\n",
    "        ('Upper Egypt', 'Cairo'), ('Upper Egypt', 'Giza'),\n",
    "        ('Cairo', 'Giza'), ('Giza', 'Cairo'),\n",
    "        ('Delta West', 'Cairo'), ('Delta East', 'Cairo'),\n",
    "        ('Delta West', 'Giza'), ('Delta East', 'Giza')\n",
    "    ) AS region_mapping(region, fallback_region)\n",
    "),\n",
    "\n",
    "all_regions as (\n",
    "    SELECT * FROM (VALUES\n",
    "        ('Cairo'), ('Giza'), ('Delta West'), ('Delta East'), ('Upper Egypt'), ('Alexandria')\n",
    "    ) AS x(region)\n",
    "),\n",
    "\n",
    "full_data as (\n",
    "    select products.id as product_id, ar.region\n",
    "    from products, all_regions ar\n",
    "    where activation = 'true'\n",
    ")\n",
    "\n",
    "select region, product_id,\n",
    "    min(final_min_price) as final_min_price, \n",
    "    min(final_max_price) as final_max_price,\n",
    "    min(final_mod_price) as final_mod_price, \n",
    "    min(final_true_min) as final_true_min,\n",
    "    min(final_true_max) as final_true_max\n",
    "from (\n",
    "    SELECT distinct w.region, w.product_id,\n",
    "        COALESCE(m1.min_price, m2.min_price) AS final_min_price,\n",
    "        COALESCE(m1.max_price, m2.max_price) AS final_max_price,\n",
    "        COALESCE(m1.mod_price, m2.mod_price) AS final_mod_price,\n",
    "        COALESCE(m1.true_min, m2.true_min) AS final_true_min,\n",
    "        COALESCE(m1.true_max, m2.true_max) AS final_true_max\n",
    "    FROM full_data w\n",
    "    LEFT JOIN MP m1 ON w.region = m1.region and w.product_id = m1.product_id\n",
    "    LEFT JOIN region_mapping rm ON w.region = rm.region\n",
    "    LEFT JOIN MP m2 ON rm.fallback_region = m2.region AND w.product_id = m2.product_id\n",
    ")\n",
    "where final_min_price is not null \n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. SCRAPPED DATA QUERY (Competitor prices from scraping)\n",
    "# =============================================================================\n",
    "SCRAPPED_DATA_QUERY = f'''\n",
    "select product_id, region,\n",
    "    MIN(market_price) AS min_scrapped,\n",
    "    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY market_price) AS scrapped25,\n",
    "    PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY market_price) AS scrapped50,\n",
    "    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY market_price) AS scrapped75,\n",
    "    MAX(market_price) AS max_scrapped\n",
    "from (\n",
    "    select distinct cmp.*, max(date) over(partition by region, cmp.product_id, competitor) as max_date\n",
    "    from MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES cmp\n",
    "    join finance.all_cogs f on f.product_id = cmp.product_id \n",
    "        and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_date and f.to_date \n",
    "    where date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 7 \n",
    "        and MARKET_PRICE between f.wac_p * 0.8 and wac_p * 1.3\n",
    "    qualify date = max_date \n",
    ")\n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional Data Queries (Sales, Groups, WAC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. PRODUCT BASE DATA QUERY (product_id, sku, brand, cat, wac1, wac_p, current_price)\n",
    "# =============================================================================\n",
    "PRODUCT_BASE_QUERY = f'''\n",
    "WITH skus_prices AS (\n",
    "    WITH local_prices AS (\n",
    "        SELECT  \n",
    "            CASE \n",
    "                WHEN cpu.cohort_id IN (700, 695) THEN 'Cairo'\n",
    "                WHEN cpu.cohort_id IN (701) THEN 'Giza'\n",
    "                WHEN cpu.cohort_id IN (704, 698) THEN 'Delta East'\n",
    "                WHEN cpu.cohort_id IN (703, 697) THEN 'Delta West'\n",
    "                WHEN cpu.cohort_id IN (696, 1123, 1124, 1125, 1126) THEN 'Upper Egypt'\n",
    "                WHEN cpu.cohort_id IN (702, 699) THEN 'Alexandria'\n",
    "            END AS region,\n",
    "            cohort_id,\n",
    "            pu.product_id,\n",
    "            pu.packing_unit_id,\n",
    "            pu.basic_unit_count,\n",
    "            AVG(cpu.price) AS price\n",
    "        FROM cohort_product_packing_units cpu\n",
    "        JOIN PACKING_UNIT_PRODUCTS pu ON pu.id = cpu.product_packing_unit_id\n",
    "        WHERE cpu.cohort_id IN (700,701,702,703,704,695,696,697,698,699,1123,1124,1125,1126)\n",
    "            AND cpu.created_at::date <> '2023-07-31'\n",
    "            AND cpu.is_customized = TRUE\n",
    "        GROUP BY ALL\n",
    "    ),\n",
    "    \n",
    "    live_prices AS (\n",
    "        SELECT \n",
    "            region, cohort_id, product_id, \n",
    "            pu_id AS packing_unit_id, \n",
    "            buc AS basic_unit_count, \n",
    "            NEW_PRICE AS price\n",
    "        FROM materialized_views.DBDP_PRICES\n",
    "        WHERE created_at = CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date\n",
    "            AND DATE_PART('hour', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::time) \n",
    "                BETWEEN SPLIT_PART(time_slot, '-', 1)::int AND (SPLIT_PART(time_slot, '-', 1)::int) + 1\n",
    "            AND cohort_id IN (700,701,702,703,704,695,696,697,698,699,1123,1124,1125,1126)\n",
    "    ),\n",
    "    \n",
    "    prices AS (\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT *, 1 AS priority FROM live_prices\n",
    "            UNION ALL\n",
    "            SELECT *, 2 AS priority FROM local_prices\n",
    "        )\n",
    "        QUALIFY ROW_NUMBER() OVER (PARTITION BY region, cohort_id, product_id, packing_unit_id ORDER BY priority) = 1\n",
    "    )\n",
    "    \n",
    "    SELECT region, cohort_id, product_id, price\n",
    "    FROM prices\n",
    "    WHERE basic_unit_count = 1\n",
    "        AND ((product_id = 1309 AND packing_unit_id = 2) OR (product_id <> 1309))\n",
    ")\n",
    "\n",
    "SELECT distinct\n",
    "    region, cohort_id, p.product_id,\n",
    "    CONCAT(products.name_ar, ' ', products.size, ' ', product_units.name_ar) AS sku,\n",
    "    b.name_ar AS brand,\n",
    "    cat.name_ar AS cat,\n",
    "    wac1, wac_p, p.price as current_price\n",
    "FROM skus_prices p\n",
    "JOIN finance.all_cogs c ON c.product_id = p.product_id \n",
    "    AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) BETWEEN c.from_date AND c.to_date\n",
    "JOIN products ON products.id = p.product_id\n",
    "JOIN categories cat ON cat.id = products.category_id\n",
    "JOIN brands b ON b.id = products.brand_id\n",
    "JOIN product_units ON product_units.id = products.unit_id\n",
    "WHERE wac1 > 0 AND wac_p > 0\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 5. SALES DATA QUERY (120-day NMV by cohort/product)\n",
    "# =============================================================================\n",
    "SALES_QUERY = f'''\n",
    "SELECT DISTINCT cpc.cohort_id, pso.product_id,\n",
    "    CONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "    brands.name_ar as brand, categories.name_ar as cat,\n",
    "    sum(pso.total_price) as nmv\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN COHORT_PRICING_CHANGES cpc ON cpc.id = pso.COHORT_PRICING_CHANGE_id\n",
    "JOIN products ON products.id = pso.product_id\n",
    "JOIN brands ON products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "WHERE so.created_at::date BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 120 \n",
    "    AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 1 \n",
    "    AND so.sales_order_status_id NOT IN (7, 12)\n",
    "    AND so.channel IN ('telesales', 'retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "    AND cpc.cohort_id IN (700,701,702,703,704,1123,1124,1125,1126)\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 6. MARGIN STATS QUERY (STD and average margins)  \n",
    "# =============================================================================\n",
    "MARGIN_STATS_QUERY = f'''\n",
    "select product_id, cohort_id, \n",
    "    (0.6*product_std) + (0.3*brand_std) + (0.1*cat_std) as std, \n",
    "    avg_margin\n",
    "from (\n",
    "    select product_id, cohort_id, \n",
    "        stddev(product_margin) as product_std, \n",
    "        stddev(brand_margin) as brand_std,\n",
    "        stddev(cat_margin) as cat_std, \n",
    "        avg(product_margin) as avg_margin\n",
    "    from (\n",
    "        select distinct product_id, order_date, cohort_id,\n",
    "            (nmv-cogs_p)/nmv as product_margin, \n",
    "            (brand_nmv-brand_cogs)/brand_nmv as brand_margin,\n",
    "            (cat_nmv-cat_cogs)/cat_nmv as cat_margin\n",
    "        from (\n",
    "            SELECT DISTINCT so.created_at::date as order_date, cpc.cohort_id, pso.product_id,\n",
    "                brands.name_ar as brand, categories.name_ar as cat,\n",
    "                sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs_p,\n",
    "                sum(pso.total_price) as nmv,\n",
    "                sum(nmv) over(partition by order_date, cat, brand) as brand_nmv,\n",
    "                sum(cogs_p) over(partition by order_date, cat, brand) as brand_cogs,\n",
    "                sum(nmv) over(partition by order_date, cat) as cat_nmv,\n",
    "                sum(cogs_p) over(partition by order_date, cat) as cat_cogs\n",
    "            FROM product_sales_order pso\n",
    "            JOIN sales_orders so ON so.id = pso.sales_order_id   \n",
    "            JOIN COHORT_PRICING_CHANGES cpc on cpc.id = pso.cohort_pricing_change_id\n",
    "            JOIN products on products.id = pso.product_id\n",
    "            JOIN brands on products.brand_id = brands.id \n",
    "            JOIN categories ON products.category_id = categories.id\n",
    "            JOIN finance.all_cogs f ON f.product_id = pso.product_id\n",
    "                AND f.from_date::date <= so.created_at::date AND f.to_date::date > so.created_at::date\n",
    "            WHERE so.created_at::date between \n",
    "                date_trunc('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 120) \n",
    "                and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date\n",
    "                AND so.sales_order_status_id not in (7,12)\n",
    "                AND so.channel IN ('telesales','retailer')\n",
    "                AND pso.purchased_item_count <> 0\n",
    "            GROUP BY ALL\n",
    "        )\n",
    "    ) group by all \n",
    ")\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 7. TARGET MARGINS QUERY\n",
    "# =============================================================================\n",
    "TARGET_MARGINS_QUERY = f'''\n",
    "WITH cat_brand_target as (\n",
    "    SELECT DISTINCT cat, brand, margin as target_bm\n",
    "    FROM performance.commercial_targets cplan\n",
    "    QUALIFY CASE \n",
    "        WHEN DATE_TRUNC('month', MAX(DATE) OVER()) = DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date) \n",
    "        THEN DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date)\n",
    "        ELSE DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - INTERVAL '1 month') \n",
    "    END = DATE_TRUNC('month', date)\n",
    "),\n",
    "cat_target as (\n",
    "    select cat, sum(target_bm * (target_nmv/cat_total)) as cat_target_margin\n",
    "    from (\n",
    "        select *, sum(target_nmv) over(partition by cat) as cat_total\n",
    "        from (\n",
    "            select cat, brand, avg(target_bm) as target_bm, sum(target_nmv) as target_nmv\n",
    "            from (\n",
    "                SELECT DISTINCT date, city as region, cat, brand, margin as target_bm, nmv as target_nmv\n",
    "                FROM performance.commercial_targets cplan\n",
    "                QUALIFY CASE \n",
    "                    WHEN DATE_TRUNC('month', MAX(DATE) OVER()) = DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date) \n",
    "                    THEN DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date)\n",
    "                    ELSE DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - INTERVAL '1 month') \n",
    "                END = DATE_TRUNC('month', date)\n",
    "            ) group by all\n",
    "        )\n",
    "    ) group by all \n",
    ")\n",
    "SELECT DISTINCT cbt.cat, cbt.brand, cbt.target_bm, ct.cat_target_margin\n",
    "FROM cat_brand_target cbt\n",
    "LEFT JOIN cat_target ct ON ct.cat = cbt.cat\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute All Queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Snowflake...\n",
      "  1. Loading Ben Soliman prices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 1525 Ben Soliman price records\n",
      "  2. Loading marketplace prices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 11267 marketplace price records\n",
      "  3. Loading scrapped data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 5115 scrapped price records\n",
      "  4. Loading product base data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 101770 product base records\n",
      "  5. Loading sales data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 20650 sales records\n",
      "  6. Loading margin stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 28770 margin stat records\n",
      "  7. Loading target margins...\n",
      "     Loaded 478 target margin records\n",
      "  8. Loading product groups...\n",
      "     Loaded 1622 group records\n",
      "\n",
      "All queries completed!\n",
      "\n",
      "============================================================\n",
      "df_product_base DataFrame available with columns:\n",
      "  - region, cohort_id, product_id, sku, brand, cat, wac1, wac_p, current_price\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n",
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Execute all queries\n",
    "# =============================================================================\n",
    "print(\"Loading data from Snowflake...\")\n",
    "\n",
    "# 1. Ben Soliman Prices\n",
    "print(\"  1. Loading Ben Soliman prices...\")\n",
    "df_ben_soliman = query_snowflake(BEN_SOLIMAN_QUERY)\n",
    "df_ben_soliman = convert_to_numeric(df_ben_soliman)\n",
    "print(f\"     Loaded {len(df_ben_soliman)} Ben Soliman price records\")\n",
    "\n",
    "# 2. Marketplace Prices\n",
    "print(\"  2. Loading marketplace prices...\")\n",
    "df_marketplace = query_snowflake(MARKETPLACE_PRICES_QUERY)\n",
    "df_marketplace = convert_to_numeric(df_marketplace)\n",
    "print(f\"     Loaded {len(df_marketplace)} marketplace price records\")\n",
    "\n",
    "# 3. Scrapped Data\n",
    "print(\"  3. Loading scrapped data...\")\n",
    "df_scrapped = query_snowflake(SCRAPPED_DATA_QUERY)\n",
    "df_scrapped = convert_to_numeric(df_scrapped)\n",
    "print(f\"     Loaded {len(df_scrapped)} scrapped price records\")\n",
    "\n",
    "# 4. Product Base Data (product_id, sku, brand, cat, wac1, wac_p, current_price)\n",
    "print(\"  4. Loading product base data...\")\n",
    "df_product_base = query_snowflake(PRODUCT_BASE_QUERY)\n",
    "df_product_base = convert_to_numeric(df_product_base)\n",
    "print(f\"     Loaded {len(df_product_base)} product base records\")\n",
    "\n",
    "# 5. Sales Data\n",
    "print(\"  5. Loading sales data...\")\n",
    "df_sales = query_snowflake(SALES_QUERY)\n",
    "df_sales = convert_to_numeric(df_sales)\n",
    "print(f\"     Loaded {len(df_sales)} sales records\")\n",
    "\n",
    "# 6. Margin Stats\n",
    "print(\"  6. Loading margin stats...\")\n",
    "df_margin_stats = query_snowflake(MARGIN_STATS_QUERY)\n",
    "df_margin_stats = convert_to_numeric(df_margin_stats)\n",
    "print(f\"     Loaded {len(df_margin_stats)} margin stat records\")\n",
    "\n",
    "# 7. Target Margins\n",
    "print(\"  7. Loading target margins...\")\n",
    "df_targets = query_snowflake(TARGET_MARGINS_QUERY)\n",
    "df_targets = convert_to_numeric(df_targets)\n",
    "print(f\"     Loaded {len(df_targets)} target margin records\")\n",
    "\n",
    "# 8. Product Groups (from PostgreSQL)\n",
    "print(\"  8. Loading product groups...\")\n",
    "df_groups = setup_environment_2.dwh_pg_query(\n",
    "    \"SELECT * FROM materialized_views.sku_commercial_groups\", \n",
    "    columns=['product_id', 'group']\n",
    ")\n",
    "df_groups.columns = df_groups.columns.str.lower()\n",
    "df_groups = convert_to_numeric(df_groups)\n",
    "print(f\"     Loaded {len(df_groups)} group records\")\n",
    "\n",
    "print(\"\\nAll queries completed!\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"df_product_base DataFrame available with columns:\")\n",
    "print(\"  - region, cohort_id, product_id, sku, brand, cat, wac1, wac_p, current_price\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building market_data DataFrame (market prices only)...\n",
      "  Step 1: Joining all market price sources (outer join)...\n",
      "     Market prices base: 15971 records\n",
      "  Step 2: Adding cohort IDs and supporting data for processing...\n",
      "\n",
      "============================================================\n",
      "MARKET DATA BASE READY FOR PROCESSING\n",
      "============================================================\n",
      "Total records: 23591\n",
      "  - With marketplace prices: 16553\n",
      "  - With scrapped prices: 7593\n",
      "  - With Ben Soliman prices: 13725\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PART A: Build market_data DataFrame - Process market prices SEPARATELY\n",
    "# =============================================================================\n",
    "print(\"Building market_data DataFrame (market prices only)...\")\n",
    "\n",
    "# Create region-cohort mapping\n",
    "REGION_COHORT_DF = pd.DataFrame({\n",
    "    'region': ['Cairo', 'Giza', 'Delta West', 'Delta East', \n",
    "               'Upper Egypt', 'Upper Egypt', 'Upper Egypt', 'Upper Egypt', 'Alexandria'],\n",
    "    'cohort_id': [700, 701, 703, 704, 1124, 1126, 1123, 1125, 702]\n",
    "})\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Outer join all market price sources\n",
    "# =============================================================================\n",
    "print(\"  Step 1: Joining all market price sources (outer join)...\")\n",
    "\n",
    "# Start with marketplace prices (has region + product_id)\n",
    "market_data = df_marketplace.copy()\n",
    "\n",
    "# Outer join with scrapped data (by region + product_id)\n",
    "market_data = market_data.merge(df_scrapped, on=['region', 'product_id'], how='outer')\n",
    "\n",
    "# Outer join with Ben Soliman prices (by product_id only - expand to all regions)\n",
    "all_regions = pd.DataFrame({'region': ['Cairo', 'Giza', 'Delta West', 'Delta East', 'Upper Egypt', 'Alexandria']})\n",
    "df_ben_soliman_expanded = df_ben_soliman.merge(all_regions, how='cross')\n",
    "\n",
    "# Outer join with Ben Soliman\n",
    "market_data = market_data.merge(df_ben_soliman_expanded, on=['region', 'product_id'], how='outer')\n",
    "\n",
    "print(f\"     Market prices base: {len(market_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Add cohort_id and supporting data for market processing\n",
    "# =============================================================================\n",
    "print(\"  Step 2: Adding cohort IDs and supporting data for processing...\")\n",
    "market_data = market_data.merge(REGION_COHORT_DF, on='region')\n",
    "\n",
    "# Need sales data for group processing (weighted median)\n",
    "market_data = market_data.merge(\n",
    "    df_sales[['cohort_id', 'product_id', 'nmv']], \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "market_data['nmv'] = market_data['nmv'].fillna(0)\n",
    "\n",
    "# Need margin stats for price analysis\n",
    "market_data = market_data.merge(df_margin_stats, on=['cohort_id', 'product_id'], how='left')\n",
    "\n",
    "# Need WAC for price analysis - get from product base\n",
    "market_data = market_data.merge(\n",
    "    df_product_base[['cohort_id', 'product_id', 'wac_p', 'brand', 'cat']].drop_duplicates(), \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Need target margins for price analysis\n",
    "market_data = market_data.merge(df_targets, on=['brand', 'cat'], how='left')\n",
    "market_data['target_margin'] = market_data['target_bm'].fillna(market_data['cat_target_margin']).fillna(0)\n",
    "market_data = market_data.drop(columns=['target_bm', 'cat_target_margin'], errors='ignore')\n",
    "\n",
    "# Fill NaN values with defaults\n",
    "market_data['std'] = market_data['std'].fillna(0.01)\n",
    "market_data['avg_margin'] = market_data['avg_margin'].fillna(0)\n",
    "\n",
    "# Merge product groups for group processing\n",
    "market_data = market_data.merge(df_groups, on='product_id', how='left')\n",
    "\n",
    "# Remove duplicates\n",
    "market_data = market_data.drop_duplicates(subset=['cohort_id', 'product_id'])\n",
    "\n",
    "# Filter out records without WAC (can't process prices without cost)\n",
    "market_data = market_data[~market_data['wac_p'].isna()]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MARKET DATA BASE READY FOR PROCESSING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(market_data)}\")\n",
    "print(f\"  - With marketplace prices: {len(market_data[~market_data['final_min_price'].isna()])}\")\n",
    "print(f\"  - With scrapped prices: {len(market_data[~market_data['min_scrapped'].isna()])}\")\n",
    "print(f\"  - With Ben Soliman prices: {len(market_data[~market_data['ben_soliman_price'].isna()])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART A: Market Data Processing\n",
    "Process market prices separately (group fill, coverage filter, price analysis, margin tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after group processing: 23591 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/2745197058.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Group Processing - Calculate group-level aggregated prices (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate group-level aggregated prices for products with group assignments\n",
    "groups_data = market_data[~market_data['group'].isna()].copy()\n",
    "groups_data['group_nmv'] = groups_data.groupby(['group', 'cohort_id'])['nmv'].transform('sum')\n",
    "groups_data['cntrb'] = (groups_data['nmv'] / groups_data['group_nmv']).fillna(1)\n",
    "\n",
    "# Flag if any price/scrapped column is non-NaN\n",
    "price_cols = [\n",
    "    'ben_soliman_price', 'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped'\n",
    "]\n",
    "groups_data['flag_non_nan'] = groups_data[price_cols].notna().any(axis=1).astype(int)\n",
    "\n",
    "# Weighted Median Function\n",
    "def weighted_median(series, weights):\n",
    "    valid = ~series.isna() & ~weights.isna()\n",
    "    s = series[valid]\n",
    "    w = weights[valid]\n",
    "    if len(s) == 0:\n",
    "        return np.nan\n",
    "    order = np.argsort(s)\n",
    "    s, w = s.iloc[order], w.iloc[order]\n",
    "    return s.iloc[np.searchsorted(np.cumsum(w), w.sum() / 2)]\n",
    "\n",
    "# Perform Weighted Aggregation\n",
    "groups_agg = (\n",
    "    groups_data[groups_data['flag_non_nan'] == 1]\n",
    "    .groupby(['group', 'cohort_id'])\n",
    "    .apply(lambda g: pd.Series({\n",
    "        col: weighted_median(g[col], g['cntrb']) for col in price_cols\n",
    "    }))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Fill missing prices with group-level prices\n",
    "merged = market_data.merge(groups_agg, on=['group', 'cohort_id'], how='left', suffixes=('', '_group'))\n",
    "for col in price_cols:\n",
    "    merged[col] = merged[col].fillna(merged[f'{col}_group'])\n",
    "\n",
    "market_data = merged.drop(columns=[f'{c}_group' for c in price_cols])\n",
    "\n",
    "print(f\"Market data after group processing: {len(market_data)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Coverage Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after price coverage filtering: 12783 records\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Price Coverage Filtering - Filter products with sufficient price data (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Score price coverage\n",
    "market_data['ben'] = 0\n",
    "market_data['MP'] = 0\n",
    "market_data['sp'] = 0\n",
    "\n",
    "# Ben Soliman: 1 point if present\n",
    "market_data.loc[~market_data['ben_soliman_price'].isna(), 'ben'] = 1\n",
    "\n",
    "# Marketplace: 1 point if single price, 3 points if range\n",
    "market_data.loc[(market_data['final_min_price'] == market_data['final_max_price']) & \n",
    "                (~market_data['final_min_price'].isna()), 'MP'] = 1\n",
    "market_data.loc[(market_data['final_min_price'] != market_data['final_max_price']) & \n",
    "                (~market_data['final_min_price'].isna()), 'MP'] = 3\n",
    "\n",
    "# Scrapped: 1 point if single price, 5 points if range\n",
    "market_data.loc[(market_data['min_scrapped'] == market_data['max_scrapped']) & \n",
    "                (~market_data['min_scrapped'].isna()), 'sp'] = 1\n",
    "market_data.loc[(market_data['min_scrapped'] != market_data['max_scrapped']) & \n",
    "                (~market_data['min_scrapped'].isna()), 'sp'] = 5\n",
    "\n",
    "# Total price coverage score\n",
    "market_data['total_p'] = market_data['ben'] + market_data['MP'] + market_data['sp']\n",
    "\n",
    "# Filter: keep only products with total_p > 2\n",
    "market_data = market_data[market_data['total_p'] > 2]\n",
    "\n",
    "print(f\"Market data after price coverage filtering: {len(market_data)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Analysis & Margin Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Price Analysis Functions\n",
    "# =============================================================================\n",
    "\n",
    "def price_analysis(row):\n",
    "    \"\"\"Analyze prices and calculate percentiles for a product.\"\"\"\n",
    "    wac = row['wac_p']\n",
    "    avg_margin = row['avg_margin'] if row['avg_margin'] >= 0.01 else row['target_margin']\n",
    "    std = np.maximum(row['std'], 0.0025)\n",
    "    target_margin = row['target_margin']\n",
    "    max_marg = np.maximum(avg_margin, target_margin)\n",
    "    \n",
    "    # Collect all price points\n",
    "    price_list = [\n",
    "        row['ben_soliman_price'], row['final_min_price'], row['final_mod_price'],\n",
    "        row['final_max_price'], row['final_true_min'], row['final_true_max'],\n",
    "        row['min_scrapped'], row['scrapped25'], row['scrapped50'], row['scrapped75'], row['max_scrapped']\n",
    "    ]\n",
    "    \n",
    "    # Filter valid prices within acceptable range\n",
    "    valid_prices = sorted({\n",
    "        x for x in price_list \n",
    "        if x and not pd.isna(x) and x != 0 \n",
    "        and wac / (1 - (avg_margin - (10 * std))) <= x <= wac / (1 - (max_marg + 10 * std))\n",
    "        and x >= wac * 0.9\n",
    "    })\n",
    "    \n",
    "    if not valid_prices:\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    return (\n",
    "        np.min(valid_prices),\n",
    "        np.percentile(valid_prices, 25),\n",
    "        np.percentile(valid_prices, 50),\n",
    "        np.percentile(valid_prices, 75),\n",
    "        np.max(valid_prices)\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_step_bounds(row):\n",
    "    \"\"\"Calculate below/above market bounds based on price steps.\"\"\"\n",
    "    wac = row['wac_p']\n",
    "    std = row['std']\n",
    "    prices = [row['minimum'], row['percentile_25'], row['percentile_50'], row['percentile_75'], row['maximum']]\n",
    "    \n",
    "    # Calculate valid steps between price points\n",
    "    valid_steps = []\n",
    "    for i in range(len(prices) - 1):\n",
    "        step = prices[i + 1] - prices[i]\n",
    "        if (step / wac) <= std * 1.2:\n",
    "            valid_steps.append(step)\n",
    "    \n",
    "    avg_step = np.mean(valid_steps) if valid_steps else min(2 * std, 0.2 * row['target_margin'])\n",
    "    \n",
    "    new_min = prices[0] - avg_step if (prices[0] - avg_step) >= wac else prices[0]\n",
    "    new_max = prices[-1] + avg_step if (prices[-1] + avg_step) >= wac else prices[-1]\n",
    "    \n",
    "    return new_min, new_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after price analysis: 12047 records\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Apply Price Analysis & Margin Calculation (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Apply price analysis to calculate price percentiles\n",
    "market_data[['minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum']] = \\\n",
    "    market_data.apply(price_analysis, axis=1, result_type='expand')\n",
    "\n",
    "# Filter out records without valid price analysis\n",
    "market_data = market_data[~market_data['minimum'].isna()]\n",
    "\n",
    "# Calculate below/above market bounds\n",
    "market_data[['below_market', 'above_market']] = market_data.apply(calculate_step_bounds, axis=1, result_type='expand')\n",
    "\n",
    "print(f\"Market data after price analysis: {len(market_data)} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MARKET DATA PROCESSING COMPLETE\n",
      "============================================================\n",
      "Total processed market records: 12047\n",
      "\n",
      "Market data columns:\n",
      "  - Price columns: ben_soliman_price, final_min_price, final_max_price, etc.\n",
      "  - Percentiles: minimum, percentile_25, percentile_50, percentile_75, maximum\n",
      "  - Margin tiers: below_market, market_min, market_25, market_50, market_75, market_max, above_market\n",
      "\n",
      "Sample processed market data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>ben_soliman_price</th>\n",
       "      <th>final_min_price</th>\n",
       "      <th>final_max_price</th>\n",
       "      <th>final_mod_price</th>\n",
       "      <th>final_true_min</th>\n",
       "      <th>final_true_max</th>\n",
       "      <th>min_scrapped</th>\n",
       "      <th>scrapped25</th>\n",
       "      <th>scrapped50</th>\n",
       "      <th>scrapped75</th>\n",
       "      <th>max_scrapped</th>\n",
       "      <th>minimum</th>\n",
       "      <th>percentile_25</th>\n",
       "      <th>percentile_50</th>\n",
       "      <th>percentile_75</th>\n",
       "      <th>maximum</th>\n",
       "      <th>below_market</th>\n",
       "      <th>market_min</th>\n",
       "      <th>market_25</th>\n",
       "      <th>market_50</th>\n",
       "      <th>market_75</th>\n",
       "      <th>market_max</th>\n",
       "      <th>above_market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>702</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.5</td>\n",
       "      <td>255.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>254.630005</td>\n",
       "      <td>254.957504</td>\n",
       "      <td>255.285004</td>\n",
       "      <td>255.612503</td>\n",
       "      <td>255.940002</td>\n",
       "      <td>254.630005</td>\n",
       "      <td>254.989376</td>\n",
       "      <td>255.448753</td>\n",
       "      <td>256.080002</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.055203</td>\n",
       "      <td>0.056997</td>\n",
       "      <td>0.058326</td>\n",
       "      <td>0.060019</td>\n",
       "      <td>0.062336</td>\n",
       "      <td>0.139366</td>\n",
       "      <td>0.140854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>702</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831.4</td>\n",
       "      <td>848.4</td>\n",
       "      <td>829.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>829.000000</td>\n",
       "      <td>830.800000</td>\n",
       "      <td>839.900000</td>\n",
       "      <td>848.800000</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.005926</td>\n",
       "      <td>0.012221</td>\n",
       "      <td>0.014361</td>\n",
       "      <td>0.025040</td>\n",
       "      <td>0.035263</td>\n",
       "      <td>0.036625</td>\n",
       "      <td>0.042539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>702</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>271.500000</td>\n",
       "      <td>280.000000</td>\n",
       "      <td>288.500000</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.025238</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.036009</td>\n",
       "      <td>0.065273</td>\n",
       "      <td>0.092812</td>\n",
       "      <td>0.097505</td>\n",
       "      <td>0.102149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>702</td>\n",
       "      <td>14.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>461.5</td>\n",
       "      <td>477.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>461.125000</td>\n",
       "      <td>463.250000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>477.0</td>\n",
       "      <td>0.022753</td>\n",
       "      <td>0.028418</td>\n",
       "      <td>0.030789</td>\n",
       "      <td>0.035234</td>\n",
       "      <td>0.045026</td>\n",
       "      <td>0.063045</td>\n",
       "      <td>0.068254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>702</td>\n",
       "      <td>17.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>631.4</td>\n",
       "      <td>595.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>598.500000</td>\n",
       "      <td>598.500000</td>\n",
       "      <td>598.750000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>595.000000</td>\n",
       "      <td>598.125000</td>\n",
       "      <td>598.875000</td>\n",
       "      <td>610.850000</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.019382</td>\n",
       "      <td>0.022575</td>\n",
       "      <td>0.027682</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.047937</td>\n",
       "      <td>0.089879</td>\n",
       "      <td>0.092630</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_id  product_id  ben_soliman_price  final_min_price  final_max_price  \\\n",
       "0        702         3.0              256.5            255.0            279.0   \n",
       "1        702         9.0                NaN            831.4            848.4   \n",
       "2        702        10.0                NaN            272.0            288.0   \n",
       "4        702        14.0              465.0            461.5            477.0   \n",
       "5        702        17.0              604.0            597.0            631.4   \n",
       "\n",
       "   final_mod_price  final_true_min  final_true_max  min_scrapped  scrapped25  \\\n",
       "0            255.0           255.0           300.0    254.630005  254.957504   \n",
       "1            829.0           829.0           850.0           NaN         NaN   \n",
       "2            270.0           270.0           290.0           NaN         NaN   \n",
       "4            477.0           460.0           477.0           NaN         NaN   \n",
       "5            595.0           595.0           639.0    598.500000  598.500000   \n",
       "\n",
       "   scrapped50  scrapped75  max_scrapped     minimum  percentile_25  \\\n",
       "0  255.285004  255.612503    255.940002  254.630005     254.989376   \n",
       "1         NaN         NaN           NaN  829.000000     830.800000   \n",
       "2         NaN         NaN           NaN  270.000000     271.500000   \n",
       "4         NaN         NaN           NaN  460.000000     461.125000   \n",
       "5  598.750000  599.000000    599.000000  595.000000     598.125000   \n",
       "\n",
       "   percentile_50  percentile_75  maximum  below_market  market_min  market_25  \\\n",
       "0     255.448753     256.080002    279.0      0.055203    0.056997   0.058326   \n",
       "1     839.900000     848.800000    850.0      0.005926    0.012221   0.014361   \n",
       "2     280.000000     288.500000    290.0      0.025238    0.030653   0.036009   \n",
       "4     463.250000     468.000000    477.0      0.022753    0.028418   0.030789   \n",
       "5     598.875000     610.850000    639.0      0.019382    0.022575   0.027682   \n",
       "\n",
       "   market_50  market_75  market_max  above_market  \n",
       "0   0.060019   0.062336    0.139366      0.140854  \n",
       "1   0.025040   0.035263    0.036625      0.042539  \n",
       "2   0.065273   0.092812    0.097505      0.102149  \n",
       "4   0.035234   0.045026    0.063045      0.068254  \n",
       "5   0.028900   0.047937    0.089879      0.092630  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Convert prices to margins (on market_data) - FINALIZE market_data processing\n",
    "# =============================================================================\n",
    "\n",
    "market_data['below_market'] = (market_data['below_market'] - market_data['wac_p']) / market_data['below_market']\n",
    "market_data['market_min'] = (market_data['minimum'] - market_data['wac_p']) / market_data['minimum']\n",
    "market_data['market_25'] = (market_data['percentile_25'] - market_data['wac_p']) / market_data['percentile_25']\n",
    "market_data['market_50'] = (market_data['percentile_50'] - market_data['wac_p']) / market_data['percentile_50']\n",
    "market_data['market_75'] = (market_data['percentile_75'] - market_data['wac_p']) / market_data['percentile_75']\n",
    "market_data['market_max'] = (market_data['maximum'] - market_data['wac_p']) / market_data['maximum']\n",
    "market_data['above_market'] = (market_data['above_market'] - market_data['wac_p']) / market_data['above_market']\n",
    "\n",
    "# Select only the market-related columns to merge later\n",
    "market_columns = [\n",
    "    'cohort_id', 'product_id',\n",
    "    # Market Prices (raw)\n",
    "    'ben_soliman_price', \n",
    "    'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped',\n",
    "    # Price Percentiles\n",
    "    'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum',\n",
    "    # Margin Tiers\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market'\n",
    "]\n",
    "market_data = market_data[[c for c in market_columns if c in market_data.columns]]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MARKET DATA PROCESSING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total processed market records: {len(market_data)}\")\n",
    "print(f\"\\nMarket data columns:\")\n",
    "print(\"  - Price columns: ben_soliman_price, final_min_price, final_max_price, etc.\")\n",
    "print(\"  - Percentiles: minimum, percentile_25, percentile_50, percentile_75, maximum\")\n",
    "print(\"  - Margin tiers: below_market, market_min, market_25, market_50, market_75, market_max, above_market\")\n",
    "print(f\"\\nSample processed market data:\")\n",
    "market_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART B: Build Main pricing_data DataFrame\n",
    "Start with df_product_base (all our SKUs) and LEFT JOIN the processed market_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building main pricing_data DataFrame...\n",
      "  Step 1: Starting with product base (all SKUs)...\n",
      "     Product base: 101770 records\n",
      "  Step 2: Adding warehouse mapping...\n",
      "     After warehouse mapping: 85930 records\n",
      "  Step 3: Left joining processed market data...\n",
      "     After market data join: 85930 records\n",
      "  Step 4: Left joining supporting data...\n",
      "\n",
      "============================================================\n",
      "PRICING DATA COMPLETE\n",
      "============================================================\n",
      "Total records: 64427\n",
      "\n",
      "Records with market data: 12047\n",
      "Records without market data: 52380\n",
      "\n",
      "Records with sales (nmv > 0): 20646\n",
      "Records without sales (nmv = 0): 43781\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>region</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>sku</th>\n",
       "      <th>brand</th>\n",
       "      <th>cat</th>\n",
       "      <th>wac1</th>\n",
       "      <th>wac_p</th>\n",
       "      <th>current_price</th>\n",
       "      <th>current_margin</th>\n",
       "      <th>nmv</th>\n",
       "      <th>ben_soliman_price</th>\n",
       "      <th>final_min_price</th>\n",
       "      <th>final_max_price</th>\n",
       "      <th>final_mod_price</th>\n",
       "      <th>final_true_min</th>\n",
       "      <th>final_true_max</th>\n",
       "      <th>min_scrapped</th>\n",
       "      <th>scrapped25</th>\n",
       "      <th>scrapped50</th>\n",
       "      <th>scrapped75</th>\n",
       "      <th>max_scrapped</th>\n",
       "      <th>minimum</th>\n",
       "      <th>percentile_25</th>\n",
       "      <th>percentile_50</th>\n",
       "      <th>percentile_75</th>\n",
       "      <th>maximum</th>\n",
       "      <th>below_market</th>\n",
       "      <th>market_min</th>\n",
       "      <th>market_25</th>\n",
       "      <th>market_50</th>\n",
       "      <th>market_75</th>\n",
       "      <th>market_max</th>\n",
       "      <th>above_market</th>\n",
       "      <th>std</th>\n",
       "      <th>avg_margin</th>\n",
       "      <th>target_margin</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>703</td>\n",
       "      <td>964</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>337</td>\n",
       "      <td>El-Mahala</td>\n",
       "      <td>   - 130 </td>\n",
       "      <td> </td>\n",
       "      <td></td>\n",
       "      <td>27.609183</td>\n",
       "      <td>25.400448</td>\n",
       "      <td>26.50</td>\n",
       "      <td>0.041493</td>\n",
       "      <td>2589.25</td>\n",
       "      <td>25.9</td>\n",
       "      <td>27.75</td>\n",
       "      <td>30.4</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.9</td>\n",
       "      <td>26.05</td>\n",
       "      <td>26.2</td>\n",
       "      <td>26.35</td>\n",
       "      <td>26.5</td>\n",
       "      <td>0.018981</td>\n",
       "      <td>0.019288</td>\n",
       "      <td>0.024935</td>\n",
       "      <td>0.030517</td>\n",
       "      <td>0.036036</td>\n",
       "      <td>0.041493</td>\n",
       "      <td>0.041786</td>\n",
       "      <td>0.004310</td>\n",
       "      <td>0.034762</td>\n",
       "      <td>0.040523</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>701</td>\n",
       "      <td>1504</td>\n",
       "      <td>Giza</td>\n",
       "      <td>236</td>\n",
       "      <td>Barageel</td>\n",
       "      <td>  - 1.45 </td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "      <td>167.852369</td>\n",
       "      <td>153.852369</td>\n",
       "      <td>165.25</td>\n",
       "      <td>0.068972</td>\n",
       "      <td>590963.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145.60</td>\n",
       "      <td>173.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>167.5</td>\n",
       "      <td>170.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>167.50</td>\n",
       "      <td>170.0</td>\n",
       "      <td>173.00</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0.054186</td>\n",
       "      <td>0.067561</td>\n",
       "      <td>0.081478</td>\n",
       "      <td>0.094986</td>\n",
       "      <td>0.110680</td>\n",
       "      <td>0.120844</td>\n",
       "      <td>0.132411</td>\n",
       "      <td>0.013689</td>\n",
       "      <td>0.081591</td>\n",
       "      <td>0.085527</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1126</td>\n",
       "      <td>21793</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>401</td>\n",
       "      <td>Bani sweif</td>\n",
       "      <td>  32  - 50 </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>114.883450</td>\n",
       "      <td>111.483839</td>\n",
       "      <td>124.25</td>\n",
       "      <td>0.102746</td>\n",
       "      <td>140120.00</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.30</td>\n",
       "      <td>137.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.30</td>\n",
       "      <td>125.0</td>\n",
       "      <td>137.00</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.086198</td>\n",
       "      <td>0.093627</td>\n",
       "      <td>0.103107</td>\n",
       "      <td>0.108129</td>\n",
       "      <td>0.186249</td>\n",
       "      <td>0.231146</td>\n",
       "      <td>0.236412</td>\n",
       "      <td>0.018031</td>\n",
       "      <td>0.076018</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1125</td>\n",
       "      <td>21793</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>632</td>\n",
       "      <td>Sohag</td>\n",
       "      <td>  32  - 50 </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>114.883450</td>\n",
       "      <td>111.483839</td>\n",
       "      <td>133.75</td>\n",
       "      <td>0.166476</td>\n",
       "      <td>31347.00</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.30</td>\n",
       "      <td>137.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.0</td>\n",
       "      <td>124.30</td>\n",
       "      <td>125.0</td>\n",
       "      <td>137.00</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.086198</td>\n",
       "      <td>0.093627</td>\n",
       "      <td>0.103107</td>\n",
       "      <td>0.108129</td>\n",
       "      <td>0.186249</td>\n",
       "      <td>0.231146</td>\n",
       "      <td>0.236412</td>\n",
       "      <td>0.025657</td>\n",
       "      <td>0.075093</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>703</td>\n",
       "      <td>11403</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>337</td>\n",
       "      <td>El-Mahala</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>320.084666</td>\n",
       "      <td>313.728880</td>\n",
       "      <td>328.00</td>\n",
       "      <td>0.043510</td>\n",
       "      <td>89655.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009183</td>\n",
       "      <td>0.039130</td>\n",
       "      <td>0.049392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_id  product_id       region  warehouse_id   warehouse  \\\n",
       "0        703         964   Delta West           337   El-Mahala   \n",
       "2        701        1504         Giza           236    Barageel   \n",
       "4       1126       21793  Upper Egypt           401  Bani sweif   \n",
       "5       1125       21793  Upper Egypt           632       Sohag   \n",
       "6        703       11403   Delta West           337   El-Mahala   \n",
       "\n",
       "                               sku            brand         cat        wac1  \\\n",
       "0      - 130              27.609183   \n",
       "2               - 1.45               167.852369   \n",
       "4          32  - 50                     114.883450   \n",
       "5          32  - 50                     114.883450   \n",
       "6      - 300                       320.084666   \n",
       "\n",
       "        wac_p  current_price  current_margin        nmv  ben_soliman_price  \\\n",
       "0   25.400448          26.50        0.041493    2589.25               25.9   \n",
       "2  153.852369         165.25        0.068972  590963.00                NaN   \n",
       "4  111.483839         124.25        0.102746  140120.00              123.0   \n",
       "5  111.483839         133.75        0.166476   31347.00              123.0   \n",
       "6  313.728880         328.00        0.043510   89655.25                NaN   \n",
       "\n",
       "   final_min_price  final_max_price  final_mod_price  final_true_min  \\\n",
       "0            27.75             30.4             28.0            26.5   \n",
       "2           145.60            173.0            165.0           140.0   \n",
       "4           124.30            137.0            125.0           123.0   \n",
       "5           124.30            137.0            125.0           123.0   \n",
       "6              NaN              NaN              NaN             NaN   \n",
       "\n",
       "   final_true_max  min_scrapped  scrapped25  scrapped50  scrapped75  \\\n",
       "0            31.0           NaN         NaN         NaN         NaN   \n",
       "2           175.0         165.0       165.0       167.5       170.0   \n",
       "4           145.0           NaN         NaN         NaN         NaN   \n",
       "5           145.0           NaN         NaN         NaN         NaN   \n",
       "6             NaN           NaN         NaN         NaN         NaN   \n",
       "\n",
       "   max_scrapped  minimum  percentile_25  percentile_50  percentile_75  \\\n",
       "0           NaN     25.9          26.05           26.2          26.35   \n",
       "2         170.0    165.0         167.50          170.0         173.00   \n",
       "4           NaN    123.0         124.30          125.0         137.00   \n",
       "5           NaN    123.0         124.30          125.0         137.00   \n",
       "6           NaN      NaN            NaN            NaN            NaN   \n",
       "\n",
       "   maximum  below_market  market_min  market_25  market_50  market_75  \\\n",
       "0     26.5      0.018981    0.019288   0.024935   0.030517   0.036036   \n",
       "2    175.0      0.054186    0.067561   0.081478   0.094986   0.110680   \n",
       "4    145.0      0.086198    0.093627   0.103107   0.108129   0.186249   \n",
       "5    145.0      0.086198    0.093627   0.103107   0.108129   0.186249   \n",
       "6      NaN           NaN         NaN        NaN        NaN        NaN   \n",
       "\n",
       "   market_max  above_market       std  avg_margin  target_margin  group  \n",
       "0    0.041493      0.041786  0.004310    0.034762       0.040523    NaN  \n",
       "2    0.120844      0.132411  0.013689    0.081591       0.085527    NaN  \n",
       "4    0.231146      0.236412  0.018031    0.076018       0.060000    NaN  \n",
       "5    0.231146      0.236412  0.025657    0.075093       0.060000    NaN  \n",
       "6         NaN           NaN  0.009183    0.039130       0.049392    NaN  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PART B: Build Main pricing_data DataFrame from df_product_base\n",
    "# =============================================================================\n",
    "print(\"Building main pricing_data DataFrame...\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Start with df_product_base as the MAIN dataframe (all our SKUs)\n",
    "# =============================================================================\n",
    "print(\"  Step 1: Starting with product base (all SKUs)...\")\n",
    "pricing_data = df_product_base.copy()\n",
    "print(f\"     Product base: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Add warehouse mapping (warehouse_id and warehouse name)\n",
    "# =============================================================================\n",
    "print(\"  Step 2: Adding warehouse mapping...\")\n",
    "warehouse_df = get_warehouse_df()\n",
    "pricing_data = pricing_data.merge(\n",
    "    warehouse_df[['cohort_id', 'warehouse_id', 'warehouse']], \n",
    "    on='cohort_id'\n",
    ")\n",
    "print(f\"     After warehouse mapping: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 3: LEFT JOIN processed market_data\n",
    "# =============================================================================\n",
    "print(\"  Step 3: Left joining processed market data...\")\n",
    "pricing_data = pricing_data.merge(\n",
    "    market_data, \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "print(f\"     After market data join: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 4: LEFT JOIN supporting data (sales, margins, targets, groups)\n",
    "# =============================================================================\n",
    "print(\"  Step 4: Left joining supporting data...\")\n",
    "\n",
    "# Merge sales data (nmv only)\n",
    "pricing_data = pricing_data.merge(\n",
    "    df_sales[['cohort_id', 'product_id', 'nmv']], \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "pricing_data['nmv'] = pricing_data['nmv'].fillna(0)\n",
    "\n",
    "# Merge margin statistics (by cohort_id + product_id)\n",
    "pricing_data = pricing_data.merge(df_margin_stats, on=['cohort_id', 'product_id'], how='left')\n",
    "\n",
    "# Merge target margins (by brand + cat)\n",
    "pricing_data = pricing_data.merge(df_targets, on=['brand', 'cat'], how='left')\n",
    "pricing_data['target_margin'] = pricing_data['target_bm'].fillna(pricing_data['cat_target_margin']).fillna(0)\n",
    "pricing_data = pricing_data.drop(columns=['target_bm', 'cat_target_margin'], errors='ignore')\n",
    "\n",
    "# Fill NaN values with defaults\n",
    "pricing_data['std'] = pricing_data['std'].fillna(0.01)\n",
    "pricing_data['avg_margin'] = pricing_data['avg_margin'].fillna(0)\n",
    "\n",
    "# Merge product groups\n",
    "pricing_data = pricing_data.merge(df_groups, on='product_id', how='left')\n",
    "\n",
    "# =============================================================================\n",
    "# Step 5: Calculate current margin\n",
    "# =============================================================================\n",
    "pricing_data['current_margin'] = (pricing_data['current_price'] - pricing_data['wac_p']) / pricing_data['current_price']\n",
    "\n",
    "# Remove duplicates\n",
    "pricing_data = pricing_data.drop_duplicates(subset=['cohort_id', 'product_id'])\n",
    "\n",
    "# =============================================================================\n",
    "# Reorder columns\n",
    "# =============================================================================\n",
    "final_columns = [\n",
    "    # Product Base Info\n",
    "    'cohort_id', 'product_id', 'region', 'warehouse_id', 'warehouse', 'sku', 'brand', 'cat',\n",
    "    # Cost & Price\n",
    "    'wac1', 'wac_p', 'current_price', 'current_margin',\n",
    "    # Sales\n",
    "    'nmv',\n",
    "    # Market Prices (raw)\n",
    "    'ben_soliman_price', \n",
    "    'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped',\n",
    "    # Price Percentiles\n",
    "    'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum',\n",
    "    # Margin Tiers\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market',\n",
    "    # Supporting Data\n",
    "    'std', 'avg_margin', 'target_margin', 'group'\n",
    "]\n",
    "pricing_data = pricing_data[[c for c in final_columns if c in pricing_data.columns]]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICING DATA COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(pricing_data)}\")\n",
    "print(f\"\\nRecords with market data: {len(pricing_data[~pricing_data['minimum'].isna()])}\")\n",
    "print(f\"Records without market data: {len(pricing_data[pricing_data['minimum'].isna()])}\")\n",
    "print(f\"\\nRecords with sales (nmv > 0): {len(pricing_data[pricing_data['nmv'] > 0])}\")\n",
    "print(f\"Records without sales (nmv = 0): {len(pricing_data[pricing_data['nmv'] == 0])}\")\n",
    "print(f\"\\nSample data:\")\n",
    "pricing_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discount Analysis - Price & Margin After Discount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading discount data...\n",
      "Loaded 10773 discount records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Discount Query - Get discount percentage by warehouse and product\n",
    "# =============================================================================\n",
    "DISCOUNT_QUERY = f'''\n",
    "SELECT warehouse_id, product_id, total_discount/total_nmv AS discount_perc\n",
    "FROM (\n",
    "    SELECT  \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        SUM(pso.total_price) AS total_nmv,\n",
    "        SUM((ITEM_QUANTITY_DISCOUNT_VALUE * pso.purchased_item_count) + \n",
    "            (ITEM_DISCOUNT_VALUE * pso.purchased_item_count)) AS total_discount\n",
    "    FROM product_sales_order pso \n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1 \n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY ALL\n",
    ")\n",
    "WHERE total_nmv > 0\n",
    "'''\n",
    "\n",
    "# Execute discount query\n",
    "print(\"Loading discount data...\")\n",
    "df_discount = query_snowflake(DISCOUNT_QUERY)\n",
    "df_discount = convert_to_numeric(df_discount)\n",
    "print(f\"Loaded {len(df_discount)} discount records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pricing_with_discount DataFrame...\n",
      "\n",
      "============================================================\n",
      "PRICING WITH DISCOUNT DATA COMPLETE\n",
      "============================================================\n",
      "Total records: 64427\n",
      "Records with discount (discount_perc > 0): 3406\n",
      "Records without discount: 61021\n",
      "\n",
      "New columns added:\n",
      "  - discount_perc: discount percentage from sales\n",
      "  - price_after_discount: current_price * (1 - discount_perc)\n",
      "  - margin_after_discount: (price_after_discount - wac_p) / price_after_discount\n",
      "\n",
      "Sample data with discounts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>current_price</th>\n",
       "      <th>current_margin</th>\n",
       "      <th>discount_perc</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>margin_after_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3016</td>\n",
       "      <td>1</td>\n",
       "      <td>560.00</td>\n",
       "      <td>0.048931</td>\n",
       "      <td>0.007690</td>\n",
       "      <td>555.693546</td>\n",
       "      <td>0.041561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23339</td>\n",
       "      <td>236</td>\n",
       "      <td>155.50</td>\n",
       "      <td>0.041578</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>155.103450</td>\n",
       "      <td>0.039128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5208</td>\n",
       "      <td>632</td>\n",
       "      <td>55.75</td>\n",
       "      <td>0.100604</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>54.550000</td>\n",
       "      <td>0.080819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8106</td>\n",
       "      <td>797</td>\n",
       "      <td>427.75</td>\n",
       "      <td>0.037938</td>\n",
       "      <td>0.016700</td>\n",
       "      <td>420.606600</td>\n",
       "      <td>0.021598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24154</td>\n",
       "      <td>339</td>\n",
       "      <td>45.25</td>\n",
       "      <td>0.065193</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>45.202475</td>\n",
       "      <td>0.064211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13284</td>\n",
       "      <td>236</td>\n",
       "      <td>93.75</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>93.532510</td>\n",
       "      <td>0.085879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10388</td>\n",
       "      <td>339</td>\n",
       "      <td>146.75</td>\n",
       "      <td>0.069318</td>\n",
       "      <td>0.008559</td>\n",
       "      <td>145.493972</td>\n",
       "      <td>0.061284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>12238</td>\n",
       "      <td>339</td>\n",
       "      <td>202.25</td>\n",
       "      <td>0.153318</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>200.267950</td>\n",
       "      <td>0.144938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10993</td>\n",
       "      <td>501</td>\n",
       "      <td>551.25</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>548.412037</td>\n",
       "      <td>0.057035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6935</td>\n",
       "      <td>401</td>\n",
       "      <td>106.25</td>\n",
       "      <td>0.124706</td>\n",
       "      <td>0.003301</td>\n",
       "      <td>105.899216</td>\n",
       "      <td>0.121807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  current_price  current_margin  discount_perc  \\\n",
       "10        3016             1         560.00        0.048931       0.007690   \n",
       "11       23339           236         155.50        0.041578       0.002550   \n",
       "15        5208           632          55.75        0.100604       0.021525   \n",
       "18        8106           797         427.75        0.037938       0.016700   \n",
       "21       24154           339          45.25        0.065193       0.001050   \n",
       "27       13284           236          93.75        0.088000       0.002320   \n",
       "31       10388           339         146.75        0.069318       0.008559   \n",
       "32       12238           339         202.25        0.153318       0.009800   \n",
       "36       10993           501         551.25        0.061889       0.005148   \n",
       "37        6935           401         106.25        0.124706       0.003301   \n",
       "\n",
       "    price_after_discount  margin_after_discount  \n",
       "10            555.693546               0.041561  \n",
       "11            155.103450               0.039128  \n",
       "15             54.550000               0.080819  \n",
       "18            420.606600               0.021598  \n",
       "21             45.202475               0.064211  \n",
       "27             93.532510               0.085879  \n",
       "31            145.493972               0.061284  \n",
       "32            200.267950               0.144938  \n",
       "36            548.412037               0.057035  \n",
       "37            105.899216               0.121807  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Create pricing_with_discount DataFrame\n",
    "# =============================================================================\n",
    "print(\"Creating pricing_with_discount DataFrame...\")\n",
    "\n",
    "# Copy pricing_data\n",
    "pricing_with_discount = pricing_data.copy()\n",
    "\n",
    "# Merge discount data (by warehouse_id + product_id)\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_discount[['warehouse_id', 'product_id', 'discount_perc']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing discount_perc with 0 (no discount)\n",
    "pricing_with_discount['discount_perc'] = pricing_with_discount['discount_perc'].fillna(0)\n",
    "\n",
    "# =============================================================================\n",
    "# Calculate price and margin after discount\n",
    "# =============================================================================\n",
    "# Price after discount = current_price * (1 - discount_perc)\n",
    "pricing_with_discount['price_after_discount'] = (\n",
    "    pricing_with_discount['current_price'] * (1 - pricing_with_discount['discount_perc'])\n",
    ")\n",
    "\n",
    "# Margin after discount = (price_after_discount - wac_p) / price_after_discount\n",
    "pricing_with_discount['margin_after_discount'] = (\n",
    "    (pricing_with_discount['price_after_discount'] - pricing_with_discount['wac_p']) / \n",
    "    pricing_with_discount['price_after_discount']\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICING WITH DISCOUNT DATA COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(pricing_with_discount)}\")\n",
    "print(f\"Records with discount (discount_perc > 0): {len(pricing_with_discount[pricing_with_discount['discount_perc'] > 0])}\")\n",
    "print(f\"Records without discount: {len(pricing_with_discount[pricing_with_discount['discount_perc'] == 0])}\")\n",
    "print(f\"\\nNew columns added:\")\n",
    "print(\"  - discount_perc: discount percentage from sales\")\n",
    "print(\"  - price_after_discount: current_price * (1 - discount_perc)\")\n",
    "print(\"  - margin_after_discount: (price_after_discount - wac_p) / price_after_discount\")\n",
    "print(f\"\\nSample data with discounts:\")\n",
    "pricing_with_discount[pricing_with_discount['discount_perc'] > 0][\n",
    "    ['product_id', 'warehouse_id', 'current_price', 'current_margin', \n",
    "     'discount_perc', 'price_after_discount', 'margin_after_discount']\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PRICE POSITION ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Price Position Distribution:\n",
      "price_position\n",
      "No Market Data    52380\n",
      "At 50th            2127\n",
      "At Max             1769\n",
      "At 75th            1732\n",
      "At Min             1657\n",
      "At 25th            1654\n",
      "Below Market       1566\n",
      "Above Market       1281\n",
      "Below Min           261\n",
      "\n",
      "Price Position Percentages:\n",
      "price_position\n",
      "No Market Data    81.3%\n",
      "At 50th            3.3%\n",
      "At Max            2.75%\n",
      "At 75th           2.69%\n",
      "At Min            2.57%\n",
      "At 25th           2.57%\n",
      "Below Market      2.43%\n",
      "Above Market      1.99%\n",
      "Below Min         0.41%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Sample data with price position:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>current_price</th>\n",
       "      <th>discount_perc</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>price_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>964</td>\n",
       "      <td>337</td>\n",
       "      <td>   - 130 </td>\n",
       "      <td>26.50</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>25.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1504</td>\n",
       "      <td>236</td>\n",
       "      <td>  - 1.45 </td>\n",
       "      <td>165.25</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>165.250000</td>\n",
       "      <td>165.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21793</td>\n",
       "      <td>401</td>\n",
       "      <td>  32  - 50 </td>\n",
       "      <td>124.25</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>124.250000</td>\n",
       "      <td>123.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21793</td>\n",
       "      <td>632</td>\n",
       "      <td>  32  - 50 </td>\n",
       "      <td>133.75</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>133.750000</td>\n",
       "      <td>123.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>At 50th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11403</td>\n",
       "      <td>337</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td>328.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11403</td>\n",
       "      <td>632</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td>325.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11766</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 100 </td>\n",
       "      <td>100.50</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>100.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13880</td>\n",
       "      <td>501</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>132.25</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>132.250000</td>\n",
       "      <td>130.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>Above Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3670</td>\n",
       "      <td>501</td>\n",
       "      <td>  - 0.95 </td>\n",
       "      <td>117.50</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>117.500000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>At 25th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11454</td>\n",
       "      <td>501</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td>70.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3016</td>\n",
       "      <td>1</td>\n",
       "      <td>       - 48 </td>\n",
       "      <td>560.00</td>\n",
       "      <td>0.00769</td>\n",
       "      <td>555.693546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23339</td>\n",
       "      <td>236</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>155.50</td>\n",
       "      <td>0.00255</td>\n",
       "      <td>155.103450</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19968</td>\n",
       "      <td>401</td>\n",
       "      <td>      4- 56...</td>\n",
       "      <td>329.25</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>329.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11425</td>\n",
       "      <td>703</td>\n",
       "      <td>     1 - 60 </td>\n",
       "      <td>247.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>245.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>At 25th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25352</td>\n",
       "      <td>797</td>\n",
       "      <td>   5  + 250   - 5.25...</td>\n",
       "      <td>1280.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1280.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "0          964           337   \n",
       "1         1504           236   \n",
       "2        21793           401   \n",
       "3        21793           632   \n",
       "4        11403           337   \n",
       "5        11403           632   \n",
       "6        11766           339   \n",
       "7        13880           501   \n",
       "8         3670           501   \n",
       "9        11454           501   \n",
       "10        3016             1   \n",
       "11       23339           236   \n",
       "12       19968           401   \n",
       "13       11425           703   \n",
       "14       25352           797   \n",
       "\n",
       "                                                  sku  current_price  \\\n",
       "0                         - 130           26.50   \n",
       "1                                  - 1.45          165.25   \n",
       "2                             32  - 50          124.25   \n",
       "3                             32  - 50          133.75   \n",
       "4                         - 300          328.00   \n",
       "5                         - 300          325.00   \n",
       "6                     - 100          100.50   \n",
       "7                       - 15          132.25   \n",
       "8                                  - 0.95          117.50   \n",
       "9                            - 300           70.00   \n",
       "10          - 48          560.00   \n",
       "11                         - 8          155.50   \n",
       "12        4- 56...         329.25   \n",
       "13                1 - 60          247.00   \n",
       "14     5  + 250   - 5.25...        1280.00   \n",
       "\n",
       "    discount_perc  price_after_discount  minimum  maximum  price_position  \n",
       "0         0.00000             26.500000     25.9     26.5          At Max  \n",
       "1         0.00000            165.250000    165.0    175.0          At Min  \n",
       "2         0.00000            124.250000    123.0    145.0          At Min  \n",
       "3         0.00000            133.750000    123.0    145.0         At 50th  \n",
       "4         0.00000            328.000000      NaN      NaN  No Market Data  \n",
       "5         0.00000            325.000000      NaN      NaN  No Market Data  \n",
       "6         0.00000            100.500000      NaN      NaN  No Market Data  \n",
       "7         0.00000            132.250000    130.0    130.0    Above Market  \n",
       "8         0.00000            117.500000    110.0    130.0         At 25th  \n",
       "9         0.00000             70.000000      NaN      NaN  No Market Data  \n",
       "10        0.00769            555.693546      NaN      NaN  No Market Data  \n",
       "11        0.00255            155.103450      NaN      NaN  No Market Data  \n",
       "12        0.00000            329.250000      NaN      NaN  No Market Data  \n",
       "13        0.00000            247.000000    245.0    267.0         At 25th  \n",
       "14        0.00000           1280.000000      NaN      NaN  No Market Data  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Price Position - Determine where price_after_discount falls in market tiers\n",
    "# =============================================================================\n",
    "\n",
    "def get_price_position(row):\n",
    "    \"\"\"Determine the price position relative to market price tiers.\"\"\"\n",
    "    price = row['price_after_discount']\n",
    "    wac = row['wac_p']\n",
    "    \n",
    "    # Check if we have market data (minimum price exists)\n",
    "    if pd.isna(row['minimum']) or pd.isna(price):\n",
    "        return \"No Market Data\"\n",
    "    \n",
    "    # Get price tiers\n",
    "    min_price = row['minimum']\n",
    "    p25 = row['percentile_25']\n",
    "    p50 = row['percentile_50']\n",
    "    p75 = row['percentile_75']\n",
    "    max_price = row['maximum']\n",
    "    \n",
    "    # Calculate below_market and above_market prices from margins\n",
    "    # margin = (price - wac) / price  =>  price = wac / (1 - margin)\n",
    "    below_market_margin = row['below_market']\n",
    "    above_market_margin = row['above_market']\n",
    "    \n",
    "    below_market_price = wac / (1 - below_market_margin) if below_market_margin < 1 else min_price\n",
    "    above_market_price = wac / (1 - above_market_margin) if above_market_margin < 1 else max_price\n",
    "    \n",
    "    # Determine position based on price tiers\n",
    "    if price < below_market_price:\n",
    "        return \"Below Market\"\n",
    "    elif price < min_price:\n",
    "        return \"Below Min\"\n",
    "    elif price < p25:\n",
    "        return \"At Min\"\n",
    "    elif price < p50:\n",
    "        return \"At 25th\"\n",
    "    elif price < p75:\n",
    "        return \"At 50th\"\n",
    "    elif price < max_price:\n",
    "        return \"At 75th\"\n",
    "    elif price < above_market_price:\n",
    "        return \"At Max\"\n",
    "    else:\n",
    "        return \"Above Market\"\n",
    "\n",
    "# Apply price position function\n",
    "pricing_with_discount['price_position'] = pricing_with_discount.apply(get_price_position, axis=1)\n",
    "\n",
    "# Summary of price positions\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICE POSITION ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nPrice Position Distribution:\")\n",
    "print(pricing_with_discount['price_position'].value_counts().to_string())\n",
    "print(f\"\\nPrice Position Percentages:\")\n",
    "print((pricing_with_discount['price_position'].value_counts(normalize=True) * 100).round(2).astype(str) + '%')\n",
    "\n",
    "# Sample data showing price position\n",
    "print(f\"\\nSample data with price position:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'current_price', 'discount_perc', \n",
    "     'price_after_discount', 'minimum', 'maximum', 'price_position']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stock data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1833478 stock records\n",
      "\n",
      "Stock data merged!\n",
      "Records with stock (stocks > 0): 13640\n",
      "Records without stock (stocks = 0): 50787\n",
      "\n",
      "Sample data with stocks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>stocks</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>price_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>964</td>\n",
       "      <td>337</td>\n",
       "      <td>   - 130 </td>\n",
       "      <td>2</td>\n",
       "      <td>26.50</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1504</td>\n",
       "      <td>236</td>\n",
       "      <td>  - 1.45 </td>\n",
       "      <td>319</td>\n",
       "      <td>165.25</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21793</td>\n",
       "      <td>401</td>\n",
       "      <td>  32  - 50 </td>\n",
       "      <td>5</td>\n",
       "      <td>124.25</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21793</td>\n",
       "      <td>632</td>\n",
       "      <td>  32  - 50 </td>\n",
       "      <td>167</td>\n",
       "      <td>133.75</td>\n",
       "      <td>At 50th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11403</td>\n",
       "      <td>337</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td>1</td>\n",
       "      <td>328.00</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11403</td>\n",
       "      <td>632</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td>46</td>\n",
       "      <td>325.00</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11766</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 100 </td>\n",
       "      <td>0</td>\n",
       "      <td>100.50</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13880</td>\n",
       "      <td>501</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>0</td>\n",
       "      <td>132.25</td>\n",
       "      <td>Above Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3670</td>\n",
       "      <td>501</td>\n",
       "      <td>  - 0.95 </td>\n",
       "      <td>0</td>\n",
       "      <td>117.50</td>\n",
       "      <td>At 25th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11454</td>\n",
       "      <td>501</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td>0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  warehouse_id                                  sku  stocks  \\\n",
       "0         964           337          - 130        2   \n",
       "1        1504           236                   - 1.45      319   \n",
       "2       21793           401              32  - 50        5   \n",
       "3       21793           632              32  - 50      167   \n",
       "4       11403           337          - 300        1   \n",
       "5       11403           632          - 300       46   \n",
       "6       11766           339      - 100        0   \n",
       "7       13880           501        - 15        0   \n",
       "8        3670           501                   - 0.95        0   \n",
       "9       11454           501             - 300        0   \n",
       "\n",
       "   price_after_discount  price_position  \n",
       "0                 26.50          At Max  \n",
       "1                165.25          At Min  \n",
       "2                124.25          At Min  \n",
       "3                133.75         At 50th  \n",
       "4                328.00  No Market Data  \n",
       "5                325.00  No Market Data  \n",
       "6                100.50  No Market Data  \n",
       "7                132.25    Above Market  \n",
       "8                117.50         At 25th  \n",
       "9                 70.00  No Market Data  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Stock Query - Get available stock by warehouse and product\n",
    "# =============================================================================\n",
    "STOCK_QUERY = '''\n",
    "SELECT \n",
    "    pw.warehouse_id,\n",
    "    pw.product_id,\n",
    "    pw.available_stock::INTEGER AS stocks\n",
    "FROM product_warehouse pw\n",
    "WHERE pw.warehouse_id NOT IN (6, 9, 10)\n",
    "    AND pw.is_basic_unit = 1\n",
    "'''\n",
    "\n",
    "# Execute stock query\n",
    "print(\"Loading stock data...\")\n",
    "df_stocks = query_snowflake(STOCK_QUERY)\n",
    "df_stocks = convert_to_numeric(df_stocks)\n",
    "print(f\"Loaded {len(df_stocks)} stock records\")\n",
    "\n",
    "# Merge stock data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_stocks[['warehouse_id', 'product_id', 'stocks']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing stocks with 0\n",
    "pricing_with_discount['stocks'] = pricing_with_discount['stocks'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"\\nStock data merged!\")\n",
    "print(f\"Records with stock (stocks > 0): {len(pricing_with_discount[pricing_with_discount['stocks'] > 0])}\")\n",
    "print(f\"Records without stock (stocks = 0): {len(pricing_with_discount[pricing_with_discount['stocks'] == 0])}\")\n",
    "print(f\"\\nSample data with stocks:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'stocks', 'price_after_discount', 'price_position']\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading zero demand SKUs...\n",
      "Loaded 3974 zero demand SKU records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Zero Demand Query - Identify SKUs with zero/low demand\n",
    "# =============================================================================\n",
    "ZERO_DEMAND_QUERY = f'''\n",
    "WITH last_oss AS (\n",
    "    SELECT product_id, warehouse_id, TIMESTAMP AS last_in_stock_day\n",
    "    FROM (\n",
    "        SELECT *, ROW_NUMBER() OVER(PARTITION BY product_id, warehouse_id ORDER BY TIMESTAMP DESC) AS rnk \n",
    "        FROM materialized_views.STOCK_DAY_CLOSE\n",
    "        WHERE AVAILABLE_STOCK = 0 \n",
    "            AND TIMESTAMP >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "        QUALIFY rnk = 1 \n",
    "    )\n",
    "),\n",
    "\n",
    "current_stocks AS (\n",
    "    SELECT product_id, warehouse_id, AVAILABLE_STOCK, activation\n",
    "    FROM PRODUCT_WAREHOUSE\n",
    "    WHERE IS_BASIC_UNIT = 1\n",
    "        AND CASE WHEN product_id = 1309 THEN packing_unit_id <> 23 ELSE TRUE END\n",
    "),\n",
    "\n",
    "prs AS (\n",
    "    SELECT DISTINCT \n",
    "        product_purchased_receipts.product_id,\n",
    "        purchased_receipts.warehouse_id,\n",
    "        purchased_receipts.date::DATE AS date,\n",
    "        product_purchased_receipts.purchased_item_count * product_purchased_receipts.basic_unit_count AS purchase_min_count\n",
    "    FROM product_purchased_receipts\n",
    "    JOIN purchased_receipts ON purchased_receipts.id = product_purchased_receipts.purchased_receipt_id\n",
    "    JOIN last_oss lo ON product_purchased_receipts.product_id = lo.product_id \n",
    "        AND lo.warehouse_id = purchased_receipts.warehouse_id \n",
    "        AND purchased_receipts.date > lo.last_in_stock_day \n",
    "    WHERE product_purchased_receipts.purchased_item_count <> 0\n",
    "        AND purchased_receipts.purchased_receipt_status_id IN (4, 5, 7)\n",
    "        AND purchased_receipts.date::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "),\n",
    "\n",
    "main AS (\n",
    "    SELECT \n",
    "        prs.product_id, \n",
    "        prs.warehouse_id, \n",
    "        MIN(date) AS first_order_date, \n",
    "        SUM(purchase_min_count) AS total_recieved, \n",
    "        cs.AVAILABLE_STOCK, \n",
    "        cs.activation\n",
    "    FROM prs \n",
    "    JOIN current_stocks cs ON cs.product_id = prs.product_id AND prs.warehouse_id = cs.warehouse_id\n",
    "    GROUP BY prs.product_id, prs.warehouse_id, cs.AVAILABLE_STOCK, cs.activation\n",
    "),\n",
    "\n",
    "sold_days AS (\n",
    "    SELECT product_id, warehouse_id, COUNT(DISTINCT o_date) AS sales_days\n",
    "    FROM (\n",
    "        SELECT DISTINCT\n",
    "            so.created_at::DATE AS o_date,\n",
    "            pso.warehouse_id,\n",
    "            pso.product_id,\n",
    "            SUM(pso.purchased_item_count * basic_unit_count) AS daily_qty\n",
    "        FROM product_sales_order pso\n",
    "        JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "        JOIN main m ON m.product_id = pso.product_id \n",
    "            AND m.warehouse_id = pso.warehouse_id \n",
    "            AND so.created_at::DATE >= m.first_order_date\n",
    "        WHERE so.created_at::DATE BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120 \n",
    "            AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "            AND so.sales_order_status_id NOT IN (7, 12)\n",
    "            AND so.channel IN ('telesales', 'retailer')\n",
    "            AND pso.purchased_item_count <> 0\n",
    "        GROUP BY o_date, pso.warehouse_id, pso.product_id\n",
    "    )\n",
    "    GROUP BY product_id, warehouse_id\n",
    ")\n",
    "\n",
    "SELECT DISTINCT warehouse_id, product_id\n",
    "FROM (\n",
    "    SELECT m.product_id, m.warehouse_id, m.first_order_date, m.activation,\n",
    "        COALESCE(sd.sales_days, 0) AS sales_days,\n",
    "        COALESCE(sd.sales_days, 0)::FLOAT / NULLIF((CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1) - m.first_order_date, 0) AS perc_days\n",
    "    FROM main m \n",
    "    LEFT JOIN sold_days sd ON sd.product_id = m.product_id AND sd.warehouse_id = m.warehouse_id\n",
    "    WHERE m.first_order_date < CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 10\n",
    ")\n",
    "WHERE perc_days <= 0.3\n",
    "    AND activation = 'true'\n",
    "'''\n",
    "\n",
    "# Execute zero demand query\n",
    "print(\"Loading zero demand SKUs...\")\n",
    "df_zero_demand = query_snowflake(ZERO_DEMAND_QUERY)\n",
    "df_zero_demand = convert_to_numeric(df_zero_demand)\n",
    "print(f\"Loaded {len(df_zero_demand)} zero demand SKU records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero demand flag added!\n",
      "SKUs flagged as zero demand: 2793\n",
      "SKUs with normal demand: 61634\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Zero Demand Flag to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Add a marker column to identify zero demand SKUs\n",
    "df_zero_demand['zero_demand'] = 1\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_zero_demand[['warehouse_id', 'product_id', 'zero_demand']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values with 0 (not zero demand)\n",
    "pricing_with_discount['zero_demand'] = pricing_with_discount['zero_demand'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"Zero demand flag added!\")\n",
    "print(f\"SKUs flagged as zero demand: {len(pricing_with_discount[pricing_with_discount['zero_demand'] == 1])}\")\n",
    "print(f\"SKUs with normal demand: {len(pricing_with_discount[pricing_with_discount['zero_demand'] == 0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OOS yesterday data...\n",
      "Loaded 1882448 OOS yesterday records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OOS Yesterday Query - Identify SKUs out of stock yesterday\n",
    "# =============================================================================\n",
    "OOS_YESTERDAY_QUERY = f'''\n",
    "SELECT DISTINCT product_id, warehouse_id,\n",
    "    CASE WHEN opening_stocks = 0 AND closing_stocks = 0 THEN 1\n",
    "         ELSE 0 \n",
    "    END AS oos_yesterday\n",
    "FROM (\n",
    "    SELECT \n",
    "        timestamp,\n",
    "        product_id,\n",
    "        warehouse_id, \n",
    "        AVAILABLE_STOCK AS closing_stocks,\n",
    "        LAG(AVAILABLE_STOCK) OVER (PARTITION BY product_id, warehouse_id ORDER BY TIMESTAMP) AS opening_stocks\n",
    "    FROM materialized_views.stock_day_close\n",
    "    WHERE timestamp::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 2\n",
    "    QUALIFY opening_stocks IS NOT NULL\n",
    ")\n",
    "WHERE oos_yesterday = 1\n",
    "'''\n",
    "\n",
    "# Execute OOS yesterday query\n",
    "print(\"Loading OOS yesterday data...\")\n",
    "df_oos_yesterday = query_snowflake(OOS_YESTERDAY_QUERY)\n",
    "df_oos_yesterday = convert_to_numeric(df_oos_yesterday)\n",
    "print(f\"Loaded {len(df_oos_yesterday)} OOS yesterday records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS yesterday flag added!\n",
      "SKUs out of stock yesterday: 50431\n",
      "SKUs in stock yesterday: 13996\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add OOS Yesterday Flag to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_oos_yesterday[['warehouse_id', 'product_id', 'oos_yesterday']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values with 0 (not OOS yesterday)\n",
    "pricing_with_discount['oos_yesterday'] = pricing_with_discount['oos_yesterday'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"OOS yesterday flag added!\")\n",
    "print(f\"SKUs out of stock yesterday: {len(pricing_with_discount[pricing_with_discount['oos_yesterday'] == 1])}\")\n",
    "print(f\"SKUs in stock yesterday: {len(pricing_with_discount[pricing_with_discount['oos_yesterday'] == 0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading running rate data (this may take a moment)...\n",
      "Loaded 22191 running rate records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Running Rate Query - Get in-stock running rate by warehouse and product\n",
    "# =============================================================================\n",
    "RUNNING_RATE_QUERY = f'''\n",
    "WITH params AS (\n",
    "    SELECT\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE AS run_date,\n",
    "        DATEADD(month, -3, CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE) AS history_start\n",
    "),\n",
    "\n",
    "-- Daily sales aggregation\n",
    "sales_base AS (\n",
    "    SELECT\n",
    "        pso.product_id,\n",
    "        pso.warehouse_id,\n",
    "        DATE_TRUNC('day', pso.created_at)::DATE AS date,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count) AS sold_units,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count * pso.item_price)\n",
    "            / NULLIF(SUM(pso.purchased_item_count * pso.basic_unit_count), 0) AS avg_selling_price,\n",
    "        COUNT(DISTINCT so.retailer_id) AS retailer_count\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON pso.sales_order_id = so.id\n",
    "    WHERE DATE_TRUNC('day', pso.created_at)::DATE >= (SELECT history_start FROM params)\n",
    "    GROUP BY 1, 2, 3\n",
    "),\n",
    "\n",
    "-- Stock daily metrics\n",
    "stock_daily AS (\n",
    "    SELECT\n",
    "        product_id,\n",
    "        warehouse_id,\n",
    "        DATE_TRUNC('day', TIMESTAMP)::DATE AS date,\n",
    "        MAX_BY(available_stock, TIMESTAMP) AS stock_closing,\n",
    "        24 * SUM(CASE WHEN activation = FALSE OR available_stock = 0 THEN 1 ELSE 0 END)::FLOAT \n",
    "            / NULLIF(COUNT(*), 0) AS oos_hours,\n",
    "        MAX(CASE WHEN activation = TRUE AND available_stock > 0 THEN 1 ELSE 0 END) AS in_stock_flag\n",
    "    FROM materialized_views.STOCK_SNAP_SHOTS_RECENT\n",
    "    WHERE product_id IS NOT NULL\n",
    "    GROUP BY product_id, warehouse_id, date\n",
    "),\n",
    "\n",
    "-- Join sales + stock + WAC (only in-stock days)\n",
    "base_data AS (\n",
    "    SELECT\n",
    "        sb.product_id,\n",
    "        sb.warehouse_id,\n",
    "        sb.date,\n",
    "        sb.sold_units,\n",
    "        sb.avg_selling_price,\n",
    "        sb.retailer_count,\n",
    "        sd.oos_hours,\n",
    "        sd.in_stock_flag,\n",
    "        ac.wac_p AS wac,\n",
    "        CASE WHEN DAYOFWEEKISO(sb.date) IN (5, 6) THEN 1 ELSE 0 END AS is_weekend\n",
    "    FROM sales_base sb\n",
    "    LEFT JOIN stock_daily sd ON sb.product_id = sd.product_id \n",
    "        AND sb.warehouse_id = sd.warehouse_id AND sb.date = sd.date\n",
    "    LEFT JOIN finance.ALL_COGS ac ON sb.product_id = ac.product_id \n",
    "        AND sb.date BETWEEN ac.from_date AND ac.to_date\n",
    "    WHERE sd.in_stock_flag = 1\n",
    "),\n",
    "\n",
    "-- Stats per SKU x Warehouse\n",
    "sku_wh_stats AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY sold_units) AS med_units,\n",
    "        PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY sold_units) AS pct95_units,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY retailer_count) AS med_retailers,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY \n",
    "            CASE WHEN avg_selling_price IS NULL OR avg_selling_price = 0 THEN 0 \n",
    "            ELSE (avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0) END\n",
    "        ) AS med_margin\n",
    "    FROM base_data\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Cap outliers and adjust for retailer spikes\n",
    "adjusted AS (\n",
    "    SELECT\n",
    "        b.product_id, b.warehouse_id, b.date, b.in_stock_flag, b.oos_hours, b.is_weekend,\n",
    "        b.avg_selling_price, b.wac, s.med_margin,\n",
    "        CASE \n",
    "            WHEN b.retailer_count > GREATEST(2, s.med_retailers * 2) \n",
    "                AND b.retailer_count > 0 AND s.med_retailers IS NOT NULL\n",
    "            THEN ROUND(LEAST(b.sold_units, s.pct95_units) * (s.med_retailers::FLOAT / NULLIF(b.retailer_count::FLOAT, 0)), 0)\n",
    "            ELSE LEAST(b.sold_units, s.pct95_units)\n",
    "        END AS units_adjusted\n",
    "    FROM base_data b\n",
    "    LEFT JOIN sku_wh_stats s ON b.product_id = s.product_id AND b.warehouse_id = s.warehouse_id\n",
    "),\n",
    "\n",
    "-- Apply weights (recency, stock availability, weekend, margin)\n",
    "weighted AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id, date, units_adjusted,\n",
    "        (\n",
    "            -- Recency weight\n",
    "            CASE WHEN date >= DATEADD(day, -21, (SELECT run_date FROM params)) THEN 1.5\n",
    "                 WHEN date >= DATEADD(day, -90, (SELECT run_date FROM params)) THEN 1.0\n",
    "                 ELSE 0.5 END\n",
    "            -- In-stock weight\n",
    "            * CASE WHEN in_stock_flag = 1 AND COALESCE(oos_hours, 0) < 12 THEN 1.4\n",
    "                   WHEN in_stock_flag = 1 AND COALESCE(oos_hours, 0) >= 12 THEN 0.9\n",
    "                   ELSE 0.6 END\n",
    "            -- Weekend weight\n",
    "            * CASE WHEN is_weekend = 1 THEN 0.7 ELSE 1.0 END\n",
    "            -- Margin weight\n",
    "            * CASE WHEN avg_selling_price IS NULL OR avg_selling_price = 0 OR med_margin IS NULL THEN 1.0\n",
    "                   WHEN ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) < med_margin\n",
    "                   THEN 1.0 + LEAST((med_margin - ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0))) * 2.0, 0.6)\n",
    "                   WHEN ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) > med_margin\n",
    "                   THEN 1.0 - LEAST((((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) - med_margin) * 2.0, 0.4)\n",
    "                   ELSE 1.0 END\n",
    "        ) AS final_weight\n",
    "    FROM adjusted\n",
    "    WHERE units_adjusted IS NOT NULL\n",
    "),\n",
    "\n",
    "-- Weighted average forecast\n",
    "forecast_base AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id,\n",
    "        SUM(units_adjusted * final_weight) / NULLIF(SUM(final_weight), 0) AS weighted_avg_units\n",
    "    FROM weighted\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Zero-sales last 4 days (with stock) exclusion flag\n",
    "last4_flag AS (\n",
    "    SELECT product_id, warehouse_id,\n",
    "        CASE WHEN COUNT(*) = 4 \n",
    "             AND SUM(CASE WHEN COALESCE(sold_units, 0) = 0 AND in_stock_flag = 1 THEN 1 ELSE 0 END) = 4\n",
    "        THEN 1 ELSE 0 END AS exclude_flag\n",
    "    FROM base_data\n",
    "    WHERE date >= DATEADD(day, -4, (SELECT run_date FROM params)) \n",
    "        AND date < (SELECT run_date FROM params)\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Zero sales excluded (in stock but no sales)\n",
    "zero_sales_excluded AS (\n",
    "    SELECT DISTINCT s.warehouse_id, s.product_id\n",
    "    FROM (\n",
    "        SELECT pw.warehouse_id, pw.product_id, SUM(pw.available_stock)::INT AS stocks\n",
    "        FROM product_warehouse pw\n",
    "        WHERE pw.warehouse_id NOT IN (6, 9, 10) AND pw.is_basic_unit = 1 AND pw.available_stock > 0\n",
    "        GROUP BY pw.warehouse_id, pw.product_id\n",
    "    ) s\n",
    "    LEFT JOIN (\n",
    "        SELECT pso.product_id, pso.warehouse_id, SUM(pso.total_price) AS nmv\n",
    "        FROM product_sales_order pso\n",
    "        JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "        WHERE so.created_at::date BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 5 \n",
    "            AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1\n",
    "            AND so.sales_order_status_id NOT IN (7, 12) AND so.channel IN ('telesales', 'retailer')\n",
    "            AND pso.purchased_item_count <> 0\n",
    "        GROUP BY pso.product_id, pso.warehouse_id\n",
    "    ) md ON md.product_id = s.product_id AND md.warehouse_id = s.warehouse_id\n",
    "    LEFT JOIN finance.all_cogs f ON f.product_id = s.product_id\n",
    "        AND f.from_date::date <= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "        AND f.to_date::date > CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "    LEFT JOIN (\n",
    "        SELECT pr.warehouse_id, ppr.product_id, SUM(ppr.final_price) AS total_prs\n",
    "        FROM product_purchased_receipts ppr\n",
    "        JOIN purchased_receipts pr ON pr.id = ppr.purchased_receipt_id\n",
    "        WHERE pr.date::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 4\n",
    "            AND pr.is_actual = 'true' AND pr.purchased_receipt_status_id IN (4, 5, 7)\n",
    "            AND ppr.purchased_item_count <> 0\n",
    "        GROUP BY pr.warehouse_id, ppr.product_id\n",
    "    ) prs ON prs.product_id = s.product_id AND prs.warehouse_id = s.warehouse_id\n",
    "    WHERE COALESCE(md.nmv, 0) = 0 \n",
    "        AND COALESCE(prs.total_prs, 0) < 0.7 * (COALESCE(f.wac_p, 0) * s.stocks)\n",
    "),\n",
    "\n",
    "-- First sale date for new products\n",
    "first_sale AS (\n",
    "    SELECT product_id, warehouse_id, MIN(date) AS first_sale_date\n",
    "    FROM base_data WHERE sold_units > 0\n",
    "    GROUP BY product_id, warehouse_id\n",
    ")\n",
    "\n",
    "-- Final output: running rate per warehouse/product\n",
    "SELECT\n",
    "    fb.warehouse_id,\n",
    "    fb.product_id,\n",
    "    CASE\n",
    "        WHEN l4.exclude_flag = 1 THEN 0\n",
    "        WHEN fs.first_sale_date >= DATEADD(day, -2, (SELECT run_date FROM params))\n",
    "        THEN GREATEST(CEIL(fb.weighted_avg_units), 1)\n",
    "        ELSE CEIL(fb.weighted_avg_units)\n",
    "    END AS In_stock_rr\n",
    "FROM forecast_base fb\n",
    "LEFT JOIN last4_flag l4 ON fb.product_id = l4.product_id AND fb.warehouse_id = l4.warehouse_id\n",
    "LEFT JOIN first_sale fs ON fb.product_id = fs.product_id AND fb.warehouse_id = fs.warehouse_id\n",
    "LEFT JOIN zero_sales_excluded zse ON fb.product_id = zse.product_id AND fb.warehouse_id = zse.warehouse_id\n",
    "WHERE zse.product_id IS NULL\n",
    "'''\n",
    "\n",
    "# Execute running rate query\n",
    "print(\"Loading running rate data (this may take a moment)...\")\n",
    "df_running_rate = query_snowflake(RUNNING_RATE_QUERY)\n",
    "df_running_rate = convert_to_numeric(df_running_rate)\n",
    "print(f\"Loaded {len(df_running_rate)} running rate records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Merge Running Rate and Calculate DOH (Days on Hand)\n",
    "# =============================================================================\n",
    "\n",
    "# Merge running rate data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_running_rate[['warehouse_id', 'product_id', 'in_stock_rr']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing running rate with 0\n",
    "pricing_with_discount['in_stock_rr'] = pricing_with_discount['in_stock_rr'].fillna(0)\n",
    "\n",
    "# Calculate DOH (Days on Hand) = stocks / in_stock_rr\n",
    "# Handle division by zero - if running rate is 0, DOH is infinite (use 999)\n",
    "pricing_with_discount['doh'] = np.select(\n",
    "    [\n",
    "        (pricing_with_discount['in_stock_rr'] > 0) & (pricing_with_discount['stocks'] > 0),\n",
    "        pricing_with_discount['stocks'] == 0\n",
    "    ],\n",
    "    [\n",
    "        pricing_with_discount['stocks'] / pricing_with_discount['in_stock_rr'],\n",
    "        0\n",
    "    ],\n",
    "    default=999\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading product classification data...\n",
      "Loaded 27433 product classification records\n",
      "\n",
      "Classification distribution:\n",
      "abc_class\n",
      "C    20787\n",
      "B     5487\n",
      "A     1159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Product Classification Query - ABC Classification based on order contribution\n",
    "# =============================================================================\n",
    "PRODUCT_CLASSIFICATION_QUERY = f'''\n",
    "WITH order_counts AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        COUNT(DISTINCT pso.sales_order_id) AS order_count\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 90\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id\n",
    "),\n",
    "\n",
    "warehouse_totals AS (\n",
    "    SELECT \n",
    "        warehouse_id,\n",
    "        SUM(order_count) AS total_orders\n",
    "    FROM order_counts\n",
    "    GROUP BY warehouse_id\n",
    "),\n",
    "\n",
    "ranked_products AS (\n",
    "    SELECT \n",
    "        oc.warehouse_id,\n",
    "        oc.product_id,\n",
    "        oc.order_count,\n",
    "        wt.total_orders,\n",
    "        oc.order_count::FLOAT / NULLIF(wt.total_orders, 0) AS contribution,\n",
    "        SUM(oc.order_count::FLOAT / NULLIF(wt.total_orders, 0)) \n",
    "            OVER (PARTITION BY oc.warehouse_id ORDER BY oc.order_count DESC \n",
    "                  ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_contribution\n",
    "    FROM order_counts oc\n",
    "    JOIN warehouse_totals wt ON oc.warehouse_id = wt.warehouse_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    warehouse_id,\n",
    "    product_id,\n",
    "    order_count,\n",
    "    contribution,\n",
    "    cumulative_contribution,\n",
    "    CASE \n",
    "        WHEN cumulative_contribution <= 0.4 THEN 'A'\n",
    "        WHEN cumulative_contribution <= 0.8 THEN 'B'\n",
    "        ELSE 'C'\n",
    "    END AS abc_class\n",
    "FROM ranked_products\n",
    "'''\n",
    "\n",
    "# Execute product classification query\n",
    "print(\"Loading product classification data...\")\n",
    "df_classification = query_snowflake(PRODUCT_CLASSIFICATION_QUERY)\n",
    "df_classification = convert_to_numeric(df_classification)\n",
    "print(f\"Loaded {len(df_classification)} product classification records\")\n",
    "print(f\"\\nClassification distribution:\")\n",
    "print(df_classification['abc_class'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC Classification added!\n",
      "\n",
      "Classification in pricing_with_discount:\n",
      "abc_class\n",
      "C    59956\n",
      "B     3698\n",
      "A      773\n",
      "\n",
      "Sample data with classification:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>order_count</th>\n",
       "      <th>contribution</th>\n",
       "      <th>abc_class</th>\n",
       "      <th>stocks</th>\n",
       "      <th>doh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>964</td>\n",
       "      <td>337</td>\n",
       "      <td>   - 130 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1504</td>\n",
       "      <td>236</td>\n",
       "      <td>  - 1.45 </td>\n",
       "      <td>810</td>\n",
       "      <td>0.001481</td>\n",
       "      <td>B</td>\n",
       "      <td>319</td>\n",
       "      <td>12.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21793</td>\n",
       "      <td>401</td>\n",
       "      <td>  32  - 50 </td>\n",
       "      <td>272</td>\n",
       "      <td>0.003122</td>\n",
       "      <td>B</td>\n",
       "      <td>5</td>\n",
       "      <td>0.151515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21793</td>\n",
       "      <td>632</td>\n",
       "      <td>  32  - 50 </td>\n",
       "      <td>122</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>B</td>\n",
       "      <td>167</td>\n",
       "      <td>7.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11403</td>\n",
       "      <td>337</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td>33</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11403</td>\n",
       "      <td>632</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td>14</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>C</td>\n",
       "      <td>46</td>\n",
       "      <td>15.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11766</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 100 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13880</td>\n",
       "      <td>501</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3670</td>\n",
       "      <td>501</td>\n",
       "      <td>  - 0.95 </td>\n",
       "      <td>473</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11454</td>\n",
       "      <td>501</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3016</td>\n",
       "      <td>1</td>\n",
       "      <td>       - 48 </td>\n",
       "      <td>622</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>B</td>\n",
       "      <td>9</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23339</td>\n",
       "      <td>236</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>385</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>B</td>\n",
       "      <td>68</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19968</td>\n",
       "      <td>401</td>\n",
       "      <td>      4- 56...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>C</td>\n",
       "      <td>21</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11425</td>\n",
       "      <td>703</td>\n",
       "      <td>     1 - 60 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25352</td>\n",
       "      <td>797</td>\n",
       "      <td>   5  + 250   - 5.25...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "0          964           337   \n",
       "1         1504           236   \n",
       "2        21793           401   \n",
       "3        21793           632   \n",
       "4        11403           337   \n",
       "5        11403           632   \n",
       "6        11766           339   \n",
       "7        13880           501   \n",
       "8         3670           501   \n",
       "9        11454           501   \n",
       "10        3016             1   \n",
       "11       23339           236   \n",
       "12       19968           401   \n",
       "13       11425           703   \n",
       "14       25352           797   \n",
       "\n",
       "                                                  sku  order_count  \\\n",
       "0                         - 130             0   \n",
       "1                                  - 1.45           810   \n",
       "2                             32  - 50           272   \n",
       "3                             32  - 50           122   \n",
       "4                         - 300            33   \n",
       "5                         - 300            14   \n",
       "6                     - 100             0   \n",
       "7                       - 15             0   \n",
       "8                                  - 0.95           473   \n",
       "9                            - 300             0   \n",
       "10          - 48           622   \n",
       "11                         - 8           385   \n",
       "12        4- 56...           10   \n",
       "13                1 - 60             0   \n",
       "14     5  + 250   - 5.25...            0   \n",
       "\n",
       "    contribution abc_class  stocks         doh  \n",
       "0       0.000000         C       2  999.000000  \n",
       "1       0.001481         B     319   12.760000  \n",
       "2       0.003122         B       5    0.151515  \n",
       "3       0.001320         B     167    7.260870  \n",
       "4       0.000151         C       1    0.090909  \n",
       "5       0.000151         C      46   15.333333  \n",
       "6       0.000000         C       0    0.000000  \n",
       "7       0.000000         C       0    0.000000  \n",
       "8       0.003635         B       0    0.000000  \n",
       "9       0.000000         C       0    0.000000  \n",
       "10      0.000688         B       9    0.818182  \n",
       "11      0.000704         B      68    8.500000  \n",
       "12      0.000115         C      21  999.000000  \n",
       "13      0.000000         C       0    0.000000  \n",
       "14      0.000000         C       0    0.000000  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add ABC Classification to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge classification data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_classification[['warehouse_id', 'product_id', 'order_count', 'contribution', 'abc_class']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values - products without orders in last 3 months get class 'C'\n",
    "pricing_with_discount['order_count'] = pricing_with_discount['order_count'].fillna(0).astype(int)\n",
    "pricing_with_discount['contribution'] = pricing_with_discount['contribution'].fillna(0)\n",
    "pricing_with_discount['abc_class'] = pricing_with_discount['abc_class'].fillna('C')\n",
    "\n",
    "print(f\"ABC Classification added!\")\n",
    "print(f\"\\nClassification in pricing_with_discount:\")\n",
    "print(pricing_with_discount['abc_class'].value_counts().to_string())\n",
    "print(f\"\\nSample data with classification:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'order_count', 'contribution', 'abc_class', 'stocks', 'doh']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PO data...\n",
      "Loaded 16456 PO records\n",
      "\n",
      "Confirmation status distribution:\n",
      "confirmation_status\n",
      "yes    8874\n",
      "no     1786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PO (Purchase Order) Data Query - Last PO status and rejection count\n",
    "# =============================================================================\n",
    "PO_DATA_QUERY = '''\n",
    "WITH last_data AS (\n",
    "    SELECT product_id, warehouse_id, confirmation_status, PO_date::DATE AS last_po_date, ordered_qty\n",
    "    FROM (\n",
    "        SELECT \n",
    "            product_id,\n",
    "            Target_WAREHOUSE_ID AS warehouse_id,\n",
    "            confirmation_status,\n",
    "            created_at AS PO_date,\n",
    "            MIN_QUANTITY AS ordered_qty,\n",
    "            reason,\n",
    "            MAX(created_at) OVER (PARTITION BY product_id, Target_WAREHOUSE_ID) AS last_po\n",
    "        FROM retool.PO_INITIAL_PLAN\n",
    "        WHERE created_at::DATE >= CURRENT_DATE - 15 \n",
    "    ) x\n",
    "    WHERE last_po = PO_date\n",
    "),\n",
    "\n",
    "last_15_data AS (\n",
    "    SELECT \n",
    "        product_id,\n",
    "        target_WAREHOUSE_ID AS warehouse_id,\n",
    "        COUNT(DISTINCT CASE WHEN confirmation_status <> 'yes' THEN created_at END) AS no_last_15\n",
    "    FROM retool.PO_INITIAL_PLAN\n",
    "    WHERE created_at::DATE >= CURRENT_DATE - 15 \n",
    "    GROUP BY 1, 2\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    ld.product_id,\n",
    "    ld.warehouse_id,\n",
    "    ld.confirmation_status,\n",
    "    ld.last_po_date,\n",
    "    ld.ordered_qty,\n",
    "    COALESCE(lfd.no_last_15, 0) AS no_last_15\n",
    "FROM last_data ld \n",
    "LEFT JOIN last_15_data lfd \n",
    "    ON lfd.product_id = ld.product_id \n",
    "    AND lfd.warehouse_id = ld.warehouse_id\n",
    "'''\n",
    "\n",
    "# Execute PO data query using dwh_pg_query\n",
    "print(\"Loading PO data...\")\n",
    "df_po_data = setup_environment_2.dwh_pg_query(\n",
    "    PO_DATA_QUERY, \n",
    "    columns=['product_id', 'warehouse_id', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']\n",
    ")\n",
    "df_po_data.columns = df_po_data.columns.str.lower()\n",
    "df_po_data = convert_to_numeric(df_po_data)\n",
    "print(f\"Loaded {len(df_po_data)} PO records\")\n",
    "print(f\"\\nConfirmation status distribution:\")\n",
    "print(df_po_data['confirmation_status'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO data added!\n",
      "\n",
      "Records with PO data: 7220\n",
      "Records without PO data: 57207\n",
      "\n",
      "Sample data with PO info:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>confirmation_status</th>\n",
       "      <th>last_po_date</th>\n",
       "      <th>ordered_qty</th>\n",
       "      <th>no_last_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1504</td>\n",
       "      <td>236</td>\n",
       "      <td>  - 1.45 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-12</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21793</td>\n",
       "      <td>401</td>\n",
       "      <td>  32  - 50 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>355.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11403</td>\n",
       "      <td>337</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3670</td>\n",
       "      <td>501</td>\n",
       "      <td>  - 0.95 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-12</td>\n",
       "      <td>336.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19968</td>\n",
       "      <td>401</td>\n",
       "      <td>      4- 56...</td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2308</td>\n",
       "      <td>401</td>\n",
       "      <td>     1 - 60 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22236</td>\n",
       "      <td>401</td>\n",
       "      <td>    - 600 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5852</td>\n",
       "      <td>236</td>\n",
       "      <td>    - 400 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1339</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 400 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10825</td>\n",
       "      <td>337</td>\n",
       "      <td>   25 + 8  ( 32% )   - 3...</td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10388</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 225 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>434</td>\n",
       "      <td>501</td>\n",
       "      <td>   - 240 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>176.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>9690</td>\n",
       "      <td>632</td>\n",
       "      <td>     - 125 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-12</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>21699</td>\n",
       "      <td>339</td>\n",
       "      <td>  - 200 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6872</td>\n",
       "      <td>1</td>\n",
       "      <td>     1 - 60 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "1         1504           236   \n",
       "2        21793           401   \n",
       "4        11403           337   \n",
       "8         3670           501   \n",
       "12       19968           401   \n",
       "16        2308           401   \n",
       "17       22236           401   \n",
       "19        5852           236   \n",
       "25        1339           339   \n",
       "28       10825           337   \n",
       "31       10388           339   \n",
       "51         434           501   \n",
       "52        9690           632   \n",
       "53       21699           339   \n",
       "54        6872             1   \n",
       "\n",
       "                                                  sku confirmation_status  \\\n",
       "1                                  - 1.45                  yes   \n",
       "2                             32  - 50                  yes   \n",
       "4                         - 300                  yes   \n",
       "8                                  - 0.95                  yes   \n",
       "12        4- 56...                 yes   \n",
       "16            1 - 60                  yes   \n",
       "17                          - 600                  yes   \n",
       "19                       - 400                  yes   \n",
       "25                          - 400                  yes   \n",
       "28     25 + 8  ( 32% )   - 3...                 yes   \n",
       "31                              - 225                  yes   \n",
       "51                               - 240                  yes   \n",
       "52                    - 125                  yes   \n",
       "53                                - 200                  yes   \n",
       "54           1 - 60                  yes   \n",
       "\n",
       "   last_po_date  ordered_qty  no_last_15  \n",
       "1    2026-01-12        200.0           2  \n",
       "2    2026-01-05        355.0           0  \n",
       "4    2026-01-13        109.0           0  \n",
       "8    2026-01-12        336.0           3  \n",
       "12   2026-01-05         21.0           0  \n",
       "16   2026-01-06          3.0           0  \n",
       "17   2026-01-05          1.0           0  \n",
       "19   2026-01-08          4.0           1  \n",
       "25   2026-01-11         96.0           0  \n",
       "28   2026-01-11         72.0           0  \n",
       "31   2026-01-11         30.0           3  \n",
       "51   2026-01-05        176.0           0  \n",
       "52   2026-01-12         13.0           5  \n",
       "53   2026-01-05         12.0           0  \n",
       "54   2026-01-05          6.0           0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add PO Data to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge PO data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_po_data[['warehouse_id', 'product_id', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values\n",
    "pricing_with_discount['ordered_qty'] = pricing_with_discount['ordered_qty'].fillna(0)\n",
    "pricing_with_discount['no_last_15'] = pricing_with_discount['no_last_15'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"PO data added!\")\n",
    "print(f\"\\nRecords with PO data: {len(pricing_with_discount[~pricing_with_discount['confirmation_status'].isna()])}\")\n",
    "print(f\"Records without PO data: {len(pricing_with_discount[pricing_with_discount['confirmation_status'].isna()])}\")\n",
    "print(f\"\\nSample data with PO info:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']\n",
    "].dropna(subset=['confirmation_status']).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading leadtime data...\n",
      "Loaded 14867 leadtime records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28989/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Leadtime Query - Supplier leadtime by brand, category, and warehouse\n",
    "# =============================================================================\n",
    "LEADTIME_QUERY = '''\n",
    "SELECT brand, cat, warehouse_id, leadtime\n",
    "FROM (\n",
    "    SELECT a.*, b.name_ar AS brand, c.name_ar AS cat\n",
    "    FROM (\n",
    "        SELECT DISTINCT \n",
    "            sl.supplier_id, \n",
    "            warehouse_id, \n",
    "            category_id, \n",
    "            brand_id, \n",
    "            sl.updated_at, \n",
    "            leadtime,\n",
    "            MAX(sl.updated_at) OVER (PARTITION BY sl.supplier_id, warehouse_id) AS last_update\n",
    "        FROM retool.SUPPLIER_MOQ sl \n",
    "        JOIN retool.PO_SUPPLIER_MAPPING sm ON sl.supplier_id = sm.supplier_id \n",
    "    ) a\n",
    "    JOIN brands b ON b.id = a.brand_id \n",
    "    JOIN categories c ON c.id = a.category_id\n",
    "    WHERE a.updated_at = last_update\n",
    ") d\n",
    "'''\n",
    "\n",
    "# Execute leadtime query using dwh_pg_query\n",
    "print(\"Loading leadtime data...\")\n",
    "df_leadtime = setup_environment_2.dwh_pg_query(\n",
    "    LEADTIME_QUERY, \n",
    "    columns=['brand', 'cat', 'warehouse_id', 'leadtime']\n",
    ")\n",
    "df_leadtime.columns = df_leadtime.columns.str.lower()\n",
    "df_leadtime = convert_to_numeric(df_leadtime)\n",
    "print(f\"Loaded {len(df_leadtime)} leadtime records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leadtime data added!\n",
      "\n",
      "Records with leadtime: 68537\n",
      "Records without leadtime: 0\n",
      "\n",
      "Leadtime distribution:\n",
      "count    68537.000000\n",
      "mean         2.131214\n",
      "std          0.841874\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          2.000000\n",
      "75%          3.000000\n",
      "max          7.000000\n",
      "Name: leadtime, dtype: float64\n",
      "\n",
      "Sample data with leadtime:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>cat</th>\n",
       "      <th>leadtime</th>\n",
       "      <th>doh</th>\n",
       "      <th>abc_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>964</td>\n",
       "      <td>337</td>\n",
       "      <td> </td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1504</td>\n",
       "      <td>236</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.760000</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21793</td>\n",
       "      <td>401</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21793</td>\n",
       "      <td>632</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.260870</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11403</td>\n",
       "      <td>337</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11403</td>\n",
       "      <td>632</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11766</td>\n",
       "      <td>339</td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13880</td>\n",
       "      <td>501</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3670</td>\n",
       "      <td>501</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11454</td>\n",
       "      <td>501</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3016</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23339</td>\n",
       "      <td>236</td>\n",
       "      <td></td>\n",
       "      <td>  </td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19968</td>\n",
       "      <td>401</td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11425</td>\n",
       "      <td>703</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25352</td>\n",
       "      <td>797</td>\n",
       "      <td> </td>\n",
       "      <td> </td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id            brand            cat  leadtime  \\\n",
       "0          964           337                    2.0   \n",
       "1         1504           236                      1.0   \n",
       "2        21793           401                            1.0   \n",
       "3        21793           632                            1.0   \n",
       "4        11403           337                              2.0   \n",
       "5        11403           632                              2.0   \n",
       "6        11766           339                         1.0   \n",
       "7        13880           501                          3.0   \n",
       "8         3670           501                      1.0   \n",
       "9        11454           501                      1.0   \n",
       "10        3016             1                        3.0   \n",
       "11       23339           236                        1.0   \n",
       "12       19968           401                     1.0   \n",
       "13       11425           703                     2.0   \n",
       "14       25352           797                 3.0   \n",
       "\n",
       "           doh abc_class  \n",
       "0   999.000000         C  \n",
       "1    12.760000         B  \n",
       "2     0.151515         B  \n",
       "3     7.260870         B  \n",
       "4     0.090909         C  \n",
       "5    15.333333         C  \n",
       "6     0.000000         C  \n",
       "7     0.000000         C  \n",
       "8     0.000000         B  \n",
       "9     0.000000         C  \n",
       "10    0.818182         B  \n",
       "11    8.500000         B  \n",
       "12  999.000000         C  \n",
       "13    0.000000         C  \n",
       "14    0.000000         C  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Leadtime to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge leadtime data with pricing_with_discount (by brand, cat, warehouse_id)\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_leadtime[['brand', 'cat', 'warehouse_id', 'leadtime']], \n",
    "    on=['brand', 'cat', 'warehouse_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing leadtime with 0 or a default value\n",
    "pricing_with_discount['leadtime'] = pricing_with_discount['leadtime'].fillna(72)\n",
    "pricing_with_discount['leadtime']=pricing_with_discount['leadtime']/24\n",
    "\n",
    "print(f\"Leadtime data added!\")\n",
    "print(f\"\\nRecords with leadtime: {len(pricing_with_discount[pricing_with_discount['leadtime'] > 0])}\")\n",
    "print(f\"Records without leadtime: {len(pricing_with_discount[pricing_with_discount['leadtime'] == 0])}\")\n",
    "print(f\"\\nLeadtime distribution:\")\n",
    "print(pricing_with_discount['leadtime'].describe())\n",
    "print(f\"\\nSample data with leadtime:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'brand', 'cat', 'leadtime', 'doh', 'abc_class']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>region</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>sku</th>\n",
       "      <th>brand</th>\n",
       "      <th>cat</th>\n",
       "      <th>wac1</th>\n",
       "      <th>wac_p</th>\n",
       "      <th>current_price</th>\n",
       "      <th>current_margin</th>\n",
       "      <th>nmv</th>\n",
       "      <th>ben_soliman_price</th>\n",
       "      <th>final_min_price</th>\n",
       "      <th>final_max_price</th>\n",
       "      <th>final_mod_price</th>\n",
       "      <th>final_true_min</th>\n",
       "      <th>final_true_max</th>\n",
       "      <th>min_scrapped</th>\n",
       "      <th>scrapped25</th>\n",
       "      <th>scrapped50</th>\n",
       "      <th>scrapped75</th>\n",
       "      <th>max_scrapped</th>\n",
       "      <th>minimum</th>\n",
       "      <th>percentile_25</th>\n",
       "      <th>percentile_50</th>\n",
       "      <th>percentile_75</th>\n",
       "      <th>maximum</th>\n",
       "      <th>below_market</th>\n",
       "      <th>market_min</th>\n",
       "      <th>market_25</th>\n",
       "      <th>market_50</th>\n",
       "      <th>market_75</th>\n",
       "      <th>market_max</th>\n",
       "      <th>above_market</th>\n",
       "      <th>std</th>\n",
       "      <th>avg_margin</th>\n",
       "      <th>target_margin</th>\n",
       "      <th>group</th>\n",
       "      <th>discount_perc</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>margin_after_discount</th>\n",
       "      <th>price_position</th>\n",
       "      <th>stocks</th>\n",
       "      <th>zero_demand</th>\n",
       "      <th>oos_yesterday</th>\n",
       "      <th>in_stock_rr</th>\n",
       "      <th>doh</th>\n",
       "      <th>order_count</th>\n",
       "      <th>contribution</th>\n",
       "      <th>abc_class</th>\n",
       "      <th>confirmation_status</th>\n",
       "      <th>last_po_date</th>\n",
       "      <th>ordered_qty</th>\n",
       "      <th>no_last_15</th>\n",
       "      <th>leadtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9116</th>\n",
       "      <td>704</td>\n",
       "      <td>326</td>\n",
       "      <td>Delta East</td>\n",
       "      <td>339</td>\n",
       "      <td>Mansoura FC</td>\n",
       "      <td>   - 320 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>324.583569</td>\n",
       "      <td>318.667833</td>\n",
       "      <td>334.75</td>\n",
       "      <td>0.048042</td>\n",
       "      <td>3.328994e+06</td>\n",
       "      <td>339.946667</td>\n",
       "      <td>325.4</td>\n",
       "      <td>345.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>322.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>332.494995</td>\n",
       "      <td>340.104996</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>320.00000</td>\n",
       "      <td>326.550000</td>\n",
       "      <td>333.747498</td>\n",
       "      <td>340.065413</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.024138</td>\n",
       "      <td>0.045183</td>\n",
       "      <td>0.062922</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>0.089541</td>\n",
       "      <td>0.011325</td>\n",
       "      <td>0.046060</td>\n",
       "      <td>0.04</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>332.132260</td>\n",
       "      <td>0.040539</td>\n",
       "      <td>At 25th</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>1255</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17717</th>\n",
       "      <td>702</td>\n",
       "      <td>326</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>797</td>\n",
       "      <td>Khorshed Alex</td>\n",
       "      <td>   - 320 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>324.583569</td>\n",
       "      <td>318.667833</td>\n",
       "      <td>331.75</td>\n",
       "      <td>0.039434</td>\n",
       "      <td>1.717604e+06</td>\n",
       "      <td>339.946667</td>\n",
       "      <td>325.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>327.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>334.700012</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>341.899994</td>\n",
       "      <td>320.00000</td>\n",
       "      <td>328.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>340.949997</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.028452</td>\n",
       "      <td>0.048753</td>\n",
       "      <td>0.065353</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>0.089541</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.047822</td>\n",
       "      <td>0.04</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.022111</td>\n",
       "      <td>324.414593</td>\n",
       "      <td>0.017714</td>\n",
       "      <td>At Min</td>\n",
       "      <td>1206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>11.596154</td>\n",
       "      <td>1140</td>\n",
       "      <td>0.007258</td>\n",
       "      <td>A</td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-10</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24716</th>\n",
       "      <td>1123</td>\n",
       "      <td>326</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>703</td>\n",
       "      <td>Menya Samalot</td>\n",
       "      <td>   - 320 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>324.583569</td>\n",
       "      <td>318.667833</td>\n",
       "      <td>332.25</td>\n",
       "      <td>0.040879</td>\n",
       "      <td>9.813759e+05</td>\n",
       "      <td>339.946667</td>\n",
       "      <td>325.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>315.046290</td>\n",
       "      <td>318.392761</td>\n",
       "      <td>320.161615</td>\n",
       "      <td>320.305030</td>\n",
       "      <td>326.902351</td>\n",
       "      <td>315.04629</td>\n",
       "      <td>320.080808</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>337.473333</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.019484</td>\n",
       "      <td>0.055724</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>0.089541</td>\n",
       "      <td>0.012669</td>\n",
       "      <td>0.049658</td>\n",
       "      <td>0.04</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>329.492331</td>\n",
       "      <td>0.032852</td>\n",
       "      <td>At 50th</td>\n",
       "      <td>707</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.428571</td>\n",
       "      <td>749</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>A</td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30674</th>\n",
       "      <td>701</td>\n",
       "      <td>326</td>\n",
       "      <td>Giza</td>\n",
       "      <td>236</td>\n",
       "      <td>Barageel</td>\n",
       "      <td>   - 320 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>324.583569</td>\n",
       "      <td>318.667833</td>\n",
       "      <td>333.25</td>\n",
       "      <td>0.043757</td>\n",
       "      <td>7.181582e+06</td>\n",
       "      <td>339.946667</td>\n",
       "      <td>325.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>329.500000</td>\n",
       "      <td>333.000000</td>\n",
       "      <td>334.850006</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>341.899994</td>\n",
       "      <td>320.00000</td>\n",
       "      <td>330.375000</td>\n",
       "      <td>334.925003</td>\n",
       "      <td>339.986667</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.035436</td>\n",
       "      <td>0.048540</td>\n",
       "      <td>0.062705</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>0.089541</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>0.045386</td>\n",
       "      <td>0.04</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>331.433055</td>\n",
       "      <td>0.038515</td>\n",
       "      <td>At 25th</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>9.217593</td>\n",
       "      <td>3241</td>\n",
       "      <td>0.005927</td>\n",
       "      <td>A</td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-12</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44962</th>\n",
       "      <td>1125</td>\n",
       "      <td>326</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>632</td>\n",
       "      <td>Sohag</td>\n",
       "      <td>   - 320 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>324.583569</td>\n",
       "      <td>318.667833</td>\n",
       "      <td>345.00</td>\n",
       "      <td>0.076325</td>\n",
       "      <td>3.158310e+05</td>\n",
       "      <td>339.946667</td>\n",
       "      <td>325.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>315.046290</td>\n",
       "      <td>318.392761</td>\n",
       "      <td>320.161615</td>\n",
       "      <td>320.305030</td>\n",
       "      <td>326.902351</td>\n",
       "      <td>315.04629</td>\n",
       "      <td>320.080808</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>337.473333</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.019484</td>\n",
       "      <td>0.055724</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>0.089541</td>\n",
       "      <td>0.012278</td>\n",
       "      <td>0.050606</td>\n",
       "      <td>0.04</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.044156</td>\n",
       "      <td>329.766271</td>\n",
       "      <td>0.033655</td>\n",
       "      <td>At 50th</td>\n",
       "      <td>669</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>51.461538</td>\n",
       "      <td>300</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50949</th>\n",
       "      <td>1126</td>\n",
       "      <td>326</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>401</td>\n",
       "      <td>Bani sweif</td>\n",
       "      <td>   - 320 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>324.583569</td>\n",
       "      <td>318.667833</td>\n",
       "      <td>338.00</td>\n",
       "      <td>0.057196</td>\n",
       "      <td>9.761304e+05</td>\n",
       "      <td>339.946667</td>\n",
       "      <td>325.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>315.046290</td>\n",
       "      <td>318.392761</td>\n",
       "      <td>320.161615</td>\n",
       "      <td>320.305030</td>\n",
       "      <td>326.902351</td>\n",
       "      <td>315.04629</td>\n",
       "      <td>320.080808</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>337.473333</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.019484</td>\n",
       "      <td>0.055724</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>0.089541</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.049463</td>\n",
       "      <td>0.04</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>338.000000</td>\n",
       "      <td>0.057196</td>\n",
       "      <td>At 75th</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>646</td>\n",
       "      <td>0.007414</td>\n",
       "      <td>A</td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>429.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58427</th>\n",
       "      <td>703</td>\n",
       "      <td>326</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>337</td>\n",
       "      <td>El-Mahala</td>\n",
       "      <td>   - 320 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>324.583569</td>\n",
       "      <td>318.667833</td>\n",
       "      <td>333.75</td>\n",
       "      <td>0.045190</td>\n",
       "      <td>3.661608e+06</td>\n",
       "      <td>339.946667</td>\n",
       "      <td>325.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>338.799988</td>\n",
       "      <td>339.624992</td>\n",
       "      <td>339.949997</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>320.00000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>339.624992</td>\n",
       "      <td>339.949997</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.048753</td>\n",
       "      <td>0.061707</td>\n",
       "      <td>0.062604</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>0.095914</td>\n",
       "      <td>0.012155</td>\n",
       "      <td>0.050244</td>\n",
       "      <td>0.04</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.008711</td>\n",
       "      <td>330.842764</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>At Min</td>\n",
       "      <td>661</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.960784</td>\n",
       "      <td>1117</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>A</td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-11</td>\n",
       "      <td>143.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58949</th>\n",
       "      <td>700</td>\n",
       "      <td>326</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>1</td>\n",
       "      <td>Mostorod</td>\n",
       "      <td>   - 320 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>324.583569</td>\n",
       "      <td>318.667833</td>\n",
       "      <td>334.75</td>\n",
       "      <td>0.048042</td>\n",
       "      <td>1.411702e+07</td>\n",
       "      <td>339.946667</td>\n",
       "      <td>325.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>348.125000</td>\n",
       "      <td>355.299988</td>\n",
       "      <td>320.00000</td>\n",
       "      <td>330.500000</td>\n",
       "      <td>337.473333</td>\n",
       "      <td>346.093750</td>\n",
       "      <td>355.299988</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.035801</td>\n",
       "      <td>0.055724</td>\n",
       "      <td>0.079244</td>\n",
       "      <td>0.103102</td>\n",
       "      <td>0.103122</td>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.046257</td>\n",
       "      <td>0.04</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>332.709151</td>\n",
       "      <td>0.042203</td>\n",
       "      <td>At 25th</td>\n",
       "      <td>4408</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>10.347418</td>\n",
       "      <td>5878</td>\n",
       "      <td>0.006505</td>\n",
       "      <td>A</td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-10</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59481</th>\n",
       "      <td>1124</td>\n",
       "      <td>326</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>501</td>\n",
       "      <td>Assiut FC</td>\n",
       "      <td>   - 320 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>324.583569</td>\n",
       "      <td>318.667833</td>\n",
       "      <td>340.25</td>\n",
       "      <td>0.063430</td>\n",
       "      <td>4.566285e+05</td>\n",
       "      <td>339.946667</td>\n",
       "      <td>325.0</td>\n",
       "      <td>340.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>315.046290</td>\n",
       "      <td>318.392761</td>\n",
       "      <td>320.161615</td>\n",
       "      <td>320.305030</td>\n",
       "      <td>326.902351</td>\n",
       "      <td>315.04629</td>\n",
       "      <td>320.080808</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>337.473333</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>-0.011495</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>0.019484</td>\n",
       "      <td>0.055724</td>\n",
       "      <td>0.089520</td>\n",
       "      <td>0.089541</td>\n",
       "      <td>0.011613</td>\n",
       "      <td>0.049054</td>\n",
       "      <td>0.04</td>\n",
       "      <td>431.0</td>\n",
       "      <td>0.043530</td>\n",
       "      <td>325.438773</td>\n",
       "      <td>0.020806</td>\n",
       "      <td>At 50th</td>\n",
       "      <td>1080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>83.076923</td>\n",
       "      <td>373</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cohort_id  product_id       region  warehouse_id      warehouse  \\\n",
       "9116         704         326   Delta East           339    Mansoura FC   \n",
       "17717        702         326   Alexandria           797  Khorshed Alex   \n",
       "24716       1123         326  Upper Egypt           703  Menya Samalot   \n",
       "30674        701         326         Giza           236       Barageel   \n",
       "44962       1125         326  Upper Egypt           632          Sohag   \n",
       "50949       1126         326  Upper Egypt           401     Bani sweif   \n",
       "58427        703         326   Delta West           337      El-Mahala   \n",
       "58949        700         326        Cairo             1       Mostorod   \n",
       "59481       1124         326  Upper Egypt           501      Assiut FC   \n",
       "\n",
       "                            sku  brand         cat        wac1       wac_p  \\\n",
       "9116      - 320        324.583569  318.667833   \n",
       "17717     - 320        324.583569  318.667833   \n",
       "24716     - 320        324.583569  318.667833   \n",
       "30674     - 320        324.583569  318.667833   \n",
       "44962     - 320        324.583569  318.667833   \n",
       "50949     - 320        324.583569  318.667833   \n",
       "58427     - 320        324.583569  318.667833   \n",
       "58949     - 320        324.583569  318.667833   \n",
       "59481     - 320        324.583569  318.667833   \n",
       "\n",
       "       current_price  current_margin           nmv  ben_soliman_price  \\\n",
       "9116          334.75        0.048042  3.328994e+06         339.946667   \n",
       "17717         331.75        0.039434  1.717604e+06         339.946667   \n",
       "24716         332.25        0.040879  9.813759e+05         339.946667   \n",
       "30674         333.25        0.043757  7.181582e+06         339.946667   \n",
       "44962         345.00        0.076325  3.158310e+05         339.946667   \n",
       "50949         338.00        0.057196  9.761304e+05         339.946667   \n",
       "58427         333.75        0.045190  3.661608e+06         339.946667   \n",
       "58949         334.75        0.048042  1.411702e+07         339.946667   \n",
       "59481         340.25        0.063430  4.566285e+05         339.946667   \n",
       "\n",
       "       final_min_price  final_max_price  final_mod_price  final_true_min  \\\n",
       "9116             325.4            345.0            335.0           320.0   \n",
       "17717            325.0            343.0            335.0           320.0   \n",
       "24716            325.0            340.0            335.0           320.0   \n",
       "30674            325.0            340.0            335.0           320.0   \n",
       "44962            325.0            340.0            335.0           320.0   \n",
       "50949            325.0            340.0            335.0           320.0   \n",
       "58427            325.0            340.0            335.0           320.0   \n",
       "58949            325.0            340.0            335.0           320.0   \n",
       "59481            325.0            340.0            335.0           320.0   \n",
       "\n",
       "       final_true_max  min_scrapped  scrapped25  scrapped50  scrapped75  \\\n",
       "9116            350.0    322.000000  330.000000  332.494995  340.104996   \n",
       "17717           350.0    327.000000  329.000000  334.700012  340.000000   \n",
       "24716           350.0    315.046290  318.392761  320.161615  320.305030   \n",
       "30674           350.0    329.500000  333.000000  334.850006  335.000000   \n",
       "44962           350.0    315.046290  318.392761  320.161615  320.305030   \n",
       "50949           350.0    315.046290  318.392761  320.161615  320.305030   \n",
       "58427           350.0    338.799988  339.624992  339.949997  340.000000   \n",
       "58949           355.0    330.000000  332.000000  335.000000  348.125000   \n",
       "59481           350.0    315.046290  318.392761  320.161615  320.305030   \n",
       "\n",
       "       max_scrapped    minimum  percentile_25  percentile_50  percentile_75  \\\n",
       "9116     345.000000  320.00000     326.550000     333.747498     340.065413   \n",
       "17717    341.899994  320.00000     328.000000     335.000000     340.949997   \n",
       "24716    326.902351  315.04629     320.080808     325.000000     337.473333   \n",
       "30674    341.899994  320.00000     330.375000     334.925003     339.986667   \n",
       "44962    326.902351  315.04629     320.080808     325.000000     337.473333   \n",
       "50949    326.902351  315.04629     320.080808     325.000000     337.473333   \n",
       "58427    340.000000  320.00000     335.000000     339.624992     339.949997   \n",
       "58949    355.299988  320.00000     330.500000     337.473333     346.093750   \n",
       "59481    326.902351  315.04629     320.080808     325.000000     337.473333   \n",
       "\n",
       "          maximum  below_market  market_min  market_25  market_50  market_75  \\\n",
       "9116   350.000000      0.004138    0.004163   0.024138   0.045183   0.062922   \n",
       "17717  350.000000      0.004138    0.004163   0.028452   0.048753   0.065353   \n",
       "24716  350.000000     -0.011495   -0.011495   0.004414   0.019484   0.055724   \n",
       "30674  350.000000      0.004138    0.004163   0.035436   0.048540   0.062705   \n",
       "44962  350.000000     -0.011495   -0.011495   0.004414   0.019484   0.055724   \n",
       "50949  350.000000     -0.011495   -0.011495   0.004414   0.019484   0.055724   \n",
       "58427  350.000000      0.004163    0.004163   0.048753   0.061707   0.062604   \n",
       "58949  355.299988      0.004138    0.004163   0.035801   0.055724   0.079244   \n",
       "59481  350.000000     -0.011495   -0.011495   0.004414   0.019484   0.055724   \n",
       "\n",
       "       market_max  above_market       std  avg_margin  target_margin  group  \\\n",
       "9116     0.089520      0.089541  0.011325    0.046060           0.04  431.0   \n",
       "17717    0.089520      0.089541  0.011426    0.047822           0.04  431.0   \n",
       "24716    0.089520      0.089541  0.012669    0.049658           0.04  431.0   \n",
       "30674    0.089520      0.089541  0.011314    0.045386           0.04  431.0   \n",
       "44962    0.089520      0.089541  0.012278    0.050606           0.04  431.0   \n",
       "50949    0.089520      0.089541  0.011416    0.049463           0.04  431.0   \n",
       "58427    0.089520      0.095914  0.012155    0.050244           0.04  431.0   \n",
       "58949    0.103102      0.103122  0.011269    0.046257           0.04  431.0   \n",
       "59481    0.089520      0.089541  0.011613    0.049054           0.04  431.0   \n",
       "\n",
       "       discount_perc  price_after_discount  margin_after_discount  \\\n",
       "9116        0.007820            332.132260               0.040539   \n",
       "17717       0.022111            324.414593               0.017714   \n",
       "24716       0.008300            329.492331               0.032852   \n",
       "30674       0.005452            331.433055               0.038515   \n",
       "44962       0.044156            329.766271               0.033655   \n",
       "50949       0.000000            338.000000               0.057196   \n",
       "58427       0.008711            330.842764               0.036800   \n",
       "58949       0.006097            332.709151               0.042203   \n",
       "59481       0.043530            325.438773               0.020806   \n",
       "\n",
       "      price_position  stocks  zero_demand  oos_yesterday  in_stock_rr  \\\n",
       "9116         At 25th     189            0              0         49.0   \n",
       "17717         At Min    1206            0              0        104.0   \n",
       "24716        At 50th     707            0              0         49.0   \n",
       "30674        At 25th    1991            0              0        216.0   \n",
       "44962        At 50th     669            0              0         13.0   \n",
       "50949        At 75th       0            0              1         30.0   \n",
       "58427         At Min     661            0              0         51.0   \n",
       "58949        At 25th    4408            0              0        426.0   \n",
       "59481        At 50th    1080            0              0         13.0   \n",
       "\n",
       "             doh  order_count  contribution abc_class confirmation_status  \\\n",
       "9116    3.857143         1255      0.004749         A                None   \n",
       "17717  11.596154         1140      0.007258         A                 yes   \n",
       "24716  14.428571          749      0.004407         A                 yes   \n",
       "30674   9.217593         3241      0.005927         A                 yes   \n",
       "44962  51.461538          300      0.003246         B                 NaN   \n",
       "50949   0.000000          646      0.007414         A                None   \n",
       "58427  12.960784         1117      0.005122         A                 yes   \n",
       "58949  10.347418         5878      0.006505         A                 yes   \n",
       "59481  83.076923          373      0.002867         B                 NaN   \n",
       "\n",
       "      last_po_date  ordered_qty  no_last_15  leadtime  \n",
       "9116    2026-01-13        143.0           0       1.0  \n",
       "17717   2026-01-10        143.0           0       1.0  \n",
       "24716   2026-01-11        143.0           0       1.0  \n",
       "30674   2026-01-12        143.0           0       1.0  \n",
       "44962          NaN          0.0           0       1.0  \n",
       "50949   2026-01-13        429.0           0       1.0  \n",
       "58427   2026-01-11        143.0           0       1.0  \n",
       "58949   2026-01-10       1144.0           0       1.0  \n",
       "59481          NaN          0.0           0       1.0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pricing_with_discount[pricing_with_discount['product_id']==326]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
