{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction Module for Pricing & Offers System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/snowflake/connector/options.py:104: UserWarning: You have an incompatible version of 'pyarrow' installed (22.0.0), please install a version that adheres to: 'pyarrow<19.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import setup_environment_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region\n",
    "REGION = \"Egypt\"\n",
    "\n",
    "# Snowflake Warehouse\n",
    "WAREHOUSE = \"COMPUTE_WH\"\n",
    "\n",
    "# Date Variables\n",
    "from datetime import datetime, timedelta\n",
    "TODAY = datetime.now().date()\n",
    "YESTERDAY = TODAY - timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "setup_environment_2.initialize_env()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warehouse & Cohort Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warehouse Mapping: (region, warehouse_name, warehouse_id, cohort_id)\n",
    "WAREHOUSE_MAPPING = [\n",
    "    ('Cairo', 'Mostorod', 1, 700),\n",
    "    ('Giza', 'Barageel', 236, 701),\n",
    "    ('Giza', 'Sakkarah', 962, 701),\n",
    "    ('Delta West', 'El-Mahala', 337, 703),\n",
    "    ('Delta West', 'Tanta', 8, 703),\n",
    "    ('Delta East', 'Mansoura FC', 339, 704),\n",
    "    ('Delta East', 'Sharqya', 170, 704),\n",
    "    ('Upper Egypt', 'Assiut FC', 501, 1124),\n",
    "    ('Upper Egypt', 'Bani sweif', 401, 1126),\n",
    "    ('Upper Egypt', 'Menya Samalot', 703, 1123),\n",
    "    ('Upper Egypt', 'Sohag', 632, 1125),\n",
    "    ('Alexandria', 'Khorshed Alex', 797, 702),\n",
    "]\n",
    "\n",
    "# Region to Cohort Mapping\n",
    "REGION_COHORT_MAPPING = {\n",
    "    'Cairo': 700,\n",
    "    'Giza': 701,\n",
    "    'Delta West': 703,\n",
    "    'Delta East': 704,\n",
    "    'Upper Egypt': 1124,\n",
    "    'Alexandria': 702,\n",
    "}\n",
    "\n",
    "# All Cohort IDs\n",
    "COHORT_IDS = [700, 701, 702, 703, 704, 1123, 1124, 1125, 1126]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowflake Query Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_snowflake(query):\n",
    "    \"\"\"Execute a query on Snowflake and return results as DataFrame.\"\"\"\n",
    "    con = snowflake.connector.connect(\n",
    "        user=os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database=os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        data = cur.fetchall()\n",
    "        columns = [desc[0].lower() for desc in cur.description]  # Get column names from cursor\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "    except Exception as e:\n",
    "        print(f\"Snowflake Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snowflake_timezone():\n",
    "    \"\"\"Get the current timezone from Snowflake.\"\"\"\n",
    "    query = \"SHOW PARAMETERS LIKE 'TIMEZONE'\"\n",
    "    result = query_snowflake(query)\n",
    "    return result.value[0] if len(result) > 0 else \"UTC\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warehouse_df():\n",
    "    \"\"\"Get warehouse mapping as DataFrame.\"\"\"\n",
    "    return pd.DataFrame(\n",
    "        WAREHOUSE_MAPPING,\n",
    "        columns=['region', 'warehouse', 'warehouse_id', 'cohort_id']\n",
    "    )\n",
    "\n",
    "\n",
    "def get_cohort_by_region(region):\n",
    "    \"\"\"Get cohort ID for a given region.\"\"\"\n",
    "    return REGION_COHORT_MAPPING.get(region)\n",
    "\n",
    "\n",
    "def convert_to_numeric(df):\n",
    "    \"\"\"Convert DataFrame columns to numeric where possible.\"\"\"\n",
    "    df.columns = df.columns.str.lower()\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Snowflake Timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake timezone: America/Los_Angeles\n"
     ]
    }
   ],
   "source": [
    "TIMEZONE = get_snowflake_timezone()\n",
    "print(f\"Snowflake timezone: {TIMEZONE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Prices Extraction Queries\n",
    "Queries for external market price data:\n",
    "1. **Ben Soliman Prices** - Competitor reference prices\n",
    "2. **Marketplace Prices** - Min, Max, Mod prices from marketplace\n",
    "3. **Scrapped Data** - Competitor prices from scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. BEN SOLIMAN PRICES QUERY\n",
    "# =============================================================================\n",
    "BEN_SOLIMAN_QUERY = f'''\n",
    "WITH lower as (\n",
    "    select distinct product_id, sku, new_d*bs_price as ben_soliman_price, INJECTION_DATE\n",
    "    from (\n",
    "        select maxab_product_id as product_id, maxab_sku as sku, INJECTION_DATE, wac1, wac_p,\n",
    "            (bs_price/bs_unit_count) as bs_price, diff, cu_price,\n",
    "            case when p1 > 1 then child_quantity else 0 end as scheck,\n",
    "            round(p1/2)*2 as p1, p2,\n",
    "            case when (ROUND(p1 / scheck) * scheck) = 0 then p1 else (ROUND(p1 / scheck) * scheck) end as new_d\n",
    "        from (\n",
    "            select sm.*, wac1, wac_p, \n",
    "                abs((bs_price/bs_unit_count)-(wac_p*maxab_basic_unit_count))/(wac_p*maxab_basic_unit_count) as diff,\n",
    "                cpc.price as cu_price, pup.child_quantity,\n",
    "                round((cu_price/(bs_price/bs_unit_count))) as p1, \n",
    "                round(((bs_price/bs_unit_count)/cu_price)) as p2\n",
    "            from materialized_views.savvy_mapping sm \n",
    "            join finance.all_cogs f on f.product_id = sm.maxab_product_id \n",
    "                and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "            join PACKING_UNIT_PRODUCTS pu on pu.product_id = sm.maxab_product_id and pu.IS_BASIC_UNIT = 1 \n",
    "            join cohort_product_packing_units cpc on cpc.PRODUCT_PACKING_UNIT_ID = pu.id and cohort_id = 700 \n",
    "            join packing_unit_products pup on pup.product_id = sm.maxab_product_id and pup.is_basic_unit = 1  \n",
    "            where bs_price is not null \n",
    "                and INJECTION_DATE::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 5 \n",
    "                and diff > 0.3 and p1 > 1\n",
    "        )\n",
    "    )\n",
    "    qualify max(INJECTION_DATE) over(partition by product_id) = INJECTION_DATE\n",
    "),\n",
    "\n",
    "m_bs as (\n",
    "    select z.* from (\n",
    "        select maxab_product_id as product_id, maxab_sku as sku, avg(bs_final_price) as ben_soliman_price, INJECTION_DATE\n",
    "        from (\n",
    "            select *, row_number() over(partition by maxab_product_id order by diff) as rnk_2 \n",
    "            from (\n",
    "                select *, (bs_final_price-wac_p)/wac_p as diff_2 \n",
    "                from (\n",
    "                    select *, bs_price/maxab_basic_unit_count as bs_final_price \n",
    "                    from (\n",
    "                        select *, row_number() over(partition by maxab_product_id, maxab_pu order by diff) as rnk \n",
    "                        from (\n",
    "                            select *, max(INJECTION_DATE::date) over(partition by maxab_product_id, maxab_pu) as max_date\n",
    "                            from (\n",
    "                                select sm.*, wac1, wac_p, \n",
    "                                    abs(bs_price-(wac_p*maxab_basic_unit_count))/(wac_p*maxab_basic_unit_count) as diff \n",
    "                                from materialized_views.savvy_mapping sm \n",
    "                                join finance.all_cogs f on f.product_id = sm.maxab_product_id \n",
    "                                    and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "                                where bs_price is not null \n",
    "                                    and INJECTION_DATE::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 5 \n",
    "                                    and diff < 0.3\n",
    "                            )\n",
    "                            qualify max_date = INJECTION_DATE\n",
    "                        ) qualify rnk = 1 \n",
    "                    )\n",
    "                ) where diff_2 between -0.5 and 0.5 \n",
    "            ) qualify rnk_2 = 1 \n",
    "        ) group by all\n",
    "    ) z \n",
    "    join finance.all_cogs f on f.product_id = z.product_id \n",
    "        and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "    where ben_soliman_price between f.wac_p*0.8 and f.wac_p*1.3\n",
    ")\n",
    "\n",
    "select product_id, avg(ben_soliman_price) as ben_soliman_price\n",
    "from (\n",
    "    select * from (\n",
    "        select * from m_bs \n",
    "        union all\n",
    "        select * from lower\n",
    "    )\n",
    "    qualify max(INJECTION_DATE) over(partition by product_id) = INJECTION_DATE\n",
    ")\n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. MARKETPLACE PRICES QUERY (with region fallback)\n",
    "# =============================================================================\n",
    "MARKETPLACE_PRICES_QUERY = f'''\n",
    "WITH MP as (\n",
    "    select region, product_id,\n",
    "        min(min_price) as min_price, min(max_price) as max_price,\n",
    "        min(mod_price) as mod_price, min(true_min) as true_min, min(true_max) as true_max\n",
    "    from (\n",
    "        select mp.region, mp.product_id, mp.pu_id,\n",
    "            min_price/BASIC_UNIT_COUNT as min_price,\n",
    "            max_price/BASIC_UNIT_COUNT as max_price,\n",
    "            mod_price/BASIC_UNIT_COUNT as mod_price,\n",
    "            TRUE_MIN_PRICE/BASIC_UNIT_COUNT as true_min,\n",
    "            TRUE_MAX_PRICE/BASIC_UNIT_COUNT as true_max\n",
    "        from materialized_views.marketplace_prices mp \n",
    "        join packing_unit_products pup on pup.product_id = mp.product_id and pup.packing_unit_id = mp.pu_id\n",
    "        join finance.all_cogs f on f.product_id = mp.product_id \n",
    "            and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_date and f.to_date\n",
    "        where least(min_price, mod_price) between wac_p*0.9 and wac_p*1.3 \n",
    "    )\n",
    "    group by all \n",
    "),\n",
    "\n",
    "region_mapping AS (\n",
    "    SELECT * FROM (VALUES\n",
    "        ('Delta East', 'Delta West'), ('Delta West', 'Delta East'),\n",
    "        ('Alexandria', 'Cairo'), ('Alexandria', 'Giza'),\n",
    "        ('Upper Egypt', 'Cairo'), ('Upper Egypt', 'Giza'),\n",
    "        ('Cairo', 'Giza'), ('Giza', 'Cairo'),\n",
    "        ('Delta West', 'Cairo'), ('Delta East', 'Cairo'),\n",
    "        ('Delta West', 'Giza'), ('Delta East', 'Giza')\n",
    "    ) AS region_mapping(region, fallback_region)\n",
    "),\n",
    "\n",
    "all_regions as (\n",
    "    SELECT * FROM (VALUES\n",
    "        ('Cairo'), ('Giza'), ('Delta West'), ('Delta East'), ('Upper Egypt'), ('Alexandria')\n",
    "    ) AS x(region)\n",
    "),\n",
    "\n",
    "full_data as (\n",
    "    select products.id as product_id, ar.region\n",
    "    from products, all_regions ar\n",
    "    where activation = 'true'\n",
    ")\n",
    "\n",
    "select region, product_id,\n",
    "    min(final_min_price) as final_min_price, \n",
    "    min(final_max_price) as final_max_price,\n",
    "    min(final_mod_price) as final_mod_price, \n",
    "    min(final_true_min) as final_true_min,\n",
    "    min(final_true_max) as final_true_max\n",
    "from (\n",
    "    SELECT distinct w.region, w.product_id,\n",
    "        COALESCE(m1.min_price, m2.min_price) AS final_min_price,\n",
    "        COALESCE(m1.max_price, m2.max_price) AS final_max_price,\n",
    "        COALESCE(m1.mod_price, m2.mod_price) AS final_mod_price,\n",
    "        COALESCE(m1.true_min, m2.true_min) AS final_true_min,\n",
    "        COALESCE(m1.true_max, m2.true_max) AS final_true_max\n",
    "    FROM full_data w\n",
    "    LEFT JOIN MP m1 ON w.region = m1.region and w.product_id = m1.product_id\n",
    "    LEFT JOIN region_mapping rm ON w.region = rm.region\n",
    "    LEFT JOIN MP m2 ON rm.fallback_region = m2.region AND w.product_id = m2.product_id\n",
    ")\n",
    "where final_min_price is not null \n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. SCRAPPED DATA QUERY (Competitor prices from scraping)\n",
    "# =============================================================================\n",
    "SCRAPPED_DATA_QUERY = f'''\n",
    "select product_id, region,\n",
    "    MIN(market_price) AS min_scrapped,\n",
    "    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY market_price) AS scrapped25,\n",
    "    PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY market_price) AS scrapped50,\n",
    "    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY market_price) AS scrapped75,\n",
    "    MAX(market_price) AS max_scrapped\n",
    "from (\n",
    "    select distinct cmp.*, max(date) over(partition by region, cmp.product_id, competitor) as max_date\n",
    "    from MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES cmp\n",
    "    join finance.all_cogs f on f.product_id = cmp.product_id \n",
    "        and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_date and f.to_date \n",
    "    where date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 7 \n",
    "        and MARKET_PRICE between f.wac_p * 0.8 and wac_p * 1.3\n",
    "    qualify date = max_date \n",
    ")\n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional Data Queries (Sales, Groups, WAC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. PRODUCT BASE DATA QUERY (product_id, sku, brand, cat, wac1, wac_p, current_price)\n",
    "# =============================================================================\n",
    "PRODUCT_BASE_QUERY = f'''\n",
    "WITH skus_prices AS (\n",
    "    WITH local_prices AS (\n",
    "        SELECT  \n",
    "            CASE \n",
    "                WHEN cpu.cohort_id IN (700, 695) THEN 'Cairo'\n",
    "                WHEN cpu.cohort_id IN (701) THEN 'Giza'\n",
    "                WHEN cpu.cohort_id IN (704, 698) THEN 'Delta East'\n",
    "                WHEN cpu.cohort_id IN (703, 697) THEN 'Delta West'\n",
    "                WHEN cpu.cohort_id IN (696, 1123, 1124, 1125, 1126) THEN 'Upper Egypt'\n",
    "                WHEN cpu.cohort_id IN (702, 699) THEN 'Alexandria'\n",
    "            END AS region,\n",
    "            cohort_id,\n",
    "            pu.product_id,\n",
    "            pu.packing_unit_id,\n",
    "            pu.basic_unit_count,\n",
    "            AVG(cpu.price) AS price\n",
    "        FROM cohort_product_packing_units cpu\n",
    "        JOIN PACKING_UNIT_PRODUCTS pu ON pu.id = cpu.product_packing_unit_id\n",
    "        WHERE cpu.cohort_id IN (700,701,702,703,704,695,696,697,698,699,1123,1124,1125,1126)\n",
    "            AND cpu.created_at::date <> '2023-07-31'\n",
    "            AND cpu.is_customized = TRUE\n",
    "        GROUP BY ALL\n",
    "    ),\n",
    "    \n",
    "    live_prices AS (\n",
    "        SELECT \n",
    "            region, cohort_id, product_id, \n",
    "            pu_id AS packing_unit_id, \n",
    "            buc AS basic_unit_count, \n",
    "            NEW_PRICE AS price\n",
    "        FROM materialized_views.DBDP_PRICES\n",
    "        WHERE created_at = CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date\n",
    "            AND DATE_PART('hour', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::time) \n",
    "                BETWEEN SPLIT_PART(time_slot, '-', 1)::int AND (SPLIT_PART(time_slot, '-', 1)::int) + 1\n",
    "            AND cohort_id IN (700,701,702,703,704,695,696,697,698,699,1123,1124,1125,1126)\n",
    "    ),\n",
    "    \n",
    "    prices AS (\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT *, 1 AS priority FROM live_prices\n",
    "            UNION ALL\n",
    "            SELECT *, 2 AS priority FROM local_prices\n",
    "        )\n",
    "        QUALIFY ROW_NUMBER() OVER (PARTITION BY region, cohort_id, product_id, packing_unit_id ORDER BY priority) = 1\n",
    "    )\n",
    "    \n",
    "    SELECT region, cohort_id, product_id, price\n",
    "    FROM prices\n",
    "    WHERE basic_unit_count = 1\n",
    "        AND ((product_id = 1309 AND packing_unit_id = 2) OR (product_id <> 1309))\n",
    ")\n",
    "\n",
    "SELECT distinct\n",
    "    region, cohort_id, p.product_id,\n",
    "    CONCAT(products.name_ar, ' ', products.size, ' ', product_units.name_ar) AS sku,\n",
    "    b.name_ar AS brand,\n",
    "    cat.name_ar AS cat,\n",
    "    wac1, wac_p, p.price as current_price\n",
    "FROM skus_prices p\n",
    "JOIN finance.all_cogs c ON c.product_id = p.product_id \n",
    "    AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) BETWEEN c.from_date AND c.to_date\n",
    "JOIN products ON products.id = p.product_id\n",
    "JOIN categories cat ON cat.id = products.category_id\n",
    "JOIN brands b ON b.id = products.brand_id\n",
    "JOIN product_units ON product_units.id = products.unit_id\n",
    "WHERE wac1 > 0 AND wac_p > 0\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 5. SALES DATA QUERY (120-day NMV by cohort/product)\n",
    "# =============================================================================\n",
    "SALES_QUERY = f'''\n",
    "SELECT DISTINCT cpc.cohort_id, pso.product_id,\n",
    "    CONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "    brands.name_ar as brand, categories.name_ar as cat,\n",
    "    sum(pso.total_price) as nmv\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN COHORT_PRICING_CHANGES cpc ON cpc.id = pso.COHORT_PRICING_CHANGE_id\n",
    "JOIN products ON products.id = pso.product_id\n",
    "JOIN brands ON products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "WHERE so.created_at::date BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 120 \n",
    "    AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 1 \n",
    "    AND so.sales_order_status_id NOT IN (7, 12)\n",
    "    AND so.channel IN ('telesales', 'retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "    AND cpc.cohort_id IN (700,701,702,703,704,1123,1124,1125,1126)\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 6. MARGIN STATS QUERY (STD and average margins)  \n",
    "# =============================================================================\n",
    "MARGIN_STATS_QUERY = f'''\n",
    "select product_id, cohort_id, \n",
    "    (0.6*product_std) + (0.3*brand_std) + (0.1*cat_std) as std, \n",
    "    avg_margin\n",
    "from (\n",
    "    select product_id, cohort_id, \n",
    "        stddev(product_margin) as product_std, \n",
    "        stddev(brand_margin) as brand_std,\n",
    "        stddev(cat_margin) as cat_std, \n",
    "        avg(product_margin) as avg_margin\n",
    "    from (\n",
    "        select distinct product_id, order_date, cohort_id,\n",
    "            (nmv-cogs_p)/nmv as product_margin, \n",
    "            (brand_nmv-brand_cogs)/brand_nmv as brand_margin,\n",
    "            (cat_nmv-cat_cogs)/cat_nmv as cat_margin\n",
    "        from (\n",
    "            SELECT DISTINCT so.created_at::date as order_date, cpc.cohort_id, pso.product_id,\n",
    "                brands.name_ar as brand, categories.name_ar as cat,\n",
    "                sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs_p,\n",
    "                sum(pso.total_price) as nmv,\n",
    "                sum(nmv) over(partition by order_date, cat, brand) as brand_nmv,\n",
    "                sum(cogs_p) over(partition by order_date, cat, brand) as brand_cogs,\n",
    "                sum(nmv) over(partition by order_date, cat) as cat_nmv,\n",
    "                sum(cogs_p) over(partition by order_date, cat) as cat_cogs\n",
    "            FROM product_sales_order pso\n",
    "            JOIN sales_orders so ON so.id = pso.sales_order_id   \n",
    "            JOIN COHORT_PRICING_CHANGES cpc on cpc.id = pso.cohort_pricing_change_id\n",
    "            JOIN products on products.id = pso.product_id\n",
    "            JOIN brands on products.brand_id = brands.id \n",
    "            JOIN categories ON products.category_id = categories.id\n",
    "            JOIN finance.all_cogs f ON f.product_id = pso.product_id\n",
    "                AND f.from_date::date <= so.created_at::date AND f.to_date::date > so.created_at::date\n",
    "            WHERE so.created_at::date between \n",
    "                date_trunc('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 120) \n",
    "                and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date\n",
    "                AND so.sales_order_status_id not in (7,12)\n",
    "                AND so.channel IN ('telesales','retailer')\n",
    "                AND pso.purchased_item_count <> 0\n",
    "            GROUP BY ALL\n",
    "        )\n",
    "    ) group by all \n",
    ")\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 7. TARGET MARGINS QUERY\n",
    "# =============================================================================\n",
    "TARGET_MARGINS_QUERY = f'''\n",
    "WITH cat_brand_target as (\n",
    "    SELECT DISTINCT cat, brand, margin as target_bm\n",
    "    FROM performance.commercial_targets cplan\n",
    "    QUALIFY CASE \n",
    "        WHEN DATE_TRUNC('month', MAX(DATE) OVER()) = DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date) \n",
    "        THEN DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date)\n",
    "        ELSE DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - INTERVAL '1 month') \n",
    "    END = DATE_TRUNC('month', date)\n",
    "),\n",
    "cat_target as (\n",
    "    select cat, sum(target_bm * (target_nmv/cat_total)) as cat_target_margin\n",
    "    from (\n",
    "        select *, sum(target_nmv) over(partition by cat) as cat_total\n",
    "        from (\n",
    "            select cat, brand, avg(target_bm) as target_bm, sum(target_nmv) as target_nmv\n",
    "            from (\n",
    "                SELECT DISTINCT date, city as region, cat, brand, margin as target_bm, nmv as target_nmv\n",
    "                FROM performance.commercial_targets cplan\n",
    "                QUALIFY CASE \n",
    "                    WHEN DATE_TRUNC('month', MAX(DATE) OVER()) = DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date) \n",
    "                    THEN DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date)\n",
    "                    ELSE DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - INTERVAL '1 month') \n",
    "                END = DATE_TRUNC('month', date)\n",
    "            ) group by all\n",
    "        )\n",
    "    ) group by all \n",
    ")\n",
    "SELECT DISTINCT cbt.cat, cbt.brand, cbt.target_bm, ct.cat_target_margin\n",
    "FROM cat_brand_target cbt\n",
    "LEFT JOIN cat_target ct ON ct.cat = cbt.cat\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute All Queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Snowflake...\n",
      "  1. Loading Ben Soliman prices...\n",
      "     Loaded 1563 Ben Soliman price records\n",
      "  2. Loading marketplace prices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n",
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 11396 marketplace price records\n",
      "  3. Loading scrapped data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 5084 scrapped price records\n",
      "  4. Loading product base data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 102221 product base records\n",
      "  5. Loading sales data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 20767 sales records\n",
      "  6. Loading margin stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 29098 margin stat records\n",
      "  7. Loading target margins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 478 target margin records\n",
      "  8. Loading product groups...\n",
      "     Loaded 1618 group records\n",
      "\n",
      "All queries completed!\n",
      "\n",
      "============================================================\n",
      "df_product_base DataFrame available with columns:\n",
      "  - region, cohort_id, product_id, sku, brand, cat, wac1, wac_p, current_price\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Execute all queries\n",
    "# =============================================================================\n",
    "print(\"Loading data from Snowflake...\")\n",
    "\n",
    "# 1. Ben Soliman Prices\n",
    "print(\"  1. Loading Ben Soliman prices...\")\n",
    "df_ben_soliman = query_snowflake(BEN_SOLIMAN_QUERY)\n",
    "df_ben_soliman = convert_to_numeric(df_ben_soliman)\n",
    "print(f\"     Loaded {len(df_ben_soliman)} Ben Soliman price records\")\n",
    "\n",
    "# 2. Marketplace Prices\n",
    "print(\"  2. Loading marketplace prices...\")\n",
    "df_marketplace = query_snowflake(MARKETPLACE_PRICES_QUERY)\n",
    "df_marketplace = convert_to_numeric(df_marketplace)\n",
    "print(f\"     Loaded {len(df_marketplace)} marketplace price records\")\n",
    "\n",
    "# 3. Scrapped Data\n",
    "print(\"  3. Loading scrapped data...\")\n",
    "df_scrapped = query_snowflake(SCRAPPED_DATA_QUERY)\n",
    "df_scrapped = convert_to_numeric(df_scrapped)\n",
    "print(f\"     Loaded {len(df_scrapped)} scrapped price records\")\n",
    "\n",
    "# 4. Product Base Data (product_id, sku, brand, cat, wac1, wac_p, current_price)\n",
    "print(\"  4. Loading product base data...\")\n",
    "df_product_base = query_snowflake(PRODUCT_BASE_QUERY)\n",
    "df_product_base = convert_to_numeric(df_product_base)\n",
    "print(f\"     Loaded {len(df_product_base)} product base records\")\n",
    "\n",
    "# 5. Sales Data\n",
    "print(\"  5. Loading sales data...\")\n",
    "df_sales = query_snowflake(SALES_QUERY)\n",
    "df_sales = convert_to_numeric(df_sales)\n",
    "print(f\"     Loaded {len(df_sales)} sales records\")\n",
    "\n",
    "# 6. Margin Stats\n",
    "print(\"  6. Loading margin stats...\")\n",
    "df_margin_stats = query_snowflake(MARGIN_STATS_QUERY)\n",
    "df_margin_stats = convert_to_numeric(df_margin_stats)\n",
    "print(f\"     Loaded {len(df_margin_stats)} margin stat records\")\n",
    "\n",
    "# 7. Target Margins\n",
    "print(\"  7. Loading target margins...\")\n",
    "df_targets = query_snowflake(TARGET_MARGINS_QUERY)\n",
    "df_targets = convert_to_numeric(df_targets)\n",
    "print(f\"     Loaded {len(df_targets)} target margin records\")\n",
    "\n",
    "# 8. Product Groups (from PostgreSQL)\n",
    "print(\"  8. Loading product groups...\")\n",
    "df_groups = query_snowflake(\n",
    "    '''SELECT * FROM materialized_views.sku_commercial_groups'''\n",
    ")\n",
    "df_groups.columns = df_groups.columns.str.lower()\n",
    "df_groups = convert_to_numeric(df_groups)\n",
    "print(f\"     Loaded {len(df_groups)} group records\")\n",
    "\n",
    "print(\"\\nAll queries completed!\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"df_product_base DataFrame available with columns:\")\n",
    "print(\"  - region, cohort_id, product_id, sku, brand, cat, wac1, wac_p, current_price\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building market_data DataFrame (market prices only)...\n",
      "  Step 1: Joining all market price sources (outer join)...\n",
      "     Market prices base: 16143 records\n",
      "  Step 2: Adding cohort IDs and supporting data for processing...\n",
      "\n",
      "============================================================\n",
      "MARKET DATA BASE READY FOR PROCESSING\n",
      "============================================================\n",
      "Total records: 23829\n",
      "  - With marketplace prices: 16739\n",
      "  - With scrapped prices: 7532\n",
      "  - With Ben Soliman prices: 14067\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PART A: Build market_data DataFrame - Process market prices SEPARATELY\n",
    "# =============================================================================\n",
    "print(\"Building market_data DataFrame (market prices only)...\")\n",
    "\n",
    "# Create region-cohort mapping\n",
    "REGION_COHORT_DF = pd.DataFrame({\n",
    "    'region': ['Cairo', 'Giza', 'Delta West', 'Delta East', \n",
    "               'Upper Egypt', 'Upper Egypt', 'Upper Egypt', 'Upper Egypt', 'Alexandria'],\n",
    "    'cohort_id': [700, 701, 703, 704, 1124, 1126, 1123, 1125, 702]\n",
    "})\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Outer join all market price sources\n",
    "# =============================================================================\n",
    "print(\"  Step 1: Joining all market price sources (outer join)...\")\n",
    "\n",
    "# Start with marketplace prices (has region + product_id)\n",
    "market_data = df_marketplace.copy()\n",
    "\n",
    "# Outer join with scrapped data (by region + product_id)\n",
    "market_data = market_data.merge(df_scrapped, on=['region', 'product_id'], how='outer')\n",
    "\n",
    "# Outer join with Ben Soliman prices (by product_id only - expand to all regions)\n",
    "all_regions = pd.DataFrame({'region': ['Cairo', 'Giza', 'Delta West', 'Delta East', 'Upper Egypt', 'Alexandria']})\n",
    "df_ben_soliman_expanded = df_ben_soliman.merge(all_regions, how='cross')\n",
    "\n",
    "# Outer join with Ben Soliman\n",
    "market_data = market_data.merge(df_ben_soliman_expanded, on=['region', 'product_id'], how='outer')\n",
    "\n",
    "print(f\"     Market prices base: {len(market_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Add cohort_id and supporting data for market processing\n",
    "# =============================================================================\n",
    "print(\"  Step 2: Adding cohort IDs and supporting data for processing...\")\n",
    "market_data = market_data.merge(REGION_COHORT_DF, on='region')\n",
    "\n",
    "# Need sales data for group processing (weighted median)\n",
    "market_data = market_data.merge(\n",
    "    df_sales[['cohort_id', 'product_id', 'nmv']], \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "market_data['nmv'] = market_data['nmv'].fillna(0)\n",
    "\n",
    "# Need margin stats for price analysis\n",
    "market_data = market_data.merge(df_margin_stats, on=['cohort_id', 'product_id'], how='left')\n",
    "\n",
    "# Need WAC for price analysis - get from product base\n",
    "market_data = market_data.merge(\n",
    "    df_product_base[['cohort_id', 'product_id', 'wac_p', 'brand', 'cat']].drop_duplicates(), \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Need target margins for price analysis\n",
    "market_data = market_data.merge(df_targets, on=['brand', 'cat'], how='left')\n",
    "market_data['target_margin'] = market_data['target_bm'].fillna(market_data['cat_target_margin']).fillna(0)\n",
    "market_data = market_data.drop(columns=['target_bm', 'cat_target_margin'], errors='ignore')\n",
    "\n",
    "# Fill NaN values with defaults\n",
    "market_data['std'] = market_data['std'].fillna(0.01)\n",
    "market_data['avg_margin'] = market_data['avg_margin'].fillna(0)\n",
    "\n",
    "# Merge product groups for group processing\n",
    "market_data = market_data.merge(df_groups, on='product_id', how='left')\n",
    "\n",
    "# Remove duplicates\n",
    "market_data = market_data.drop_duplicates(subset=['cohort_id', 'product_id'])\n",
    "\n",
    "# Filter out records without WAC (can't process prices without cost)\n",
    "market_data = market_data[~market_data['wac_p'].isna()]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MARKET DATA BASE READY FOR PROCESSING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(market_data)}\")\n",
    "print(f\"  - With marketplace prices: {len(market_data[~market_data['final_min_price'].isna()])}\")\n",
    "print(f\"  - With scrapped prices: {len(market_data[~market_data['min_scrapped'].isna()])}\")\n",
    "print(f\"  - With Ben Soliman prices: {len(market_data[~market_data['ben_soliman_price'].isna()])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART A: Market Data Processing\n",
    "Process market prices separately (group fill, coverage filter, price analysis, margin tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after group processing: 23829 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/2426940637.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Group Processing - Calculate group-level aggregated prices (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate group-level aggregated prices for products with group assignments\n",
    "groups_data = market_data[~market_data['group_id'].isna()].copy()\n",
    "groups_data['group_nmv'] = groups_data.groupby(['group_id', 'cohort_id'])['nmv'].transform('sum')\n",
    "groups_data['cntrb'] = (groups_data['nmv'] / groups_data['group_nmv']).fillna(1)\n",
    "\n",
    "# Flag if any price/scrapped column is non-NaN\n",
    "price_cols = [\n",
    "    'ben_soliman_price', 'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped'\n",
    "]\n",
    "groups_data['flag_non_nan'] = groups_data[price_cols].notna().any(axis=1).astype(int)\n",
    "\n",
    "# Weighted Median Function\n",
    "def weighted_median(series, weights):\n",
    "    valid = ~series.isna() & ~weights.isna()\n",
    "    s = series[valid]\n",
    "    w = weights[valid]\n",
    "    if len(s) == 0:\n",
    "        return np.nan\n",
    "    order = np.argsort(s)\n",
    "    s, w = s.iloc[order], w.iloc[order]\n",
    "    return s.iloc[np.searchsorted(np.cumsum(w), w.sum() / 2)]\n",
    "\n",
    "# Perform Weighted Aggregation\n",
    "groups_agg = (\n",
    "    groups_data[groups_data['flag_non_nan'] == 1]\n",
    "    .groupby(['group_id', 'cohort_id'])\n",
    "    .apply(lambda g: pd.Series({\n",
    "        col: weighted_median(g[col], g['cntrb']) for col in price_cols\n",
    "    }))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Fill missing prices with group-level prices\n",
    "merged = market_data.merge(groups_agg, on=['group_id', 'cohort_id'], how='left', suffixes=('', '_group'))\n",
    "for col in price_cols:\n",
    "    merged[col] = merged[col].fillna(merged[f'{col}_group'])\n",
    "\n",
    "market_data = merged.drop(columns=[f'{c}_group' for c in price_cols])\n",
    "\n",
    "print(f\"Market data after group processing: {len(market_data)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Coverage Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after price coverage filtering: 13009 records\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Price Coverage Filtering - Filter products with sufficient price data (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Score price coverage\n",
    "market_data['ben'] = 0\n",
    "market_data['MP'] = 0\n",
    "market_data['sp'] = 0\n",
    "\n",
    "# Ben Soliman: 1 point if present\n",
    "market_data.loc[~market_data['ben_soliman_price'].isna(), 'ben'] = 1\n",
    "\n",
    "# Marketplace: 1 point if single price, 3 points if range\n",
    "market_data.loc[(market_data['final_min_price'] == market_data['final_max_price']) & \n",
    "                (~market_data['final_min_price'].isna()), 'MP'] = 1\n",
    "market_data.loc[(market_data['final_min_price'] != market_data['final_max_price']) & \n",
    "                (~market_data['final_min_price'].isna()), 'MP'] = 3\n",
    "\n",
    "# Scrapped: 1 point if single price, 5 points if range\n",
    "market_data.loc[(market_data['min_scrapped'] == market_data['max_scrapped']) & \n",
    "                (~market_data['min_scrapped'].isna()), 'sp'] = 1\n",
    "market_data.loc[(market_data['min_scrapped'] != market_data['max_scrapped']) & \n",
    "                (~market_data['min_scrapped'].isna()), 'sp'] = 5\n",
    "\n",
    "# Total price coverage score\n",
    "market_data['total_p'] = market_data['ben'] + market_data['MP'] + market_data['sp']\n",
    "\n",
    "# Filter: keep only products with total_p > 2\n",
    "market_data = market_data[market_data['total_p'] > 2]\n",
    "\n",
    "print(f\"Market data after price coverage filtering: {len(market_data)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Analysis & Margin Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Price Analysis Functions\n",
    "# =============================================================================\n",
    "\n",
    "def price_analysis(row):\n",
    "    \"\"\"Analyze prices and calculate percentiles for a product.\"\"\"\n",
    "    wac = row['wac_p']\n",
    "    avg_margin = row['avg_margin'] if row['avg_margin'] >= 0.01 else row['target_margin']\n",
    "    std = np.maximum(row['std'], 0.0025)\n",
    "    target_margin = row['target_margin']\n",
    "    max_marg = np.maximum(avg_margin, target_margin)\n",
    "    \n",
    "    # Collect all price points\n",
    "    price_list = [\n",
    "        row['ben_soliman_price'], row['final_min_price'], row['final_mod_price'],\n",
    "        row['final_max_price'], row['final_true_min'], row['final_true_max'],\n",
    "        row['min_scrapped'], row['scrapped25'], row['scrapped50'], row['scrapped75'], row['max_scrapped']\n",
    "    ]\n",
    "    \n",
    "    # Filter valid prices within acceptable range\n",
    "    valid_prices = sorted({\n",
    "        x for x in price_list \n",
    "        if x and not pd.isna(x) and x != 0 \n",
    "        and wac / (1 - (avg_margin - (10 * std))) <= x <= wac / (1 - (max_marg + 10 * std))\n",
    "        and x >= wac *(0.9 + target_margin * 0.7)\n",
    "    })\n",
    "    \n",
    "    if not valid_prices:\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    return (\n",
    "        np.min(valid_prices),\n",
    "        np.percentile(valid_prices, 25),\n",
    "        np.percentile(valid_prices, 50),\n",
    "        np.percentile(valid_prices, 75),\n",
    "        np.max(valid_prices)\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_step_bounds(row):\n",
    "    \"\"\"Calculate below/above market bounds based on price steps.\"\"\"\n",
    "    wac = row['wac_p']\n",
    "    std = row['std']\n",
    "    prices = [row['minimum'], row['percentile_25'], row['percentile_50'], row['percentile_75'], row['maximum']]\n",
    "    \n",
    "    # Calculate valid steps between price points\n",
    "    valid_steps = []\n",
    "    for i in range(len(prices) - 1):\n",
    "        step = prices[i + 1] - prices[i]\n",
    "        if (step / wac) <= std * 1.2:\n",
    "            valid_steps.append(step)\n",
    "    \n",
    "    avg_step = np.mean(valid_steps) if valid_steps else min(2 * std, 0.2 * row['target_margin'])\n",
    "    \n",
    "    new_min = prices[0] - avg_step if (prices[0] - avg_step) >= wac else prices[0]\n",
    "    new_max = prices[-1] + avg_step if (prices[-1] + avg_step) >= wac else prices[-1]\n",
    "    \n",
    "    return new_min, new_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after price analysis: 12277 records\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Apply Price Analysis & Margin Calculation (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Apply price analysis to calculate price percentiles\n",
    "market_data[['minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum']] = \\\n",
    "    market_data.apply(price_analysis, axis=1, result_type='expand')\n",
    "\n",
    "# Filter out records without valid price analysis\n",
    "market_data = market_data[~market_data['minimum'].isna()]\n",
    "\n",
    "# Calculate below/above market bounds\n",
    "market_data[['below_market', 'above_market']] = market_data.apply(calculate_step_bounds, axis=1, result_type='expand')\n",
    "\n",
    "print(f\"Market data after price analysis: {len(market_data)} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MARKET DATA PROCESSING COMPLETE\n",
      "============================================================\n",
      "Total processed market records: 12277\n",
      "\n",
      "Market data columns:\n",
      "  - Price columns: ben_soliman_price, final_min_price, final_max_price, etc.\n",
      "  - Percentiles: minimum, percentile_25, percentile_50, percentile_75, maximum\n",
      "  - Margin tiers: below_market, market_min, market_25, market_50, market_75, market_max, above_market\n",
      "\n",
      "Sample processed market data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>ben_soliman_price</th>\n",
       "      <th>final_min_price</th>\n",
       "      <th>final_max_price</th>\n",
       "      <th>final_mod_price</th>\n",
       "      <th>final_true_min</th>\n",
       "      <th>final_true_max</th>\n",
       "      <th>min_scrapped</th>\n",
       "      <th>scrapped25</th>\n",
       "      <th>...</th>\n",
       "      <th>percentile_50</th>\n",
       "      <th>percentile_75</th>\n",
       "      <th>maximum</th>\n",
       "      <th>below_market</th>\n",
       "      <th>market_min</th>\n",
       "      <th>market_25</th>\n",
       "      <th>market_50</th>\n",
       "      <th>market_75</th>\n",
       "      <th>market_max</th>\n",
       "      <th>above_market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>702</td>\n",
       "      <td>3.0</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>255.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>254.630005</td>\n",
       "      <td>254.957504</td>\n",
       "      <td>...</td>\n",
       "      <td>255.142502</td>\n",
       "      <td>255.694378</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.043863</td>\n",
       "      <td>0.045422</td>\n",
       "      <td>0.059938</td>\n",
       "      <td>0.060921</td>\n",
       "      <td>0.062948</td>\n",
       "      <td>0.141222</td>\n",
       "      <td>0.142481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>702</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>836.2</td>\n",
       "      <td>848.4</td>\n",
       "      <td>835.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>842.300000</td>\n",
       "      <td>848.800000</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.014991</td>\n",
       "      <td>0.019415</td>\n",
       "      <td>0.020471</td>\n",
       "      <td>0.027913</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>0.036719</td>\n",
       "      <td>0.040950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>702</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.0</td>\n",
       "      <td>274.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>274.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>275.0</td>\n",
       "      <td>0.026144</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.037781</td>\n",
       "      <td>0.044804</td>\n",
       "      <td>0.046544</td>\n",
       "      <td>0.048278</td>\n",
       "      <td>0.052584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>702</td>\n",
       "      <td>14.0</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>456.5</td>\n",
       "      <td>477.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>455.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>459.250000</td>\n",
       "      <td>465.750000</td>\n",
       "      <td>477.0</td>\n",
       "      <td>0.013385</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.020415</td>\n",
       "      <td>0.027081</td>\n",
       "      <td>0.040659</td>\n",
       "      <td>0.063285</td>\n",
       "      <td>0.067439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>702</td>\n",
       "      <td>17.0</td>\n",
       "      <td>597.493333</td>\n",
       "      <td>597.5</td>\n",
       "      <td>629.5</td>\n",
       "      <td>595.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>599.250000</td>\n",
       "      <td>614.875000</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.011707</td>\n",
       "      <td>0.017759</td>\n",
       "      <td>0.025773</td>\n",
       "      <td>0.029642</td>\n",
       "      <td>0.054301</td>\n",
       "      <td>0.090005</td>\n",
       "      <td>0.095138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_id  product_id  ben_soliman_price  final_min_price  final_max_price  \\\n",
       "0        702         3.0         251.000000            255.0            279.0   \n",
       "1        702         9.0                NaN            836.2            848.4   \n",
       "2        702        10.0                NaN            270.0            274.0   \n",
       "4        702        14.0         462.000000            456.5            477.0   \n",
       "5        702        17.0         597.493333            597.5            629.5   \n",
       "\n",
       "   final_mod_price  final_true_min  final_true_max  min_scrapped  scrapped25  \\\n",
       "0            255.0           255.0           300.0    254.630005  254.957504   \n",
       "1            835.0           835.0           850.0           NaN         NaN   \n",
       "2            270.0           270.0           275.0           NaN         NaN   \n",
       "4            477.0           455.0           477.0           NaN         NaN   \n",
       "5            595.0           595.0           639.0    592.000000  592.000000   \n",
       "\n",
       "   ...  percentile_50  percentile_75  maximum  below_market  market_min  \\\n",
       "0  ...     255.142502     255.694378    279.0      0.043863    0.045422   \n",
       "1  ...     842.300000     848.800000    850.0      0.014991    0.019415   \n",
       "2  ...     274.000000     274.500000    275.0      0.026144    0.030653   \n",
       "4  ...     459.250000     465.750000    477.0      0.013385    0.017993   \n",
       "5  ...     599.250000     614.875000    639.0      0.011707    0.017759   \n",
       "\n",
       "   market_25  market_50  market_75  market_max  above_market  \n",
       "0   0.059938   0.060921   0.062948    0.141222      0.142481  \n",
       "1   0.020471   0.027913   0.035357    0.036719      0.040950  \n",
       "2   0.037781   0.044804   0.046544    0.048278      0.052584  \n",
       "4   0.020415   0.027081   0.040659    0.063285      0.067439  \n",
       "5   0.025773   0.029642   0.054301    0.090005      0.095138  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Convert prices to margins (on market_data) - FINALIZE market_data processing\n",
    "# =============================================================================\n",
    "\n",
    "market_data['below_market'] = (market_data['below_market'] - market_data['wac_p']) / market_data['below_market']\n",
    "market_data['market_min'] = (market_data['minimum'] - market_data['wac_p']) / market_data['minimum']\n",
    "market_data['market_25'] = (market_data['percentile_25'] - market_data['wac_p']) / market_data['percentile_25']\n",
    "market_data['market_50'] = (market_data['percentile_50'] - market_data['wac_p']) / market_data['percentile_50']\n",
    "market_data['market_75'] = (market_data['percentile_75'] - market_data['wac_p']) / market_data['percentile_75']\n",
    "market_data['market_max'] = (market_data['maximum'] - market_data['wac_p']) / market_data['maximum']\n",
    "market_data['above_market'] = (market_data['above_market'] - market_data['wac_p']) / market_data['above_market']\n",
    "\n",
    "# Select only the market-related columns to merge later\n",
    "market_columns = [\n",
    "    'cohort_id', 'product_id',\n",
    "    # Market Prices (raw)\n",
    "    'ben_soliman_price', \n",
    "    'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped',\n",
    "    # Price Percentiles\n",
    "    'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum',\n",
    "    # Margin Tiers\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market'\n",
    "]\n",
    "market_data = market_data[[c for c in market_columns if c in market_data.columns]]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MARKET DATA PROCESSING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total processed market records: {len(market_data)}\")\n",
    "print(f\"\\nMarket data columns:\")\n",
    "print(\"  - Price columns: ben_soliman_price, final_min_price, final_max_price, etc.\")\n",
    "print(\"  - Percentiles: minimum, percentile_25, percentile_50, percentile_75, maximum\")\n",
    "print(\"  - Margin tiers: below_market, market_min, market_25, market_50, market_75, market_max, above_market\")\n",
    "print(f\"\\nSample processed market data:\")\n",
    "market_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART B: Build Main pricing_data DataFrame\n",
    "Start with df_product_base (all our SKUs) and LEFT JOIN the processed market_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building main pricing_data DataFrame...\n",
      "  Step 1: Starting with product base (all SKUs)...\n",
      "     Product base: 102221 records\n",
      "  Step 2: Adding warehouse mapping...\n",
      "     After warehouse mapping: 86338 records\n",
      "  Step 3: Left joining processed market data...\n",
      "     After market data join: 86338 records\n",
      "  Step 4: Left joining supporting data...\n",
      "\n",
      "============================================================\n",
      "PRICING DATA COMPLETE\n",
      "============================================================\n",
      "Total records: 86338\n",
      "\n",
      "Records with market data: 16149\n",
      "Records without market data: 70189\n",
      "\n",
      "Records with sales (nmv > 0): 29490\n",
      "Records without sales (nmv = 0): 56848\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>region</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>sku</th>\n",
       "      <th>brand</th>\n",
       "      <th>cat</th>\n",
       "      <th>wac1</th>\n",
       "      <th>wac_p</th>\n",
       "      <th>...</th>\n",
       "      <th>below_market</th>\n",
       "      <th>market_min</th>\n",
       "      <th>market_25</th>\n",
       "      <th>market_50</th>\n",
       "      <th>market_75</th>\n",
       "      <th>market_max</th>\n",
       "      <th>above_market</th>\n",
       "      <th>std</th>\n",
       "      <th>avg_margin</th>\n",
       "      <th>target_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>702</td>\n",
       "      <td>8672</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>797</td>\n",
       "      <td>Khorshed Alex</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>96.859097</td>\n",
       "      <td>96.859097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028722</td>\n",
       "      <td>0.031280</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>0.059620</td>\n",
       "      <td>0.084075</td>\n",
       "      <td>0.094775</td>\n",
       "      <td>0.096997</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.067089</td>\n",
       "      <td>0.054510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1126</td>\n",
       "      <td>8674</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>401</td>\n",
       "      <td>Bani sweif</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>96.687813</td>\n",
       "      <td>96.687813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023224</td>\n",
       "      <td>0.033122</td>\n",
       "      <td>0.052080</td>\n",
       "      <td>0.070071</td>\n",
       "      <td>0.079164</td>\n",
       "      <td>0.087851</td>\n",
       "      <td>0.096488</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>0.063310</td>\n",
       "      <td>0.054510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1124</td>\n",
       "      <td>20198</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>501</td>\n",
       "      <td>Assiut FC</td>\n",
       "      <td>      - 330 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>95.000128</td>\n",
       "      <td>95.000128</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>703</td>\n",
       "      <td>23421</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>337</td>\n",
       "      <td>El-Mahala</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>157.454327</td>\n",
       "      <td>152.730697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042141</td>\n",
       "      <td>0.045433</td>\n",
       "      <td>0.048703</td>\n",
       "      <td>0.061274</td>\n",
       "      <td>0.073517</td>\n",
       "      <td>0.084155</td>\n",
       "      <td>0.087165</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.078645</td>\n",
       "      <td>0.091986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>703</td>\n",
       "      <td>23421</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>8</td>\n",
       "      <td>Tanta</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>157.454327</td>\n",
       "      <td>152.730697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042141</td>\n",
       "      <td>0.045433</td>\n",
       "      <td>0.048703</td>\n",
       "      <td>0.061274</td>\n",
       "      <td>0.073517</td>\n",
       "      <td>0.084155</td>\n",
       "      <td>0.087165</td>\n",
       "      <td>0.005192</td>\n",
       "      <td>0.078645</td>\n",
       "      <td>0.091986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_id  product_id       region  warehouse_id      warehouse  \\\n",
       "0        702        8672   Alexandria           797  Khorshed Alex   \n",
       "1       1126        8674  Upper Egypt           401     Bani sweif   \n",
       "2       1124       20198  Upper Egypt           501      Assiut FC   \n",
       "3        703       23421   Delta West           337      El-Mahala   \n",
       "4        703       23421   Delta West             8          Tanta   \n",
       "\n",
       "                                          sku  brand         cat        wac1  \\\n",
       "0                           - 400         96.859097   \n",
       "1                          - 400         96.687813   \n",
       "2        - 330         95.000128   \n",
       "3                         - 15            157.454327   \n",
       "4                         - 15            157.454327   \n",
       "\n",
       "        wac_p  ...  below_market  market_min  market_25  market_50  market_75  \\\n",
       "0   96.859097  ...      0.028722    0.031280   0.033824   0.059620   0.084075   \n",
       "1   96.687813  ...      0.023224    0.033122   0.052080   0.070071   0.079164   \n",
       "2   95.000128  ...           NaN         NaN        NaN        NaN        NaN   \n",
       "3  152.730697  ...      0.042141    0.045433   0.048703   0.061274   0.073517   \n",
       "4  152.730697  ...      0.042141    0.045433   0.048703   0.061274   0.073517   \n",
       "\n",
       "   market_max  above_market       std  avg_margin  target_margin  \n",
       "0    0.094775      0.096997  0.010482    0.067089       0.054510  \n",
       "1    0.087851      0.096488  0.009673    0.063310       0.054510  \n",
       "2         NaN           NaN  0.010000    0.000000       0.080000  \n",
       "3    0.084155      0.087165  0.005192    0.078645       0.091986  \n",
       "4    0.084155      0.087165  0.005192    0.078645       0.091986  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PART B: Build Main pricing_data DataFrame from df_product_base\n",
    "# =============================================================================\n",
    "print(\"Building main pricing_data DataFrame...\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Start with df_product_base as the MAIN dataframe (all our SKUs)\n",
    "# =============================================================================\n",
    "print(\"  Step 1: Starting with product base (all SKUs)...\")\n",
    "pricing_data = df_product_base.copy()\n",
    "print(f\"     Product base: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Add warehouse mapping (warehouse_id and warehouse name)\n",
    "# =============================================================================\n",
    "print(\"  Step 2: Adding warehouse mapping...\")\n",
    "warehouse_df = get_warehouse_df()\n",
    "pricing_data = pricing_data.merge(\n",
    "    warehouse_df[['cohort_id', 'warehouse_id', 'warehouse']], \n",
    "    on='cohort_id'\n",
    ")\n",
    "print(f\"     After warehouse mapping: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 3: LEFT JOIN processed market_data\n",
    "# =============================================================================\n",
    "print(\"  Step 3: Left joining processed market data...\")\n",
    "pricing_data = pricing_data.merge(\n",
    "    market_data, \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "print(f\"     After market data join: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 4: LEFT JOIN supporting data (sales, margins, targets, groups)\n",
    "# =============================================================================\n",
    "print(\"  Step 4: Left joining supporting data...\")\n",
    "\n",
    "# Merge sales data (nmv only)\n",
    "pricing_data = pricing_data.merge(\n",
    "    df_sales[['cohort_id', 'product_id', 'nmv']], \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "pricing_data['nmv'] = pricing_data['nmv'].fillna(0)\n",
    "\n",
    "# Merge margin statistics (by cohort_id + product_id)\n",
    "pricing_data = pricing_data.merge(df_margin_stats, on=['cohort_id', 'product_id'], how='left')\n",
    "\n",
    "# Merge target margins (by brand + cat)\n",
    "pricing_data = pricing_data.merge(df_targets, on=['brand', 'cat'], how='left')\n",
    "pricing_data['target_margin'] = pricing_data['target_bm'].fillna(pricing_data['cat_target_margin']).fillna(0)\n",
    "pricing_data = pricing_data.drop(columns=['target_bm', 'cat_target_margin'], errors='ignore')\n",
    "\n",
    "# Fill NaN values with defaults\n",
    "pricing_data['std'] = pricing_data['std'].fillna(0.01)\n",
    "pricing_data['avg_margin'] = pricing_data['avg_margin'].fillna(0)\n",
    "\n",
    "# Merge product groups\n",
    "pricing_data = pricing_data.merge(df_groups, on='product_id', how='left')\n",
    "\n",
    "# =============================================================================\n",
    "# Step 5: Calculate current margin\n",
    "# =============================================================================\n",
    "pricing_data['current_margin'] = (pricing_data['current_price'] - pricing_data['wac_p']) / pricing_data['current_price']\n",
    "\n",
    "# Remove duplicates\n",
    "pricing_data = pricing_data.drop_duplicates(subset=['cohort_id', 'product_id','warehouse_id'])\n",
    "\n",
    "# =============================================================================\n",
    "# Reorder columns\n",
    "# =============================================================================\n",
    "final_columns = [\n",
    "    # Product Base Info\n",
    "    'cohort_id', 'product_id', 'region', 'warehouse_id', 'warehouse', 'sku', 'brand', 'cat',\n",
    "    # Cost & Price\n",
    "    'wac1', 'wac_p', 'current_price', 'current_margin',\n",
    "    # Sales\n",
    "    'nmv',\n",
    "    # Market Prices (raw)\n",
    "    'ben_soliman_price', \n",
    "    'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped',\n",
    "    # Price Percentiles\n",
    "    'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum',\n",
    "    # Margin Tiers\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market',\n",
    "    # Supporting Data\n",
    "    'std', 'avg_margin', 'target_margin', 'group'\n",
    "]\n",
    "pricing_data = pricing_data[[c for c in final_columns if c in pricing_data.columns]]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICING DATA COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(pricing_data)}\")\n",
    "print(f\"\\nRecords with market data: {len(pricing_data[~pricing_data['minimum'].isna()])}\")\n",
    "print(f\"Records without market data: {len(pricing_data[pricing_data['minimum'].isna()])}\")\n",
    "print(f\"\\nRecords with sales (nmv > 0): {len(pricing_data[pricing_data['nmv'] > 0])}\")\n",
    "print(f\"Records without sales (nmv = 0): {len(pricing_data[pricing_data['nmv'] == 0])}\")\n",
    "print(f\"\\nSample data:\")\n",
    "pricing_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discount Analysis - Price & Margin After Discount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading discount data...\n",
      "Loaded 11117 discount records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Discount Query - Get discount percentage by warehouse and product\n",
    "# =============================================================================\n",
    "DISCOUNT_QUERY = f'''\n",
    "SELECT warehouse_id, product_id, total_discount/total_nmv AS discount_perc\n",
    "FROM (\n",
    "    SELECT  \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        SUM(pso.total_price) AS total_nmv,\n",
    "        SUM((ITEM_QUANTITY_DISCOUNT_VALUE * pso.purchased_item_count) + \n",
    "            (ITEM_DISCOUNT_VALUE * pso.purchased_item_count)) AS total_discount\n",
    "    FROM product_sales_order pso \n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1 \n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY ALL\n",
    ")\n",
    "WHERE total_nmv > 0\n",
    "'''\n",
    "\n",
    "# Execute discount query\n",
    "print(\"Loading discount data...\")\n",
    "df_discount = query_snowflake(DISCOUNT_QUERY)\n",
    "df_discount = convert_to_numeric(df_discount)\n",
    "print(f\"Loaded {len(df_discount)} discount records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pricing_with_discount DataFrame...\n",
      "\n",
      "============================================================\n",
      "PRICING WITH DISCOUNT DATA COMPLETE\n",
      "============================================================\n",
      "Total records: 86338\n",
      "Records with discount (discount_perc > 0): 5039\n",
      "Records without discount: 81299\n",
      "\n",
      "New columns added:\n",
      "  - discount_perc: discount percentage from sales\n",
      "  - price_after_discount: current_price * (1 - discount_perc)\n",
      "  - margin_after_discount: (price_after_discount - wac_p) / price_after_discount\n",
      "\n",
      "Sample data with discounts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>current_price</th>\n",
       "      <th>current_margin</th>\n",
       "      <th>discount_perc</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>margin_after_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147</td>\n",
       "      <td>339</td>\n",
       "      <td>337.25</td>\n",
       "      <td>0.089014</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>326.525399</td>\n",
       "      <td>0.059093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>170</td>\n",
       "      <td>337.25</td>\n",
       "      <td>0.089014</td>\n",
       "      <td>0.021208</td>\n",
       "      <td>330.097588</td>\n",
       "      <td>0.069275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10521</td>\n",
       "      <td>1</td>\n",
       "      <td>50.25</td>\n",
       "      <td>0.061034</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>50.183798</td>\n",
       "      <td>0.059796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13885</td>\n",
       "      <td>339</td>\n",
       "      <td>132.25</td>\n",
       "      <td>0.083176</td>\n",
       "      <td>0.014680</td>\n",
       "      <td>130.308560</td>\n",
       "      <td>0.069516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13885</td>\n",
       "      <td>170</td>\n",
       "      <td>132.25</td>\n",
       "      <td>0.083176</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>127.396400</td>\n",
       "      <td>0.048246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1701</td>\n",
       "      <td>1</td>\n",
       "      <td>230.00</td>\n",
       "      <td>0.285450</td>\n",
       "      <td>0.019102</td>\n",
       "      <td>225.606540</td>\n",
       "      <td>0.271534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>88</td>\n",
       "      <td>401</td>\n",
       "      <td>52.00</td>\n",
       "      <td>0.064971</td>\n",
       "      <td>0.041127</td>\n",
       "      <td>49.861408</td>\n",
       "      <td>0.024867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>161</td>\n",
       "      <td>170</td>\n",
       "      <td>41.75</td>\n",
       "      <td>0.093907</td>\n",
       "      <td>0.013301</td>\n",
       "      <td>41.194688</td>\n",
       "      <td>0.081693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10279</td>\n",
       "      <td>236</td>\n",
       "      <td>109.00</td>\n",
       "      <td>0.115904</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>108.498600</td>\n",
       "      <td>0.111818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>10279</td>\n",
       "      <td>962</td>\n",
       "      <td>109.00</td>\n",
       "      <td>0.115904</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>108.519189</td>\n",
       "      <td>0.111987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  current_price  current_margin  discount_perc  \\\n",
       "6          147           339         337.25        0.089014       0.031800   \n",
       "7          147           170         337.25        0.089014       0.021208   \n",
       "10       10521             1          50.25        0.061034       0.001317   \n",
       "11       13885           339         132.25        0.083176       0.014680   \n",
       "12       13885           170         132.25        0.083176       0.036700   \n",
       "14        1701             1         230.00        0.285450       0.019102   \n",
       "22          88           401          52.00        0.064971       0.041127   \n",
       "28         161           170          41.75        0.093907       0.013301   \n",
       "42       10279           236         109.00        0.115904       0.004600   \n",
       "43       10279           962         109.00        0.115904       0.004411   \n",
       "\n",
       "    price_after_discount  margin_after_discount  \n",
       "6             326.525399               0.059093  \n",
       "7             330.097588               0.069275  \n",
       "10             50.183798               0.059796  \n",
       "11            130.308560               0.069516  \n",
       "12            127.396400               0.048246  \n",
       "14            225.606540               0.271534  \n",
       "22             49.861408               0.024867  \n",
       "28             41.194688               0.081693  \n",
       "42            108.498600               0.111818  \n",
       "43            108.519189               0.111987  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Create pricing_with_discount DataFrame\n",
    "# =============================================================================\n",
    "print(\"Creating pricing_with_discount DataFrame...\")\n",
    "\n",
    "# Copy pricing_data\n",
    "pricing_with_discount = pricing_data.copy()\n",
    "\n",
    "# Merge discount data (by warehouse_id + product_id)\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_discount[['warehouse_id', 'product_id', 'discount_perc']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing discount_perc with 0 (no discount)\n",
    "pricing_with_discount['discount_perc'] = pricing_with_discount['discount_perc'].fillna(0)\n",
    "\n",
    "# =============================================================================\n",
    "# Calculate price and margin after discount\n",
    "# =============================================================================\n",
    "# Price after discount = current_price * (1 - discount_perc)\n",
    "pricing_with_discount['price_after_discount'] = (\n",
    "    pricing_with_discount['current_price'] * (1 - pricing_with_discount['discount_perc'])\n",
    ")\n",
    "\n",
    "# Margin after discount = (price_after_discount - wac_p) / price_after_discount\n",
    "pricing_with_discount['margin_after_discount'] = (\n",
    "    (pricing_with_discount['price_after_discount'] - pricing_with_discount['wac_p']) / \n",
    "    pricing_with_discount['price_after_discount']\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICING WITH DISCOUNT DATA COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(pricing_with_discount)}\")\n",
    "print(f\"Records with discount (discount_perc > 0): {len(pricing_with_discount[pricing_with_discount['discount_perc'] > 0])}\")\n",
    "print(f\"Records without discount: {len(pricing_with_discount[pricing_with_discount['discount_perc'] == 0])}\")\n",
    "print(f\"\\nNew columns added:\")\n",
    "print(\"  - discount_perc: discount percentage from sales\")\n",
    "print(\"  - price_after_discount: current_price * (1 - discount_perc)\")\n",
    "print(\"  - margin_after_discount: (price_after_discount - wac_p) / price_after_discount\")\n",
    "print(f\"\\nSample data with discounts:\")\n",
    "pricing_with_discount[pricing_with_discount['discount_perc'] > 0][\n",
    "    ['product_id', 'warehouse_id', 'current_price', 'current_margin', \n",
    "     'discount_perc', 'price_after_discount', 'margin_after_discount']\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PRICE POSITION ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Price Position Distribution:\n",
      "price_position\n",
      "No Market Data    70189\n",
      "At 50th            3083\n",
      "At 75th            2734\n",
      "At Max             2670\n",
      "At 25th            2193\n",
      "Below Market       1785\n",
      "At Min             1733\n",
      "Above Market       1679\n",
      "Below Min           272\n",
      "\n",
      "Price Position Percentages:\n",
      "price_position\n",
      "No Market Data    81.3%\n",
      "At 50th           3.57%\n",
      "At 75th           3.17%\n",
      "At Max            3.09%\n",
      "At 25th           2.54%\n",
      "Below Market      2.07%\n",
      "At Min            2.01%\n",
      "Above Market      1.94%\n",
      "Below Min         0.32%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Sample data with price position:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>current_price</th>\n",
       "      <th>discount_perc</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>price_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8672</td>\n",
       "      <td>797</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>106.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>99.986667</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8674</td>\n",
       "      <td>401</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>102.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>102.750000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>At 25th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20198</td>\n",
       "      <td>501</td>\n",
       "      <td>      - 330 </td>\n",
       "      <td>105.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23421</td>\n",
       "      <td>337</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>166.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>166.750000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>166.764706</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23421</td>\n",
       "      <td>8</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>166.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>166.750000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>166.764706</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11774</td>\n",
       "      <td>501</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>253.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>227.000000</td>\n",
       "      <td>253.087216</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>337.25</td>\n",
       "      <td>0.031800</td>\n",
       "      <td>326.525399</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>Below Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>170</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>337.25</td>\n",
       "      <td>0.021208</td>\n",
       "      <td>330.097588</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>345.000000</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11774</td>\n",
       "      <td>339</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>249.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>231.500000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11774</td>\n",
       "      <td>170</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>249.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>231.500000</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10521</td>\n",
       "      <td>1</td>\n",
       "      <td>     - ...</td>\n",
       "      <td>50.25</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>50.183798</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13885</td>\n",
       "      <td>339</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>132.25</td>\n",
       "      <td>0.014680</td>\n",
       "      <td>130.308560</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>Below Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13885</td>\n",
       "      <td>170</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>132.25</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>127.396400</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>Below Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>703</td>\n",
       "      <td>  - 1.2 </td>\n",
       "      <td>410.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>361.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1701</td>\n",
       "      <td>1</td>\n",
       "      <td>   2  - 2 </td>\n",
       "      <td>230.00</td>\n",
       "      <td>0.019102</td>\n",
       "      <td>225.606540</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>230.000000</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "0         8672           797   \n",
       "1         8674           401   \n",
       "2        20198           501   \n",
       "3        23421           337   \n",
       "4        23421             8   \n",
       "5        11774           501   \n",
       "6          147           339   \n",
       "7          147           170   \n",
       "8        11774           339   \n",
       "9        11774           170   \n",
       "10       10521             1   \n",
       "11       13885           339   \n",
       "12       13885           170   \n",
       "13         385           703   \n",
       "14        1701             1   \n",
       "\n",
       "                                                  sku  current_price  \\\n",
       "0                                   - 400          106.00   \n",
       "1                                  - 400          102.75   \n",
       "2                - 330          105.00   \n",
       "3                                 - 15          166.75   \n",
       "4                                 - 15          166.75   \n",
       "5               ( 8  ) - 500          253.00   \n",
       "6                                 - 1          337.25   \n",
       "7                                 - 1          337.25   \n",
       "8               ( 8  ) - 500          249.00   \n",
       "9               ( 8  ) - 500          249.00   \n",
       "10       - ...          50.25   \n",
       "11                      - 15          132.25   \n",
       "12                      - 15          132.25   \n",
       "13                                - 1.2          410.00   \n",
       "14                    2  - 2          230.00   \n",
       "\n",
       "    discount_perc  price_after_discount     minimum     maximum  \\\n",
       "0        0.000000            106.000000   99.986667  107.000000   \n",
       "1        0.000000            102.750000  100.000000  106.000000   \n",
       "2        0.000000            105.000000         NaN         NaN   \n",
       "3        0.000000            166.750000  160.000000  166.764706   \n",
       "4        0.000000            166.750000  160.000000  166.764706   \n",
       "5        0.000000            253.000000  227.000000  253.087216   \n",
       "6        0.031800            326.525399  330.000000  345.000000   \n",
       "7        0.021208            330.097588  330.000000  345.000000   \n",
       "8        0.000000            249.000000  231.500000  249.000000   \n",
       "9        0.000000            249.000000  231.500000  249.000000   \n",
       "10       0.001317             50.183798   48.000000   50.000000   \n",
       "11       0.014680            130.308560  133.000000  135.000000   \n",
       "12       0.036700            127.396400  133.000000  135.000000   \n",
       "13       0.000000            410.000000  361.000000  410.000000   \n",
       "14       0.019102            225.606540  183.000000  230.000000   \n",
       "\n",
       "    price_position  \n",
       "0          At 75th  \n",
       "1          At 25th  \n",
       "2   No Market Data  \n",
       "3          At 75th  \n",
       "4          At 75th  \n",
       "5          At 75th  \n",
       "6     Below Market  \n",
       "7           At Min  \n",
       "8           At Max  \n",
       "9           At Max  \n",
       "10          At Max  \n",
       "11    Below Market  \n",
       "12    Below Market  \n",
       "13          At Max  \n",
       "14         At 75th  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Price Position - Determine where price_after_discount falls in market tiers\n",
    "# =============================================================================\n",
    "\n",
    "def get_price_position(row):\n",
    "    \"\"\"Determine the price position relative to market price tiers.\"\"\"\n",
    "    price = row['price_after_discount']\n",
    "    wac = row['wac_p']\n",
    "    \n",
    "    # Check if we have market data (minimum price exists)\n",
    "    if pd.isna(row['minimum']) or pd.isna(price):\n",
    "        return \"No Market Data\"\n",
    "    \n",
    "    # Get price tiers\n",
    "    min_price = row['minimum']\n",
    "    p25 = row['percentile_25']\n",
    "    p50 = row['percentile_50']\n",
    "    p75 = row['percentile_75']\n",
    "    max_price = row['maximum']\n",
    "    \n",
    "    # Calculate below_market and above_market prices from margins\n",
    "    # margin = (price - wac) / price  =>  price = wac / (1 - margin)\n",
    "    below_market_margin = row['below_market']\n",
    "    above_market_margin = row['above_market']\n",
    "    \n",
    "    below_market_price = wac / (1 - below_market_margin) if below_market_margin < 1 else min_price\n",
    "    above_market_price = wac / (1 - above_market_margin) if above_market_margin < 1 else max_price\n",
    "    \n",
    "    # Determine position based on price tiers\n",
    "    if price < below_market_price:\n",
    "        return \"Below Market\"\n",
    "    elif price < min_price:\n",
    "        return \"Below Min\"\n",
    "    elif price < p25:\n",
    "        return \"At Min\"\n",
    "    elif price < p50:\n",
    "        return \"At 25th\"\n",
    "    elif price < p75:\n",
    "        return \"At 50th\"\n",
    "    elif price < max_price:\n",
    "        return \"At 75th\"\n",
    "    elif price < above_market_price:\n",
    "        return \"At Max\"\n",
    "    else:\n",
    "        return \"Above Market\"\n",
    "\n",
    "# Apply price position function\n",
    "pricing_with_discount['price_position'] = pricing_with_discount.apply(get_price_position, axis=1)\n",
    "\n",
    "# Summary of price positions\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICE POSITION ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nPrice Position Distribution:\")\n",
    "print(pricing_with_discount['price_position'].value_counts().to_string())\n",
    "print(f\"\\nPrice Position Percentages:\")\n",
    "print((pricing_with_discount['price_position'].value_counts(normalize=True) * 100).round(2).astype(str) + '%')\n",
    "\n",
    "# Sample data showing price position\n",
    "print(f\"\\nSample data with price position:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'current_price', 'discount_perc', \n",
    "     'price_after_discount', 'minimum', 'maximum', 'price_position']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stock data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1840003 stock records\n",
      "\n",
      "Stock data merged!\n",
      "Records with stock (stocks > 0): 20130\n",
      "Records without stock (stocks = 0): 66208\n",
      "\n",
      "Sample data with stocks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>stocks</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>price_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8672</td>\n",
       "      <td>797</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>0</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8674</td>\n",
       "      <td>401</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>100</td>\n",
       "      <td>102.750000</td>\n",
       "      <td>At 25th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20198</td>\n",
       "      <td>501</td>\n",
       "      <td>      - 330 </td>\n",
       "      <td>0</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23421</td>\n",
       "      <td>337</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>13</td>\n",
       "      <td>166.750000</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23421</td>\n",
       "      <td>8</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>12</td>\n",
       "      <td>166.750000</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11774</td>\n",
       "      <td>501</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>0</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>41</td>\n",
       "      <td>326.525399</td>\n",
       "      <td>Below Market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>170</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>86</td>\n",
       "      <td>330.097588</td>\n",
       "      <td>At Min</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11774</td>\n",
       "      <td>339</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>1</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11774</td>\n",
       "      <td>170</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>0</td>\n",
       "      <td>249.000000</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  warehouse_id                                         sku  \\\n",
       "0        8672           797                           - 400    \n",
       "1        8674           401                          - 400    \n",
       "2       20198           501        - 330    \n",
       "3       23421           337                         - 15    \n",
       "4       23421             8                         - 15    \n",
       "5       11774           501       ( 8  ) - 500    \n",
       "6         147           339                         - 1    \n",
       "7         147           170                         - 1    \n",
       "8       11774           339       ( 8  ) - 500    \n",
       "9       11774           170       ( 8  ) - 500    \n",
       "\n",
       "   stocks  price_after_discount  price_position  \n",
       "0       0            106.000000         At 75th  \n",
       "1     100            102.750000         At 25th  \n",
       "2       0            105.000000  No Market Data  \n",
       "3      13            166.750000         At 75th  \n",
       "4      12            166.750000         At 75th  \n",
       "5       0            253.000000         At 75th  \n",
       "6      41            326.525399    Below Market  \n",
       "7      86            330.097588          At Min  \n",
       "8       1            249.000000          At Max  \n",
       "9       0            249.000000          At Max  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Stock Query - Get available stock by warehouse and product\n",
    "# =============================================================================\n",
    "STOCK_QUERY = '''\n",
    "SELECT \n",
    "    pw.warehouse_id,\n",
    "    pw.product_id,\n",
    "    pw.available_stock::INTEGER AS stocks\n",
    "FROM product_warehouse pw\n",
    "WHERE pw.warehouse_id NOT IN (6, 9, 10)\n",
    "    AND pw.is_basic_unit = 1\n",
    "'''\n",
    "\n",
    "# Execute stock query\n",
    "print(\"Loading stock data...\")\n",
    "df_stocks = query_snowflake(STOCK_QUERY)\n",
    "df_stocks = convert_to_numeric(df_stocks)\n",
    "print(f\"Loaded {len(df_stocks)} stock records\")\n",
    "\n",
    "# Merge stock data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_stocks[['warehouse_id', 'product_id', 'stocks']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing stocks with 0\n",
    "pricing_with_discount['stocks'] = pricing_with_discount['stocks'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"\\nStock data merged!\")\n",
    "print(f\"Records with stock (stocks > 0): {len(pricing_with_discount[pricing_with_discount['stocks'] > 0])}\")\n",
    "print(f\"Records without stock (stocks = 0): {len(pricing_with_discount[pricing_with_discount['stocks'] == 0])}\")\n",
    "print(f\"\\nSample data with stocks:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'stocks', 'price_after_discount', 'price_position']\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading zero demand SKUs...\n",
      "Loaded 4388 zero demand SKU records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Zero Demand Query - Identify SKUs with zero/low demand\n",
    "# =============================================================================\n",
    "ZERO_DEMAND_QUERY = f'''\n",
    "WITH last_oss AS (\n",
    "    SELECT product_id, warehouse_id, TIMESTAMP AS last_in_stock_day\n",
    "    FROM (\n",
    "        SELECT *, ROW_NUMBER() OVER(PARTITION BY product_id, warehouse_id ORDER BY TIMESTAMP DESC) AS rnk \n",
    "        FROM materialized_views.STOCK_DAY_CLOSE\n",
    "        WHERE AVAILABLE_STOCK = 0 \n",
    "            AND TIMESTAMP >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "        QUALIFY rnk = 1 \n",
    "    )\n",
    "),\n",
    "\n",
    "current_stocks AS (\n",
    "    SELECT product_id, warehouse_id, AVAILABLE_STOCK, activation\n",
    "    FROM PRODUCT_WAREHOUSE\n",
    "    WHERE IS_BASIC_UNIT = 1\n",
    "        AND CASE WHEN product_id = 1309 THEN packing_unit_id <> 23 ELSE TRUE END\n",
    "),\n",
    "\n",
    "prs AS (\n",
    "    SELECT DISTINCT \n",
    "        product_purchased_receipts.product_id,\n",
    "        purchased_receipts.warehouse_id,\n",
    "        purchased_receipts.date::DATE AS date,\n",
    "        product_purchased_receipts.purchased_item_count * product_purchased_receipts.basic_unit_count AS purchase_min_count\n",
    "    FROM product_purchased_receipts\n",
    "    JOIN purchased_receipts ON purchased_receipts.id = product_purchased_receipts.purchased_receipt_id\n",
    "    JOIN last_oss lo ON product_purchased_receipts.product_id = lo.product_id \n",
    "        AND lo.warehouse_id = purchased_receipts.warehouse_id \n",
    "        AND purchased_receipts.date > lo.last_in_stock_day \n",
    "    WHERE product_purchased_receipts.purchased_item_count <> 0\n",
    "        AND purchased_receipts.purchased_receipt_status_id IN (4, 5, 7)\n",
    "        AND purchased_receipts.date::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "),\n",
    "\n",
    "main AS (\n",
    "    SELECT \n",
    "        prs.product_id, \n",
    "        prs.warehouse_id, \n",
    "        MIN(date) AS first_order_date, \n",
    "        SUM(purchase_min_count) AS total_recieved, \n",
    "        cs.AVAILABLE_STOCK, \n",
    "        cs.activation\n",
    "    FROM prs \n",
    "    JOIN current_stocks cs ON cs.product_id = prs.product_id AND prs.warehouse_id = cs.warehouse_id\n",
    "    GROUP BY prs.product_id, prs.warehouse_id, cs.AVAILABLE_STOCK, cs.activation\n",
    "),\n",
    "\n",
    "sold_days AS (\n",
    "    SELECT product_id, warehouse_id, COUNT(DISTINCT o_date) AS sales_days\n",
    "    FROM (\n",
    "        SELECT DISTINCT\n",
    "            so.created_at::DATE AS o_date,\n",
    "            pso.warehouse_id,\n",
    "            pso.product_id,\n",
    "            SUM(pso.purchased_item_count * basic_unit_count) AS daily_qty\n",
    "        FROM product_sales_order pso\n",
    "        JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "        JOIN main m ON m.product_id = pso.product_id \n",
    "            AND m.warehouse_id = pso.warehouse_id \n",
    "            AND so.created_at::DATE >= m.first_order_date\n",
    "        WHERE so.created_at::DATE BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120 \n",
    "            AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "            AND so.sales_order_status_id NOT IN (7, 12)\n",
    "            AND so.channel IN ('telesales', 'retailer')\n",
    "            AND pso.purchased_item_count <> 0\n",
    "        GROUP BY o_date, pso.warehouse_id, pso.product_id\n",
    "    )\n",
    "    GROUP BY product_id, warehouse_id\n",
    ")\n",
    "\n",
    "SELECT DISTINCT warehouse_id, product_id\n",
    "FROM (\n",
    "    SELECT m.product_id, m.warehouse_id, m.first_order_date, m.activation,\n",
    "        COALESCE(sd.sales_days, 0) AS sales_days,\n",
    "        COALESCE(sd.sales_days, 0)::FLOAT / NULLIF((CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1) - m.first_order_date, 0) AS perc_days\n",
    "    FROM main m \n",
    "    LEFT JOIN sold_days sd ON sd.product_id = m.product_id AND sd.warehouse_id = m.warehouse_id\n",
    "    WHERE m.first_order_date < CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 10\n",
    ")\n",
    "WHERE perc_days <= 0.3\n",
    "    AND activation = 'true'\n",
    "'''\n",
    "\n",
    "# Execute zero demand query\n",
    "print(\"Loading zero demand SKUs...\")\n",
    "df_zero_demand = query_snowflake(ZERO_DEMAND_QUERY)\n",
    "df_zero_demand = convert_to_numeric(df_zero_demand)\n",
    "print(f\"Loaded {len(df_zero_demand)} zero demand SKU records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero demand flag added!\n",
      "SKUs flagged as zero demand: 4233\n",
      "SKUs with normal demand: 82105\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Zero Demand Flag to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Add a marker column to identify zero demand SKUs\n",
    "df_zero_demand['zero_demand'] = 1\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_zero_demand[['warehouse_id', 'product_id', 'zero_demand']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values with 0 (not zero demand)\n",
    "pricing_with_discount['zero_demand'] = pricing_with_discount['zero_demand'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"Zero demand flag added!\")\n",
    "print(f\"SKUs flagged as zero demand: {len(pricing_with_discount[pricing_with_discount['zero_demand'] == 1])}\")\n",
    "print(f\"SKUs with normal demand: {len(pricing_with_discount[pricing_with_discount['zero_demand'] == 0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OOS yesterday data...\n",
      "Loaded 1889526 OOS yesterday records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OOS Yesterday Query - Identify SKUs out of stock yesterday\n",
    "# =============================================================================\n",
    "OOS_YESTERDAY_QUERY = f'''\n",
    "SELECT DISTINCT product_id, warehouse_id,\n",
    "    CASE WHEN opening_stocks = 0 AND closing_stocks = 0 THEN 1\n",
    "         ELSE 0 \n",
    "    END AS oos_yesterday\n",
    "FROM (\n",
    "    SELECT \n",
    "        timestamp,\n",
    "        product_id,\n",
    "        warehouse_id, \n",
    "        AVAILABLE_STOCK AS closing_stocks,\n",
    "        LAG(AVAILABLE_STOCK) OVER (PARTITION BY product_id, warehouse_id ORDER BY TIMESTAMP) AS opening_stocks\n",
    "    FROM materialized_views.stock_day_close\n",
    "    WHERE timestamp::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 2\n",
    "    QUALIFY opening_stocks IS NOT NULL\n",
    ")\n",
    "WHERE oos_yesterday = 1\n",
    "'''\n",
    "\n",
    "# Execute OOS yesterday query\n",
    "print(\"Loading OOS yesterday data...\")\n",
    "df_oos_yesterday = query_snowflake(OOS_YESTERDAY_QUERY)\n",
    "df_oos_yesterday = convert_to_numeric(df_oos_yesterday)\n",
    "print(f\"Loaded {len(df_oos_yesterday)} OOS yesterday records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS yesterday flag added!\n",
      "SKUs out of stock yesterday: 65711\n",
      "SKUs in stock yesterday: 20627\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add OOS Yesterday Flag to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_oos_yesterday[['warehouse_id', 'product_id', 'oos_yesterday']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values with 0 (not OOS yesterday)\n",
    "pricing_with_discount['oos_yesterday'] = pricing_with_discount['oos_yesterday'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"OOS yesterday flag added!\")\n",
    "print(f\"SKUs out of stock yesterday: {len(pricing_with_discount[pricing_with_discount['oos_yesterday'] == 1])}\")\n",
    "print(f\"SKUs in stock yesterday: {len(pricing_with_discount[pricing_with_discount['oos_yesterday'] == 0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading running rate data (this may take a moment)...\n",
      "Loaded 21884 running rate records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Running Rate Query - Get in-stock running rate by warehouse and product\n",
    "# =============================================================================\n",
    "RUNNING_RATE_QUERY = f'''\n",
    "WITH params AS (\n",
    "    SELECT\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE AS run_date,\n",
    "        DATEADD(month, -3, CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE) AS history_start\n",
    "),\n",
    "\n",
    "-- Daily sales aggregation\n",
    "sales_base AS (\n",
    "    SELECT\n",
    "        pso.product_id,\n",
    "        pso.warehouse_id,\n",
    "        DATE_TRUNC('day', pso.created_at)::DATE AS date,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count) AS sold_units,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count * pso.item_price)\n",
    "            / NULLIF(SUM(pso.purchased_item_count * pso.basic_unit_count), 0) AS avg_selling_price,\n",
    "        COUNT(DISTINCT so.retailer_id) AS retailer_count\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON pso.sales_order_id = so.id\n",
    "    WHERE DATE_TRUNC('day', pso.created_at)::DATE >= (SELECT history_start FROM params)\n",
    "    GROUP BY 1, 2, 3\n",
    "),\n",
    "\n",
    "-- Stock daily metrics\n",
    "stock_daily AS (\n",
    "    SELECT\n",
    "        product_id,\n",
    "        warehouse_id,\n",
    "        DATE_TRUNC('day', TIMESTAMP)::DATE AS date,\n",
    "        MAX_BY(available_stock, TIMESTAMP) AS stock_closing,\n",
    "        24 * SUM(CASE WHEN activation = FALSE OR available_stock = 0 THEN 1 ELSE 0 END)::FLOAT \n",
    "            / NULLIF(COUNT(*), 0) AS oos_hours,\n",
    "        MAX(CASE WHEN activation = TRUE AND available_stock > 0 THEN 1 ELSE 0 END) AS in_stock_flag\n",
    "    FROM materialized_views.STOCK_SNAP_SHOTS_RECENT\n",
    "    WHERE product_id IS NOT NULL\n",
    "    GROUP BY product_id, warehouse_id, date\n",
    "),\n",
    "\n",
    "-- Join sales + stock + WAC (only in-stock days)\n",
    "base_data AS (\n",
    "    SELECT\n",
    "        sb.product_id,\n",
    "        sb.warehouse_id,\n",
    "        sb.date,\n",
    "        sb.sold_units,\n",
    "        sb.avg_selling_price,\n",
    "        sb.retailer_count,\n",
    "        sd.oos_hours,\n",
    "        sd.in_stock_flag,\n",
    "        ac.wac_p AS wac,\n",
    "        CASE WHEN DAYOFWEEKISO(sb.date) IN (5, 6) THEN 1 ELSE 0 END AS is_weekend\n",
    "    FROM sales_base sb\n",
    "    LEFT JOIN stock_daily sd ON sb.product_id = sd.product_id \n",
    "        AND sb.warehouse_id = sd.warehouse_id AND sb.date = sd.date\n",
    "    LEFT JOIN finance.ALL_COGS ac ON sb.product_id = ac.product_id \n",
    "        AND sb.date BETWEEN ac.from_date AND ac.to_date\n",
    "    WHERE sd.in_stock_flag = 1\n",
    "),\n",
    "\n",
    "-- Stats per SKU x Warehouse\n",
    "sku_wh_stats AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY sold_units) AS med_units,\n",
    "        PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY sold_units) AS pct95_units,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY retailer_count) AS med_retailers,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY \n",
    "            CASE WHEN avg_selling_price IS NULL OR avg_selling_price = 0 THEN 0 \n",
    "            ELSE (avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0) END\n",
    "        ) AS med_margin\n",
    "    FROM base_data\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Cap outliers and adjust for retailer spikes\n",
    "adjusted AS (\n",
    "    SELECT\n",
    "        b.product_id, b.warehouse_id, b.date, b.in_stock_flag, b.oos_hours, b.is_weekend,\n",
    "        b.avg_selling_price, b.wac, s.med_margin,\n",
    "        CASE \n",
    "            WHEN b.retailer_count > GREATEST(2, s.med_retailers * 2) \n",
    "                AND b.retailer_count > 0 AND s.med_retailers IS NOT NULL\n",
    "            THEN ROUND(LEAST(b.sold_units, s.pct95_units) * (s.med_retailers::FLOAT / NULLIF(b.retailer_count::FLOAT, 0)), 0)\n",
    "            ELSE LEAST(b.sold_units, s.pct95_units)\n",
    "        END AS units_adjusted\n",
    "    FROM base_data b\n",
    "    LEFT JOIN sku_wh_stats s ON b.product_id = s.product_id AND b.warehouse_id = s.warehouse_id\n",
    "),\n",
    "\n",
    "-- Apply weights (recency, stock availability, weekend, margin)\n",
    "weighted AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id, date, units_adjusted,\n",
    "        (\n",
    "            -- Recency weight\n",
    "            CASE WHEN date >= DATEADD(day, -21, (SELECT run_date FROM params)) THEN 1.5\n",
    "                 WHEN date >= DATEADD(day, -90, (SELECT run_date FROM params)) THEN 1.0\n",
    "                 ELSE 0.5 END\n",
    "            -- In-stock weight\n",
    "            * CASE WHEN in_stock_flag = 1 AND COALESCE(oos_hours, 0) < 12 THEN 1.4\n",
    "                   WHEN in_stock_flag = 1 AND COALESCE(oos_hours, 0) >= 12 THEN 0.9\n",
    "                   ELSE 0.6 END\n",
    "            -- Weekend weight\n",
    "            * CASE WHEN is_weekend = 1 THEN 0.7 ELSE 1.0 END\n",
    "            -- Margin weight\n",
    "            * CASE WHEN avg_selling_price IS NULL OR avg_selling_price = 0 OR med_margin IS NULL THEN 1.0\n",
    "                   WHEN ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) < med_margin\n",
    "                   THEN 1.0 + LEAST((med_margin - ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0))) * 2.0, 0.6)\n",
    "                   WHEN ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) > med_margin\n",
    "                   THEN 1.0 - LEAST((((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) - med_margin) * 2.0, 0.4)\n",
    "                   ELSE 1.0 END\n",
    "        ) AS final_weight\n",
    "    FROM adjusted\n",
    "    WHERE units_adjusted IS NOT NULL\n",
    "),\n",
    "\n",
    "-- Weighted average forecast\n",
    "forecast_base AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id,\n",
    "        SUM(units_adjusted * final_weight) / NULLIF(SUM(final_weight), 0) AS weighted_avg_units\n",
    "    FROM weighted\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Zero-sales last 4 days (with stock) exclusion flag\n",
    "last4_flag AS (\n",
    "    SELECT product_id, warehouse_id,\n",
    "        CASE WHEN COUNT(*) = 4 \n",
    "             AND SUM(CASE WHEN COALESCE(sold_units, 0) = 0 AND in_stock_flag = 1 THEN 1 ELSE 0 END) = 4\n",
    "        THEN 1 ELSE 0 END AS exclude_flag\n",
    "    FROM base_data\n",
    "    WHERE date >= DATEADD(day, -4, (SELECT run_date FROM params)) \n",
    "        AND date < (SELECT run_date FROM params)\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Zero sales excluded (in stock but no sales)\n",
    "zero_sales_excluded AS (\n",
    "    SELECT DISTINCT s.warehouse_id, s.product_id\n",
    "    FROM (\n",
    "        SELECT pw.warehouse_id, pw.product_id, SUM(pw.available_stock)::INT AS stocks\n",
    "        FROM product_warehouse pw\n",
    "        WHERE pw.warehouse_id NOT IN (6, 9, 10) AND pw.is_basic_unit = 1 AND pw.available_stock > 0\n",
    "        GROUP BY pw.warehouse_id, pw.product_id\n",
    "    ) s\n",
    "    LEFT JOIN (\n",
    "        SELECT pso.product_id, pso.warehouse_id, SUM(pso.total_price) AS nmv\n",
    "        FROM product_sales_order pso\n",
    "        JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "        WHERE so.created_at::date BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 5 \n",
    "            AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1\n",
    "            AND so.sales_order_status_id NOT IN (7, 12) AND so.channel IN ('telesales', 'retailer')\n",
    "            AND pso.purchased_item_count <> 0\n",
    "        GROUP BY pso.product_id, pso.warehouse_id\n",
    "    ) md ON md.product_id = s.product_id AND md.warehouse_id = s.warehouse_id\n",
    "    LEFT JOIN finance.all_cogs f ON f.product_id = s.product_id\n",
    "        AND f.from_date::date <= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "        AND f.to_date::date > CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "    LEFT JOIN (\n",
    "        SELECT pr.warehouse_id, ppr.product_id, SUM(ppr.final_price) AS total_prs\n",
    "        FROM product_purchased_receipts ppr\n",
    "        JOIN purchased_receipts pr ON pr.id = ppr.purchased_receipt_id\n",
    "        WHERE pr.date::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 4\n",
    "            AND pr.is_actual = 'true' AND pr.purchased_receipt_status_id IN (4, 5, 7)\n",
    "            AND ppr.purchased_item_count <> 0\n",
    "        GROUP BY pr.warehouse_id, ppr.product_id\n",
    "    ) prs ON prs.product_id = s.product_id AND prs.warehouse_id = s.warehouse_id\n",
    "    WHERE COALESCE(md.nmv, 0) = 0 \n",
    "        AND COALESCE(prs.total_prs, 0) < 0.7 * (COALESCE(f.wac_p, 0) * s.stocks)\n",
    "),\n",
    "\n",
    "-- First sale date for new products\n",
    "first_sale AS (\n",
    "    SELECT product_id, warehouse_id, MIN(date) AS first_sale_date\n",
    "    FROM base_data WHERE sold_units > 0\n",
    "    GROUP BY product_id, warehouse_id\n",
    ")\n",
    "\n",
    "-- Final output: running rate per warehouse/product\n",
    "SELECT\n",
    "    fb.warehouse_id,\n",
    "    fb.product_id,\n",
    "    CASE\n",
    "        WHEN l4.exclude_flag = 1 THEN 0\n",
    "        WHEN fs.first_sale_date >= DATEADD(day, -2, (SELECT run_date FROM params))\n",
    "        THEN GREATEST(CEIL(fb.weighted_avg_units), 1)\n",
    "        ELSE CEIL(fb.weighted_avg_units)\n",
    "    END AS In_stock_rr\n",
    "FROM forecast_base fb\n",
    "LEFT JOIN last4_flag l4 ON fb.product_id = l4.product_id AND fb.warehouse_id = l4.warehouse_id\n",
    "LEFT JOIN first_sale fs ON fb.product_id = fs.product_id AND fb.warehouse_id = fs.warehouse_id\n",
    "LEFT JOIN zero_sales_excluded zse ON fb.product_id = zse.product_id AND fb.warehouse_id = zse.warehouse_id\n",
    "WHERE zse.product_id IS NULL\n",
    "'''\n",
    "\n",
    "# Execute running rate query\n",
    "print(\"Loading running rate data (this may take a moment)...\")\n",
    "df_running_rate = query_snowflake(RUNNING_RATE_QUERY)\n",
    "df_running_rate = convert_to_numeric(df_running_rate)\n",
    "print(f\"Loaded {len(df_running_rate)} running rate records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Merge Running Rate and Calculate DOH (Days on Hand)\n",
    "# =============================================================================\n",
    "\n",
    "# Merge running rate data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_running_rate[['warehouse_id', 'product_id', 'in_stock_rr']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing running rate with 0\n",
    "pricing_with_discount['in_stock_rr'] = pricing_with_discount['in_stock_rr'].fillna(0)\n",
    "\n",
    "# Calculate DOH (Days on Hand) = stocks / in_stock_rr\n",
    "# Handle division by zero - if running rate is 0, DOH is infinite (use 999)\n",
    "pricing_with_discount['doh'] = np.select(\n",
    "    [\n",
    "        (pricing_with_discount['in_stock_rr'] > 0) & (pricing_with_discount['stocks'] > 0),\n",
    "        pricing_with_discount['stocks'] == 0\n",
    "    ],\n",
    "    [\n",
    "        pricing_with_discount['stocks'] / pricing_with_discount['in_stock_rr'],\n",
    "        0\n",
    "    ],\n",
    "    default=999\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading product classification data...\n",
      "Loaded 27543 product classification records\n",
      "\n",
      "Classification distribution:\n",
      "abc_class\n",
      "C    22226\n",
      "B     4623\n",
      "A      694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Product Classification Query - ABC Classification based on order contribution\n",
    "# =============================================================================\n",
    "PRODUCT_CLASSIFICATION_QUERY = f'''\n",
    "WITH order_counts AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        COUNT(DISTINCT pso.sales_order_id) AS order_count\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 90\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id\n",
    "),\n",
    "\n",
    "warehouse_totals AS (\n",
    "    SELECT \n",
    "        warehouse_id,\n",
    "        SUM(order_count) AS total_orders\n",
    "    FROM order_counts\n",
    "    GROUP BY warehouse_id\n",
    "),\n",
    "\n",
    "ranked_products AS (\n",
    "    SELECT \n",
    "        oc.warehouse_id,\n",
    "        oc.product_id,\n",
    "        oc.order_count,\n",
    "        wt.total_orders,\n",
    "        oc.order_count::FLOAT / NULLIF(wt.total_orders, 0) AS contribution,\n",
    "        SUM(oc.order_count::FLOAT / NULLIF(wt.total_orders, 0)) \n",
    "            OVER (PARTITION BY oc.warehouse_id ORDER BY oc.order_count DESC \n",
    "                  ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_contribution\n",
    "    FROM order_counts oc\n",
    "    JOIN warehouse_totals wt ON oc.warehouse_id = wt.warehouse_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    warehouse_id,\n",
    "    product_id,\n",
    "    order_count,\n",
    "    contribution,\n",
    "    cumulative_contribution,\n",
    "    CASE \n",
    "        WHEN cumulative_contribution <= 0.3 THEN 'A'\n",
    "        WHEN cumulative_contribution <= 0.75 THEN 'B'\n",
    "        ELSE 'C'\n",
    "    END AS abc_class\n",
    "FROM ranked_products\n",
    "'''\n",
    "\n",
    "# Execute product classification query\n",
    "print(\"Loading product classification data...\")\n",
    "df_classification = query_snowflake(PRODUCT_CLASSIFICATION_QUERY)\n",
    "df_classification = convert_to_numeric(df_classification)\n",
    "print(f\"Loaded {len(df_classification)} product classification records\")\n",
    "print(f\"\\nClassification distribution:\")\n",
    "print(df_classification['abc_class'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC Classification added!\n",
      "\n",
      "Classification in pricing_with_discount:\n",
      "abc_class\n",
      "C    81284\n",
      "B     4400\n",
      "A      654\n",
      "\n",
      "Sample data with classification:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>order_count</th>\n",
       "      <th>contribution</th>\n",
       "      <th>abc_class</th>\n",
       "      <th>stocks</th>\n",
       "      <th>doh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8672</td>\n",
       "      <td>797</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8674</td>\n",
       "      <td>401</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>302</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>B</td>\n",
       "      <td>100</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20198</td>\n",
       "      <td>501</td>\n",
       "      <td>      - 330 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23421</td>\n",
       "      <td>337</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>17</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>C</td>\n",
       "      <td>13</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23421</td>\n",
       "      <td>8</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>10</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>C</td>\n",
       "      <td>12</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11774</td>\n",
       "      <td>501</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>241</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>B</td>\n",
       "      <td>41</td>\n",
       "      <td>8.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>170</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>442</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>B</td>\n",
       "      <td>86</td>\n",
       "      <td>9.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11774</td>\n",
       "      <td>339</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>78</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11774</td>\n",
       "      <td>170</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>44</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10521</td>\n",
       "      <td>1</td>\n",
       "      <td>     - ...</td>\n",
       "      <td>225</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>C</td>\n",
       "      <td>5</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13885</td>\n",
       "      <td>339</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>15</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13885</td>\n",
       "      <td>170</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>13</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>703</td>\n",
       "      <td>  - 1.2 </td>\n",
       "      <td>9</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>C</td>\n",
       "      <td>25</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1701</td>\n",
       "      <td>1</td>\n",
       "      <td>   2  - 2 </td>\n",
       "      <td>326</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>C</td>\n",
       "      <td>47</td>\n",
       "      <td>6.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "0         8672           797   \n",
       "1         8674           401   \n",
       "2        20198           501   \n",
       "3        23421           337   \n",
       "4        23421             8   \n",
       "5        11774           501   \n",
       "6          147           339   \n",
       "7          147           170   \n",
       "8        11774           339   \n",
       "9        11774           170   \n",
       "10       10521             1   \n",
       "11       13885           339   \n",
       "12       13885           170   \n",
       "13         385           703   \n",
       "14        1701             1   \n",
       "\n",
       "                                                  sku  order_count  \\\n",
       "0                                   - 400             0   \n",
       "1                                  - 400           302   \n",
       "2                - 330             0   \n",
       "3                                 - 15            17   \n",
       "4                                 - 15            10   \n",
       "5               ( 8  ) - 500             0   \n",
       "6                                 - 1           241   \n",
       "7                                 - 1           442   \n",
       "8               ( 8  ) - 500            78   \n",
       "9               ( 8  ) - 500            44   \n",
       "10       - ...          225   \n",
       "11                      - 15            15   \n",
       "12                      - 15            13   \n",
       "13                                - 1.2             9   \n",
       "14                    2  - 2           326   \n",
       "\n",
       "    contribution abc_class  stocks         doh  \n",
       "0       0.000000         C       0    0.000000  \n",
       "1       0.003497         B     100   11.111111  \n",
       "2       0.000000         C       0    0.000000  \n",
       "3       0.000079         C      13    6.500000  \n",
       "4       0.000034         C      12    6.000000  \n",
       "5       0.000000         C       0    0.000000  \n",
       "6       0.000927         B      41    8.200000  \n",
       "7       0.002062         B      86    9.555556  \n",
       "8       0.000300         C       1  999.000000  \n",
       "9       0.000205         C       0    0.000000  \n",
       "10      0.000251         C       5    0.454545  \n",
       "11      0.000058         C       7    3.500000  \n",
       "12      0.000061         C      10    5.000000  \n",
       "13      0.000054         C      25  999.000000  \n",
       "14      0.000364         C      47    6.714286  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add ABC Classification to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge classification data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_classification[['warehouse_id', 'product_id', 'order_count', 'contribution', 'abc_class']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values - products without orders in last 3 months get class 'C'\n",
    "pricing_with_discount['order_count'] = pricing_with_discount['order_count'].fillna(0).astype(int)\n",
    "pricing_with_discount['contribution'] = pricing_with_discount['contribution'].fillna(0)\n",
    "pricing_with_discount['abc_class'] = pricing_with_discount['abc_class'].fillna('C')\n",
    "\n",
    "print(f\"ABC Classification added!\")\n",
    "print(f\"\\nClassification in pricing_with_discount:\")\n",
    "print(pricing_with_discount['abc_class'].value_counts().to_string())\n",
    "print(f\"\\nSample data with classification:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'order_count', 'contribution', 'abc_class', 'stocks', 'doh']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PO data...\n",
      "Loaded 17872 PO records\n",
      "\n",
      "Confirmation status distribution:\n",
      "confirmation_status\n",
      "yes    11645\n",
      "no      2893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PO (Purchase Order) Data Query - Last PO status and rejection count\n",
    "# =============================================================================\n",
    "PO_DATA_QUERY = '''\n",
    "WITH last_data AS (\n",
    "    SELECT product_id, warehouse_id, confirmation_status, PO_date::DATE AS last_po_date, ordered_qty\n",
    "    FROM (\n",
    "        SELECT \n",
    "            product_id,\n",
    "            Target_WAREHOUSE_ID AS warehouse_id,\n",
    "            confirmation_status,\n",
    "            created_at AS PO_date,\n",
    "            MIN_QUANTITY AS ordered_qty,\n",
    "            reason,\n",
    "            MAX(created_at) OVER (PARTITION BY product_id, Target_WAREHOUSE_ID) AS last_po\n",
    "        FROM retool.PO_INITIAL_PLAN\n",
    "        WHERE created_at::DATE >= CURRENT_DATE - 15 \n",
    "    ) x\n",
    "    WHERE last_po = PO_date\n",
    "),\n",
    "\n",
    "last_15_data AS (\n",
    "    SELECT \n",
    "        product_id,\n",
    "        target_WAREHOUSE_ID AS warehouse_id,\n",
    "        COUNT(DISTINCT CASE WHEN confirmation_status <> 'yes' THEN created_at END) AS no_last_15\n",
    "    FROM retool.PO_INITIAL_PLAN\n",
    "    WHERE created_at::DATE >= CURRENT_DATE - 15 \n",
    "    GROUP BY 1, 2\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    ld.product_id,\n",
    "    ld.warehouse_id,\n",
    "    ld.confirmation_status,\n",
    "    ld.last_po_date,\n",
    "    ld.ordered_qty,\n",
    "    COALESCE(lfd.no_last_15, 0) AS no_last_15\n",
    "FROM last_data ld \n",
    "LEFT JOIN last_15_data lfd \n",
    "    ON lfd.product_id = ld.product_id \n",
    "    AND lfd.warehouse_id = ld.warehouse_id\n",
    "'''\n",
    "\n",
    "# Execute PO data query using dwh_pg_query\n",
    "print(\"Loading PO data...\")\n",
    "df_po_data = setup_environment_2.dwh_pg_query(\n",
    "    PO_DATA_QUERY, \n",
    "    columns=['product_id', 'warehouse_id', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']\n",
    ")\n",
    "df_po_data.columns = df_po_data.columns.str.lower()\n",
    "df_po_data = convert_to_numeric(df_po_data)\n",
    "print(f\"Loaded {len(df_po_data)} PO records\")\n",
    "print(f\"\\nConfirmation status distribution:\")\n",
    "print(df_po_data['confirmation_status'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO data added!\n",
      "\n",
      "Records with PO data: 13876\n",
      "Records without PO data: 72462\n",
      "\n",
      "Sample data with PO info:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>confirmation_status</th>\n",
       "      <th>last_po_date</th>\n",
       "      <th>ordered_qty</th>\n",
       "      <th>no_last_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23421</td>\n",
       "      <td>337</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23421</td>\n",
       "      <td>8</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>170</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11774</td>\n",
       "      <td>339</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10521</td>\n",
       "      <td>1</td>\n",
       "      <td>     - ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13885</td>\n",
       "      <td>339</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13885</td>\n",
       "      <td>170</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>380</td>\n",
       "      <td>797</td>\n",
       "      <td>    - 380 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2718</td>\n",
       "      <td>401</td>\n",
       "      <td>   - 20 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>     - 6 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>3480.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>286</td>\n",
       "      <td>337</td>\n",
       "      <td>    - 45 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>72.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>286</td>\n",
       "      <td>8</td>\n",
       "      <td>    - 45 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>168.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>161</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>252.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>161</td>\n",
       "      <td>170</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>414.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>308</td>\n",
       "      <td>632</td>\n",
       "      <td>   - 10 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-12</td>\n",
       "      <td>920.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "3        23421           337   \n",
       "4        23421             8   \n",
       "7          147           170   \n",
       "8        11774           339   \n",
       "10       10521             1   \n",
       "11       13885           339   \n",
       "12       13885           170   \n",
       "15         380           797   \n",
       "17        2718           401   \n",
       "21          60           170   \n",
       "25         286           337   \n",
       "26         286             8   \n",
       "27         161           339   \n",
       "28         161           170   \n",
       "31         308           632   \n",
       "\n",
       "                                                  sku confirmation_status  \\\n",
       "3                                 - 15                  yes   \n",
       "4                                 - 15                  yes   \n",
       "7                                 - 1                  yes   \n",
       "8               ( 8  ) - 500                  yes   \n",
       "10       - ...                 yes   \n",
       "11                      - 15                  yes   \n",
       "12                      - 15                  yes   \n",
       "15                     - 380                  yes   \n",
       "17                              - 20                  yes   \n",
       "21                   - 6                   no   \n",
       "25                           - 45                   no   \n",
       "26                           - 45                   no   \n",
       "27                             - 8                   no   \n",
       "28                             - 8                   no   \n",
       "31                        - 10                   no   \n",
       "\n",
       "   last_po_date  ordered_qty  no_last_15  \n",
       "3    2026-01-12          3.0           0  \n",
       "4    2026-01-18          2.0           0  \n",
       "7    2026-01-15         60.0           1  \n",
       "8    2026-01-05         24.0           0  \n",
       "10   2026-01-19         72.0           0  \n",
       "11   2026-01-19          5.0           0  \n",
       "12   2026-01-19          4.0           0  \n",
       "15   2026-01-13          6.0           1  \n",
       "17   2026-01-15          6.0           0  \n",
       "21   2026-01-19       3480.0           4  \n",
       "25   2026-01-19         72.0          12  \n",
       "26   2026-01-19        168.0          11  \n",
       "27   2026-01-19        252.0           3  \n",
       "28   2026-01-19        414.0           3  \n",
       "31   2026-01-12        920.0           5  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add PO Data to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge PO data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_po_data[['warehouse_id', 'product_id', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values\n",
    "pricing_with_discount['ordered_qty'] = pricing_with_discount['ordered_qty'].fillna(0)\n",
    "pricing_with_discount['no_last_15'] = pricing_with_discount['no_last_15'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"PO data added!\")\n",
    "print(f\"\\nRecords with PO data: {len(pricing_with_discount[~pricing_with_discount['confirmation_status'].isna()])}\")\n",
    "print(f\"Records without PO data: {len(pricing_with_discount[pricing_with_discount['confirmation_status'].isna()])}\")\n",
    "print(f\"\\nSample data with PO info:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']\n",
    "].dropna(subset=['confirmation_status']).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading leadtime data...\n",
      "Loaded 14853 leadtime records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Leadtime Query - Supplier leadtime by brand, category, and warehouse\n",
    "# =============================================================================\n",
    "LEADTIME_QUERY = '''\n",
    "SELECT brand, cat, warehouse_id, leadtime\n",
    "FROM (\n",
    "    SELECT a.*, b.name_ar AS brand, c.name_ar AS cat\n",
    "    FROM (\n",
    "        SELECT DISTINCT \n",
    "            sl.supplier_id, \n",
    "            warehouse_id, \n",
    "            category_id, \n",
    "            brand_id, \n",
    "            sl.updated_at, \n",
    "            leadtime,\n",
    "            MAX(sl.updated_at) OVER (PARTITION BY sl.supplier_id, warehouse_id) AS last_update\n",
    "        FROM retool.SUPPLIER_MOQ sl \n",
    "        JOIN retool.PO_SUPPLIER_MAPPING sm ON sl.supplier_id = sm.supplier_id \n",
    "    ) a\n",
    "    JOIN brands b ON b.id = a.brand_id \n",
    "    JOIN categories c ON c.id = a.category_id\n",
    "    WHERE a.updated_at = last_update\n",
    ") d\n",
    "'''\n",
    "\n",
    "# Execute leadtime query using dwh_pg_query\n",
    "print(\"Loading leadtime data...\")\n",
    "df_leadtime = setup_environment_2.dwh_pg_query(\n",
    "    LEADTIME_QUERY, \n",
    "    columns=['brand', 'cat', 'warehouse_id', 'leadtime']\n",
    ")\n",
    "df_leadtime.columns = df_leadtime.columns.str.lower()\n",
    "df_leadtime = convert_to_numeric(df_leadtime)\n",
    "print(f\"Loaded {len(df_leadtime)} leadtime records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leadtime data added!\n",
      "\n",
      "Records with leadtime: 91348\n",
      "Records without leadtime: 0\n",
      "\n",
      "Leadtime distribution:\n",
      "count    91348.000000\n",
      "mean        55.214608\n",
      "std         30.655723\n",
      "min         24.000000\n",
      "25%         48.000000\n",
      "50%         48.000000\n",
      "75%         72.000000\n",
      "max        168.000000\n",
      "Name: leadtime, dtype: float64\n",
      "\n",
      "Expected receiving day calculated!\n",
      "Records with expected receiving day (future dates only): 10532\n",
      "Records with past expected dates (set to empty): 7366\n",
      "Records with confirmation_status='no' (added 2 extra days): 2848\n",
      "\n",
      "Sample data with expected receiving day:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>confirmation_status</th>\n",
       "      <th>last_po_date</th>\n",
       "      <th>leadtime</th>\n",
       "      <th>adjusted_leadtime</th>\n",
       "      <th>expected_receiving_day</th>\n",
       "      <th>doh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23421</td>\n",
       "      <td>337</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-12</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>6.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23421</td>\n",
       "      <td>8</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2026-01-21</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>170</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>9.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11774</td>\n",
       "      <td>339</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11774</td>\n",
       "      <td>170</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-06</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10521</td>\n",
       "      <td>1</td>\n",
       "      <td>     - ...</td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13885</td>\n",
       "      <td>339</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13885</td>\n",
       "      <td>170</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1701</td>\n",
       "      <td>1</td>\n",
       "      <td>   2  - 2 </td>\n",
       "      <td>None</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>6.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>380</td>\n",
       "      <td>797</td>\n",
       "      <td>    - 380 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2718</td>\n",
       "      <td>401</td>\n",
       "      <td>   - 20 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>17.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>     - 6 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>48.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>286</td>\n",
       "      <td>337</td>\n",
       "      <td>    - 45 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>48.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>286</td>\n",
       "      <td>8</td>\n",
       "      <td>    - 45 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>48.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>161</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-19</td>\n",
       "      <td>48.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2026-01-23</td>\n",
       "      <td>4.916667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "3        23421           337   \n",
       "4        23421             8   \n",
       "7          147           170   \n",
       "8        11774           339   \n",
       "9        11774           170   \n",
       "10       10521             1   \n",
       "11       13885           339   \n",
       "12       13885           170   \n",
       "14        1701             1   \n",
       "15         380           797   \n",
       "17        2718           401   \n",
       "21          60           170   \n",
       "25         286           337   \n",
       "26         286             8   \n",
       "27         161           339   \n",
       "\n",
       "                                                  sku confirmation_status  \\\n",
       "3                                 - 15                  yes   \n",
       "4                                 - 15                  yes   \n",
       "7                                 - 1                  yes   \n",
       "8               ( 8  ) - 500                  yes   \n",
       "9               ( 8  ) - 500                 None   \n",
       "10       - ...                 yes   \n",
       "11                      - 15                  yes   \n",
       "12                      - 15                  yes   \n",
       "14                    2  - 2                 None   \n",
       "15                     - 380                  yes   \n",
       "17                              - 20                  yes   \n",
       "21                   - 6                   no   \n",
       "25                           - 45                   no   \n",
       "26                           - 45                   no   \n",
       "27                             - 8                   no   \n",
       "\n",
       "   last_po_date  leadtime  adjusted_leadtime expected_receiving_day  \\\n",
       "3    2026-01-12      72.0               72.0                    NaT   \n",
       "4    2026-01-18      72.0               72.0             2026-01-21   \n",
       "7    2026-01-15      24.0               24.0                    NaT   \n",
       "8    2026-01-05      24.0               24.0                    NaT   \n",
       "9    2026-01-06      72.0               72.0                    NaT   \n",
       "10   2026-01-19      24.0               24.0             2026-01-20   \n",
       "11   2026-01-19      24.0               24.0             2026-01-20   \n",
       "12   2026-01-19      24.0               24.0             2026-01-20   \n",
       "14   2026-01-19      24.0               24.0             2026-01-20   \n",
       "15   2026-01-13      48.0               48.0                    NaT   \n",
       "17   2026-01-15      48.0               48.0                    NaT   \n",
       "21   2026-01-19      48.0               96.0             2026-01-23   \n",
       "25   2026-01-19      48.0               96.0             2026-01-23   \n",
       "26   2026-01-19      48.0               96.0             2026-01-23   \n",
       "27   2026-01-19      48.0               96.0             2026-01-23   \n",
       "\n",
       "           doh  \n",
       "3     6.500000  \n",
       "4     6.000000  \n",
       "7     9.555556  \n",
       "8   999.000000  \n",
       "9     0.000000  \n",
       "10    0.454545  \n",
       "11    3.500000  \n",
       "12    5.000000  \n",
       "14    6.714286  \n",
       "15  999.000000  \n",
       "17   17.000000  \n",
       "21    0.000000  \n",
       "25    0.000000  \n",
       "26    0.000000  \n",
       "27    4.916667  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Leadtime to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge leadtime data with pricing_with_discount (by brand, cat, warehouse_id)\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_leadtime[['brand', 'cat', 'warehouse_id', 'leadtime']], \n",
    "    on=['brand', 'cat', 'warehouse_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing leadtime with 0 or a default value\n",
    "pricing_with_discount['leadtime'] = pricing_with_discount['leadtime'].fillna(72)\n",
    "\n",
    "\n",
    "print(f\"Leadtime data added!\")\n",
    "print(f\"\\nRecords with leadtime: {len(pricing_with_discount[pricing_with_discount['leadtime'] > 0])}\")\n",
    "print(f\"Records without leadtime: {len(pricing_with_discount[pricing_with_discount['leadtime'] == 0])}\")\n",
    "print(f\"\\nLeadtime distribution:\")\n",
    "print(pricing_with_discount['leadtime'].describe())\n",
    "\n",
    "# =============================================================================\n",
    "# Calculate Expected Receiving Day\n",
    "# If confirmation_status is 'no': add 2 extra days (48 hours) before adding leadtime\n",
    "# expected_receiving_day = last_po_date + ((2 + leadtime) / 24) if not confirmed\n",
    "# expected_receiving_day = last_po_date + (leadtime / 24) if confirmed\n",
    "# =============================================================================\n",
    "\n",
    "# Convert last_po_date to datetime if not already\n",
    "pricing_with_discount['last_po_date'] = pd.to_datetime(pricing_with_discount['last_po_date'], errors='coerce')\n",
    "\n",
    "# Calculate adjusted leadtime: add 48 hours (2 days) if confirmation_status is 'no'\n",
    "pricing_with_discount['adjusted_leadtime'] = np.where(\n",
    "    pricing_with_discount['confirmation_status'].str.lower() == 'no',\n",
    "    pricing_with_discount['leadtime'] + 48,  # Add 2 days (48 hours) if not confirmed\n",
    "    pricing_with_discount['leadtime']\n",
    ")\n",
    "\n",
    "# Calculate expected receiving day (leadtime is in hours, divide by 24 for days)\n",
    "pricing_with_discount['expected_receiving_day'] = pricing_with_discount['last_po_date'] + pd.to_timedelta(\n",
    "    pricing_with_discount['adjusted_leadtime'] / 24, unit='D'\n",
    ")\n",
    "\n",
    "# Set expected_receiving_day to empty if it's in the past (smaller than today)\n",
    "pricing_with_discount['expected_receiving_day'] = np.where(\n",
    "    pricing_with_discount['expected_receiving_day'] < pd.Timestamp(TODAY),\n",
    "    pd.NaT,\n",
    "    pricing_with_discount['expected_receiving_day']\n",
    ")\n",
    "# Convert back to datetime (np.where returns object type)\n",
    "pricing_with_discount['expected_receiving_day'] = pd.to_datetime(pricing_with_discount['expected_receiving_day'])\n",
    "\n",
    "print(f\"\\nExpected receiving day calculated!\")\n",
    "print(f\"Records with expected receiving day (future dates only): {len(pricing_with_discount[~pricing_with_discount['expected_receiving_day'].isna()])}\")\n",
    "print(f\"Records with past expected dates (set to empty): {len(pricing_with_discount[pricing_with_discount['expected_receiving_day'].isna() & pricing_with_discount['last_po_date'].notna()])}\")\n",
    "print(f\"Records with confirmation_status='no' (added 2 extra days): {len(pricing_with_discount[pricing_with_discount['confirmation_status'].str.lower() == 'no'])}\")\n",
    "print(f\"\\nSample data with expected receiving day:\")\n",
    "pricing_with_discount[~pricing_with_discount['last_po_date'].isna()][\n",
    "    ['product_id', 'warehouse_id', 'sku', 'confirmation_status', 'last_po_date', 'leadtime', 'adjusted_leadtime', 'expected_receiving_day', 'doh']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading margin boundaries data...\n",
      "Loaded 18039 margin boundary records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Margin Boundaries Query - Get optimal, min, max boundaries from PRODUCT_STATISTICS\n",
    "# =============================================================================\n",
    "MARGIN_BOUNDARIES_QUERY = f'''\n",
    "SELECT \n",
    "    region,\n",
    "    product_id,\n",
    "    optimal_bm,\n",
    "    MIN_BOUNDARY,\n",
    "    MAX_BOUNDARY,\n",
    "    MEDIAN_BM\n",
    "FROM (\n",
    "    SELECT \n",
    "        region,\n",
    "        product_id,\n",
    "        target_bm,\n",
    "        optimal_bm,\n",
    "        MIN_BOUNDARY,\n",
    "        MAX_BOUNDARY,\n",
    "        MEDIAN_BM,\n",
    "        MAX(created_at) OVER (PARTITION BY product_id, region) AS max_date,\n",
    "        created_at\n",
    "    FROM materialized_views.PRODUCT_STATISTICS\n",
    "    WHERE created_at::DATE >= DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 60)\n",
    "    QUALIFY max_date = created_at\n",
    ")\n",
    "'''\n",
    "\n",
    "# Execute margin boundaries query\n",
    "print(\"Loading margin boundaries data...\")\n",
    "df_margin_boundaries = query_snowflake(MARGIN_BOUNDARIES_QUERY)\n",
    "df_margin_boundaries.columns = df_margin_boundaries.columns.str.lower()\n",
    "df_margin_boundaries = convert_to_numeric(df_margin_boundaries)\n",
    "print(f\"Loaded {len(df_margin_boundaries)} margin boundary records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin boundaries and tiers added!\n",
      "\n",
      "Records with margin boundaries: 34631\n",
      "Records without margin boundaries: 56717\n",
      "\n",
      "Margin Tier Structure:\n",
      "  margin_tier_below:   effective_min - step (1 below)\n",
      "  margin_tier_1:       effective_min_margin\n",
      "  margin_tier_2:       effective_min + 1*step\n",
      "  margin_tier_3:       effective_min + 2*step\n",
      "  margin_tier_4:       effective_min + 3*step\n",
      "  margin_tier_5:       max_boundary\n",
      "  margin_tier_above_1: max_boundary + 1*step\n",
      "  margin_tier_above_2: max_boundary + 2*step\n",
      "\n",
      "Sample margin tiers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>effective_min_margin</th>\n",
       "      <th>max_boundary</th>\n",
       "      <th>margin_step</th>\n",
       "      <th>margin_tier_below</th>\n",
       "      <th>margin_tier_1</th>\n",
       "      <th>margin_tier_3</th>\n",
       "      <th>margin_tier_5</th>\n",
       "      <th>margin_tier_above_1</th>\n",
       "      <th>margin_tier_above_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8672</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>0.043905</td>\n",
       "      <td>0.081765</td>\n",
       "      <td>0.009465</td>\n",
       "      <td>0.034440</td>\n",
       "      <td>0.043905</td>\n",
       "      <td>0.062835</td>\n",
       "      <td>0.081765</td>\n",
       "      <td>0.091230</td>\n",
       "      <td>0.100695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8674</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>0.047430</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.005668</td>\n",
       "      <td>0.041763</td>\n",
       "      <td>0.047430</td>\n",
       "      <td>0.058766</td>\n",
       "      <td>0.070101</td>\n",
       "      <td>0.075768</td>\n",
       "      <td>0.081436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20198</td>\n",
       "      <td>      - 330 </td>\n",
       "      <td>0.051594</td>\n",
       "      <td>0.090547</td>\n",
       "      <td>0.009738</td>\n",
       "      <td>0.041856</td>\n",
       "      <td>0.051594</td>\n",
       "      <td>0.071071</td>\n",
       "      <td>0.090547</td>\n",
       "      <td>0.100285</td>\n",
       "      <td>0.110023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23421</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>0.064390</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>0.014639</td>\n",
       "      <td>0.049751</td>\n",
       "      <td>0.064390</td>\n",
       "      <td>0.093667</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>0.137583</td>\n",
       "      <td>0.152221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23421</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>0.064390</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>0.014639</td>\n",
       "      <td>0.049751</td>\n",
       "      <td>0.064390</td>\n",
       "      <td>0.093667</td>\n",
       "      <td>0.122944</td>\n",
       "      <td>0.137583</td>\n",
       "      <td>0.152221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11774</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.081521</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.061761</td>\n",
       "      <td>0.081521</td>\n",
       "      <td>0.091401</td>\n",
       "      <td>0.101282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>0.051389</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.045986</td>\n",
       "      <td>0.051389</td>\n",
       "      <td>0.062194</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.078403</td>\n",
       "      <td>0.083806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>0.051389</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.045986</td>\n",
       "      <td>0.051389</td>\n",
       "      <td>0.062194</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.078403</td>\n",
       "      <td>0.083806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11774</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.078715</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.032821</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.060358</td>\n",
       "      <td>0.078715</td>\n",
       "      <td>0.087894</td>\n",
       "      <td>0.097073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11774</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.078715</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.032821</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.060358</td>\n",
       "      <td>0.078715</td>\n",
       "      <td>0.087894</td>\n",
       "      <td>0.097073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                         sku  \\\n",
       "0        8672                           - 400    \n",
       "1        8674                          - 400    \n",
       "2       20198        - 330    \n",
       "3       23421                         - 15    \n",
       "4       23421                         - 15    \n",
       "5       11774       ( 8  ) - 500    \n",
       "6         147                         - 1    \n",
       "7         147                         - 1    \n",
       "8       11774       ( 8  ) - 500    \n",
       "9       11774       ( 8  ) - 500    \n",
       "\n",
       "   effective_min_margin  max_boundary  margin_step  margin_tier_below  \\\n",
       "0              0.043905      0.081765     0.009465           0.034440   \n",
       "1              0.047430      0.070101     0.005668           0.041763   \n",
       "2              0.051594      0.090547     0.009738           0.041856   \n",
       "3              0.064390      0.122944     0.014639           0.049751   \n",
       "4              0.064390      0.122944     0.014639           0.049751   \n",
       "5              0.042000      0.081521     0.009880           0.032120   \n",
       "6              0.051389      0.073000     0.005403           0.045986   \n",
       "7              0.051389      0.073000     0.005403           0.045986   \n",
       "8              0.042000      0.078715     0.009179           0.032821   \n",
       "9              0.042000      0.078715     0.009179           0.032821   \n",
       "\n",
       "   margin_tier_1  margin_tier_3  margin_tier_5  margin_tier_above_1  \\\n",
       "0       0.043905       0.062835       0.081765             0.091230   \n",
       "1       0.047430       0.058766       0.070101             0.075768   \n",
       "2       0.051594       0.071071       0.090547             0.100285   \n",
       "3       0.064390       0.093667       0.122944             0.137583   \n",
       "4       0.064390       0.093667       0.122944             0.137583   \n",
       "5       0.042000       0.061761       0.081521             0.091401   \n",
       "6       0.051389       0.062194       0.073000             0.078403   \n",
       "7       0.051389       0.062194       0.073000             0.078403   \n",
       "8       0.042000       0.060358       0.078715             0.087894   \n",
       "9       0.042000       0.060358       0.078715             0.087894   \n",
       "\n",
       "   margin_tier_above_2  \n",
       "0             0.100695  \n",
       "1             0.081436  \n",
       "2             0.110023  \n",
       "3             0.152221  \n",
       "4             0.152221  \n",
       "5             0.101282  \n",
       "6             0.083806  \n",
       "7             0.083806  \n",
       "8             0.097073  \n",
       "9             0.097073  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Margin Boundaries and Calculate Margin Tiers\n",
    "# Tiers: 1 below min + 5 equally spaced in range + 2 above max = 8 tiers\n",
    "# =============================================================================\n",
    "\n",
    "# Merge margin boundaries with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_margin_boundaries[['region','product_id', 'optimal_bm', 'min_boundary', 'max_boundary', 'median_bm']], \n",
    "    on=['product_id','region'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate the effective minimum margin (min of MIN_BOUNDARY and optimal_bm)\n",
    "pricing_with_discount['effective_min_margin'] = pricing_with_discount[['min_boundary', 'optimal_bm']].min(axis=1)\n",
    "\n",
    "# Calculate step size: (max_boundary - effective_min_margin) / 4\n",
    "# This gives 5 points including both endpoints\n",
    "pricing_with_discount['margin_step'] = (\n",
    "    pricing_with_discount['max_boundary'] - pricing_with_discount['effective_min_margin']\n",
    ") / 4\n",
    "\n",
    "# Calculate the 8 margin tiers:\n",
    "# Tier -1: 1 step below minimum (below_min)\n",
    "# Tiers 1-5: 5 equally spaced margins in [effective_min, max_boundary]\n",
    "# Tier 6-7: 2 steps above maximum\n",
    "\n",
    "# Below minimum (1 step below)\n",
    "pricing_with_discount['margin_tier_below'] = pricing_with_discount['effective_min_margin'] - pricing_with_discount['margin_step']\n",
    "\n",
    "# 5 tiers in range (equally spaced)\n",
    "pricing_with_discount['margin_tier_1'] = pricing_with_discount['effective_min_margin']  # Min\n",
    "pricing_with_discount['margin_tier_2'] = pricing_with_discount['effective_min_margin'] + pricing_with_discount['margin_step']\n",
    "pricing_with_discount['margin_tier_3'] = pricing_with_discount['effective_min_margin'] + 2 * pricing_with_discount['margin_step']\n",
    "pricing_with_discount['margin_tier_4'] = pricing_with_discount['effective_min_margin'] + 3 * pricing_with_discount['margin_step']\n",
    "pricing_with_discount['margin_tier_5'] = pricing_with_discount['max_boundary']  # Max\n",
    "\n",
    "# Above maximum (2 steps above)\n",
    "pricing_with_discount['margin_tier_above_1'] = pricing_with_discount['max_boundary'] + pricing_with_discount['margin_step']\n",
    "pricing_with_discount['margin_tier_above_2'] = pricing_with_discount['max_boundary'] + 2 * pricing_with_discount['margin_step']\n",
    "\n",
    "# Fill NaN values for products without margin boundaries\n",
    "margin_tier_cols = [\n",
    "    'margin_tier_below', 'margin_tier_1', 'margin_tier_2', 'margin_tier_3', \n",
    "    'margin_tier_4', 'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2'\n",
    "]\n",
    "\n",
    "print(f\"Margin boundaries and tiers added!\")\n",
    "print(f\"\\nRecords with margin boundaries: {len(pricing_with_discount[~pricing_with_discount['max_boundary'].isna()])}\")\n",
    "print(f\"Records without margin boundaries: {len(pricing_with_discount[pricing_with_discount['max_boundary'].isna()])}\")\n",
    "\n",
    "print(f\"\\nMargin Tier Structure:\")\n",
    "print(f\"  margin_tier_below:   effective_min - step (1 below)\")\n",
    "print(f\"  margin_tier_1:       effective_min_margin\")\n",
    "print(f\"  margin_tier_2:       effective_min + 1*step\")\n",
    "print(f\"  margin_tier_3:       effective_min + 2*step\")\n",
    "print(f\"  margin_tier_4:       effective_min + 3*step\")\n",
    "print(f\"  margin_tier_5:       max_boundary\")\n",
    "print(f\"  margin_tier_above_1: max_boundary + 1*step\")\n",
    "print(f\"  margin_tier_above_2: max_boundary + 2*step\")\n",
    "\n",
    "print(f\"\\nSample margin tiers:\")\n",
    "pricing_with_discount[~pricing_with_discount['max_boundary'].isna()][\n",
    "    ['product_id', 'sku', 'effective_min_margin', 'max_boundary', 'margin_step',\n",
    "     'margin_tier_below', 'margin_tier_1', 'margin_tier_3', 'margin_tier_5', \n",
    "     'margin_tier_above_1', 'margin_tier_above_2']\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading minimum selling quantity data...\n",
      "Loaded 3884 min selling qty records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Minimum Selling Quantity Query - Get min selling qty per product\n",
    "# =============================================================================\n",
    "MIN_SELLING_QTY_QUERY = f'''\n",
    "SELECT product_id, min_selling_qty\n",
    "FROM (\n",
    "    SELECT *, MIN(basic_unit_count) OVER (PARTITION BY product_id) AS min_selling_qty\n",
    "    FROM (\n",
    "        SELECT DISTINCT\n",
    "            pso.product_id,\n",
    "            pso.PACKING_UNIT_ID,\n",
    "            pup.basic_unit_count,\n",
    "            SUM(pso.total_price) AS nmv,\n",
    "            SUM(pso.total_price) / SUM(nmv) OVER (PARTITION BY pso.product_id) AS cntrb\n",
    "        FROM product_sales_order pso\n",
    "        JOIN PACKING_UNIT_PRODUCTS pup ON pup.product_id = pso.product_id \n",
    "            AND pup.PACKING_UNIT_ID = pso.PACKING_UNIT_ID\n",
    "        JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "        WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "            AND so.sales_order_status_id NOT IN (7, 12)\n",
    "            AND so.channel IN ('telesales', 'retailer')\n",
    "            AND pso.purchased_item_count <> 0\n",
    "        GROUP BY ALL\n",
    "        QUALIFY cntrb > 0.05\n",
    "    )\n",
    "    QUALIFY basic_unit_count = min_selling_qty\n",
    ")\n",
    "'''\n",
    "\n",
    "# Execute min selling qty query\n",
    "print(\"Loading minimum selling quantity data...\")\n",
    "df_min_selling_qty = query_snowflake(MIN_SELLING_QTY_QUERY)\n",
    "df_min_selling_qty = convert_to_numeric(df_min_selling_qty)\n",
    "print(f\"Loaded {len(df_min_selling_qty)} min selling qty records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min selling qty and below_min_stock_flag added!\n",
      "\n",
      "SKUs flagged (zero RR & stocks < min_selling_qty): 118\n",
      "SKUs not flagged: 91230\n",
      "\n",
      "Sample flagged SKUs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>stocks</th>\n",
       "      <th>min_selling_qty</th>\n",
       "      <th>in_stock_rr</th>\n",
       "      <th>below_min_stock_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>1409</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 125 </td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>1205</td>\n",
       "      <td>236</td>\n",
       "      <td>   - 165 </td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>70</td>\n",
       "      <td>401</td>\n",
       "      <td>   - 680 </td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>948</td>\n",
       "      <td>632</td>\n",
       "      <td>    - 280 </td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>1053</td>\n",
       "      <td>401</td>\n",
       "      <td>   - 545 </td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7353</th>\n",
       "      <td>964</td>\n",
       "      <td>337</td>\n",
       "      <td>   - 130 </td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7354</th>\n",
       "      <td>964</td>\n",
       "      <td>8</td>\n",
       "      <td>   - 130 </td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7362</th>\n",
       "      <td>1053</td>\n",
       "      <td>632</td>\n",
       "      <td>   - 545 </td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8289</th>\n",
       "      <td>12456</td>\n",
       "      <td>339</td>\n",
       "      <td>      - 150 </td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8290</th>\n",
       "      <td>12456</td>\n",
       "      <td>170</td>\n",
       "      <td>      - 150 </td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8579</th>\n",
       "      <td>9122</td>\n",
       "      <td>337</td>\n",
       "      <td>       ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8580</th>\n",
       "      <td>9122</td>\n",
       "      <td>8</td>\n",
       "      <td>       ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8932</th>\n",
       "      <td>3557</td>\n",
       "      <td>797</td>\n",
       "      <td>     - 150 </td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>2480</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 185 </td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11521</th>\n",
       "      <td>633</td>\n",
       "      <td>339</td>\n",
       "      <td>     - 140 </td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id  warehouse_id  \\\n",
       "1872         1409           797   \n",
       "1933         1205           236   \n",
       "2876           70           401   \n",
       "2883          948           632   \n",
       "5903         1053           401   \n",
       "7353          964           337   \n",
       "7354          964             8   \n",
       "7362         1053           632   \n",
       "8289        12456           339   \n",
       "8290        12456           170   \n",
       "8579         9122           337   \n",
       "8580         9122             8   \n",
       "8932         3557           797   \n",
       "10302        2480           339   \n",
       "11521         633           339   \n",
       "\n",
       "                                                     sku  stocks  \\\n",
       "1872                             - 125        6   \n",
       "1933                            - 165        1   \n",
       "2876                              - 680        5   \n",
       "2883                       - 280        1   \n",
       "5903                         - 545        1   \n",
       "7353                         - 130        2   \n",
       "7354                         - 130        2   \n",
       "7362                         - 545        1   \n",
       "8289                   - 150        4   \n",
       "8290                   - 150        3   \n",
       "8579          ...       3   \n",
       "8580          ...       3   \n",
       "8932                        - 150        3   \n",
       "10302                        - 185        7   \n",
       "11521                - 140        7   \n",
       "\n",
       "       min_selling_qty  in_stock_rr  below_min_stock_flag  \n",
       "1872                15          0.0                     1  \n",
       "1933                12          0.0                     1  \n",
       "2876                 6          0.0                     1  \n",
       "2883                 5          0.0                     1  \n",
       "5903                 3          0.0                     1  \n",
       "7353                10          0.0                     1  \n",
       "7354                10          0.0                     1  \n",
       "7362                 3          0.0                     1  \n",
       "8289                12          0.0                     1  \n",
       "8290                12          0.0                     1  \n",
       "8579                 4          0.0                     1  \n",
       "8580                 4          0.0                     1  \n",
       "8932                12          0.0                     1  \n",
       "10302               12          0.0                     1  \n",
       "11521               12          0.0                     1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Min Selling Qty and Below Min Stock Flag to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge min selling qty with pricing_with_discount (by product_id)\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_min_selling_qty[['product_id', 'min_selling_qty']], \n",
    "    on='product_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing min_selling_qty with 1 (default)\n",
    "pricing_with_discount['min_selling_qty'] = pricing_with_discount['min_selling_qty'].fillna(1).astype(int)\n",
    "\n",
    "# Create flag: below_min_stock_flag = 1 if (RR = 0 AND stocks > 0 AND stocks < min_selling_qty)\n",
    "pricing_with_discount['below_min_stock_flag'] = np.where(\n",
    "    (pricing_with_discount['in_stock_rr'] == 0) & \n",
    "    (pricing_with_discount['stocks'] > 0) &\n",
    "    (pricing_with_discount['stocks'] < pricing_with_discount['min_selling_qty']),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "print(f\"Min selling qty and below_min_stock_flag added!\")\n",
    "print(f\"\\nSKUs flagged (zero RR & stocks < min_selling_qty): {len(pricing_with_discount[pricing_with_discount['below_min_stock_flag'] == 1])}\")\n",
    "print(f\"SKUs not flagged: {len(pricing_with_discount[pricing_with_discount['below_min_stock_flag'] == 0])}\")\n",
    "print(f\"\\nSample flagged SKUs:\")\n",
    "pricing_with_discount[pricing_with_discount['below_min_stock_flag'] == 1][\n",
    "    ['product_id', 'warehouse_id', 'sku', 'stocks', 'min_selling_qty', 'in_stock_rr', 'below_min_stock_flag']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading yesterday's discount analysis data...\n",
      "Loaded 9704 SKU discount records from yesterday\n",
      "\n",
      "============================================================\n",
      "YESTERDAY'S DISCOUNT ANALYSIS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Total NMV yesterday: 21,724,975\n",
      "SKU Discount NMV: 4,913,435\n",
      "Quantity Discount NMV: 3,616,950\n",
      "\n",
      "NMV by Tier:\n",
      "  Tier 1: 810,498\n",
      "  Tier 2: 1,686,729\n",
      "  Tier 3: 1,059,579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>total_nmv</th>\n",
       "      <th>sku_discount_nmv</th>\n",
       "      <th>qty_discount_nmv</th>\n",
       "      <th>tier1_nmv</th>\n",
       "      <th>tier2_nmv</th>\n",
       "      <th>tier3_nmv</th>\n",
       "      <th>tier_1_qty</th>\n",
       "      <th>tier_1_discount_pct</th>\n",
       "      <th>tier_2_qty</th>\n",
       "      <th>tier_2_discount_pct</th>\n",
       "      <th>tier_3_qty</th>\n",
       "      <th>tier_3_discount_pct</th>\n",
       "      <th>sku_discount_nmv_cntrb</th>\n",
       "      <th>qty_discount_nmv_cntrb</th>\n",
       "      <th>tier1_nmv_cntrb</th>\n",
       "      <th>tier2_nmv_cntrb</th>\n",
       "      <th>tier3_nmv_cntrb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>208710.00</td>\n",
       "      <td>688.00</td>\n",
       "      <td>197154.00</td>\n",
       "      <td>13457.25</td>\n",
       "      <td>34248.00</td>\n",
       "      <td>149448.75</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.94</td>\n",
       "      <td>46.0</td>\n",
       "      <td>4.78</td>\n",
       "      <td>0.33</td>\n",
       "      <td>94.46</td>\n",
       "      <td>6.45</td>\n",
       "      <td>16.41</td>\n",
       "      <td>71.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8915</td>\n",
       "      <td>170871.90</td>\n",
       "      <td>354.50</td>\n",
       "      <td>142147.00</td>\n",
       "      <td>7558.75</td>\n",
       "      <td>64533.25</td>\n",
       "      <td>70055.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>178.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.21</td>\n",
       "      <td>83.19</td>\n",
       "      <td>4.42</td>\n",
       "      <td>37.77</td>\n",
       "      <td>41.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>703</td>\n",
       "      <td>2424</td>\n",
       "      <td>149922.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>137917.50</td>\n",
       "      <td>3336.00</td>\n",
       "      <td>4342.00</td>\n",
       "      <td>130239.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>188.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>91.99</td>\n",
       "      <td>2.23</td>\n",
       "      <td>2.90</td>\n",
       "      <td>86.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>962</td>\n",
       "      <td>8915</td>\n",
       "      <td>142547.76</td>\n",
       "      <td>1406.75</td>\n",
       "      <td>125884.00</td>\n",
       "      <td>4425.25</td>\n",
       "      <td>49008.75</td>\n",
       "      <td>72450.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>186.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.99</td>\n",
       "      <td>88.31</td>\n",
       "      <td>3.10</td>\n",
       "      <td>34.38</td>\n",
       "      <td>50.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5151</td>\n",
       "      <td>106898.00</td>\n",
       "      <td>81388.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>102273.00</td>\n",
       "      <td>13632.25</td>\n",
       "      <td>18029.75</td>\n",
       "      <td>8795.00</td>\n",
       "      <td>9234.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.33</td>\n",
       "      <td>17.63</td>\n",
       "      <td>8.60</td>\n",
       "      <td>9.03</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1492</td>\n",
       "      <td>92894.50</td>\n",
       "      <td>11797.75</td>\n",
       "      <td>51257.50</td>\n",
       "      <td>3955.00</td>\n",
       "      <td>14238.00</td>\n",
       "      <td>33064.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.76</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.73</td>\n",
       "      <td>12.70</td>\n",
       "      <td>55.18</td>\n",
       "      <td>4.26</td>\n",
       "      <td>15.33</td>\n",
       "      <td>35.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>91521.75</td>\n",
       "      <td>69300.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>236</td>\n",
       "      <td>8915</td>\n",
       "      <td>82135.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3530.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>236</td>\n",
       "      <td>151</td>\n",
       "      <td>77856.75</td>\n",
       "      <td>39970.50</td>\n",
       "      <td>10581.75</td>\n",
       "      <td>10581.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>51.34</td>\n",
       "      <td>13.59</td>\n",
       "      <td>13.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warehouse_id  product_id  total_nmv  sku_discount_nmv  qty_discount_nmv  \\\n",
       "0             1         326  208710.00            688.00         197154.00   \n",
       "1             1        8915  170871.90            354.50         142147.00   \n",
       "2           703        2424  149922.50              0.00         137917.50   \n",
       "3           962        8915  142547.76           1406.75         125884.00   \n",
       "4             1        5151  106898.00          81388.25              0.00   \n",
       "5             1         151  102273.00          13632.25          18029.75   \n",
       "6             1        1492   92894.50          11797.75          51257.50   \n",
       "7             1         130   91521.75          69300.00              0.00   \n",
       "8           236        8915   82135.17              0.00           3530.00   \n",
       "9           236         151   77856.75          39970.50          10581.75   \n",
       "\n",
       "   tier1_nmv  tier2_nmv  tier3_nmv  tier_1_qty  tier_1_discount_pct  \\\n",
       "0   13457.25   34248.00  149448.75         4.0                 1.62   \n",
       "1    7558.75   64533.25   70055.00         5.0                 1.22   \n",
       "2    3336.00    4342.00  130239.50         6.0                 0.20   \n",
       "3    4425.25   49008.75   72450.00         5.0                 0.53   \n",
       "4       0.00       0.00       0.00         NaN                  NaN   \n",
       "5    8795.00    9234.75       0.00         4.0                 0.58   \n",
       "6    3955.00   14238.00   33064.50         4.0                 0.21   \n",
       "7       0.00       0.00       0.00         NaN                  NaN   \n",
       "8       0.00       0.00       0.00         NaN                  NaN   \n",
       "9   10581.75       0.00       0.00         4.0                 0.46   \n",
       "\n",
       "   tier_2_qty  tier_2_discount_pct  tier_3_qty  tier_3_discount_pct  \\\n",
       "0         9.0                 3.94        46.0                 4.78   \n",
       "1        10.0                 2.68       178.0                 3.65   \n",
       "2        11.0                 0.81       188.0                 2.89   \n",
       "3        10.0                 1.17       186.0                 2.06   \n",
       "4         NaN                  NaN         NaN                  NaN   \n",
       "5         7.0                 1.12         NaN                  NaN   \n",
       "6         7.0                 0.76        42.0                 1.73   \n",
       "7         NaN                  NaN         NaN                  NaN   \n",
       "8         NaN                  NaN         NaN                  NaN   \n",
       "9         7.0                 0.91        36.0                 1.62   \n",
       "\n",
       "   sku_discount_nmv_cntrb  qty_discount_nmv_cntrb  tier1_nmv_cntrb  \\\n",
       "0                    0.33                   94.46             6.45   \n",
       "1                    0.21                   83.19             4.42   \n",
       "2                    0.00                   91.99             2.23   \n",
       "3                    0.99                   88.31             3.10   \n",
       "4                   76.14                    0.00             0.00   \n",
       "5                   13.33                   17.63             8.60   \n",
       "6                   12.70                   55.18             4.26   \n",
       "7                   75.72                    0.00             0.00   \n",
       "8                    0.00                    4.30             0.00   \n",
       "9                   51.34                   13.59            13.59   \n",
       "\n",
       "   tier2_nmv_cntrb  tier3_nmv_cntrb  \n",
       "0            16.41            71.61  \n",
       "1            37.77            41.00  \n",
       "2             2.90            86.87  \n",
       "3            34.38            50.83  \n",
       "4             0.00             0.00  \n",
       "5             9.03             0.00  \n",
       "6            15.33            35.59  \n",
       "7             0.00             0.00  \n",
       "8             0.00             0.00  \n",
       "9             0.00             0.00  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Yesterday's Discount Analysis Query\n",
    "# Gets: SKU discount, Quantity discount, Tier 1/2/3 NMV breakdown and contributions\n",
    "# =============================================================================\n",
    "YESTERDAY_DISCOUNT_QUERY = f'''\n",
    "WITH qd_det AS (\n",
    "    -- Map dynamic tags to warehouse IDs using name matching\n",
    "    SELECT DISTINCT \n",
    "        dt.id AS tag_id, \n",
    "        dt.name AS tag_name,\n",
    "        REPLACE(w.name, ' ', '') AS warehouse_name,\n",
    "        w.id AS warehouse_id,\n",
    "        warehouse_name ILIKE '%' || CASE \n",
    "            WHEN SPLIT_PART(tag_name, '_', 1) = 'El' THEN SPLIT_PART(tag_name, '_', 2) \n",
    "            ELSE SPLIT_PART(tag_name, '_', 1) \n",
    "        END || '%' AS contains_flag\n",
    "    FROM dynamic_tags dt\n",
    "    JOIN dynamic_taggables dta ON dt.id = dta.dynamic_tag_id \n",
    "    CROSS JOIN warehouses w \n",
    "    WHERE dt.id > 3000\n",
    "        AND dt.name LIKE '%QD_rets%'\n",
    "        AND w.id IN (1, 236, 337, 8, 339, 170, 501, 401, 703, 632, 797, 962)\n",
    "        AND contains_flag = 'true'\n",
    "),\n",
    "\n",
    "qd_config AS (\n",
    "    SELECT * \n",
    "    FROM (\n",
    "        SELECT \n",
    "            product_id,\n",
    "            start_at,\n",
    "            end_at,\n",
    "            packing_unit_id,\n",
    "            id AS qd_id,\n",
    "            qd.warehouse_id,\n",
    "            MAX(CASE WHEN tier = 1 THEN quantity END) AS tier_1_qty,\n",
    "            MAX(CASE WHEN tier = 1 THEN discount_percentage END) AS tier_1_discount_pct,\n",
    "            MAX(CASE WHEN tier = 2 THEN quantity END) AS tier_2_qty,\n",
    "            MAX(CASE WHEN tier = 2 THEN discount_percentage END) AS tier_2_discount_pct,\n",
    "            MAX(CASE WHEN tier = 3 THEN quantity END) AS tier_3_qty,\n",
    "            MAX(CASE WHEN tier = 3 THEN discount_percentage END) AS tier_3_discount_pct\n",
    "        FROM (\n",
    "            SELECT \n",
    "                qd.id,\n",
    "                qdv.product_id,\n",
    "                qdv.packing_unit_id,\n",
    "                qdv.quantity,\n",
    "                qdv.discount_percentage,\n",
    "                qd.dynamic_tag_id,\n",
    "                qd.start_at,\n",
    "                qd.end_at,\n",
    "                ROW_NUMBER() OVER (\n",
    "                    PARTITION BY qdv.product_id, qdv.packing_unit_id, qd.id \n",
    "                    ORDER BY qdv.quantity\n",
    "                ) AS tier\n",
    "            FROM quantity_discounts qd \n",
    "            JOIN quantity_discount_values qdv ON qd.id = qdv.quantity_discount_id \n",
    "            WHERE CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1 \n",
    "                  BETWEEN qd.start_at::DATE AND qd.end_at::DATE\n",
    "                AND qd.start_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 5\n",
    "        ) qd_tiers\n",
    "        JOIN qd_det qd ON qd.tag_id = qd_tiers.dynamic_tag_id\n",
    "        GROUP BY ALL\n",
    "    )\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY product_id, packing_unit_id, warehouse_id ORDER BY start_at DESC) = 1\n",
    "),\n",
    "\n",
    "-- Get all sales from yesterday\n",
    "yesterday_sales AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        so.retailer_id,\n",
    "        pso.packing_unit_id,\n",
    "        pso.purchased_item_count AS qty,\n",
    "        pso.total_price AS nmv,\n",
    "        pso.item_price / pso.basic_unit_count AS unit_price,\n",
    "        pso.ITEM_DISCOUNT_VALUE AS sku_discount_per_unit,\n",
    "        pso.ITEM_QUANTITY_DISCOUNT_VALUE AS qty_discount_per_unit,\n",
    "        pso.ITEM_DISCOUNT_VALUE * pso.purchased_item_count AS sku_discount_total,\n",
    "        pso.ITEM_QUANTITY_DISCOUNT_VALUE * pso.purchased_item_count AS qty_discount_total,\n",
    "        qd.tier_1_qty,\n",
    "        qd.tier_2_qty,\n",
    "        qd.tier_3_qty,\n",
    "        qd.tier_1_discount_pct,\n",
    "        qd.tier_2_discount_pct,\n",
    "        qd.tier_3_discount_pct,\n",
    "        -- Determine tier used\n",
    "        CASE \n",
    "            WHEN pso.ITEM_QUANTITY_DISCOUNT_VALUE = 0 OR qd.tier_1_qty IS NULL THEN 'Base'\n",
    "            WHEN qd.tier_3_qty IS NOT NULL AND pso.purchased_item_count >= qd.tier_3_qty THEN 'Tier 3'\n",
    "            WHEN qd.tier_2_qty IS NOT NULL AND pso.purchased_item_count >= qd.tier_2_qty THEN 'Tier 2'\n",
    "            WHEN qd.tier_1_qty IS NOT NULL AND pso.purchased_item_count >= qd.tier_1_qty THEN 'Tier 1'\n",
    "            ELSE 'Base'\n",
    "        END AS tier_used\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    LEFT JOIN qd_config qd \n",
    "        ON qd.product_id = pso.product_id \n",
    "        AND qd.packing_unit_id = pso.packing_unit_id\n",
    "        AND qd.warehouse_id = so.warehouse_id\n",
    "    WHERE so.created_at::DATE = CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    warehouse_id,\n",
    "    product_id,\n",
    "    SUM(nmv) AS total_nmv,\n",
    "    SUM(CASE WHEN sku_discount_per_unit > 0 THEN nmv ELSE 0 END) AS sku_discount_nmv,\n",
    "    SUM(CASE WHEN qty_discount_per_unit > 0 THEN nmv ELSE 0 END) AS qty_discount_nmv,\n",
    "    SUM(CASE WHEN tier_used = 'Tier 1' THEN nmv ELSE 0 END) AS tier1_nmv,\n",
    "    SUM(CASE WHEN tier_used = 'Tier 2' THEN nmv ELSE 0 END) AS tier2_nmv,\n",
    "    SUM(CASE WHEN tier_used = 'Tier 3' THEN nmv ELSE 0 END) AS tier3_nmv,\n",
    "    -- Tier quantities and discount percentages (from the active QD config)\n",
    "    MAX(tier_1_qty) AS tier_1_qty,\n",
    "    MAX(tier_1_discount_pct) AS tier_1_discount_pct,\n",
    "    MAX(tier_2_qty) AS tier_2_qty,\n",
    "    MAX(tier_2_discount_pct) AS tier_2_discount_pct,\n",
    "    MAX(tier_3_qty) AS tier_3_qty,\n",
    "    MAX(tier_3_discount_pct) AS tier_3_discount_pct\n",
    "FROM yesterday_sales\n",
    "GROUP BY warehouse_id, product_id\n",
    "HAVING SUM(nmv) > 0\n",
    "ORDER BY total_nmv DESC\n",
    "'''\n",
    "\n",
    "# Execute yesterday discount query\n",
    "print(\"Loading yesterday's discount analysis data...\")\n",
    "df_yesterday_discount = query_snowflake(YESTERDAY_DISCOUNT_QUERY)\n",
    "df_yesterday_discount = convert_to_numeric(df_yesterday_discount)\n",
    "print(f\"Loaded {len(df_yesterday_discount)} SKU discount records from yesterday\")\n",
    "\n",
    "# Calculate contributions in Python\n",
    "df_yesterday_discount['sku_discount_nmv_cntrb'] = (\n",
    "    df_yesterday_discount['sku_discount_nmv'] / df_yesterday_discount['total_nmv'] * 100\n",
    ").round(2)\n",
    "df_yesterday_discount['qty_discount_nmv_cntrb'] = (\n",
    "    df_yesterday_discount['qty_discount_nmv'] / df_yesterday_discount['total_nmv'] * 100\n",
    ").round(2)\n",
    "df_yesterday_discount['tier1_nmv_cntrb'] = (\n",
    "    df_yesterday_discount['tier1_nmv'] / df_yesterday_discount['total_nmv'] * 100\n",
    ").round(2)\n",
    "df_yesterday_discount['tier2_nmv_cntrb'] = (\n",
    "    df_yesterday_discount['tier2_nmv'] / df_yesterday_discount['total_nmv'] * 100\n",
    ").round(2)\n",
    "df_yesterday_discount['tier3_nmv_cntrb'] = (\n",
    "    df_yesterday_discount['tier3_nmv'] / df_yesterday_discount['total_nmv'] * 100\n",
    ").round(2)\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"YESTERDAY'S DISCOUNT ANALYSIS SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nTotal NMV yesterday: {df_yesterday_discount['total_nmv'].sum():,.0f}\")\n",
    "print(f\"SKU Discount NMV: {df_yesterday_discount['sku_discount_nmv'].sum():,.0f}\")\n",
    "print(f\"Quantity Discount NMV: {df_yesterday_discount['qty_discount_nmv'].sum():,.0f}\")\n",
    "print(f\"\\nNMV by Tier:\")\n",
    "print(f\"  Tier 1: {df_yesterday_discount['tier1_nmv'].sum():,.0f}\")\n",
    "print(f\"  Tier 2: {df_yesterday_discount['tier2_nmv'].sum():,.0f}\")\n",
    "print(f\"  Tier 3: {df_yesterday_discount['tier3_nmv'].sum():,.0f}\")\n",
    "\n",
    "df_yesterday_discount.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yesterday's discount contributions and QD tier config added!\n",
      "\n",
      "SKUs with discount data: 4754\n",
      "SKUs with QD tier config: 1829\n",
      "\n",
      "Sample data with yesterday's discount contributions and QD tiers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>yesterday_sku_disc_cntrb</th>\n",
       "      <th>yesterday_qty_disc_cntrb</th>\n",
       "      <th>qd_tier_1_qty</th>\n",
       "      <th>qd_tier_1_disc_pct</th>\n",
       "      <th>qd_tier_2_qty</th>\n",
       "      <th>qd_tier_2_disc_pct</th>\n",
       "      <th>qd_tier_3_qty</th>\n",
       "      <th>qd_tier_3_disc_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>170</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>66.69</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>88</td>\n",
       "      <td>401</td>\n",
       "      <td>    - 250 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.35</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>642.0</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>161</td>\n",
       "      <td>170</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>771.0</td>\n",
       "      <td>4.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>9964</td>\n",
       "      <td>797</td>\n",
       "      <td>    - 330 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>309.0</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2438</td>\n",
       "      <td>632</td>\n",
       "      <td>    - 110 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.51</td>\n",
       "      <td>739.0</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>523</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 235 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>41.88</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.68</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>523</td>\n",
       "      <td>170</td>\n",
       "      <td>    - 235 </td>\n",
       "      <td>6.24</td>\n",
       "      <td>43.77</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.31</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>8943</td>\n",
       "      <td>401</td>\n",
       "      <td>   - 22 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>69.02</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>434.0</td>\n",
       "      <td>4.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1895</td>\n",
       "      <td>339</td>\n",
       "      <td>     5   ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.56</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>336.0</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>1895</td>\n",
       "      <td>170</td>\n",
       "      <td>     5   ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>336.0</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>996</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 225 </td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.79</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.47</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>21269</td>\n",
       "      <td>1</td>\n",
       "      <td>  - 10 </td>\n",
       "      <td>2.56</td>\n",
       "      <td>15.41</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.47</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>267.0</td>\n",
       "      <td>3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>944</td>\n",
       "      <td>703</td>\n",
       "      <td>    - 185 </td>\n",
       "      <td>12.50</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.41</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>972</td>\n",
       "      <td>236</td>\n",
       "      <td> - 5 </td>\n",
       "      <td>39.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>972</td>\n",
       "      <td>236</td>\n",
       "      <td> - 5 </td>\n",
       "      <td>39.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>108.0</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id  warehouse_id  \\\n",
       "7           147           170   \n",
       "22           88           401   \n",
       "28          161           170   \n",
       "76         9964           797   \n",
       "107        2438           632   \n",
       "119         523           339   \n",
       "120         523           170   \n",
       "132        8943           401   \n",
       "159        1895           339   \n",
       "160        1895           170   \n",
       "261         996             1   \n",
       "355       21269             1   \n",
       "361         944           703   \n",
       "364         972           236   \n",
       "365         972           236   \n",
       "\n",
       "                                                   sku  \\\n",
       "7                                  - 1    \n",
       "22                               - 250    \n",
       "28                              - 8    \n",
       "76                         - 330    \n",
       "107                             - 110    \n",
       "119                           - 235    \n",
       "120                           - 235    \n",
       "132                           - 22    \n",
       "159       5   ...   \n",
       "160       5   ...   \n",
       "261                            - 225    \n",
       "355                               - 10    \n",
       "361                          - 185    \n",
       "364                                   - 5    \n",
       "365                                   - 5    \n",
       "\n",
       "     yesterday_sku_disc_cntrb  yesterday_qty_disc_cntrb  qd_tier_1_qty  \\\n",
       "7                       66.69                      0.00            4.0   \n",
       "22                       0.00                    100.00            8.0   \n",
       "28                       0.00                      0.00            5.0   \n",
       "76                       0.00                      0.00            4.0   \n",
       "107                      0.00                    100.00            5.0   \n",
       "119                      0.00                     41.88            4.0   \n",
       "120                      6.24                     43.77            4.0   \n",
       "132                      0.00                     69.02            4.0   \n",
       "159                      0.00                     62.56            4.0   \n",
       "160                      0.00                      0.00            4.0   \n",
       "261                      2.85                     42.79            5.0   \n",
       "355                      2.56                     15.41            5.0   \n",
       "361                     12.50                     50.00            4.0   \n",
       "364                     39.18                      0.00            4.0   \n",
       "365                     39.18                      0.00            4.0   \n",
       "\n",
       "     qd_tier_1_disc_pct  qd_tier_2_qty  qd_tier_2_disc_pct  qd_tier_3_qty  \\\n",
       "7                  0.60            7.0                1.16          100.0   \n",
       "22                 2.35           16.0                5.00          642.0   \n",
       "28                 0.58            9.0                3.12          771.0   \n",
       "76                 2.73            7.0                5.00          309.0   \n",
       "107                0.86            8.0                1.51          739.0   \n",
       "119                0.68            7.0                1.31          154.0   \n",
       "120                0.43            9.0                1.31          154.0   \n",
       "132                1.90            7.0                3.66          434.0   \n",
       "159                1.76            7.0                3.39          336.0   \n",
       "160                1.76            7.0                3.39          336.0   \n",
       "261                2.47           14.0                5.00            0.0   \n",
       "355                0.47            7.0                2.46          267.0   \n",
       "361                0.41            7.0                0.79           39.0   \n",
       "364                0.92            7.0                1.77          108.0   \n",
       "365                0.92            7.0                1.77          108.0   \n",
       "\n",
       "     qd_tier_3_disc_pct  \n",
       "7                  2.20  \n",
       "22                 6.00  \n",
       "28                 4.16  \n",
       "76                 6.00  \n",
       "107                2.70  \n",
       "119                2.60  \n",
       "120                2.60  \n",
       "132                4.84  \n",
       "159                4.42  \n",
       "160                4.42  \n",
       "261                0.00  \n",
       "355                3.68  \n",
       "361                1.91  \n",
       "364                2.66  \n",
       "365                2.66  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Yesterday's Discount Analysis to pricing_with_discount (Contributions Only)\n",
    "# =============================================================================\n",
    "\n",
    "# Merge yesterday discount data with pricing_with_discount - contributions + tier config\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_yesterday_discount[[\n",
    "        'warehouse_id', 'product_id', \n",
    "        'sku_discount_nmv_cntrb', 'qty_discount_nmv_cntrb',\n",
    "        'tier1_nmv_cntrb', 'tier2_nmv_cntrb', 'tier3_nmv_cntrb',\n",
    "        'tier_1_qty', 'tier_1_discount_pct',\n",
    "        'tier_2_qty', 'tier_2_discount_pct',\n",
    "        'tier_3_qty', 'tier_3_discount_pct'\n",
    "    ]].rename(columns={\n",
    "        'sku_discount_nmv_cntrb': 'yesterday_sku_disc_cntrb',\n",
    "        'qty_discount_nmv_cntrb': 'yesterday_qty_disc_cntrb',\n",
    "        'tier1_nmv_cntrb': 'yesterday_t1_cntrb',\n",
    "        'tier2_nmv_cntrb': 'yesterday_t2_cntrb',\n",
    "        'tier3_nmv_cntrb': 'yesterday_t3_cntrb',\n",
    "        'tier_1_qty': 'qd_tier_1_qty',\n",
    "        'tier_1_discount_pct': 'qd_tier_1_disc_pct',\n",
    "        'tier_2_qty': 'qd_tier_2_qty',\n",
    "        'tier_2_discount_pct': 'qd_tier_2_disc_pct',\n",
    "        'tier_3_qty': 'qd_tier_3_qty',\n",
    "        'tier_3_discount_pct': 'qd_tier_3_disc_pct'\n",
    "    }), \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN for SKUs that had no sales yesterday\n",
    "contrib_cols = [\n",
    "    'yesterday_sku_disc_cntrb', 'yesterday_qty_disc_cntrb',\n",
    "    'yesterday_t1_cntrb', 'yesterday_t2_cntrb', 'yesterday_t3_cntrb'\n",
    "]\n",
    "for col in contrib_cols:\n",
    "    if col in pricing_with_discount.columns:\n",
    "        pricing_with_discount[col] = pricing_with_discount[col].fillna(0)\n",
    "\n",
    "# Fill NaN for QD tier config (0 means no tier configured)\n",
    "qd_config_cols = [\n",
    "    'qd_tier_1_qty', 'qd_tier_1_disc_pct',\n",
    "    'qd_tier_2_qty', 'qd_tier_2_disc_pct',\n",
    "    'qd_tier_3_qty', 'qd_tier_3_disc_pct'\n",
    "]\n",
    "for col in qd_config_cols:\n",
    "    if col in pricing_with_discount.columns:\n",
    "        pricing_with_discount[col] = pricing_with_discount[col].fillna(0)\n",
    "\n",
    "print(f\"Yesterday's discount contributions and QD tier config added!\")\n",
    "print(f\"\\nSKUs with discount data: {len(pricing_with_discount[pricing_with_discount['yesterday_sku_disc_cntrb'] > 0]) + len(pricing_with_discount[pricing_with_discount['yesterday_qty_disc_cntrb'] > 0])}\")\n",
    "print(f\"SKUs with QD tier config: {len(pricing_with_discount[pricing_with_discount['qd_tier_1_qty'] > 0])}\")\n",
    "print(f\"\\nSample data with yesterday's discount contributions and QD tiers:\")\n",
    "pricing_with_discount[pricing_with_discount['qd_tier_1_qty'] > 0][\n",
    "    ['product_id', 'warehouse_id', 'sku', \n",
    "     'yesterday_sku_disc_cntrb', 'yesterday_qty_disc_cntrb',\n",
    "     'qd_tier_1_qty', 'qd_tier_1_disc_pct', 'qd_tier_2_qty', 'qd_tier_2_disc_pct', 'qd_tier_3_qty', 'qd_tier_3_disc_pct']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading performance benchmark data (this may take a moment due to 240-day history)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 294469 benchmark records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>yesterday_qty</th>\n",
       "      <th>recent_7d_qty</th>\n",
       "      <th>recent_7d_in_stock_days</th>\n",
       "      <th>mtd_qty</th>\n",
       "      <th>mtd_in_stock_days</th>\n",
       "      <th>p80_daily_240d</th>\n",
       "      <th>avg_daily_240d</th>\n",
       "      <th>in_stock_days_240d</th>\n",
       "      <th>p80_7d_sum_240d</th>\n",
       "      <th>p80_mtd_12mo</th>\n",
       "      <th>yesterday_ratio</th>\n",
       "      <th>recent_ratio</th>\n",
       "      <th>mtd_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>23251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703</td>\n",
       "      <td>20030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>703</td>\n",
       "      <td>19724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>501</td>\n",
       "      <td>5182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>797</td>\n",
       "      <td>7232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>15896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>339</td>\n",
       "      <td>25251</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>170</td>\n",
       "      <td>22095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>9379</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013699</td>\n",
       "      <td>146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>339</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warehouse_id  product_id  yesterday_qty  recent_7d_qty  \\\n",
       "0           337       23251              0              0   \n",
       "1           703       20030              0              0   \n",
       "2           703       19724              0              0   \n",
       "3           501        5182              0              0   \n",
       "4           797        7232              0              0   \n",
       "5             8       15896              0              0   \n",
       "6           339       25251              1              2   \n",
       "7           170       22095              0              0   \n",
       "8           501        9379              0              0   \n",
       "9           339         103              0              0   \n",
       "\n",
       "   recent_7d_in_stock_days  mtd_qty  mtd_in_stock_days  p80_daily_240d  \\\n",
       "0                        0        0                  0             1.0   \n",
       "1                        0        0                  0             1.0   \n",
       "2                        0        0                  0             1.0   \n",
       "3                        0        0                  0             1.0   \n",
       "4                        0        0                  0             1.0   \n",
       "5                        0        0                  0             1.0   \n",
       "6                        4        2                  4             1.0   \n",
       "7                        0        0                  0             1.0   \n",
       "8                        7        2                 18             0.0   \n",
       "9                        0        0                  0             1.0   \n",
       "\n",
       "   avg_daily_240d  in_stock_days_240d  p80_7d_sum_240d  p80_mtd_12mo  \\\n",
       "0        0.000000                   0              1.0           0.0   \n",
       "1        0.000000                   0              1.0           0.0   \n",
       "2        0.000000                   0              1.0           0.0   \n",
       "3        0.000000                   0              1.0           0.0   \n",
       "4        0.000000                   0              1.0           0.0   \n",
       "5        0.000000                   0              1.0           0.0   \n",
       "6        0.000000                   0              1.0           1.0   \n",
       "7        0.000000                   0              1.0           0.0   \n",
       "8        0.013699                 146              0.0           0.0   \n",
       "9        0.000000                   0              1.0           0.0   \n",
       "\n",
       "   yesterday_ratio  recent_ratio  mtd_ratio  \n",
       "0              0.0           0.0        NaN  \n",
       "1              0.0           0.0        NaN  \n",
       "2              0.0           0.0        NaN  \n",
       "3              0.0           0.0        NaN  \n",
       "4              0.0           0.0        NaN  \n",
       "5              0.0           0.0        NaN  \n",
       "6              1.0           2.0        2.0  \n",
       "7              0.0           0.0        NaN  \n",
       "8              NaN           NaN        NaN  \n",
       "9              0.0           0.0        NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Performance Benchmark Query\n",
    "# Gets: Yesterday qty, Recent 7d qty, MTD qty, and P80 benchmarks (240 days)\n",
    "# Uses materialized_views.stock_day_close for in-stock determination\n",
    "# =============================================================================\n",
    "PERFORMANCE_BENCHMARK_QUERY = f'''\n",
    "WITH params AS (\n",
    "    SELECT\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE AS today,\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1 AS yesterday,\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 240 AS history_start,\n",
    "        DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE) AS current_month_start,\n",
    "        DAY(CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE) AS current_day_of_month\n",
    "),\n",
    "\n",
    "-- Daily sales aggregation (240 days) - includes qty and retailer count\n",
    "daily_sales AS (\n",
    "    SELECT\n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        so.created_at::DATE AS sale_date,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count) AS daily_qty,\n",
    "        COUNT(DISTINCT so.retailer_id) AS daily_retailers\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    CROSS JOIN params p\n",
    "    WHERE so.created_at::DATE >= p.history_start\n",
    "        AND so.created_at::DATE < p.today\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id, so.created_at::DATE\n",
    "),\n",
    "\n",
    "-- Daily stock status using stock_day_close\n",
    "-- In-stock = opening (prev day close) > 0 AND closing > 0\n",
    "daily_stock AS (\n",
    "    SELECT\n",
    "        sdc.warehouse_id,\n",
    "        sdc.product_id,\n",
    "        sdc.TIMESTAMP::DATE AS stock_date,\n",
    "        sdc.available_stock,\n",
    "        LAG(sdc.available_stock, 1) OVER (\n",
    "            PARTITION BY sdc.warehouse_id, sdc.product_id \n",
    "            ORDER BY sdc.TIMESTAMP::DATE\n",
    "        ) AS opening_stock,\n",
    "        CASE \n",
    "            WHEN LAG(sdc.available_stock, 1) OVER (\n",
    "                    PARTITION BY sdc.warehouse_id, sdc.product_id ORDER BY sdc.TIMESTAMP::DATE\n",
    "                 ) > 0 \n",
    "                 AND sdc.available_stock > 0 \n",
    "            THEN 1 \n",
    "            ELSE 0 \n",
    "        END AS in_stock_flag\n",
    "    FROM materialized_views.stock_day_close sdc\n",
    "    CROSS JOIN params p\n",
    "    WHERE sdc.TIMESTAMP::DATE >= p.history_start - 1  -- Need one extra day for LAG\n",
    "        AND sdc.TIMESTAMP::DATE < p.today\n",
    "),\n",
    "\n",
    "-- Combine sales with stock status\n",
    "daily_with_stock AS (\n",
    "    SELECT\n",
    "        COALESCE(ds.warehouse_id, st.warehouse_id) AS warehouse_id,\n",
    "        COALESCE(ds.product_id, st.product_id) AS product_id,\n",
    "        COALESCE(ds.sale_date, st.stock_date) AS the_date,\n",
    "        COALESCE(ds.daily_qty, 0) AS daily_qty,\n",
    "        COALESCE(ds.daily_retailers, 0) AS daily_retailers,\n",
    "        COALESCE(st.in_stock_flag, 0) AS in_stock_flag\n",
    "    FROM daily_sales ds\n",
    "    FULL OUTER JOIN daily_stock st \n",
    "        ON ds.warehouse_id = st.warehouse_id \n",
    "        AND ds.product_id = st.product_id \n",
    "        AND ds.sale_date = st.stock_date\n",
    "    WHERE COALESCE(ds.sale_date, st.stock_date) >= (SELECT history_start FROM params)\n",
    "),\n",
    "\n",
    "-- Calculate P80 benchmark (in-stock days only, 240 days, EXCLUDING last 7 days)\n",
    "p80_daily_benchmark AS (\n",
    "    SELECT\n",
    "        warehouse_id,\n",
    "        product_id,\n",
    "        PERCENTILE_CONT(0.8) WITHIN GROUP (ORDER BY daily_qty) AS p80_daily_240d,\n",
    "        AVG(daily_qty) AS avg_daily_240d,\n",
    "        STDDEV(daily_qty) AS std_daily_240d,\n",
    "        COUNT(*) AS in_stock_days_240d\n",
    "    FROM daily_with_stock\n",
    "    CROSS JOIN params p\n",
    "    WHERE in_stock_flag = 1\n",
    "        AND the_date >= p.history_start\n",
    "        AND the_date < p.today - 7  -- Exclude last 7 days from benchmark\n",
    "    GROUP BY warehouse_id, product_id\n",
    "),\n",
    "\n",
    "-- Calculate P70 retailer benchmark (in-stock days only, 240 days, EXCLUDING last 7 days)\n",
    "p70_retailer_benchmark AS (\n",
    "    SELECT\n",
    "        warehouse_id,\n",
    "        product_id,\n",
    "        PERCENTILE_CONT(0.7) WITHIN GROUP (ORDER BY daily_retailers) AS p70_daily_retailers_240d,\n",
    "        AVG(daily_retailers) AS avg_daily_retailers_240d,\n",
    "        STDDEV(daily_retailers) AS std_daily_retailers_240d\n",
    "    FROM daily_with_stock\n",
    "    CROSS JOIN params p\n",
    "    WHERE in_stock_flag = 1\n",
    "        AND the_date >= p.history_start\n",
    "        AND the_date < p.today - 7  -- Exclude last 7 days from benchmark\n",
    "    GROUP BY warehouse_id, product_id\n",
    "),\n",
    "\n",
    "-- Calculate 7-day rolling SUM for P80 recent benchmark\n",
    "rolling_7d AS (\n",
    "    SELECT\n",
    "        warehouse_id,\n",
    "        product_id,\n",
    "        the_date,\n",
    "        SUM(daily_qty) OVER (\n",
    "            PARTITION BY warehouse_id, product_id \n",
    "            ORDER BY the_date \n",
    "            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
    "        ) AS rolling_7d_sum,\n",
    "        SUM(in_stock_flag) OVER (\n",
    "            PARTITION BY warehouse_id, product_id \n",
    "            ORDER BY the_date \n",
    "            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
    "        ) AS in_stock_days_7d\n",
    "    FROM daily_with_stock\n",
    "),\n",
    "\n",
    "p80_7d_benchmark AS (\n",
    "    SELECT\n",
    "        warehouse_id,\n",
    "        product_id,\n",
    "        PERCENTILE_CONT(0.8) WITHIN GROUP (ORDER BY rolling_7d_sum) AS p80_7d_rolling_240d\n",
    "    FROM rolling_7d\n",
    "    CROSS JOIN params p\n",
    "    WHERE the_date >= p.history_start + 7  -- Need 7 days for rolling\n",
    "        AND the_date < p.today - 7  -- Exclude last 7 days from benchmark\n",
    "        AND in_stock_days_7d >= 4  -- At least 4 of 7 days in stock\n",
    "    GROUP BY warehouse_id, product_id\n",
    "),\n",
    "\n",
    "-- MTD benchmark: P80 of same MTD period totals (last 12 months)\n",
    "-- Sum all sales from day 1 to current day of month for each historical month\n",
    "mtd_historical AS (\n",
    "    SELECT\n",
    "        dws.warehouse_id,\n",
    "        dws.product_id,\n",
    "        DATE_TRUNC('month', dws.the_date) AS period_month_start,\n",
    "        SUM(dws.daily_qty) AS mtd_total_qty  -- Sum of all days from 1 to current_day_of_month\n",
    "    FROM daily_with_stock dws\n",
    "    CROSS JOIN params p\n",
    "    WHERE DAY(dws.the_date) <= p.current_day_of_month  -- Only days up to current day of month\n",
    "    GROUP BY dws.warehouse_id, dws.product_id, DATE_TRUNC('month', dws.the_date)\n",
    "),\n",
    "\n",
    "mtd_by_period AS (\n",
    "    SELECT\n",
    "        mh.warehouse_id,\n",
    "        mh.product_id,\n",
    "        mh.period_month_start,\n",
    "        mh.mtd_total_qty AS mtd_qty_at_day  -- Total MTD qty for that month\n",
    "    FROM mtd_historical mh\n",
    "    CROSS JOIN params p\n",
    "    WHERE mh.period_month_start >= DATEADD(month, -12, p.current_month_start)\n",
    "        AND mh.period_month_start < p.current_month_start\n",
    "),\n",
    "\n",
    "p80_mtd_benchmark AS (\n",
    "    SELECT\n",
    "        warehouse_id,\n",
    "        product_id,\n",
    "        PERCENTILE_CONT(0.8) WITHIN GROUP (ORDER BY mtd_qty_at_day) AS p80_mtd_12mo,\n",
    "        AVG(mtd_qty_at_day) AS avg_mtd_12mo\n",
    "    FROM mtd_by_period\n",
    "    GROUP BY warehouse_id, product_id\n",
    "    HAVING COUNT(*) >= 3  -- At least 3 months of data\n",
    "),\n",
    "\n",
    "-- Current period quantities\n",
    "current_metrics AS (\n",
    "    SELECT\n",
    "        warehouse_id,\n",
    "        product_id,\n",
    "        -- Yesterday\n",
    "        SUM(CASE WHEN the_date = (SELECT yesterday FROM params) THEN daily_qty ELSE 0 END) AS yesterday_qty,\n",
    "        SUM(CASE WHEN the_date = (SELECT yesterday FROM params) THEN daily_retailers ELSE 0 END) AS yesterday_retailers,\n",
    "        -- Recent 7 days\n",
    "        SUM(CASE WHEN the_date >= (SELECT today FROM params) - 7 AND the_date < (SELECT today FROM params) THEN daily_qty ELSE 0 END) AS recent_7d_qty,\n",
    "        SUM(CASE WHEN the_date >= (SELECT today FROM params) - 7 AND the_date < (SELECT today FROM params) AND in_stock_flag = 1 THEN 1 ELSE 0 END) AS recent_7d_in_stock_days,\n",
    "        -- MTD\n",
    "        SUM(CASE WHEN the_date >= (SELECT current_month_start FROM params) AND the_date < (SELECT today FROM params) THEN daily_qty ELSE 0 END) AS mtd_qty,\n",
    "        SUM(CASE WHEN the_date >= (SELECT current_month_start FROM params) AND the_date < (SELECT today FROM params) AND in_stock_flag = 1 THEN 1 ELSE 0 END) AS mtd_in_stock_days\n",
    "    FROM daily_with_stock\n",
    "    GROUP BY warehouse_id, product_id\n",
    ")\n",
    "\n",
    "-- Final output\n",
    "SELECT\n",
    "    cm.warehouse_id,\n",
    "    cm.product_id,\n",
    "    \n",
    "    -- Current period quantities\n",
    "    cm.yesterday_qty,\n",
    "    cm.yesterday_retailers,\n",
    "    cm.recent_7d_qty,\n",
    "    cm.recent_7d_in_stock_days,\n",
    "    cm.mtd_qty,\n",
    "    cm.mtd_in_stock_days,\n",
    "    \n",
    "    -- Quantity Benchmarks (P80)\n",
    "    COALESCE(pb.p80_daily_240d, 1) AS p80_daily_240d,\n",
    "    COALESCE(pb.avg_daily_240d, 0) AS avg_daily_240d,\n",
    "    COALESCE(pb.in_stock_days_240d, 0) AS in_stock_days_240d,\n",
    "    COALESCE(p7.p80_7d_rolling_240d, pb.p80_daily_240d * 7, 1) AS p80_7d_sum_240d,\n",
    "    COALESCE(pm.p80_mtd_12mo, pb.p80_daily_240d * (SELECT current_day_of_month FROM params), 1) AS p80_mtd_12mo,\n",
    "    \n",
    "    -- Retailer Benchmarks (P70)\n",
    "    COALESCE(pr.p70_daily_retailers_240d, 1) AS p70_daily_retailers_240d,\n",
    "    COALESCE(pr.avg_daily_retailers_240d, 0) AS avg_daily_retailers_240d,\n",
    "    COALESCE(pr.std_daily_retailers_240d, 0) AS std_daily_retailers_240d,\n",
    "    \n",
    "    -- Performance ratios (all comparing sums to sums)\n",
    "    -- Yesterday: daily qty vs P80 daily\n",
    "    ROUND(cm.yesterday_qty / NULLIF(COALESCE(pb.p80_daily_240d, 1), 0), 2) AS yesterday_ratio,\n",
    "    -- Recent 7d: 7-day sum vs P80 of 7-day sums\n",
    "    ROUND(cm.recent_7d_qty / NULLIF(COALESCE(p7.p80_7d_rolling_240d, pb.p80_daily_240d * 7, 1), 0), 2) AS recent_ratio,\n",
    "    -- MTD: MTD sum vs P80 of historical MTD sums\n",
    "    ROUND(cm.mtd_qty / NULLIF(COALESCE(pm.p80_mtd_12mo, pb.p80_daily_240d * (SELECT current_day_of_month FROM params), 1), 0), 2) AS mtd_ratio,\n",
    "    -- Retailer ratio: yesterday retailers vs P70 daily retailers\n",
    "    ROUND(cm.yesterday_retailers / NULLIF(COALESCE(pr.p70_daily_retailers_240d, 1), 0), 2) AS yesterday_retailer_ratio\n",
    "\n",
    "FROM current_metrics cm\n",
    "LEFT JOIN p80_daily_benchmark pb ON cm.warehouse_id = pb.warehouse_id AND cm.product_id = pb.product_id\n",
    "LEFT JOIN p80_7d_benchmark p7 ON cm.warehouse_id = p7.warehouse_id AND cm.product_id = p7.product_id\n",
    "LEFT JOIN p80_mtd_benchmark pm ON cm.warehouse_id = pm.warehouse_id AND cm.product_id = pm.product_id\n",
    "LEFT JOIN p70_retailer_benchmark pr ON cm.warehouse_id = pr.warehouse_id AND cm.product_id = pr.product_id\n",
    "where cm.warehouse_id in (1, 236, 337, 8, 339, 170, 501, 401, 703, 632, 797, 962)\n",
    "'''\n",
    "\n",
    "# Execute benchmark query\n",
    "print(\"Loading performance benchmark data (this may take a moment due to 240-day history)...\")\n",
    "df_benchmarks = query_snowflake(PERFORMANCE_BENCHMARK_QUERY)\n",
    "df_benchmarks = convert_to_numeric(df_benchmarks)\n",
    "print(f\"Loaded {len(df_benchmarks)} benchmark records\")\n",
    "\n",
    "# Preview\n",
    "df_benchmarks.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dynamic weight calculation complete!\n",
      "Days in month so far: 18\n",
      "\n",
      "Sample of weight distributions:\n",
      "    product_id  warehouse_id  oos_yesterday  recent_7d_in_stock_days  \\\n",
      "1         8674           401              0                        7   \n",
      "3        23421           337              0                        7   \n",
      "4        23421             8              0                        7   \n",
      "6          147           339              0                        7   \n",
      "7          147           170              0                        7   \n",
      "8        11774           339              0                        7   \n",
      "9        11774           170              1                        0   \n",
      "10       10521             1              0                        7   \n",
      "11       13885           339              0                        7   \n",
      "12       13885           170              0                        6   \n",
      "\n",
      "    mtd_in_stock_days  yesterday_norm_weight  recent_7d_norm_weight  \\\n",
      "1                  18               0.200000               0.400000   \n",
      "3                  18               0.200000               0.400000   \n",
      "4                  18               0.200000               0.400000   \n",
      "6                  18               0.200000               0.400000   \n",
      "7                  18               0.200000               0.400000   \n",
      "8                  18               0.200000               0.400000   \n",
      "9                  11               0.000000               0.000000   \n",
      "10                 12               0.230769               0.461538   \n",
      "11                  7               0.264706               0.529412   \n",
      "12                  6               0.295775               0.507042   \n",
      "\n",
      "    mtd_norm_weight  combined_perf_ratio  \n",
      "1          0.400000             0.402000  \n",
      "3          0.400000             0.828000  \n",
      "4          0.400000             0.860000  \n",
      "6          0.400000             0.350000  \n",
      "7          0.400000             0.388000  \n",
      "8          0.400000             0.432000  \n",
      "9          1.000000             0.780000  \n",
      "10         0.307692             1.244615  \n",
      "11         0.205882             1.148824  \n",
      "12         0.197183             0.436056  \n",
      "Performance benchmarks added!\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE STATUS DISTRIBUTION\n",
      "============================================================\n",
      "\n",
      "Yesterday Status:\n",
      "yesterday_status\n",
      "No Data            82190\n",
      "Critical            2259\n",
      "Struggling          2104\n",
      "On Track            1663\n",
      "Star Performer      1453\n",
      "Over Achiever        912\n",
      "Underperforming      767\n",
      "\n",
      "Recent 7d Status:\n",
      "recent_status\n",
      "No Data            74195\n",
      "Critical            5444\n",
      "Struggling          4598\n",
      "On Track            2169\n",
      "Underperforming     1905\n",
      "Over Achiever       1619\n",
      "Star Performer      1418\n",
      "\n",
      "MTD Status:\n",
      "mtd_status\n",
      "No Data            71111\n",
      "Struggling          5074\n",
      "Critical            4896\n",
      "Underperforming     2763\n",
      "On Track            2586\n",
      "Over Achiever       2552\n",
      "Star Performer      2366\n",
      "\n",
      "Combined Status:\n",
      "combined_status\n",
      "No Data            70871\n",
      "Critical            6287\n",
      "Struggling          5664\n",
      "Underperforming     2673\n",
      "Over Achiever       2570\n",
      "On Track            2085\n",
      "Star Performer      1198\n",
      "\n",
      "============================================================\n",
      "HIGH PERFORMERS (Action Candidates)\n",
      "============================================================\n",
      "High Performers (flag=1): 430\n",
      "Star Performers (flag=1): 237\n",
      "\n",
      "Top 15 Star Performers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>yesterday_ratio</th>\n",
       "      <th>recent_ratio</th>\n",
       "      <th>mtd_ratio</th>\n",
       "      <th>combined_perf_ratio</th>\n",
       "      <th>yesterday_status</th>\n",
       "      <th>combined_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>13326</td>\n",
       "      <td>236</td>\n",
       "      <td>     - 18 </td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.14</td>\n",
       "      <td>4.94</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53195</th>\n",
       "      <td>25287</td>\n",
       "      <td>236</td>\n",
       "      <td>  - 60 </td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53196</th>\n",
       "      <td>25287</td>\n",
       "      <td>236</td>\n",
       "      <td>  - 60 </td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53197</th>\n",
       "      <td>25287</td>\n",
       "      <td>236</td>\n",
       "      <td>  - 60 </td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60229</th>\n",
       "      <td>24626</td>\n",
       "      <td>962</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60230</th>\n",
       "      <td>24626</td>\n",
       "      <td>962</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60231</th>\n",
       "      <td>24626</td>\n",
       "      <td>962</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61387</th>\n",
       "      <td>473</td>\n",
       "      <td>1</td>\n",
       "      <td>     - 350 </td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61388</th>\n",
       "      <td>473</td>\n",
       "      <td>1</td>\n",
       "      <td>     - 350 </td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>3.94</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71400</th>\n",
       "      <td>9357</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71401</th>\n",
       "      <td>9357</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71402</th>\n",
       "      <td>9357</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>10275</td>\n",
       "      <td>236</td>\n",
       "      <td>    - 12.5 </td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.73</td>\n",
       "      <td>35.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8816</th>\n",
       "      <td>25291</td>\n",
       "      <td>962</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11321</th>\n",
       "      <td>8089</td>\n",
       "      <td>401</td>\n",
       "      <td>    3  - 500 </td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>13.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id  warehouse_id                                          sku  \\\n",
       "1611        13326           236                   - 18    \n",
       "53195       25287           236                        - 60    \n",
       "53196       25287           236                        - 60    \n",
       "53197       25287           236                        - 60    \n",
       "60229       24626           962                   - 15    \n",
       "60230       24626           962                   - 15    \n",
       "60231       24626           962                   - 15    \n",
       "61387         473             1          - 350    \n",
       "61388         473             1          - 350    \n",
       "71400        9357             1                        - 1    \n",
       "71401        9357             1                        - 1    \n",
       "71402        9357             1                        - 1    \n",
       "4396        10275           236          - 12.5    \n",
       "8816        25291           962                         - 400    \n",
       "11321        8089           401      3  - 500    \n",
       "\n",
       "       yesterday_ratio  recent_ratio  mtd_ratio  combined_perf_ratio  \\\n",
       "1611              19.0          3.14       4.94                  3.0   \n",
       "53195              3.0          5.00       5.00                  3.0   \n",
       "53196              3.0          5.00       5.00                  3.0   \n",
       "53197              3.0          5.00       5.00                  3.0   \n",
       "60229              4.0          4.00       4.00                  3.0   \n",
       "60230              4.0          4.00       4.00                  3.0   \n",
       "60231              4.0          4.00       4.00                  3.0   \n",
       "61387             35.0          4.20       3.94                  3.0   \n",
       "61388             35.0          4.20       3.94                  3.0   \n",
       "71400              8.0          3.00       4.00                  3.0   \n",
       "71401              8.0          3.00       4.00                  3.0   \n",
       "71402              8.0          3.00       4.00                  3.0   \n",
       "4396               4.0         11.73      35.00                  3.0   \n",
       "8816              16.0         23.00      23.00                  3.0   \n",
       "11321              4.0          9.00      13.75                  3.0   \n",
       "\n",
       "      yesterday_status combined_status  \n",
       "1611    Star Performer  Star Performer  \n",
       "53195   Star Performer  Star Performer  \n",
       "53196   Star Performer  Star Performer  \n",
       "53197   Star Performer  Star Performer  \n",
       "60229   Star Performer  Star Performer  \n",
       "60230   Star Performer  Star Performer  \n",
       "60231   Star Performer  Star Performer  \n",
       "61387   Star Performer  Star Performer  \n",
       "61388   Star Performer  Star Performer  \n",
       "71400   Star Performer  Star Performer  \n",
       "71401   Star Performer  Star Performer  \n",
       "71402   Star Performer  Star Performer  \n",
       "4396    Star Performer  Star Performer  \n",
       "8816    Star Performer  Star Performer  \n",
       "11321   Star Performer  Star Performer  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Performance Benchmarks and Tags to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge benchmark data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_benchmarks[[\n",
    "        'warehouse_id', 'product_id',\n",
    "        'yesterday_qty', 'yesterday_retailers', 'recent_7d_qty', 'recent_7d_in_stock_days', 'mtd_qty', 'mtd_in_stock_days',\n",
    "        'p80_daily_240d', 'avg_daily_240d', 'in_stock_days_240d',\n",
    "        'p80_7d_sum_240d', 'p80_mtd_12mo',\n",
    "        'p70_daily_retailers_240d', 'avg_daily_retailers_240d', 'std_daily_retailers_240d',\n",
    "        'yesterday_ratio', 'recent_ratio', 'mtd_ratio', 'yesterday_retailer_ratio'\n",
    "    ]], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values\n",
    "qty_cols = ['yesterday_qty', 'yesterday_retailers', 'recent_7d_qty', 'recent_7d_in_stock_days', 'mtd_qty', 'mtd_in_stock_days']\n",
    "for col in qty_cols:\n",
    "    pricing_with_discount[col] = pricing_with_discount[col].fillna(0)\n",
    "\n",
    "benchmark_cols = ['p80_daily_240d', 'p80_7d_sum_240d', 'p80_mtd_12mo', 'p70_daily_retailers_240d']\n",
    "for col in benchmark_cols:\n",
    "    pricing_with_discount[col] = pricing_with_discount[col].fillna(1)  # Default to 1 to avoid division issues\n",
    "\n",
    "ratio_cols = ['yesterday_ratio', 'recent_ratio', 'mtd_ratio', 'yesterday_retailer_ratio']\n",
    "for col in ratio_cols:\n",
    "    pricing_with_discount[col] = pricing_with_discount[col].fillna(0)\n",
    "\n",
    "pricing_with_discount['avg_daily_240d'] = pricing_with_discount['avg_daily_240d'].fillna(0)\n",
    "pricing_with_discount['in_stock_days_240d'] = pricing_with_discount['in_stock_days_240d'].fillna(0)\n",
    "pricing_with_discount['avg_daily_retailers_240d'] = pricing_with_discount['avg_daily_retailers_240d'].fillna(0)\n",
    "pricing_with_discount['std_daily_retailers_240d'] = pricing_with_discount['std_daily_retailers_240d'].fillna(0)\n",
    "\n",
    "# =============================================================================\n",
    "# Performance Tags - Classify each ratio\n",
    "# =============================================================================\n",
    "def get_performance_tag(ratio):\n",
    "    \"\"\"\n",
    "    Classify performance based on ratio to benchmark\n",
    "    On Track: 90% to 115% of benchmark\n",
    "    Upper tiers: start from 115%\n",
    "    Lower tiers: start from 90%\n",
    "    \"\"\"\n",
    "    if pd.isna(ratio) or ratio == 0:\n",
    "        return 'No Data'\n",
    "    elif ratio >= 1.75:\n",
    "        return 'Star Performer'      #  75%+ above benchmark\n",
    "    elif ratio > 1.15:\n",
    "        return 'Over Achiever'       #  15%+ above benchmark  \n",
    "    elif ratio >= 0.90:\n",
    "        return 'On Track'            #  Meeting benchmark (90%-115%)\n",
    "    elif ratio >= 0.70:\n",
    "        return 'Underperforming'     #  10%-30% below benchmark\n",
    "    elif ratio >= 0.40:\n",
    "        return 'Struggling'          #  30%-60% below benchmark\n",
    "    else:\n",
    "        return 'Critical'            #  60%+ below benchmark\n",
    "\n",
    "# Apply tags to each timeframe\n",
    "pricing_with_discount['yesterday_status'] = pricing_with_discount['yesterday_ratio'].apply(get_performance_tag)\n",
    "pricing_with_discount['recent_status'] = pricing_with_discount['recent_ratio'].apply(get_performance_tag)\n",
    "pricing_with_discount['mtd_status'] = pricing_with_discount['mtd_ratio'].apply(get_performance_tag)\n",
    "\n",
    "# =============================================================================\n",
    "# Combined Performance Score (weighted average of ratios)\n",
    "# Approach 2: Scale Weights by In-Stock Percentage\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate days in month so far (excluding today)\n",
    "days_in_month_so_far = max(TODAY.day - 1, 1)  # At least 1 to avoid division by zero\n",
    "\n",
    "# Calculate in-stock percentages for each period\n",
    "pricing_with_discount['yesterday_in_stock_pct'] = 1 - pricing_with_discount['oos_yesterday']\n",
    "pricing_with_discount['recent_7d_in_stock_pct'] = pricing_with_discount['recent_7d_in_stock_days'] / 7\n",
    "pricing_with_discount['mtd_in_stock_pct'] = pricing_with_discount['mtd_in_stock_days'] / days_in_month_so_far\n",
    "\n",
    "# Base weights: Yesterday 20%, Recent 7d 40%, MTD 40%\n",
    "# Scale by in-stock percentage\n",
    "# NOTE: MTD weight = 0 for first 3 days of month (unreliable data)\n",
    "MTD_RELIABLE_DAY = 3  # Only use MTD when day >= 3\n",
    "pricing_with_discount['yesterday_raw_weight'] = 0.2 * pricing_with_discount['yesterday_in_stock_pct']\n",
    "pricing_with_discount['recent_7d_raw_weight'] = 0.4 * pricing_with_discount['recent_7d_in_stock_pct']\n",
    "pricing_with_discount['mtd_raw_weight'] = np.where(\n",
    "    TODAY.day >= MTD_RELIABLE_DAY,\n",
    "    0.4 * pricing_with_discount['mtd_in_stock_pct'],\n",
    "    0  # Set MTD weight to 0 at start of month\n",
    ")\n",
    "\n",
    "# Total raw weight for normalization\n",
    "pricing_with_discount['total_raw_weight'] = (\n",
    "    pricing_with_discount['yesterday_raw_weight'] + \n",
    "    pricing_with_discount['recent_7d_raw_weight'] + \n",
    "    pricing_with_discount['mtd_raw_weight']\n",
    ")\n",
    "\n",
    "# Normalized weights (sum to 1)\n",
    "pricing_with_discount['yesterday_norm_weight'] = np.where(\n",
    "    pricing_with_discount['total_raw_weight'] > 0,\n",
    "    pricing_with_discount['yesterday_raw_weight'] / pricing_with_discount['total_raw_weight'],\n",
    "    0\n",
    ")\n",
    "pricing_with_discount['recent_7d_norm_weight'] = np.where(\n",
    "    pricing_with_discount['total_raw_weight'] > 0,\n",
    "    pricing_with_discount['recent_7d_raw_weight'] / pricing_with_discount['total_raw_weight'],\n",
    "    0\n",
    ")\n",
    "pricing_with_discount['mtd_norm_weight'] = np.where(\n",
    "    pricing_with_discount['total_raw_weight'] > 0,\n",
    "    pricing_with_discount['mtd_raw_weight'] / pricing_with_discount['total_raw_weight'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Combined performance ratio with dynamic weights based on in-stock days\n",
    "pricing_with_discount['combined_perf_ratio'] = (\n",
    "    pricing_with_discount['yesterday_norm_weight'] * pricing_with_discount['yesterday_ratio'].clip(upper=3) +\n",
    "    pricing_with_discount['recent_7d_norm_weight'] * pricing_with_discount['recent_ratio'].clip(upper=3) +\n",
    "    pricing_with_discount['mtd_norm_weight'] * pricing_with_discount['mtd_ratio'].clip(upper=3)\n",
    ")\n",
    "\n",
    "# Handle cases where total_raw_weight = 0 (completely OOS in all periods)\n",
    "pricing_with_discount['combined_perf_ratio'] = pricing_with_discount['combined_perf_ratio'].fillna(0)\n",
    "\n",
    "# Clean up intermediate columns (optional - keep for debugging)\n",
    "weight_debug_cols = ['yesterday_in_stock_pct', 'recent_7d_in_stock_pct', 'mtd_in_stock_pct',\n",
    "                     'yesterday_raw_weight', 'recent_7d_raw_weight', 'mtd_raw_weight', 'total_raw_weight',\n",
    "                     'yesterday_norm_weight', 'recent_7d_norm_weight', 'mtd_norm_weight']\n",
    "# Uncomment to drop: pricing_with_discount.drop(columns=weight_debug_cols, inplace=True)\n",
    "\n",
    "print(f\"\\nDynamic weight calculation complete!\")\n",
    "print(f\"Days in month so far: {days_in_month_so_far}\")\n",
    "print(f\"\\nSample of weight distributions:\")\n",
    "print(pricing_with_discount[pricing_with_discount['total_raw_weight'] > 0][\n",
    "    ['product_id', 'warehouse_id', 'oos_yesterday', 'recent_7d_in_stock_days', 'mtd_in_stock_days',\n",
    "     'yesterday_norm_weight', 'recent_7d_norm_weight', 'mtd_norm_weight', 'combined_perf_ratio']\n",
    "].head(10))\n",
    "\n",
    "pricing_with_discount['combined_status'] = pricing_with_discount['combined_perf_ratio'].apply(get_performance_tag)\n",
    "\n",
    "# =============================================================================\n",
    "# High Performer Flag (for immediate action consideration)\n",
    "# =============================================================================\n",
    "# Flag SKUs that are significantly over-achieving and may need action (price increase, etc.)\n",
    "pricing_with_discount['high_performer_flag'] = np.where(\n",
    "    (pricing_with_discount['yesterday_ratio'] >= 1.5) & \n",
    "    (pricing_with_discount['recent_ratio'] >= 1.3) &\n",
    "    (pricing_with_discount['mtd_ratio'] >= 1.2),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "# Star performer flag (exceptional - all metrics 2x+ benchmark)\n",
    "pricing_with_discount['star_performer_flag'] = np.where(\n",
    "    (pricing_with_discount['yesterday_ratio'] >= 2.0) & \n",
    "    (pricing_with_discount['recent_ratio'] >= 1.5) &\n",
    "    (pricing_with_discount['mtd_ratio'] >= 1.5),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Summary\n",
    "# =============================================================================\n",
    "print(f\"Performance benchmarks added!\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PERFORMANCE STATUS DISTRIBUTION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nYesterday Status:\")\n",
    "print(pricing_with_discount['yesterday_status'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\nRecent 7d Status:\")\n",
    "print(pricing_with_discount['recent_status'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\nMTD Status:\")\n",
    "print(pricing_with_discount['mtd_status'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\nCombined Status:\")\n",
    "print(pricing_with_discount['combined_status'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"HIGH PERFORMERS (Action Candidates)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"High Performers (flag=1): {len(pricing_with_discount[pricing_with_discount['high_performer_flag'] == 1])}\")\n",
    "print(f\"Star Performers (flag=1): {len(pricing_with_discount[pricing_with_discount['star_performer_flag'] == 1])}\")\n",
    "\n",
    "# Show top performers\n",
    "print(f\"\\nTop 15 Star Performers:\")\n",
    "pricing_with_discount[pricing_with_discount['star_performer_flag'] == 1].nlargest(15, 'combined_perf_ratio')[\n",
    "    ['product_id', 'warehouse_id', 'sku', \n",
    "     'yesterday_ratio', 'recent_ratio', 'mtd_ratio', 'combined_perf_ratio',\n",
    "     'yesterday_status', 'combined_status']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SKUs with NMV in last 4 months...\n",
      "Found 28728 SKU-warehouse combinations with NMV in last 4 months\n",
      "\n",
      "============================================================\n",
      "NO NMV IN LAST 4 MONTHS ANALYSIS\n",
      "============================================================\n",
      "Total records: 91348\n",
      "SKUs with NO NMV in 4 months (no_nmv_4m=1): 62460\n",
      "SKUs with NMV in 4 months (no_nmv_4m=0): 28888\n",
      "\n",
      "Sample SKUs with no NMV in last 4 months:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>stocks</th>\n",
       "      <th>in_stock_rr</th>\n",
       "      <th>zero_demand</th>\n",
       "      <th>no_nmv_4m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8672</td>\n",
       "      <td>797</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20198</td>\n",
       "      <td>501</td>\n",
       "      <td>      - 330 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11774</td>\n",
       "      <td>501</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18</td>\n",
       "      <td>401</td>\n",
       "      <td>   - 1.5 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1767</td>\n",
       "      <td>632</td>\n",
       "      <td>   5- 40 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>501</td>\n",
       "      <td>    - 55 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td> - 600 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>268</td>\n",
       "      <td>703</td>\n",
       "      <td>   3  - 14 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>313</td>\n",
       "      <td>797</td>\n",
       "      <td>  - 170 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>13163</td>\n",
       "      <td>501</td>\n",
       "      <td>  - 5 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10597</td>\n",
       "      <td>339</td>\n",
       "      <td>    55%- 45 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10597</td>\n",
       "      <td>170</td>\n",
       "      <td>    55%- 45 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20498</td>\n",
       "      <td>401</td>\n",
       "      <td>    - 5 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20498</td>\n",
       "      <td>632</td>\n",
       "      <td>    - 5 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>286</td>\n",
       "      <td>703</td>\n",
       "      <td>    - 45 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id                                         sku  \\\n",
       "0         8672           797                           - 400    \n",
       "2        20198           501        - 330    \n",
       "5        11774           501       ( 8  ) - 500    \n",
       "16          18           401                     - 1.5    \n",
       "18        1767           632                 5- 40    \n",
       "19          11           501                    - 55    \n",
       "23         128             1                        - 600    \n",
       "24         268           703          3  - 14    \n",
       "32         313           797                      - 170    \n",
       "34       13163           501                           - 5    \n",
       "36       10597           339       55%- 45    \n",
       "37       10597           170       55%- 45    \n",
       "38       20498           401         - 5    \n",
       "39       20498           632         - 5    \n",
       "44         286           703                    - 45    \n",
       "\n",
       "    stocks  in_stock_rr  zero_demand  no_nmv_4m  \n",
       "0        0          0.0            0          1  \n",
       "2        0          0.0            0          1  \n",
       "5        0          0.0            0          1  \n",
       "16       0          0.0            0          1  \n",
       "18       0          0.0            0          1  \n",
       "19       0          0.0            0          1  \n",
       "23       0          0.0            0          1  \n",
       "24       0          0.0            0          1  \n",
       "32       0          0.0            0          1  \n",
       "34       0          0.0            0          1  \n",
       "36       0          0.0            0          1  \n",
       "37       0          0.0            0          1  \n",
       "38       0          0.0            0          1  \n",
       "39       0          0.0            0          1  \n",
       "44       0          0.0            0          1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# No NMV in Last 4 Months Flag\n",
    "# Identifies SKUs that have not generated any NMV in the past 4 months (120 days)\n",
    "# =============================================================================\n",
    "NO_NMV_4M_QUERY = f'''\n",
    "WITH nmv_last_4m AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        SUM(pso.total_price) AS total_nmv_4m\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "        AND so.created_at::DATE < CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id\n",
    "    HAVING SUM(pso.total_price) > 0\n",
    ")\n",
    "SELECT \n",
    "    warehouse_id,\n",
    "    product_id,\n",
    "    total_nmv_4m\n",
    "FROM nmv_last_4m\n",
    "'''\n",
    "\n",
    "# Execute query\n",
    "print(\"Loading SKUs with NMV in last 4 months...\")\n",
    "df_nmv_4m = query_snowflake(NO_NMV_4M_QUERY)\n",
    "df_nmv_4m = convert_to_numeric(df_nmv_4m)\n",
    "print(f\"Found {len(df_nmv_4m)} SKU-warehouse combinations with NMV in last 4 months\")\n",
    "\n",
    "# Merge and create no_nmv_4m flag\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_nmv_4m[['warehouse_id', 'product_id', 'total_nmv_4m']],\n",
    "    on=['warehouse_id', 'product_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Flag SKUs with no NMV in last 4 months\n",
    "# 1 = No NMV (should potentially be filtered), 0 = Has NMV\n",
    "pricing_with_discount['no_nmv_4m'] = np.where(\n",
    "    pricing_with_discount['total_nmv_4m'].isna() | (pricing_with_discount['total_nmv_4m'] == 0),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "# Fill NaN for total_nmv_4m\n",
    "pricing_with_discount['total_nmv_4m'] = pricing_with_discount['total_nmv_4m'].fillna(0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"NO NMV IN LAST 4 MONTHS ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(pricing_with_discount)}\")\n",
    "print(f\"SKUs with NO NMV in 4 months (no_nmv_4m=1): {len(pricing_with_discount[pricing_with_discount['no_nmv_4m'] == 1])}\")\n",
    "print(f\"SKUs with NMV in 4 months (no_nmv_4m=0): {len(pricing_with_discount[pricing_with_discount['no_nmv_4m'] == 0])}\")\n",
    "\n",
    "# Show sample of SKUs with no NMV\n",
    "print(f\"\\nSample SKUs with no NMV in last 4 months:\")\n",
    "pricing_with_discount[pricing_with_discount['no_nmv_4m'] == 1][\n",
    "    ['product_id', 'warehouse_id', 'sku', 'stocks', 'in_stock_rr', 'zero_demand', 'no_nmv_4m']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading retailer order data for normal refill calculation (last 120 days)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4871694 retailer order records\n",
      "ABC classification mapping: 86338 product-warehouse combinations\n",
      "Records after ABC merge: 4647836\n",
      "Records from frequent retailers: 1650095\n",
      "Final normal refill records (min 2 orders): 21807\n",
      "\n",
      "============================================================\n",
      "NORMAL REFILL ANALYSIS (Frequent Retailers - 120 days)\n",
      "============================================================\n",
      "Records with normal_refill data: 22877\n",
      "Records without normal_refill data: 68471\n",
      "\n",
      "Normal refill distribution:\n",
      "count    22877.000000\n",
      "mean         3.104716\n",
      "std         33.105834\n",
      "min          1.000000\n",
      "25%          1.210000\n",
      "50%          1.710000\n",
      "75%          2.840000\n",
      "max       4534.000000\n",
      "Name: normal_refill, dtype: float64\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>abc_class</th>\n",
       "      <th>frequent_retailer_count</th>\n",
       "      <th>frequent_order_count</th>\n",
       "      <th>normal_refill</th>\n",
       "      <th>refill_stddev</th>\n",
       "      <th>in_stock_rr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8674</td>\n",
       "      <td>401</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>B</td>\n",
       "      <td>26.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.40</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23421</td>\n",
       "      <td>337</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23421</td>\n",
       "      <td>8</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>B</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.55</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>170</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>B</td>\n",
       "      <td>20.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2.08</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11774</td>\n",
       "      <td>339</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>C</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11774</td>\n",
       "      <td>170</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>C</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10521</td>\n",
       "      <td>1</td>\n",
       "      <td>     - ...</td>\n",
       "      <td>C</td>\n",
       "      <td>54.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>3.34</td>\n",
       "      <td>3.22</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13885</td>\n",
       "      <td>170</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>703</td>\n",
       "      <td>  - 1.2 </td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1701</td>\n",
       "      <td>1</td>\n",
       "      <td>   2  - 2 </td>\n",
       "      <td>C</td>\n",
       "      <td>81.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.81</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>380</td>\n",
       "      <td>797</td>\n",
       "      <td>    - 380 </td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2718</td>\n",
       "      <td>401</td>\n",
       "      <td>   - 20 </td>\n",
       "      <td>C</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>     - 6 </td>\n",
       "      <td>C</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.75</td>\n",
       "      <td>13.00</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>88</td>\n",
       "      <td>401</td>\n",
       "      <td>    - 250 </td>\n",
       "      <td>B</td>\n",
       "      <td>11.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.68</td>\n",
       "      <td>5.01</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "1         8674           401   \n",
       "3        23421           337   \n",
       "4        23421             8   \n",
       "6          147           339   \n",
       "7          147           170   \n",
       "8        11774           339   \n",
       "9        11774           170   \n",
       "10       10521             1   \n",
       "12       13885           170   \n",
       "13         385           703   \n",
       "14        1701             1   \n",
       "15         380           797   \n",
       "17        2718           401   \n",
       "21          60           170   \n",
       "22          88           401   \n",
       "\n",
       "                                                  sku abc_class  \\\n",
       "1                                  - 400          B   \n",
       "3                                 - 15          C   \n",
       "4                                 - 15          C   \n",
       "6                                 - 1          B   \n",
       "7                                 - 1          B   \n",
       "8               ( 8  ) - 500          C   \n",
       "9               ( 8  ) - 500          C   \n",
       "10       - ...         C   \n",
       "12                      - 15          C   \n",
       "13                                - 1.2          C   \n",
       "14                    2  - 2          C   \n",
       "15                     - 380          C   \n",
       "17                              - 20          C   \n",
       "21                   - 6          C   \n",
       "22                              - 250          B   \n",
       "\n",
       "    frequent_retailer_count  frequent_order_count  normal_refill  \\\n",
       "1                      26.0                 101.0           3.00   \n",
       "3                       2.0                   5.0           1.00   \n",
       "4                       1.0                   2.0           1.00   \n",
       "6                       6.0                  20.0           1.75   \n",
       "7                      20.0                  74.0           2.08   \n",
       "8                      12.0                  32.0           1.34   \n",
       "9                       5.0                  10.0           1.60   \n",
       "10                     54.0                 173.0           3.34   \n",
       "12                      2.0                   4.0           1.00   \n",
       "13                      1.0                   3.0           1.00   \n",
       "14                     81.0                 227.0           1.85   \n",
       "15                      2.0                   4.0           1.00   \n",
       "17                      1.0                   2.0           1.00   \n",
       "21                      2.0                   4.0          12.75   \n",
       "22                     11.0                  56.0           5.68   \n",
       "\n",
       "    refill_stddev  in_stock_rr  \n",
       "1            4.40          9.0  \n",
       "3            0.00          2.0  \n",
       "4            0.00          2.0  \n",
       "6            1.55          5.0  \n",
       "7            3.47          9.0  \n",
       "8            0.65          0.0  \n",
       "9            0.70          2.0  \n",
       "10           3.22         11.0  \n",
       "12           0.00          2.0  \n",
       "13           0.00          0.0  \n",
       "14           2.81          7.0  \n",
       "15           0.00          0.0  \n",
       "17           0.00          1.0  \n",
       "21          13.00        379.0  \n",
       "22           5.01         21.0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Normal Refill Query - Avg qty & stddev for frequent retailers (last 120 days)\n",
    "# Frequent retailer definition based on ABC classification (from existing dataframe):\n",
    "#   - Class A: bought 4+ times\n",
    "#   - Class B: bought 3+ times\n",
    "#   - Class C: bought 2+ times\n",
    "# =============================================================================\n",
    "NORMAL_REFILL_QUERY = f'''\n",
    "WITH params AS (\n",
    "    SELECT \n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE AS today,\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120 AS history_start\n",
    "),\n",
    "\n",
    "-- Get retailer order counts per product-warehouse (last 120 days)\n",
    "retailer_orders AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        so.retailer_id,\n",
    "        COUNT(DISTINCT so.id) AS order_count\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    CROSS JOIN params p\n",
    "    WHERE so.created_at::DATE >= p.history_start\n",
    "        AND so.created_at::DATE < p.today\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id, so.retailer_id\n",
    "),\n",
    "\n",
    "-- Get individual order quantities per retailer\n",
    "order_quantities AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        so.retailer_id,\n",
    "        so.id AS order_id,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count) AS order_qty\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    CROSS JOIN params p\n",
    "    WHERE so.created_at::DATE >= p.history_start\n",
    "        AND so.created_at::DATE < p.today\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id, so.retailer_id, so.id\n",
    ")\n",
    "\n",
    "-- Return retailer-level data with order counts for Python filtering\n",
    "SELECT \n",
    "    oq.warehouse_id,\n",
    "    oq.product_id,\n",
    "    oq.retailer_id,\n",
    "    ro.order_count,\n",
    "    oq.order_id,\n",
    "    oq.order_qty\n",
    "FROM order_quantities oq\n",
    "JOIN retailer_orders ro \n",
    "    ON ro.warehouse_id = oq.warehouse_id \n",
    "    AND ro.product_id = oq.product_id \n",
    "    AND ro.retailer_id = oq.retailer_id\n",
    "'''\n",
    "\n",
    "# Execute normal refill query\n",
    "print(\"Loading retailer order data for normal refill calculation (last 120 days)...\")\n",
    "df_retailer_orders = query_snowflake(NORMAL_REFILL_QUERY)\n",
    "df_retailer_orders = convert_to_numeric(df_retailer_orders)\n",
    "print(f\"Loaded {len(df_retailer_orders)} retailer order records\")\n",
    "\n",
    "# Get ABC classification from existing dataframe\n",
    "abc_mapping = pricing_with_discount[['warehouse_id', 'product_id', 'abc_class']].drop_duplicates()\n",
    "print(f\"ABC classification mapping: {len(abc_mapping)} product-warehouse combinations\")\n",
    "\n",
    "# Merge ABC classification into retailer orders\n",
    "df_retailer_orders = df_retailer_orders.merge(\n",
    "    abc_mapping,\n",
    "    on=['warehouse_id', 'product_id'],\n",
    "    how='inner'\n",
    ")\n",
    "print(f\"Records after ABC merge: {len(df_retailer_orders)}\")\n",
    "\n",
    "# Filter frequent retailers based on ABC class thresholds\n",
    "# Class A: 4+ orders, Class B: 3+ orders, Class C: 2+ orders\n",
    "df_frequent = df_retailer_orders[\n",
    "    ((df_retailer_orders['abc_class'] == 'A') & (df_retailer_orders['order_count'] >= 4)) |\n",
    "    ((df_retailer_orders['abc_class'] == 'B') & (df_retailer_orders['order_count'] >= 3)) |\n",
    "    ((df_retailer_orders['abc_class'] == 'C') & (df_retailer_orders['order_count'] >= 2))\n",
    "].copy()\n",
    "print(f\"Records from frequent retailers: {len(df_frequent)}\")\n",
    "\n",
    "# Calculate normal_refill (avg qty) and refill_stddev per product-warehouse\n",
    "df_normal_refill = df_frequent.groupby(['warehouse_id', 'product_id']).agg(\n",
    "    frequent_retailer_count=('retailer_id', 'nunique'),\n",
    "    frequent_order_count=('order_id', 'nunique'),\n",
    "    normal_refill=('order_qty', 'mean'),\n",
    "    refill_stddev=('order_qty', 'std')\n",
    ").reset_index()\n",
    "\n",
    "# Round values and fill NaN stddev (when only 1 order)\n",
    "df_normal_refill['normal_refill'] = df_normal_refill['normal_refill'].round(2)\n",
    "df_normal_refill['refill_stddev'] = df_normal_refill['refill_stddev'].fillna(0).round(2)\n",
    "\n",
    "# Filter to products with at least 2 orders for meaningful stats\n",
    "df_normal_refill = df_normal_refill[df_normal_refill['frequent_order_count'] >= 2]\n",
    "print(f\"Final normal refill records (min 2 orders): {len(df_normal_refill)}\")\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_normal_refill[['warehouse_id', 'product_id', 'frequent_retailer_count', \n",
    "                      'frequent_order_count', 'normal_refill', 'refill_stddev']],\n",
    "    on=['warehouse_id', 'product_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values\n",
    "pricing_with_discount['frequent_retailer_count'] = pricing_with_discount['frequent_retailer_count'].fillna(0)\n",
    "pricing_with_discount['frequent_order_count'] = pricing_with_discount['frequent_order_count'].fillna(0)\n",
    "pricing_with_discount['normal_refill'] = pricing_with_discount['normal_refill'].fillna(0)\n",
    "pricing_with_discount['refill_stddev'] = pricing_with_discount['refill_stddev'].fillna(0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"NORMAL REFILL ANALYSIS (Frequent Retailers - 120 days)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Records with normal_refill data: {len(pricing_with_discount[pricing_with_discount['normal_refill'] > 0])}\")\n",
    "print(f\"Records without normal_refill data: {len(pricing_with_discount[pricing_with_discount['normal_refill'] == 0])}\")\n",
    "print(f\"\\nNormal refill distribution:\")\n",
    "print(pricing_with_discount[pricing_with_discount['normal_refill'] > 0]['normal_refill'].describe())\n",
    "print(f\"\\nSample data:\")\n",
    "pricing_with_discount[pricing_with_discount['normal_refill'] > 0][\n",
    "    ['product_id', 'warehouse_id', 'sku', 'abc_class', 'frequent_retailer_count', \n",
    "     'frequent_order_count', 'normal_refill', 'refill_stddev', 'in_stock_rr']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading live cart rules...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 110372 cart rule records\n",
      "Basic unit cart rules: 72842\n",
      "Final cart rules (product-cohort level): 72824\n",
      "\n",
      "============================================================\n",
      "LIVE CART RULES ANALYSIS\n",
      "============================================================\n",
      "Records with cart rule > 0: 91305\n",
      "Records without cart rule: 55\n",
      "\n",
      "Cart rule distribution:\n",
      "count    91305.000000\n",
      "mean        70.258201\n",
      "std        641.814448\n",
      "min          1.000000\n",
      "25%         10.000000\n",
      "50%         17.000000\n",
      "75%         25.000000\n",
      "max      10000.000000\n",
      "Name: current_cart_rule, dtype: float64\n",
      "\n",
      "Sample data with cart rules:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>current_price</th>\n",
       "      <th>current_cart_rule</th>\n",
       "      <th>in_stock_rr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8672</td>\n",
       "      <td>702</td>\n",
       "      <td>797</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>106.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8674</td>\n",
       "      <td>1126</td>\n",
       "      <td>401</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>102.75</td>\n",
       "      <td>322.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20198</td>\n",
       "      <td>1124</td>\n",
       "      <td>501</td>\n",
       "      <td>      - 330 </td>\n",
       "      <td>105.00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23421</td>\n",
       "      <td>703</td>\n",
       "      <td>337</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>166.75</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23421</td>\n",
       "      <td>703</td>\n",
       "      <td>8</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>166.75</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11774</td>\n",
       "      <td>1124</td>\n",
       "      <td>501</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>253.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147</td>\n",
       "      <td>704</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>337.25</td>\n",
       "      <td>101.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>704</td>\n",
       "      <td>170</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>337.25</td>\n",
       "      <td>101.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11774</td>\n",
       "      <td>704</td>\n",
       "      <td>339</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>249.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11774</td>\n",
       "      <td>704</td>\n",
       "      <td>170</td>\n",
       "      <td>    ( 8  ) - 500 </td>\n",
       "      <td>249.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10521</td>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "      <td>     - ...</td>\n",
       "      <td>50.25</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13885</td>\n",
       "      <td>704</td>\n",
       "      <td>339</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>132.25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13885</td>\n",
       "      <td>704</td>\n",
       "      <td>170</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>132.25</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>1123</td>\n",
       "      <td>703</td>\n",
       "      <td>  - 1.2 </td>\n",
       "      <td>410.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1701</td>\n",
       "      <td>700</td>\n",
       "      <td>1</td>\n",
       "      <td>   2  - 2 </td>\n",
       "      <td>230.00</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  cohort_id  warehouse_id  \\\n",
       "0         8672        702           797   \n",
       "1         8674       1126           401   \n",
       "2        20198       1124           501   \n",
       "3        23421        703           337   \n",
       "4        23421        703             8   \n",
       "5        11774       1124           501   \n",
       "6          147        704           339   \n",
       "7          147        704           170   \n",
       "8        11774        704           339   \n",
       "9        11774        704           170   \n",
       "10       10521        700             1   \n",
       "11       13885        704           339   \n",
       "12       13885        704           170   \n",
       "13         385       1123           703   \n",
       "14        1701        700             1   \n",
       "\n",
       "                                                  sku  current_price  \\\n",
       "0                                   - 400          106.00   \n",
       "1                                  - 400          102.75   \n",
       "2                - 330          105.00   \n",
       "3                                 - 15          166.75   \n",
       "4                                 - 15          166.75   \n",
       "5               ( 8  ) - 500          253.00   \n",
       "6                                 - 1          337.25   \n",
       "7                                 - 1          337.25   \n",
       "8               ( 8  ) - 500          249.00   \n",
       "9               ( 8  ) - 500          249.00   \n",
       "10       - ...          50.25   \n",
       "11                      - 15          132.25   \n",
       "12                      - 15          132.25   \n",
       "13                                - 1.2          410.00   \n",
       "14                    2  - 2          230.00   \n",
       "\n",
       "    current_cart_rule  in_stock_rr  \n",
       "0                25.0          0.0  \n",
       "1               322.0          9.0  \n",
       "2                10.0          0.0  \n",
       "3                10.0          2.0  \n",
       "4                10.0          2.0  \n",
       "5                25.0          0.0  \n",
       "6               101.0          5.0  \n",
       "7               101.0          9.0  \n",
       "8                25.0          0.0  \n",
       "9                25.0          2.0  \n",
       "10               12.0         11.0  \n",
       "11               10.0          2.0  \n",
       "12               10.0          2.0  \n",
       "13               25.0          0.0  \n",
       "14               25.0          7.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Live Cart Rules Query - Get current cart rules from the system\n",
    "# Merges on product_id and cohort_id\n",
    "# =============================================================================\n",
    "LIVE_CART_RULES_QUERY = f'''\n",
    "SELECT \n",
    "    cppu.cohort_id,\n",
    "    pup.product_id,\n",
    "    pup.packing_unit_id,\n",
    "    pup.basic_unit_count,\n",
    "    COALESCE(cppu.MAX_PER_SALES_ORDER, cppu2.MAX_PER_SALES_ORDER) AS current_cart_rule\n",
    "FROM COHORT_PRODUCT_PACKING_UNITS cppu \n",
    "JOIN PACKING_UNIT_PRODUCTS pup ON cppu.PRODUCT_PACKING_UNIT_ID = pup.id \n",
    "JOIN cohorts c ON c.id = cppu.cohort_id\n",
    "LEFT JOIN COHORT_PRODUCT_PACKING_UNITS cppu2 \n",
    "    ON cppu.PRODUCT_PACKING_UNIT_ID = cppu2.PRODUCT_PACKING_UNIT_ID \n",
    "    AND cppu2.cohort_id = c.FALLBACK_COHORT_ID\n",
    "WHERE cppu.cohort_id IN ({','.join(map(str, COHORT_IDS))})\n",
    "'''\n",
    "\n",
    "# Execute live cart rules query\n",
    "print(\"Loading live cart rules...\")\n",
    "df_cart_rules = query_snowflake(LIVE_CART_RULES_QUERY)\n",
    "df_cart_rules = convert_to_numeric(df_cart_rules)\n",
    "print(f\"Loaded {len(df_cart_rules)} cart rule records\")\n",
    "\n",
    "# Aggregate to product-cohort level (take the cart rule for basic unit, or min if multiple)\n",
    "# Filter to basic unit (packing_unit_id where basic_unit_count = 1) for simpler merging\n",
    "df_cart_rules_basic = df_cart_rules[df_cart_rules['basic_unit_count'] == 1].copy()\n",
    "print(f\"Basic unit cart rules: {len(df_cart_rules_basic)}\")\n",
    "\n",
    "# If no basic unit, take the minimum cart rule per product-cohort\n",
    "df_cart_rules_agg = df_cart_rules.groupby(['cohort_id', 'product_id']).agg(\n",
    "    current_cart_rule=('current_cart_rule', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Prefer basic unit cart rule, fallback to aggregated\n",
    "df_cart_rules_final = df_cart_rules_basic[['cohort_id', 'product_id', 'current_cart_rule']].drop_duplicates()\n",
    "df_cart_rules_final = df_cart_rules_final.merge(\n",
    "    df_cart_rules_agg[['cohort_id', 'product_id', 'current_cart_rule']].rename(columns={'current_cart_rule': 'cart_rule_agg'}),\n",
    "    on=['cohort_id', 'product_id'],\n",
    "    how='outer'\n",
    ")\n",
    "df_cart_rules_final['current_cart_rule'] = df_cart_rules_final['current_cart_rule'].fillna(df_cart_rules_final['cart_rule_agg'])\n",
    "df_cart_rules_final = df_cart_rules_final[['cohort_id', 'product_id', 'current_cart_rule']].drop_duplicates()\n",
    "print(f\"Final cart rules (product-cohort level): {len(df_cart_rules_final)}\")\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_cart_rules_final,\n",
    "    on=['cohort_id', 'product_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN cart rules with 0 (no cart rule set)\n",
    "pricing_with_discount['current_cart_rule'] = pricing_with_discount['current_cart_rule'].fillna(0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"LIVE CART RULES ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Records with cart rule > 0: {len(pricing_with_discount[pricing_with_discount['current_cart_rule'] > 0])}\")\n",
    "print(f\"Records without cart rule: {len(pricing_with_discount[pricing_with_discount['current_cart_rule'] == 0])}\")\n",
    "print(f\"\\nCart rule distribution:\")\n",
    "print(pricing_with_discount[pricing_with_discount['current_cart_rule'] > 0]['current_cart_rule'].describe())\n",
    "print(f\"\\nSample data with cart rules:\")\n",
    "pricing_with_discount[pricing_with_discount['current_cart_rule'] > 0][\n",
    "    ['product_id', 'cohort_id', 'warehouse_id', 'sku', 'current_price', 'current_cart_rule', 'in_stock_rr']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading commercial minimum price constraints...\n",
      "Loaded 782 commercial min price records\n",
      "\n",
      "============================================================\n",
      "COMMERCIAL MINIMUM PRICE CONSTRAINTS\n",
      "============================================================\n",
      "Records with commercial min price: 1576\n",
      "Records without commercial min price: 89784\n",
      "\n",
      "Commercial min price distribution:\n",
      "count    1576.000000\n",
      "mean      153.922009\n",
      "std       171.896901\n",
      "min        11.750000\n",
      "25%        48.500000\n",
      "50%        95.000000\n",
      "75%       189.700000\n",
      "max       815.000000\n",
      "Name: commercial_min_price, dtype: float64\n",
      "\n",
      "Sample data with commercial constraints:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>region</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>current_price</th>\n",
       "      <th>commercial_min_price</th>\n",
       "      <th>price_after_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20498</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>401</td>\n",
       "      <td>    - 5 </td>\n",
       "      <td>48.50</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>48.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20498</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>632</td>\n",
       "      <td>    - 5 </td>\n",
       "      <td>48.50</td>\n",
       "      <td>47.0000</td>\n",
       "      <td>48.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>13025</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>501</td>\n",
       "      <td>      - 6 </td>\n",
       "      <td>24.50</td>\n",
       "      <td>24.2500</td>\n",
       "      <td>24.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>10459</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>501</td>\n",
       "      <td>HD-     - 7 </td>\n",
       "      <td>48.50</td>\n",
       "      <td>47.5000</td>\n",
       "      <td>48.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>10459</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>501</td>\n",
       "      <td>HD-     - 7 </td>\n",
       "      <td>48.50</td>\n",
       "      <td>47.5000</td>\n",
       "      <td>48.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>21700</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>501</td>\n",
       "      <td>  - 240 </td>\n",
       "      <td>105.00</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>105.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>9623</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>401</td>\n",
       "      <td>     - 10 </td>\n",
       "      <td>116.75</td>\n",
       "      <td>114.0000</td>\n",
       "      <td>116.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>9623</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>401</td>\n",
       "      <td>     - 10 </td>\n",
       "      <td>116.75</td>\n",
       "      <td>114.0000</td>\n",
       "      <td>116.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>4671</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>632</td>\n",
       "      <td>   - 850 </td>\n",
       "      <td>815.00</td>\n",
       "      <td>815.0000</td>\n",
       "      <td>815.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>12474</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>401</td>\n",
       "      <td>       - 10 </td>\n",
       "      <td>46.50</td>\n",
       "      <td>46.0000</td>\n",
       "      <td>46.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>12477</td>\n",
       "      <td>Delta East</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 10 </td>\n",
       "      <td>46.75</td>\n",
       "      <td>45.5126</td>\n",
       "      <td>46.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>12477</td>\n",
       "      <td>Delta East</td>\n",
       "      <td>170</td>\n",
       "      <td>    - 10 </td>\n",
       "      <td>46.75</td>\n",
       "      <td>45.5126</td>\n",
       "      <td>46.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>12918</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>632</td>\n",
       "      <td>       ...</td>\n",
       "      <td>146.75</td>\n",
       "      <td>146.6670</td>\n",
       "      <td>146.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>12919</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>401</td>\n",
       "      <td>      ...</td>\n",
       "      <td>146.75</td>\n",
       "      <td>146.6670</td>\n",
       "      <td>146.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>13462</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>401</td>\n",
       "      <td>  3  2   - 250 </td>\n",
       "      <td>465.00</td>\n",
       "      <td>465.0000</td>\n",
       "      <td>465.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id       region  warehouse_id  \\\n",
       "38         20498  Upper Egypt           401   \n",
       "39         20498  Upper Egypt           632   \n",
       "75         13025  Upper Egypt           501   \n",
       "386        10459  Upper Egypt           501   \n",
       "387        10459  Upper Egypt           501   \n",
       "452        21700  Upper Egypt           501   \n",
       "479         9623  Upper Egypt           401   \n",
       "480         9623  Upper Egypt           401   \n",
       "562         4671  Upper Egypt           632   \n",
       "1122       12474  Upper Egypt           401   \n",
       "1123       12477   Delta East           339   \n",
       "1124       12477   Delta East           170   \n",
       "1141       12918  Upper Egypt           632   \n",
       "1142       12919  Upper Egypt           401   \n",
       "1191       13462  Upper Egypt           401   \n",
       "\n",
       "                                                    sku  current_price  \\\n",
       "38                  - 5           48.50   \n",
       "39                  - 5           48.50   \n",
       "75                   - 6           24.50   \n",
       "386       HD-     - 7           48.50   \n",
       "387       HD-     - 7           48.50   \n",
       "452                                 - 240          105.00   \n",
       "479                 - 10          116.75   \n",
       "480                 - 10          116.75   \n",
       "562                               - 850          815.00   \n",
       "1122             - 10           46.50   \n",
       "1123                          - 10           46.75   \n",
       "1124                          - 10           46.75   \n",
       "1141         ...         146.75   \n",
       "1142        ...         146.75   \n",
       "1191                     3  2   - 250          465.00   \n",
       "\n",
       "      commercial_min_price  price_after_discount  \n",
       "38                 47.0000                 48.50  \n",
       "39                 47.0000                 48.50  \n",
       "75                 24.2500                 24.50  \n",
       "386                47.5000                 48.50  \n",
       "387                47.5000                 48.50  \n",
       "452               100.0000                105.00  \n",
       "479               114.0000                116.75  \n",
       "480               114.0000                116.75  \n",
       "562               815.0000                815.00  \n",
       "1122               46.0000                 46.50  \n",
       "1123               45.5126                 46.75  \n",
       "1124               45.5126                 46.75  \n",
       "1141              146.6670                146.75  \n",
       "1142              146.6670                146.75  \n",
       "1191              465.0000                465.00  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Commercial Constraint Minimum Price Query\n",
    "# Gets the minimum price constraints from finance.minimum_prices\n",
    "# =============================================================================\n",
    "COMMERCIAL_MIN_PRICE_QUERY = f'''\n",
    "WITH to_remove AS (\n",
    "    SELECT \n",
    "        check_date AS start_date,\n",
    "        (check_date + INTERVAL '1 month') + 6 AS end_date \n",
    "    FROM (\n",
    "        SELECT \n",
    "            CASE \n",
    "                WHEN DATE_PART('day', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE) < 7 \n",
    "                THEN DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - INTERVAL '1 month') \n",
    "                ELSE DATE_FROM_PARTS(\n",
    "                    YEAR(CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE), \n",
    "                    MONTH(CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE), \n",
    "                    1\n",
    "                )  \n",
    "            END AS check_date\n",
    "    )\n",
    ") \n",
    "\n",
    "SELECT  \n",
    "    sku_id AS product_id,\n",
    "    sku,\n",
    "    brand AS comm_brand,\n",
    "    cat AS comm_cat,\n",
    "    region,\n",
    "    created_at AS comm_created_at,\n",
    "    min_price AS commercial_min_price\n",
    "FROM (\n",
    "    SELECT \n",
    "        product_id AS sku_id,\n",
    "        product_name AS sku,\n",
    "        brand,\n",
    "        category AS cat,\n",
    "        region,\n",
    "        min_price,\n",
    "        created_at,\n",
    "        MAX(created_at) OVER (PARTITION BY product_id, region) AS latest_date\n",
    "    FROM finance.minimum_prices\n",
    "    WHERE is_deleted = 'false'\n",
    "        AND created_at BETWEEN (SELECT start_date FROM to_remove) AND (SELECT end_date FROM to_remove)\n",
    ") comm\n",
    "WHERE created_at = latest_date\n",
    "'''\n",
    "\n",
    "# Execute commercial min price query\n",
    "print(\"Loading commercial minimum price constraints...\")\n",
    "df_commercial_min = query_snowflake(COMMERCIAL_MIN_PRICE_QUERY)\n",
    "df_commercial_min = convert_to_numeric(df_commercial_min)\n",
    "print(f\"Loaded {len(df_commercial_min)} commercial min price records\")\n",
    "\n",
    "# Merge with pricing_with_discount on product_id and region\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_commercial_min[['product_id', 'region', 'commercial_min_price']],\n",
    "    on=['product_id', 'region'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN with 0 (no commercial constraint)\n",
    "pricing_with_discount['commercial_min_price'] = pricing_with_discount['commercial_min_price'].fillna(0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"COMMERCIAL MINIMUM PRICE CONSTRAINTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Records with commercial min price: {len(pricing_with_discount[pricing_with_discount['commercial_min_price'] > 0])}\")\n",
    "print(f\"Records without commercial min price: {len(pricing_with_discount[pricing_with_discount['commercial_min_price'] == 0])}\")\n",
    "print(f\"\\nCommercial min price distribution:\")\n",
    "print(pricing_with_discount[pricing_with_discount['commercial_min_price'] > 0]['commercial_min_price'].describe())\n",
    "print(f\"\\nSample data with commercial constraints:\")\n",
    "pricing_with_discount[pricing_with_discount['commercial_min_price'] > 0][\n",
    "    ['product_id', 'region', 'warehouse_id', 'sku', 'current_price', 'commercial_min_price', 'price_after_discount']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading active SKU discount data...\n",
      "Loaded 13585 active SKU discount records\n",
      "\n",
      "============================================================\n",
      "ACTIVE SKU DISCOUNT ANALYSIS\n",
      "============================================================\n",
      "Records with active SKU discount: 14336\n",
      "Records without active SKU discount: 77024\n",
      "\n",
      "Active SKU discount distribution:\n",
      "count    14336.000000\n",
      "mean         1.580783\n",
      "std          1.405297\n",
      "min          0.260000\n",
      "25%          0.510000\n",
      "50%          1.001660\n",
      "75%          2.150000\n",
      "max          5.000000\n",
      "Name: active_sku_disc_pct, dtype: float64\n",
      "\n",
      "Sample data with active SKU discounts:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12252/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>current_price</th>\n",
       "      <th>active_sku_disc_pct</th>\n",
       "      <th>discount_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8674</td>\n",
       "      <td>401</td>\n",
       "      <td>  - 400 </td>\n",
       "      <td>102.75</td>\n",
       "      <td>0.466807</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23421</td>\n",
       "      <td>337</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>166.75</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23421</td>\n",
       "      <td>8</td>\n",
       "      <td>  - 15 </td>\n",
       "      <td>166.75</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>147</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>337.25</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>147</td>\n",
       "      <td>170</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>337.25</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.021208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10521</td>\n",
       "      <td>1</td>\n",
       "      <td>     - ...</td>\n",
       "      <td>50.25</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.001317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13885</td>\n",
       "      <td>339</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>132.25</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>0.014680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13885</td>\n",
       "      <td>170</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>132.25</td>\n",
       "      <td>3.670000</td>\n",
       "      <td>0.036700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>385</td>\n",
       "      <td>703</td>\n",
       "      <td>  - 1.2 </td>\n",
       "      <td>410.00</td>\n",
       "      <td>4.860000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1701</td>\n",
       "      <td>1</td>\n",
       "      <td>   2  - 2 </td>\n",
       "      <td>230.00</td>\n",
       "      <td>2.870000</td>\n",
       "      <td>0.019102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>380</td>\n",
       "      <td>797</td>\n",
       "      <td>    - 380 </td>\n",
       "      <td>485.75</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>88</td>\n",
       "      <td>401</td>\n",
       "      <td>    - 250 </td>\n",
       "      <td>52.00</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.041127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>161</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>41.75</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>161</td>\n",
       "      <td>170</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>41.75</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.013301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>10279</td>\n",
       "      <td>236</td>\n",
       "      <td>     - 22.5 </td>\n",
       "      <td>109.00</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "1         8674           401   \n",
       "3        23421           337   \n",
       "4        23421             8   \n",
       "6          147           339   \n",
       "7          147           170   \n",
       "10       10521             1   \n",
       "11       13885           339   \n",
       "12       13885           170   \n",
       "13         385           703   \n",
       "14        1701             1   \n",
       "15         380           797   \n",
       "22          88           401   \n",
       "27         161           339   \n",
       "28         161           170   \n",
       "42       10279           236   \n",
       "\n",
       "                                                  sku  current_price  \\\n",
       "1                                  - 400          102.75   \n",
       "3                                 - 15          166.75   \n",
       "4                                 - 15          166.75   \n",
       "6                                 - 1          337.25   \n",
       "7                                 - 1          337.25   \n",
       "10       - ...          50.25   \n",
       "11                      - 15          132.25   \n",
       "12                      - 15          132.25   \n",
       "13                                - 1.2          410.00   \n",
       "14                    2  - 2          230.00   \n",
       "15                     - 380          485.75   \n",
       "22                              - 250           52.00   \n",
       "27                             - 8           41.75   \n",
       "28                             - 8           41.75   \n",
       "42               - 22.5          109.00   \n",
       "\n",
       "    active_sku_disc_pct  discount_perc  \n",
       "1              0.466807       0.000000  \n",
       "3              1.280000       0.000000  \n",
       "4              1.280000       0.000000  \n",
       "6              0.600000       0.031800  \n",
       "7              0.580000       0.021208  \n",
       "10             0.270000       0.001317  \n",
       "11             3.670000       0.014680  \n",
       "12             3.670000       0.036700  \n",
       "13             4.860000       0.000000  \n",
       "14             2.870000       0.019102  \n",
       "15             3.250000       0.000000  \n",
       "22             1.150000       0.041127  \n",
       "27             1.800000       0.000000  \n",
       "28             1.800000       0.013301  \n",
       "42             0.460000       0.004600  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Active SKU Discount Query - Get current SKU discount percentage per warehouse\n",
    "# =============================================================================\n",
    "ACTIVE_SKU_DISCOUNT_QUERY = f'''\n",
    "WITH active_sku_discount AS ( \n",
    "    SELECT \n",
    "        x.id AS sku_discount_id,\n",
    "        retailer_id,\n",
    "        product_id,\n",
    "        packing_unit_id,\n",
    "        DISCOUNT_PERCENTAGE,\n",
    "        start_at,\n",
    "        end_at \n",
    "    FROM (\n",
    "        SELECT \n",
    "            sd.*,\n",
    "            f.value::INT AS retailer_id \n",
    "        FROM SKU_DISCOUNTS sd,\n",
    "        LATERAL FLATTEN(\n",
    "            input => SPLIT(\n",
    "                REPLACE(REPLACE(REPLACE(sd.retailer_ids, '{{', ''), '}}', ''), '\"', ''), \n",
    "                ','\n",
    "            )\n",
    "        ) f\n",
    "        WHERE start_at::DATE <> CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "            AND end_at::DATE = CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "    ) x \n",
    "    JOIN SKU_DISCOUNT_VALUES sdv ON x.id = sdv.sku_discount_id\n",
    "    WHERE name_en = 'Special Discounts'\n",
    "    QUALIFY MAX(start_at) OVER (PARTITION BY retailer_id, product_id, packing_unit_id) = start_at \n",
    ")\n",
    "\n",
    "SELECT \n",
    "    product_id, \n",
    "    warehouse_id,\n",
    "    AVG(DISCOUNT_PERCENTAGE) AS active_sku_disc_pct \n",
    "FROM (\n",
    "    SELECT \n",
    "        asd.*,\n",
    "        warehouse_id \n",
    "    FROM active_sku_discount asd \n",
    "    JOIN materialized_views.retailer_polygon rp ON rp.retailer_id = asd.retailer_id\n",
    "    JOIN WAREHOUSE_DISPATCHING_RULES wdr ON wdr.product_id = asd.product_id\n",
    "    JOIN DISPATCHING_POLYGONS dp ON dp.id = wdr.DISPATCHING_POLYGON_ID AND dp.district_id = rp.district_id\n",
    ")\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "# Execute active SKU discount query\n",
    "print(\"Loading active SKU discount data...\")\n",
    "df_active_sku_disc = query_snowflake(ACTIVE_SKU_DISCOUNT_QUERY)\n",
    "df_active_sku_disc = convert_to_numeric(df_active_sku_disc)\n",
    "print(f\"Loaded {len(df_active_sku_disc)} active SKU discount records\")\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_active_sku_disc[['product_id', 'warehouse_id', 'active_sku_disc_pct']],\n",
    "    on=['product_id', 'warehouse_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN with 0 (no active SKU discount)\n",
    "pricing_with_discount['active_sku_disc_pct'] = pricing_with_discount['active_sku_disc_pct'].fillna(0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ACTIVE SKU DISCOUNT ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Records with active SKU discount: {len(pricing_with_discount[pricing_with_discount['active_sku_disc_pct'] > 0])}\")\n",
    "print(f\"Records without active SKU discount: {len(pricing_with_discount[pricing_with_discount['active_sku_disc_pct'] == 0])}\")\n",
    "print(f\"\\nActive SKU discount distribution:\")\n",
    "print(pricing_with_discount[pricing_with_discount['active_sku_disc_pct'] > 0]['active_sku_disc_pct'].describe())\n",
    "print(f\"\\nSample data with active SKU discounts:\")\n",
    "pricing_with_discount[pricing_with_discount['active_sku_disc_pct'] > 0][\n",
    "    ['product_id', 'warehouse_id', 'sku', 'current_price', 'active_sku_disc_pct', 'discount_perc']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pricing_with_discount[(pricing_with_discount['no_nmv_4m']==0)|(pricing_with_discount['stocks']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel('pricing_with_discount.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
