{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction Module for Pricing & Offers System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/snowflake/connector/options.py:104: UserWarning: You have an incompatible version of 'pyarrow' installed (22.0.0), please install a version that adheres to: 'pyarrow<19.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import snowflake.connector\n",
    "import setup_environment_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region\n",
    "REGION = \"Egypt\"\n",
    "\n",
    "# Snowflake Warehouse\n",
    "WAREHOUSE = \"COMPUTE_WH\"\n",
    "\n",
    "# Date Variables\n",
    "from datetime import datetime, timedelta\n",
    "TODAY = datetime.now().date()\n",
    "YESTERDAY = TODAY - timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    }
   ],
   "source": [
    "setup_environment_2.initialize_env()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warehouse & Cohort Mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warehouse Mapping: (region, warehouse_name, warehouse_id, cohort_id)\n",
    "WAREHOUSE_MAPPING = [\n",
    "    ('Cairo', 'Mostorod', 1, 700),\n",
    "    ('Giza', 'Barageel', 236, 701),\n",
    "    ('Giza', 'Sakkarah', 962, 701),\n",
    "    ('Delta West', 'El-Mahala', 337, 703),\n",
    "    ('Delta West', 'Tanta', 8, 703),\n",
    "    ('Delta East', 'Mansoura FC', 339, 704),\n",
    "    ('Delta East', 'Sharqya', 170, 704),\n",
    "    ('Upper Egypt', 'Assiut FC', 501, 1124),\n",
    "    ('Upper Egypt', 'Bani sweif', 401, 1126),\n",
    "    ('Upper Egypt', 'Menya Samalot', 703, 1123),\n",
    "    ('Upper Egypt', 'Sohag', 632, 1125),\n",
    "    ('Alexandria', 'Khorshed Alex', 797, 702),\n",
    "]\n",
    "\n",
    "# Region to Cohort Mapping\n",
    "REGION_COHORT_MAPPING = {\n",
    "    'Cairo': 700,\n",
    "    'Giza': 701,\n",
    "    'Delta West': 703,\n",
    "    'Delta East': 704,\n",
    "    'Upper Egypt': 1124,\n",
    "    'Alexandria': 702,\n",
    "}\n",
    "\n",
    "# All Cohort IDs\n",
    "COHORT_IDS = [700, 701, 702, 703, 704, 1123, 1124, 1125, 1126]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snowflake Query Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_snowflake(query):\n",
    "    \"\"\"Execute a query on Snowflake and return results as DataFrame.\"\"\"\n",
    "    con = snowflake.connector.connect(\n",
    "        user=os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database=os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        data = cur.fetchall()\n",
    "        columns = [desc[0].lower() for desc in cur.description]  # Get column names from cursor\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "    except Exception as e:\n",
    "        print(f\"Snowflake Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_snowflake_timezone():\n",
    "    \"\"\"Get the current timezone from Snowflake.\"\"\"\n",
    "    query = \"SHOW PARAMETERS LIKE 'TIMEZONE'\"\n",
    "    result = query_snowflake(query)\n",
    "    return result.value[0] if len(result) > 0 else \"UTC\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_warehouse_df():\n",
    "    \"\"\"Get warehouse mapping as DataFrame.\"\"\"\n",
    "    return pd.DataFrame(\n",
    "        WAREHOUSE_MAPPING,\n",
    "        columns=['region', 'warehouse', 'warehouse_id', 'cohort_id']\n",
    "    )\n",
    "\n",
    "\n",
    "def get_cohort_by_region(region):\n",
    "    \"\"\"Get cohort ID for a given region.\"\"\"\n",
    "    return REGION_COHORT_MAPPING.get(region)\n",
    "\n",
    "\n",
    "def convert_to_numeric(df):\n",
    "    \"\"\"Convert DataFrame columns to numeric where possible.\"\"\"\n",
    "    df.columns = df.columns.str.lower()\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Snowflake Timezone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snowflake timezone: America/Los_Angeles\n"
     ]
    }
   ],
   "source": [
    "TIMEZONE = get_snowflake_timezone()\n",
    "print(f\"Snowflake timezone: {TIMEZONE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Prices Extraction Queries\n",
    "Queries for external market price data:\n",
    "1. **Ben Soliman Prices** - Competitor reference prices\n",
    "2. **Marketplace Prices** - Min, Max, Mod prices from marketplace\n",
    "3. **Scrapped Data** - Competitor prices from scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. BEN SOLIMAN PRICES QUERY\n",
    "# =============================================================================\n",
    "BEN_SOLIMAN_QUERY = f'''\n",
    "WITH lower as (\n",
    "    select distinct product_id, sku, new_d*bs_price as ben_soliman_price, INJECTION_DATE\n",
    "    from (\n",
    "        select maxab_product_id as product_id, maxab_sku as sku, INJECTION_DATE, wac1, wac_p,\n",
    "            (bs_price/bs_unit_count) as bs_price, diff, cu_price,\n",
    "            case when p1 > 1 then child_quantity else 0 end as scheck,\n",
    "            round(p1/2)*2 as p1, p2,\n",
    "            case when (ROUND(p1 / scheck) * scheck) = 0 then p1 else (ROUND(p1 / scheck) * scheck) end as new_d\n",
    "        from (\n",
    "            select sm.*, wac1, wac_p, \n",
    "                abs((bs_price/bs_unit_count)-(wac_p*maxab_basic_unit_count))/(wac_p*maxab_basic_unit_count) as diff,\n",
    "                cpc.price as cu_price, pup.child_quantity,\n",
    "                round((cu_price/(bs_price/bs_unit_count))) as p1, \n",
    "                round(((bs_price/bs_unit_count)/cu_price)) as p2\n",
    "            from materialized_views.savvy_mapping sm \n",
    "            join finance.all_cogs f on f.product_id = sm.maxab_product_id \n",
    "                and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "            join PACKING_UNIT_PRODUCTS pu on pu.product_id = sm.maxab_product_id and pu.IS_BASIC_UNIT = 1 \n",
    "            join cohort_product_packing_units cpc on cpc.PRODUCT_PACKING_UNIT_ID = pu.id and cohort_id = 700 \n",
    "            join packing_unit_products pup on pup.product_id = sm.maxab_product_id and pup.is_basic_unit = 1  \n",
    "            where bs_price is not null \n",
    "                and INJECTION_DATE::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 5 \n",
    "                and diff > 0.3 and p1 > 1\n",
    "        )\n",
    "    )\n",
    "    qualify max(INJECTION_DATE) over(partition by product_id) = INJECTION_DATE\n",
    "),\n",
    "\n",
    "m_bs as (\n",
    "    select z.* from (\n",
    "        select maxab_product_id as product_id, maxab_sku as sku, avg(bs_final_price) as ben_soliman_price, INJECTION_DATE\n",
    "        from (\n",
    "            select *, row_number() over(partition by maxab_product_id order by diff) as rnk_2 \n",
    "            from (\n",
    "                select *, (bs_final_price-wac_p)/wac_p as diff_2 \n",
    "                from (\n",
    "                    select *, bs_price/maxab_basic_unit_count as bs_final_price \n",
    "                    from (\n",
    "                        select *, row_number() over(partition by maxab_product_id, maxab_pu order by diff) as rnk \n",
    "                        from (\n",
    "                            select *, max(INJECTION_DATE::date) over(partition by maxab_product_id, maxab_pu) as max_date\n",
    "                            from (\n",
    "                                select sm.*, wac1, wac_p, \n",
    "                                    abs(bs_price-(wac_p*maxab_basic_unit_count))/(wac_p*maxab_basic_unit_count) as diff \n",
    "                                from materialized_views.savvy_mapping sm \n",
    "                                join finance.all_cogs f on f.product_id = sm.maxab_product_id \n",
    "                                    and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "                                where bs_price is not null \n",
    "                                    and INJECTION_DATE::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 5 \n",
    "                                    and diff < 0.3\n",
    "                            )\n",
    "                            qualify max_date = INJECTION_DATE\n",
    "                        ) qualify rnk = 1 \n",
    "                    )\n",
    "                ) where diff_2 between -0.5 and 0.5 \n",
    "            ) qualify rnk_2 = 1 \n",
    "        ) group by all\n",
    "    ) z \n",
    "    join finance.all_cogs f on f.product_id = z.product_id \n",
    "        and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_Date and f.to_date\n",
    "    where ben_soliman_price between f.wac_p*0.8 and f.wac_p*1.3\n",
    ")\n",
    "\n",
    "select product_id, avg(ben_soliman_price) as ben_soliman_price\n",
    "from (\n",
    "    select * from (\n",
    "        select * from m_bs \n",
    "        union all\n",
    "        select * from lower\n",
    "    )\n",
    "    qualify max(INJECTION_DATE) over(partition by product_id) = INJECTION_DATE\n",
    ")\n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. MARKETPLACE PRICES QUERY (with region fallback)\n",
    "# =============================================================================\n",
    "MARKETPLACE_PRICES_QUERY = f'''\n",
    "WITH MP as (\n",
    "    select region, product_id,\n",
    "        min(min_price) as min_price, min(max_price) as max_price,\n",
    "        min(mod_price) as mod_price, min(true_min) as true_min, min(true_max) as true_max\n",
    "    from (\n",
    "        select mp.region, mp.product_id, mp.pu_id,\n",
    "            min_price/BASIC_UNIT_COUNT as min_price,\n",
    "            max_price/BASIC_UNIT_COUNT as max_price,\n",
    "            mod_price/BASIC_UNIT_COUNT as mod_price,\n",
    "            TRUE_MIN_PRICE/BASIC_UNIT_COUNT as true_min,\n",
    "            TRUE_MAX_PRICE/BASIC_UNIT_COUNT as true_max\n",
    "        from materialized_views.marketplace_prices mp \n",
    "        join packing_unit_products pup on pup.product_id = mp.product_id and pup.packing_unit_id = mp.pu_id\n",
    "        join finance.all_cogs f on f.product_id = mp.product_id \n",
    "            and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_date and f.to_date\n",
    "        where least(min_price, mod_price) between wac_p*0.9 and wac_p*1.3 \n",
    "    )\n",
    "    group by all \n",
    "),\n",
    "\n",
    "region_mapping AS (\n",
    "    SELECT * FROM (VALUES\n",
    "        ('Delta East', 'Delta West'), ('Delta West', 'Delta East'),\n",
    "        ('Alexandria', 'Cairo'), ('Alexandria', 'Giza'),\n",
    "        ('Upper Egypt', 'Cairo'), ('Upper Egypt', 'Giza'),\n",
    "        ('Cairo', 'Giza'), ('Giza', 'Cairo'),\n",
    "        ('Delta West', 'Cairo'), ('Delta East', 'Cairo'),\n",
    "        ('Delta West', 'Giza'), ('Delta East', 'Giza')\n",
    "    ) AS region_mapping(region, fallback_region)\n",
    "),\n",
    "\n",
    "all_regions as (\n",
    "    SELECT * FROM (VALUES\n",
    "        ('Cairo'), ('Giza'), ('Delta West'), ('Delta East'), ('Upper Egypt'), ('Alexandria')\n",
    "    ) AS x(region)\n",
    "),\n",
    "\n",
    "full_data as (\n",
    "    select products.id as product_id, ar.region\n",
    "    from products, all_regions ar\n",
    "    where activation = 'true'\n",
    ")\n",
    "\n",
    "select region, product_id,\n",
    "    min(final_min_price) as final_min_price, \n",
    "    min(final_max_price) as final_max_price,\n",
    "    min(final_mod_price) as final_mod_price, \n",
    "    min(final_true_min) as final_true_min,\n",
    "    min(final_true_max) as final_true_max\n",
    "from (\n",
    "    SELECT distinct w.region, w.product_id,\n",
    "        COALESCE(m1.min_price, m2.min_price) AS final_min_price,\n",
    "        COALESCE(m1.max_price, m2.max_price) AS final_max_price,\n",
    "        COALESCE(m1.mod_price, m2.mod_price) AS final_mod_price,\n",
    "        COALESCE(m1.true_min, m2.true_min) AS final_true_min,\n",
    "        COALESCE(m1.true_max, m2.true_max) AS final_true_max\n",
    "    FROM full_data w\n",
    "    LEFT JOIN MP m1 ON w.region = m1.region and w.product_id = m1.product_id\n",
    "    LEFT JOIN region_mapping rm ON w.region = rm.region\n",
    "    LEFT JOIN MP m2 ON rm.fallback_region = m2.region AND w.product_id = m2.product_id\n",
    ")\n",
    "where final_min_price is not null \n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. SCRAPPED DATA QUERY (Competitor prices from scraping)\n",
    "# =============================================================================\n",
    "SCRAPPED_DATA_QUERY = f'''\n",
    "select product_id, region,\n",
    "    MIN(market_price) AS min_scrapped,\n",
    "    PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY market_price) AS scrapped25,\n",
    "    PERCENTILE_CONT(0.50) WITHIN GROUP (ORDER BY market_price) AS scrapped50,\n",
    "    PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY market_price) AS scrapped75,\n",
    "    MAX(market_price) AS max_scrapped\n",
    "from (\n",
    "    select distinct cmp.*, max(date) over(partition by region, cmp.product_id, competitor) as max_date\n",
    "    from MATERIALIZED_VIEWS.CLEANED_MARKET_PRICES cmp\n",
    "    join finance.all_cogs f on f.product_id = cmp.product_id \n",
    "        and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) between f.from_date and f.to_date \n",
    "    where date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 7 \n",
    "        and MARKET_PRICE between f.wac_p * 0.8 and wac_p * 1.3\n",
    "    qualify date = max_date \n",
    ")\n",
    "group by all\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Additional Data Queries (Sales, Groups, WAC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. PRODUCT BASE DATA QUERY (product_id, sku, brand, cat, wac1, wac_p, current_price)\n",
    "# =============================================================================\n",
    "PRODUCT_BASE_QUERY = f'''\n",
    "WITH skus_prices AS (\n",
    "    WITH local_prices AS (\n",
    "        SELECT  \n",
    "            CASE \n",
    "                WHEN cpu.cohort_id IN (700, 695) THEN 'Cairo'\n",
    "                WHEN cpu.cohort_id IN (701) THEN 'Giza'\n",
    "                WHEN cpu.cohort_id IN (704, 698) THEN 'Delta East'\n",
    "                WHEN cpu.cohort_id IN (703, 697) THEN 'Delta West'\n",
    "                WHEN cpu.cohort_id IN (696, 1123, 1124, 1125, 1126) THEN 'Upper Egypt'\n",
    "                WHEN cpu.cohort_id IN (702, 699) THEN 'Alexandria'\n",
    "            END AS region,\n",
    "            cohort_id,\n",
    "            pu.product_id,\n",
    "            pu.packing_unit_id,\n",
    "            pu.basic_unit_count,\n",
    "            AVG(cpu.price) AS price\n",
    "        FROM cohort_product_packing_units cpu\n",
    "        JOIN PACKING_UNIT_PRODUCTS pu ON pu.id = cpu.product_packing_unit_id\n",
    "        WHERE cpu.cohort_id IN (700,701,702,703,704,695,696,697,698,699,1123,1124,1125,1126)\n",
    "            AND cpu.created_at::date <> '2023-07-31'\n",
    "            AND cpu.is_customized = TRUE\n",
    "        GROUP BY ALL\n",
    "    ),\n",
    "    \n",
    "    live_prices AS (\n",
    "        SELECT \n",
    "            region, cohort_id, product_id, \n",
    "            pu_id AS packing_unit_id, \n",
    "            buc AS basic_unit_count, \n",
    "            NEW_PRICE AS price\n",
    "        FROM materialized_views.DBDP_PRICES\n",
    "        WHERE created_at = CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date\n",
    "            AND DATE_PART('hour', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::time) \n",
    "                BETWEEN SPLIT_PART(time_slot, '-', 1)::int AND (SPLIT_PART(time_slot, '-', 1)::int) + 1\n",
    "            AND cohort_id IN (700,701,702,703,704,695,696,697,698,699,1123,1124,1125,1126)\n",
    "    ),\n",
    "    \n",
    "    prices AS (\n",
    "        SELECT *\n",
    "        FROM (\n",
    "            SELECT *, 1 AS priority FROM live_prices\n",
    "            UNION ALL\n",
    "            SELECT *, 2 AS priority FROM local_prices\n",
    "        )\n",
    "        QUALIFY ROW_NUMBER() OVER (PARTITION BY region, cohort_id, product_id, packing_unit_id ORDER BY priority) = 1\n",
    "    )\n",
    "    \n",
    "    SELECT region, cohort_id, product_id, price\n",
    "    FROM prices\n",
    "    WHERE basic_unit_count = 1\n",
    "        AND ((product_id = 1309 AND packing_unit_id = 2) OR (product_id <> 1309))\n",
    ")\n",
    "\n",
    "SELECT distinct\n",
    "    region, cohort_id, p.product_id,\n",
    "    CONCAT(products.name_ar, ' ', products.size, ' ', product_units.name_ar) AS sku,\n",
    "    b.name_ar AS brand,\n",
    "    cat.name_ar AS cat,\n",
    "    wac1, wac_p, p.price as current_price\n",
    "FROM skus_prices p\n",
    "JOIN finance.all_cogs c ON c.product_id = p.product_id \n",
    "    AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) BETWEEN c.from_date AND c.to_date\n",
    "JOIN products ON products.id = p.product_id\n",
    "JOIN categories cat ON cat.id = products.category_id\n",
    "JOIN brands b ON b.id = products.brand_id\n",
    "JOIN product_units ON product_units.id = products.unit_id\n",
    "WHERE wac1 > 0 AND wac_p > 0\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 5. SALES DATA QUERY (120-day NMV by cohort/product)\n",
    "# =============================================================================\n",
    "SALES_QUERY = f'''\n",
    "SELECT DISTINCT cpc.cohort_id, pso.product_id,\n",
    "    CONCAT(products.name_ar,' ',products.size,' ',product_units.name_ar) as sku,\n",
    "    brands.name_ar as brand, categories.name_ar as cat,\n",
    "    sum(pso.total_price) as nmv\n",
    "FROM product_sales_order pso\n",
    "JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "JOIN COHORT_PRICING_CHANGES cpc ON cpc.id = pso.COHORT_PRICING_CHANGE_id\n",
    "JOIN products ON products.id = pso.product_id\n",
    "JOIN brands ON products.brand_id = brands.id \n",
    "JOIN categories ON products.category_id = categories.id\n",
    "JOIN product_units ON product_units.id = products.unit_id \n",
    "WHERE so.created_at::date BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 120 \n",
    "    AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 1 \n",
    "    AND so.sales_order_status_id NOT IN (7, 12)\n",
    "    AND so.channel IN ('telesales', 'retailer')\n",
    "    AND pso.purchased_item_count <> 0\n",
    "    AND cpc.cohort_id IN (700,701,702,703,704,1123,1124,1125,1126)\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 6. MARGIN STATS QUERY (STD and average margins)  \n",
    "# =============================================================================\n",
    "MARGIN_STATS_QUERY = f'''\n",
    "select product_id, cohort_id, \n",
    "    (0.6*product_std) + (0.3*brand_std) + (0.1*cat_std) as std, \n",
    "    avg_margin\n",
    "from (\n",
    "    select product_id, cohort_id, \n",
    "        stddev(product_margin) as product_std, \n",
    "        stddev(brand_margin) as brand_std,\n",
    "        stddev(cat_margin) as cat_std, \n",
    "        avg(product_margin) as avg_margin\n",
    "    from (\n",
    "        select distinct product_id, order_date, cohort_id,\n",
    "            (nmv-cogs_p)/nmv as product_margin, \n",
    "            (brand_nmv-brand_cogs)/brand_nmv as brand_margin,\n",
    "            (cat_nmv-cat_cogs)/cat_nmv as cat_margin\n",
    "        from (\n",
    "            SELECT DISTINCT so.created_at::date as order_date, cpc.cohort_id, pso.product_id,\n",
    "                brands.name_ar as brand, categories.name_ar as cat,\n",
    "                sum(COALESCE(f.wac_p,0) * pso.purchased_item_count * pso.basic_unit_count) as cogs_p,\n",
    "                sum(pso.total_price) as nmv,\n",
    "                sum(nmv) over(partition by order_date, cat, brand) as brand_nmv,\n",
    "                sum(cogs_p) over(partition by order_date, cat, brand) as brand_cogs,\n",
    "                sum(nmv) over(partition by order_date, cat) as cat_nmv,\n",
    "                sum(cogs_p) over(partition by order_date, cat) as cat_cogs\n",
    "            FROM product_sales_order pso\n",
    "            JOIN sales_orders so ON so.id = pso.sales_order_id   \n",
    "            JOIN COHORT_PRICING_CHANGES cpc on cpc.id = pso.cohort_pricing_change_id\n",
    "            JOIN products on products.id = pso.product_id\n",
    "            JOIN brands on products.brand_id = brands.id \n",
    "            JOIN categories ON products.category_id = categories.id\n",
    "            JOIN finance.all_cogs f ON f.product_id = pso.product_id\n",
    "                AND f.from_date::date <= so.created_at::date AND f.to_date::date > so.created_at::date\n",
    "            WHERE so.created_at::date between \n",
    "                date_trunc('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - 120) \n",
    "                and CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date\n",
    "                AND so.sales_order_status_id not in (7,12)\n",
    "                AND so.channel IN ('telesales','retailer')\n",
    "                AND pso.purchased_item_count <> 0\n",
    "            GROUP BY ALL\n",
    "        )\n",
    "    ) group by all \n",
    ")\n",
    "'''\n",
    "\n",
    "# =============================================================================\n",
    "# 7. TARGET MARGINS QUERY\n",
    "# =============================================================================\n",
    "TARGET_MARGINS_QUERY = f'''\n",
    "WITH cat_brand_target as (\n",
    "    SELECT DISTINCT cat, brand, margin as target_bm\n",
    "    FROM performance.commercial_targets cplan\n",
    "    QUALIFY CASE \n",
    "        WHEN DATE_TRUNC('month', MAX(DATE) OVER()) = DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date) \n",
    "        THEN DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date)\n",
    "        ELSE DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - INTERVAL '1 month') \n",
    "    END = DATE_TRUNC('month', date)\n",
    "),\n",
    "cat_target as (\n",
    "    select cat, sum(target_bm * (target_nmv/cat_total)) as cat_target_margin\n",
    "    from (\n",
    "        select *, sum(target_nmv) over(partition by cat) as cat_total\n",
    "        from (\n",
    "            select cat, brand, avg(target_bm) as target_bm, sum(target_nmv) as target_nmv\n",
    "            from (\n",
    "                SELECT DISTINCT date, city as region, cat, brand, margin as target_bm, nmv as target_nmv\n",
    "                FROM performance.commercial_targets cplan\n",
    "                QUALIFY CASE \n",
    "                    WHEN DATE_TRUNC('month', MAX(DATE) OVER()) = DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date) \n",
    "                    THEN DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date)\n",
    "                    ELSE DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::date - INTERVAL '1 month') \n",
    "                END = DATE_TRUNC('month', date)\n",
    "            ) group by all\n",
    "        )\n",
    "    ) group by all \n",
    ")\n",
    "SELECT DISTINCT cbt.cat, cbt.brand, cbt.target_bm, ct.cat_target_margin\n",
    "FROM cat_brand_target cbt\n",
    "LEFT JOIN cat_target ct ON ct.cat = cbt.cat\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Execute All Queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Snowflake...\n",
      "  1. Loading Ben Soliman prices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 1549 Ben Soliman price records\n",
      "  2. Loading marketplace prices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 11209 marketplace price records\n",
      "  3. Loading scrapped data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 5159 scrapped price records\n",
      "  4. Loading product base data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 101994 product base records\n",
      "  5. Loading sales data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 20671 sales records\n",
      "  6. Loading margin stats...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 28930 margin stat records\n",
      "  7. Loading target margins...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Loaded 478 target margin records\n",
      "  8. Loading product groups...\n",
      "     Loaded 1649 group records\n",
      "\n",
      "All queries completed!\n",
      "\n",
      "============================================================\n",
      "df_product_base DataFrame available with columns:\n",
      "  - region, cohort_id, product_id, sku, brand, cat, wac1, wac_p, current_price\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Execute all queries\n",
    "# =============================================================================\n",
    "print(\"Loading data from Snowflake...\")\n",
    "\n",
    "# 1. Ben Soliman Prices\n",
    "print(\"  1. Loading Ben Soliman prices...\")\n",
    "df_ben_soliman = query_snowflake(BEN_SOLIMAN_QUERY)\n",
    "df_ben_soliman = convert_to_numeric(df_ben_soliman)\n",
    "print(f\"     Loaded {len(df_ben_soliman)} Ben Soliman price records\")\n",
    "\n",
    "# 2. Marketplace Prices\n",
    "print(\"  2. Loading marketplace prices...\")\n",
    "df_marketplace = query_snowflake(MARKETPLACE_PRICES_QUERY)\n",
    "df_marketplace = convert_to_numeric(df_marketplace)\n",
    "print(f\"     Loaded {len(df_marketplace)} marketplace price records\")\n",
    "\n",
    "# 3. Scrapped Data\n",
    "print(\"  3. Loading scrapped data...\")\n",
    "df_scrapped = query_snowflake(SCRAPPED_DATA_QUERY)\n",
    "df_scrapped = convert_to_numeric(df_scrapped)\n",
    "print(f\"     Loaded {len(df_scrapped)} scrapped price records\")\n",
    "\n",
    "# 4. Product Base Data (product_id, sku, brand, cat, wac1, wac_p, current_price)\n",
    "print(\"  4. Loading product base data...\")\n",
    "df_product_base = query_snowflake(PRODUCT_BASE_QUERY)\n",
    "df_product_base = convert_to_numeric(df_product_base)\n",
    "print(f\"     Loaded {len(df_product_base)} product base records\")\n",
    "\n",
    "# 5. Sales Data\n",
    "print(\"  5. Loading sales data...\")\n",
    "df_sales = query_snowflake(SALES_QUERY)\n",
    "df_sales = convert_to_numeric(df_sales)\n",
    "print(f\"     Loaded {len(df_sales)} sales records\")\n",
    "\n",
    "# 6. Margin Stats\n",
    "print(\"  6. Loading margin stats...\")\n",
    "df_margin_stats = query_snowflake(MARGIN_STATS_QUERY)\n",
    "df_margin_stats = convert_to_numeric(df_margin_stats)\n",
    "print(f\"     Loaded {len(df_margin_stats)} margin stat records\")\n",
    "\n",
    "# 7. Target Margins\n",
    "print(\"  7. Loading target margins...\")\n",
    "df_targets = query_snowflake(TARGET_MARGINS_QUERY)\n",
    "df_targets = convert_to_numeric(df_targets)\n",
    "print(f\"     Loaded {len(df_targets)} target margin records\")\n",
    "\n",
    "# 8. Product Groups (from PostgreSQL)\n",
    "print(\"  8. Loading product groups...\")\n",
    "df_groups = query_snowflake(\n",
    "    '''SELECT * FROM materialized_views.sku_commercial_groups'''\n",
    ")\n",
    "df_groups.columns = df_groups.columns.str.lower()\n",
    "df_groups = convert_to_numeric(df_groups)\n",
    "print(f\"     Loaded {len(df_groups)} group records\")\n",
    "\n",
    "print(\"\\nAll queries completed!\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"df_product_base DataFrame available with columns:\")\n",
    "print(\"  - region, cohort_id, product_id, sku, brand, cat, wac1, wac_p, current_price\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building market_data DataFrame (market prices only)...\n",
      "  Step 1: Joining all market price sources (outer join)...\n",
      "     Market prices base: 16030 records\n",
      "  Step 2: Adding cohort IDs and supporting data for processing...\n",
      "\n",
      "============================================================\n",
      "MARKET DATA BASE READY FOR PROCESSING\n",
      "============================================================\n",
      "Total records: 23674\n",
      "  - With marketplace prices: 16462\n",
      "  - With scrapped prices: 7661\n",
      "  - With Ben Soliman prices: 13941\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PART A: Build market_data DataFrame - Process market prices SEPARATELY\n",
    "# =============================================================================\n",
    "print(\"Building market_data DataFrame (market prices only)...\")\n",
    "\n",
    "# Create region-cohort mapping\n",
    "REGION_COHORT_DF = pd.DataFrame({\n",
    "    'region': ['Cairo', 'Giza', 'Delta West', 'Delta East', \n",
    "               'Upper Egypt', 'Upper Egypt', 'Upper Egypt', 'Upper Egypt', 'Alexandria'],\n",
    "    'cohort_id': [700, 701, 703, 704, 1124, 1126, 1123, 1125, 702]\n",
    "})\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Outer join all market price sources\n",
    "# =============================================================================\n",
    "print(\"  Step 1: Joining all market price sources (outer join)...\")\n",
    "\n",
    "# Start with marketplace prices (has region + product_id)\n",
    "market_data = df_marketplace.copy()\n",
    "\n",
    "# Outer join with scrapped data (by region + product_id)\n",
    "market_data = market_data.merge(df_scrapped, on=['region', 'product_id'], how='outer')\n",
    "\n",
    "# Outer join with Ben Soliman prices (by product_id only - expand to all regions)\n",
    "all_regions = pd.DataFrame({'region': ['Cairo', 'Giza', 'Delta West', 'Delta East', 'Upper Egypt', 'Alexandria']})\n",
    "df_ben_soliman_expanded = df_ben_soliman.merge(all_regions, how='cross')\n",
    "\n",
    "# Outer join with Ben Soliman\n",
    "market_data = market_data.merge(df_ben_soliman_expanded, on=['region', 'product_id'], how='outer')\n",
    "\n",
    "print(f\"     Market prices base: {len(market_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Add cohort_id and supporting data for market processing\n",
    "# =============================================================================\n",
    "print(\"  Step 2: Adding cohort IDs and supporting data for processing...\")\n",
    "market_data = market_data.merge(REGION_COHORT_DF, on='region')\n",
    "\n",
    "# Need sales data for group processing (weighted median)\n",
    "market_data = market_data.merge(\n",
    "    df_sales[['cohort_id', 'product_id', 'nmv']], \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "market_data['nmv'] = market_data['nmv'].fillna(0)\n",
    "\n",
    "# Need margin stats for price analysis\n",
    "market_data = market_data.merge(df_margin_stats, on=['cohort_id', 'product_id'], how='left')\n",
    "\n",
    "# Need WAC for price analysis - get from product base\n",
    "market_data = market_data.merge(\n",
    "    df_product_base[['cohort_id', 'product_id', 'wac_p', 'brand', 'cat']].drop_duplicates(), \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Need target margins for price analysis\n",
    "market_data = market_data.merge(df_targets, on=['brand', 'cat'], how='left')\n",
    "market_data['target_margin'] = market_data['target_bm'].fillna(market_data['cat_target_margin']).fillna(0)\n",
    "market_data = market_data.drop(columns=['target_bm', 'cat_target_margin'], errors='ignore')\n",
    "\n",
    "# Fill NaN values with defaults\n",
    "market_data['std'] = market_data['std'].fillna(0.01)\n",
    "market_data['avg_margin'] = market_data['avg_margin'].fillna(0)\n",
    "\n",
    "# Merge product groups for group processing\n",
    "market_data = market_data.merge(df_groups, on='product_id', how='left')\n",
    "\n",
    "# Remove duplicates\n",
    "market_data = market_data.drop_duplicates(subset=['cohort_id', 'product_id'])\n",
    "\n",
    "# Filter out records without WAC (can't process prices without cost)\n",
    "market_data = market_data[~market_data['wac_p'].isna()]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MARKET DATA BASE READY FOR PROCESSING\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(market_data)}\")\n",
    "print(f\"  - With marketplace prices: {len(market_data[~market_data['final_min_price'].isna()])}\")\n",
    "print(f\"  - With scrapped prices: {len(market_data[~market_data['min_scrapped'].isna()])}\")\n",
    "print(f\"  - With Ben Soliman prices: {len(market_data[~market_data['ben_soliman_price'].isna()])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART A: Market Data Processing\n",
    "Process market prices separately (group fill, coverage filter, price analysis, margin tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after group processing: 23674 records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/2426940637.py:32: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Group Processing - Calculate group-level aggregated prices (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate group-level aggregated prices for products with group assignments\n",
    "groups_data = market_data[~market_data['group_id'].isna()].copy()\n",
    "groups_data['group_nmv'] = groups_data.groupby(['group_id', 'cohort_id'])['nmv'].transform('sum')\n",
    "groups_data['cntrb'] = (groups_data['nmv'] / groups_data['group_nmv']).fillna(1)\n",
    "\n",
    "# Flag if any price/scrapped column is non-NaN\n",
    "price_cols = [\n",
    "    'ben_soliman_price', 'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped'\n",
    "]\n",
    "groups_data['flag_non_nan'] = groups_data[price_cols].notna().any(axis=1).astype(int)\n",
    "\n",
    "# Weighted Median Function\n",
    "def weighted_median(series, weights):\n",
    "    valid = ~series.isna() & ~weights.isna()\n",
    "    s = series[valid]\n",
    "    w = weights[valid]\n",
    "    if len(s) == 0:\n",
    "        return np.nan\n",
    "    order = np.argsort(s)\n",
    "    s, w = s.iloc[order], w.iloc[order]\n",
    "    return s.iloc[np.searchsorted(np.cumsum(w), w.sum() / 2)]\n",
    "\n",
    "# Perform Weighted Aggregation\n",
    "groups_agg = (\n",
    "    groups_data[groups_data['flag_non_nan'] == 1]\n",
    "    .groupby(['group_id', 'cohort_id'])\n",
    "    .apply(lambda g: pd.Series({\n",
    "        col: weighted_median(g[col], g['cntrb']) for col in price_cols\n",
    "    }))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Fill missing prices with group-level prices\n",
    "merged = market_data.merge(groups_agg, on=['group_id', 'cohort_id'], how='left', suffixes=('', '_group'))\n",
    "for col in price_cols:\n",
    "    merged[col] = merged[col].fillna(merged[f'{col}_group'])\n",
    "\n",
    "market_data = merged.drop(columns=[f'{c}_group' for c in price_cols])\n",
    "\n",
    "print(f\"Market data after group processing: {len(market_data)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Coverage Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after price coverage filtering: 13075 records\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Price Coverage Filtering - Filter products with sufficient price data (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Score price coverage\n",
    "market_data['ben'] = 0\n",
    "market_data['MP'] = 0\n",
    "market_data['sp'] = 0\n",
    "\n",
    "# Ben Soliman: 1 point if present\n",
    "market_data.loc[~market_data['ben_soliman_price'].isna(), 'ben'] = 1\n",
    "\n",
    "# Marketplace: 1 point if single price, 3 points if range\n",
    "market_data.loc[(market_data['final_min_price'] == market_data['final_max_price']) & \n",
    "                (~market_data['final_min_price'].isna()), 'MP'] = 1\n",
    "market_data.loc[(market_data['final_min_price'] != market_data['final_max_price']) & \n",
    "                (~market_data['final_min_price'].isna()), 'MP'] = 3\n",
    "\n",
    "# Scrapped: 1 point if single price, 5 points if range\n",
    "market_data.loc[(market_data['min_scrapped'] == market_data['max_scrapped']) & \n",
    "                (~market_data['min_scrapped'].isna()), 'sp'] = 1\n",
    "market_data.loc[(market_data['min_scrapped'] != market_data['max_scrapped']) & \n",
    "                (~market_data['min_scrapped'].isna()), 'sp'] = 5\n",
    "\n",
    "# Total price coverage score\n",
    "market_data['total_p'] = market_data['ben'] + market_data['MP'] + market_data['sp']\n",
    "\n",
    "# Filter: keep only products with total_p > 2\n",
    "market_data = market_data[market_data['total_p'] > 2]\n",
    "\n",
    "print(f\"Market data after price coverage filtering: {len(market_data)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Analysis & Margin Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Price Analysis Functions\n",
    "# =============================================================================\n",
    "\n",
    "def price_analysis(row):\n",
    "    \"\"\"Analyze prices and calculate percentiles for a product.\"\"\"\n",
    "    wac = row['wac_p']\n",
    "    avg_margin = row['avg_margin'] if row['avg_margin'] >= 0.01 else row['target_margin']\n",
    "    std = np.maximum(row['std'], 0.0025)\n",
    "    target_margin = row['target_margin']\n",
    "    max_marg = np.maximum(avg_margin, target_margin)\n",
    "    \n",
    "    # Collect all price points\n",
    "    price_list = [\n",
    "        row['ben_soliman_price'], row['final_min_price'], row['final_mod_price'],\n",
    "        row['final_max_price'], row['final_true_min'], row['final_true_max'],\n",
    "        row['min_scrapped'], row['scrapped25'], row['scrapped50'], row['scrapped75'], row['max_scrapped']\n",
    "    ]\n",
    "    \n",
    "    # Filter valid prices within acceptable range\n",
    "    valid_prices = sorted({\n",
    "        x for x in price_list \n",
    "        if x and not pd.isna(x) and x != 0 \n",
    "        and wac / (1 - (avg_margin - (10 * std))) <= x <= wac / (1 - (max_marg + 10 * std))\n",
    "        and x >= wac * 0.9\n",
    "    })\n",
    "    \n",
    "    if not valid_prices:\n",
    "        return np.nan, np.nan, np.nan, np.nan, np.nan\n",
    "    \n",
    "    return (\n",
    "        np.min(valid_prices),\n",
    "        np.percentile(valid_prices, 25),\n",
    "        np.percentile(valid_prices, 50),\n",
    "        np.percentile(valid_prices, 75),\n",
    "        np.max(valid_prices)\n",
    "    )\n",
    "\n",
    "\n",
    "def calculate_step_bounds(row):\n",
    "    \"\"\"Calculate below/above market bounds based on price steps.\"\"\"\n",
    "    wac = row['wac_p']\n",
    "    std = row['std']\n",
    "    prices = [row['minimum'], row['percentile_25'], row['percentile_50'], row['percentile_75'], row['maximum']]\n",
    "    \n",
    "    # Calculate valid steps between price points\n",
    "    valid_steps = []\n",
    "    for i in range(len(prices) - 1):\n",
    "        step = prices[i + 1] - prices[i]\n",
    "        if (step / wac) <= std * 1.2:\n",
    "            valid_steps.append(step)\n",
    "    \n",
    "    avg_step = np.mean(valid_steps) if valid_steps else min(2 * std, 0.2 * row['target_margin'])\n",
    "    \n",
    "    new_min = prices[0] - avg_step if (prices[0] - avg_step) >= wac else prices[0]\n",
    "    new_max = prices[-1] + avg_step if (prices[-1] + avg_step) >= wac else prices[-1]\n",
    "    \n",
    "    return new_min, new_max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market data after price analysis: 12354 records\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Apply Price Analysis & Margin Calculation (on market_data)\n",
    "# =============================================================================\n",
    "\n",
    "# Apply price analysis to calculate price percentiles\n",
    "market_data[['minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum']] = \\\n",
    "    market_data.apply(price_analysis, axis=1, result_type='expand')\n",
    "\n",
    "# Filter out records without valid price analysis\n",
    "market_data = market_data[~market_data['minimum'].isna()]\n",
    "\n",
    "# Calculate below/above market bounds\n",
    "market_data[['below_market', 'above_market']] = market_data.apply(calculate_step_bounds, axis=1, result_type='expand')\n",
    "\n",
    "print(f\"Market data after price analysis: {len(market_data)} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MARKET DATA PROCESSING COMPLETE\n",
      "============================================================\n",
      "Total processed market records: 12354\n",
      "\n",
      "Market data columns:\n",
      "  - Price columns: ben_soliman_price, final_min_price, final_max_price, etc.\n",
      "  - Percentiles: minimum, percentile_25, percentile_50, percentile_75, maximum\n",
      "  - Margin tiers: below_market, market_min, market_25, market_50, market_75, market_max, above_market\n",
      "\n",
      "Sample processed market data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>ben_soliman_price</th>\n",
       "      <th>final_min_price</th>\n",
       "      <th>final_max_price</th>\n",
       "      <th>final_mod_price</th>\n",
       "      <th>final_true_min</th>\n",
       "      <th>final_true_max</th>\n",
       "      <th>min_scrapped</th>\n",
       "      <th>scrapped25</th>\n",
       "      <th>...</th>\n",
       "      <th>percentile_50</th>\n",
       "      <th>percentile_75</th>\n",
       "      <th>maximum</th>\n",
       "      <th>below_market</th>\n",
       "      <th>market_min</th>\n",
       "      <th>market_25</th>\n",
       "      <th>market_50</th>\n",
       "      <th>market_75</th>\n",
       "      <th>market_max</th>\n",
       "      <th>above_market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>702</td>\n",
       "      <td>3.0</td>\n",
       "      <td>253.5</td>\n",
       "      <td>255.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>254.630005</td>\n",
       "      <td>255.285004</td>\n",
       "      <td>...</td>\n",
       "      <td>255.142502</td>\n",
       "      <td>255.776253</td>\n",
       "      <td>279.0</td>\n",
       "      <td>0.034136</td>\n",
       "      <td>0.037027</td>\n",
       "      <td>0.041649</td>\n",
       "      <td>0.043226</td>\n",
       "      <td>0.045597</td>\n",
       "      <td>0.125041</td>\n",
       "      <td>0.127414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>702</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>831.4</td>\n",
       "      <td>848.4</td>\n",
       "      <td>829.0</td>\n",
       "      <td>829.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>839.900000</td>\n",
       "      <td>848.800000</td>\n",
       "      <td>850.0</td>\n",
       "      <td>0.005951</td>\n",
       "      <td>0.012246</td>\n",
       "      <td>0.014386</td>\n",
       "      <td>0.025065</td>\n",
       "      <td>0.035287</td>\n",
       "      <td>0.036649</td>\n",
       "      <td>0.042563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>702</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>290.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>288.000000</td>\n",
       "      <td>290.0</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.030653</td>\n",
       "      <td>0.058548</td>\n",
       "      <td>0.084882</td>\n",
       "      <td>0.091237</td>\n",
       "      <td>0.097505</td>\n",
       "      <td>0.103686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>702</td>\n",
       "      <td>14.0</td>\n",
       "      <td>465.0</td>\n",
       "      <td>461.5</td>\n",
       "      <td>477.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>477.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>463.250000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>477.0</td>\n",
       "      <td>0.022783</td>\n",
       "      <td>0.028448</td>\n",
       "      <td>0.030818</td>\n",
       "      <td>0.035264</td>\n",
       "      <td>0.045056</td>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.068282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>702</td>\n",
       "      <td>17.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>631.4</td>\n",
       "      <td>595.0</td>\n",
       "      <td>595.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>607.250000</td>\n",
       "      <td>626.050000</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.013675</td>\n",
       "      <td>0.022585</td>\n",
       "      <td>0.031336</td>\n",
       "      <td>0.042303</td>\n",
       "      <td>0.071062</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.097479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_id  product_id  ben_soliman_price  final_min_price  final_max_price  \\\n",
       "0        702         3.0              253.5            255.0            279.0   \n",
       "1        702         9.0                NaN            831.4            848.4   \n",
       "2        702        10.0                NaN            270.0            286.0   \n",
       "4        702        14.0              465.0            461.5            477.0   \n",
       "5        702        17.0              599.0            599.0            631.4   \n",
       "\n",
       "   final_mod_price  final_true_min  final_true_max  min_scrapped  scrapped25  \\\n",
       "0            255.0           255.0           300.0    254.630005  255.285004   \n",
       "1            829.0           829.0           850.0           NaN         NaN   \n",
       "2            270.0           270.0           290.0           NaN         NaN   \n",
       "4            477.0           460.0           477.0           NaN         NaN   \n",
       "5            595.0           595.0           639.0    599.000000  599.000000   \n",
       "\n",
       "   ...  percentile_50  percentile_75  maximum  below_market  market_min  \\\n",
       "0  ...     255.142502     255.776253    279.0      0.034136    0.037027   \n",
       "1  ...     839.900000     848.800000    850.0      0.005951    0.012246   \n",
       "2  ...     286.000000     288.000000    290.0      0.023419    0.030653   \n",
       "4  ...     463.250000     468.000000    477.0      0.022783    0.028448   \n",
       "5  ...     607.250000     626.050000    639.0      0.013675    0.022585   \n",
       "\n",
       "   market_25  market_50  market_75  market_max  above_market  \n",
       "0   0.041649   0.043226   0.045597    0.125041      0.127414  \n",
       "1   0.014386   0.025065   0.035287    0.036649      0.042563  \n",
       "2   0.058548   0.084882   0.091237    0.097505      0.103686  \n",
       "4   0.030818   0.035264   0.045056    0.063074      0.068282  \n",
       "5   0.031336   0.042303   0.071062    0.089888      0.097479  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Convert prices to margins (on market_data) - FINALIZE market_data processing\n",
    "# =============================================================================\n",
    "\n",
    "market_data['below_market'] = (market_data['below_market'] - market_data['wac_p']) / market_data['below_market']\n",
    "market_data['market_min'] = (market_data['minimum'] - market_data['wac_p']) / market_data['minimum']\n",
    "market_data['market_25'] = (market_data['percentile_25'] - market_data['wac_p']) / market_data['percentile_25']\n",
    "market_data['market_50'] = (market_data['percentile_50'] - market_data['wac_p']) / market_data['percentile_50']\n",
    "market_data['market_75'] = (market_data['percentile_75'] - market_data['wac_p']) / market_data['percentile_75']\n",
    "market_data['market_max'] = (market_data['maximum'] - market_data['wac_p']) / market_data['maximum']\n",
    "market_data['above_market'] = (market_data['above_market'] - market_data['wac_p']) / market_data['above_market']\n",
    "\n",
    "# Select only the market-related columns to merge later\n",
    "market_columns = [\n",
    "    'cohort_id', 'product_id',\n",
    "    # Market Prices (raw)\n",
    "    'ben_soliman_price', \n",
    "    'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped',\n",
    "    # Price Percentiles\n",
    "    'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum',\n",
    "    # Margin Tiers\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market'\n",
    "]\n",
    "market_data = market_data[[c for c in market_columns if c in market_data.columns]]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"MARKET DATA PROCESSING COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total processed market records: {len(market_data)}\")\n",
    "print(f\"\\nMarket data columns:\")\n",
    "print(\"  - Price columns: ben_soliman_price, final_min_price, final_max_price, etc.\")\n",
    "print(\"  - Percentiles: minimum, percentile_25, percentile_50, percentile_75, maximum\")\n",
    "print(\"  - Margin tiers: below_market, market_min, market_25, market_50, market_75, market_max, above_market\")\n",
    "print(f\"\\nSample processed market data:\")\n",
    "market_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART B: Build Main pricing_data DataFrame\n",
    "Start with df_product_base (all our SKUs) and LEFT JOIN the processed market_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building main pricing_data DataFrame...\n",
      "  Step 1: Starting with product base (all SKUs)...\n",
      "     Product base: 101994 records\n",
      "  Step 2: Adding warehouse mapping...\n",
      "     After warehouse mapping: 86122 records\n",
      "  Step 3: Left joining processed market data...\n",
      "     After market data join: 86122 records\n",
      "  Step 4: Left joining supporting data...\n",
      "\n",
      "============================================================\n",
      "PRICING DATA COMPLETE\n",
      "============================================================\n",
      "Total records: 64589\n",
      "\n",
      "Records with market data: 12354\n",
      "Records without market data: 52235\n",
      "\n",
      "Records with sales (nmv > 0): 20668\n",
      "Records without sales (nmv = 0): 43921\n",
      "\n",
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>region</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>sku</th>\n",
       "      <th>brand</th>\n",
       "      <th>cat</th>\n",
       "      <th>wac1</th>\n",
       "      <th>wac_p</th>\n",
       "      <th>...</th>\n",
       "      <th>below_market</th>\n",
       "      <th>market_min</th>\n",
       "      <th>market_25</th>\n",
       "      <th>market_50</th>\n",
       "      <th>market_75</th>\n",
       "      <th>market_max</th>\n",
       "      <th>above_market</th>\n",
       "      <th>std</th>\n",
       "      <th>avg_margin</th>\n",
       "      <th>target_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>703</td>\n",
       "      <td>11769</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>337</td>\n",
       "      <td>El-Mahala</td>\n",
       "      <td>   - 330 </td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>178.345927</td>\n",
       "      <td>172.711963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017243</td>\n",
       "      <td>-0.017243</td>\n",
       "      <td>0.017286</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.044735</td>\n",
       "      <td>0.09099</td>\n",
       "      <td>0.094801</td>\n",
       "      <td>0.007115</td>\n",
       "      <td>0.046815</td>\n",
       "      <td>0.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>703</td>\n",
       "      <td>12473</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>337</td>\n",
       "      <td>El-Mahala</td>\n",
       "      <td>    6 + 1   - 7 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>26.852206</td>\n",
       "      <td>24.478930</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.048311</td>\n",
       "      <td>0.047400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1124</td>\n",
       "      <td>19964</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>501</td>\n",
       "      <td>Assiut FC</td>\n",
       "      <td>     1 - 58 </td>\n",
       "      <td></td>\n",
       "      <td> </td>\n",
       "      <td>277.356428</td>\n",
       "      <td>253.363816</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007770</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>703</td>\n",
       "      <td>4966</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>337</td>\n",
       "      <td>El-Mahala</td>\n",
       "      <td>-   - 300 </td>\n",
       "      <td>-</td>\n",
       "      <td>  </td>\n",
       "      <td>278.613980</td>\n",
       "      <td>272.201304</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015532</td>\n",
       "      <td>0.037348</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>704</td>\n",
       "      <td>18964</td>\n",
       "      <td>Delta East</td>\n",
       "      <td>339</td>\n",
       "      <td>Mansoura FC</td>\n",
       "      <td>  - 6 </td>\n",
       "      <td></td>\n",
       "      <td>  </td>\n",
       "      <td>454.335604</td>\n",
       "      <td>423.577161</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>0.036704</td>\n",
       "      <td>0.040782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cohort_id  product_id       region  warehouse_id    warehouse  \\\n",
       "0        703       11769   Delta West           337    El-Mahala   \n",
       "2        703       12473   Delta West           337    El-Mahala   \n",
       "4       1124       19964  Upper Egypt           501    Assiut FC   \n",
       "5        703        4966   Delta West           337    El-Mahala   \n",
       "7        704       18964   Delta East           339  Mansoura FC   \n",
       "\n",
       "                                                sku    brand           cat  \\\n",
       "0                           - 330                \n",
       "2      6 + 1   - 7           \n",
       "4         1 - 58         \n",
       "5                          -   - 300     -         \n",
       "7                                - 6              \n",
       "\n",
       "         wac1       wac_p  ...  below_market  market_min  market_25  \\\n",
       "0  178.345927  172.711963  ...     -0.017243   -0.017243   0.017286   \n",
       "2   26.852206   24.478930  ...           NaN         NaN        NaN   \n",
       "4  277.356428  253.363816  ...           NaN         NaN        NaN   \n",
       "5  278.613980  272.201304  ...           NaN         NaN        NaN   \n",
       "7  454.335604  423.577161  ...           NaN         NaN        NaN   \n",
       "\n",
       "   market_50  market_75  market_max  above_market       std  avg_margin  \\\n",
       "0   0.021739   0.044735     0.09099      0.094801  0.007115    0.046815   \n",
       "2        NaN        NaN         NaN           NaN  0.010000    0.048311   \n",
       "4        NaN        NaN         NaN           NaN  0.007770    0.048400   \n",
       "5        NaN        NaN         NaN           NaN  0.015532    0.037348   \n",
       "7        NaN        NaN         NaN           NaN  0.009910    0.036704   \n",
       "\n",
       "   target_margin  \n",
       "0       0.060000  \n",
       "2       0.047400  \n",
       "4       0.043200  \n",
       "5       0.045000  \n",
       "7       0.040782  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PART B: Build Main pricing_data DataFrame from df_product_base\n",
    "# =============================================================================\n",
    "print(\"Building main pricing_data DataFrame...\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 1: Start with df_product_base as the MAIN dataframe (all our SKUs)\n",
    "# =============================================================================\n",
    "print(\"  Step 1: Starting with product base (all SKUs)...\")\n",
    "pricing_data = df_product_base.copy()\n",
    "print(f\"     Product base: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 2: Add warehouse mapping (warehouse_id and warehouse name)\n",
    "# =============================================================================\n",
    "print(\"  Step 2: Adding warehouse mapping...\")\n",
    "warehouse_df = get_warehouse_df()\n",
    "pricing_data = pricing_data.merge(\n",
    "    warehouse_df[['cohort_id', 'warehouse_id', 'warehouse']], \n",
    "    on='cohort_id'\n",
    ")\n",
    "print(f\"     After warehouse mapping: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 3: LEFT JOIN processed market_data\n",
    "# =============================================================================\n",
    "print(\"  Step 3: Left joining processed market data...\")\n",
    "pricing_data = pricing_data.merge(\n",
    "    market_data, \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "print(f\"     After market data join: {len(pricing_data)} records\")\n",
    "\n",
    "# =============================================================================\n",
    "# Step 4: LEFT JOIN supporting data (sales, margins, targets, groups)\n",
    "# =============================================================================\n",
    "print(\"  Step 4: Left joining supporting data...\")\n",
    "\n",
    "# Merge sales data (nmv only)\n",
    "pricing_data = pricing_data.merge(\n",
    "    df_sales[['cohort_id', 'product_id', 'nmv']], \n",
    "    on=['cohort_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "pricing_data['nmv'] = pricing_data['nmv'].fillna(0)\n",
    "\n",
    "# Merge margin statistics (by cohort_id + product_id)\n",
    "pricing_data = pricing_data.merge(df_margin_stats, on=['cohort_id', 'product_id'], how='left')\n",
    "\n",
    "# Merge target margins (by brand + cat)\n",
    "pricing_data = pricing_data.merge(df_targets, on=['brand', 'cat'], how='left')\n",
    "pricing_data['target_margin'] = pricing_data['target_bm'].fillna(pricing_data['cat_target_margin']).fillna(0)\n",
    "pricing_data = pricing_data.drop(columns=['target_bm', 'cat_target_margin'], errors='ignore')\n",
    "\n",
    "# Fill NaN values with defaults\n",
    "pricing_data['std'] = pricing_data['std'].fillna(0.01)\n",
    "pricing_data['avg_margin'] = pricing_data['avg_margin'].fillna(0)\n",
    "\n",
    "# Merge product groups\n",
    "pricing_data = pricing_data.merge(df_groups, on='product_id', how='left')\n",
    "\n",
    "# =============================================================================\n",
    "# Step 5: Calculate current margin\n",
    "# =============================================================================\n",
    "pricing_data['current_margin'] = (pricing_data['current_price'] - pricing_data['wac_p']) / pricing_data['current_price']\n",
    "\n",
    "# Remove duplicates\n",
    "pricing_data = pricing_data.drop_duplicates(subset=['cohort_id', 'product_id'])\n",
    "\n",
    "# =============================================================================\n",
    "# Reorder columns\n",
    "# =============================================================================\n",
    "final_columns = [\n",
    "    # Product Base Info\n",
    "    'cohort_id', 'product_id', 'region', 'warehouse_id', 'warehouse', 'sku', 'brand', 'cat',\n",
    "    # Cost & Price\n",
    "    'wac1', 'wac_p', 'current_price', 'current_margin',\n",
    "    # Sales\n",
    "    'nmv',\n",
    "    # Market Prices (raw)\n",
    "    'ben_soliman_price', \n",
    "    'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max',\n",
    "    'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped',\n",
    "    # Price Percentiles\n",
    "    'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum',\n",
    "    # Margin Tiers\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market',\n",
    "    # Supporting Data\n",
    "    'std', 'avg_margin', 'target_margin', 'group'\n",
    "]\n",
    "pricing_data = pricing_data[[c for c in final_columns if c in pricing_data.columns]]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICING DATA COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(pricing_data)}\")\n",
    "print(f\"\\nRecords with market data: {len(pricing_data[~pricing_data['minimum'].isna()])}\")\n",
    "print(f\"Records without market data: {len(pricing_data[pricing_data['minimum'].isna()])}\")\n",
    "print(f\"\\nRecords with sales (nmv > 0): {len(pricing_data[pricing_data['nmv'] > 0])}\")\n",
    "print(f\"Records without sales (nmv = 0): {len(pricing_data[pricing_data['nmv'] == 0])}\")\n",
    "print(f\"\\nSample data:\")\n",
    "pricing_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discount Analysis - Price & Margin After Discount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading discount data...\n",
      "Loaded 10463 discount records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Discount Query - Get discount percentage by warehouse and product\n",
    "# =============================================================================\n",
    "DISCOUNT_QUERY = f'''\n",
    "SELECT warehouse_id, product_id, total_discount/total_nmv AS discount_perc\n",
    "FROM (\n",
    "    SELECT  \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        SUM(pso.total_price) AS total_nmv,\n",
    "        SUM((ITEM_QUANTITY_DISCOUNT_VALUE * pso.purchased_item_count) + \n",
    "            (ITEM_DISCOUNT_VALUE * pso.purchased_item_count)) AS total_discount\n",
    "    FROM product_sales_order pso \n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1 \n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY ALL\n",
    ")\n",
    "WHERE total_nmv > 0\n",
    "'''\n",
    "\n",
    "# Execute discount query\n",
    "print(\"Loading discount data...\")\n",
    "df_discount = query_snowflake(DISCOUNT_QUERY)\n",
    "df_discount = convert_to_numeric(df_discount)\n",
    "print(f\"Loaded {len(df_discount)} discount records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating pricing_with_discount DataFrame...\n",
      "\n",
      "============================================================\n",
      "PRICING WITH DISCOUNT DATA COMPLETE\n",
      "============================================================\n",
      "Total records: 64589\n",
      "Records with discount (discount_perc > 0): 3019\n",
      "Records without discount: 61570\n",
      "\n",
      "New columns added:\n",
      "  - discount_perc: discount percentage from sales\n",
      "  - price_after_discount: current_price * (1 - discount_perc)\n",
      "  - margin_after_discount: (price_after_discount - wac_p) / price_after_discount\n",
      "\n",
      "Sample data with discounts:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>current_price</th>\n",
       "      <th>current_margin</th>\n",
       "      <th>discount_perc</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>margin_after_discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23039</td>\n",
       "      <td>1</td>\n",
       "      <td>26.00</td>\n",
       "      <td>0.085596</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>25.734800</td>\n",
       "      <td>0.076173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6494</td>\n",
       "      <td>236</td>\n",
       "      <td>577.00</td>\n",
       "      <td>0.042672</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>575.454767</td>\n",
       "      <td>0.040101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6494</td>\n",
       "      <td>632</td>\n",
       "      <td>581.75</td>\n",
       "      <td>0.050489</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>578.403744</td>\n",
       "      <td>0.044995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>161</td>\n",
       "      <td>339</td>\n",
       "      <td>41.75</td>\n",
       "      <td>0.093907</td>\n",
       "      <td>0.011688</td>\n",
       "      <td>41.262039</td>\n",
       "      <td>0.083192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6872</td>\n",
       "      <td>797</td>\n",
       "      <td>270.25</td>\n",
       "      <td>0.060493</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>265.682775</td>\n",
       "      <td>0.044342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>23032</td>\n",
       "      <td>1</td>\n",
       "      <td>67.50</td>\n",
       "      <td>0.094259</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>64.941748</td>\n",
       "      <td>0.058579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>9381</td>\n",
       "      <td>401</td>\n",
       "      <td>33.50</td>\n",
       "      <td>0.047736</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>33.485475</td>\n",
       "      <td>0.047323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>11490</td>\n",
       "      <td>797</td>\n",
       "      <td>277.50</td>\n",
       "      <td>0.040033</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>274.621128</td>\n",
       "      <td>0.029969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>435</td>\n",
       "      <td>1</td>\n",
       "      <td>315.00</td>\n",
       "      <td>0.123261</td>\n",
       "      <td>0.015533</td>\n",
       "      <td>310.107000</td>\n",
       "      <td>0.109427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>590</td>\n",
       "      <td>337</td>\n",
       "      <td>50.75</td>\n",
       "      <td>0.037626</td>\n",
       "      <td>0.007833</td>\n",
       "      <td>50.352473</td>\n",
       "      <td>0.030028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  current_price  current_margin  discount_perc  \\\n",
       "5        23039             1          26.00        0.085596       0.010200   \n",
       "6         6494           236         577.00        0.042672       0.002678   \n",
       "13        6494           632         581.75        0.050489       0.005752   \n",
       "19         161           339          41.75        0.093907       0.011688   \n",
       "34        6872           797         270.25        0.060493       0.016900   \n",
       "35       23032             1          67.50        0.094259       0.037900   \n",
       "36        9381           401          33.50        0.047736       0.000434   \n",
       "43       11490           797         277.50        0.040033       0.010374   \n",
       "52         435             1         315.00        0.123261       0.015533   \n",
       "53         590           337          50.75        0.037626       0.007833   \n",
       "\n",
       "    price_after_discount  margin_after_discount  \n",
       "5              25.734800               0.076173  \n",
       "6             575.454767               0.040101  \n",
       "13            578.403744               0.044995  \n",
       "19             41.262039               0.083192  \n",
       "34            265.682775               0.044342  \n",
       "35             64.941748               0.058579  \n",
       "36             33.485475               0.047323  \n",
       "43            274.621128               0.029969  \n",
       "52            310.107000               0.109427  \n",
       "53             50.352473               0.030028  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Create pricing_with_discount DataFrame\n",
    "# =============================================================================\n",
    "print(\"Creating pricing_with_discount DataFrame...\")\n",
    "\n",
    "# Copy pricing_data\n",
    "pricing_with_discount = pricing_data.copy()\n",
    "\n",
    "# Merge discount data (by warehouse_id + product_id)\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_discount[['warehouse_id', 'product_id', 'discount_perc']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing discount_perc with 0 (no discount)\n",
    "pricing_with_discount['discount_perc'] = pricing_with_discount['discount_perc'].fillna(0)\n",
    "\n",
    "# =============================================================================\n",
    "# Calculate price and margin after discount\n",
    "# =============================================================================\n",
    "# Price after discount = current_price * (1 - discount_perc)\n",
    "pricing_with_discount['price_after_discount'] = (\n",
    "    pricing_with_discount['current_price'] * (1 - pricing_with_discount['discount_perc'])\n",
    ")\n",
    "\n",
    "# Margin after discount = (price_after_discount - wac_p) / price_after_discount\n",
    "pricing_with_discount['margin_after_discount'] = (\n",
    "    (pricing_with_discount['price_after_discount'] - pricing_with_discount['wac_p']) / \n",
    "    pricing_with_discount['price_after_discount']\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICING WITH DISCOUNT DATA COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(pricing_with_discount)}\")\n",
    "print(f\"Records with discount (discount_perc > 0): {len(pricing_with_discount[pricing_with_discount['discount_perc'] > 0])}\")\n",
    "print(f\"Records without discount: {len(pricing_with_discount[pricing_with_discount['discount_perc'] == 0])}\")\n",
    "print(f\"\\nNew columns added:\")\n",
    "print(\"  - discount_perc: discount percentage from sales\")\n",
    "print(\"  - price_after_discount: current_price * (1 - discount_perc)\")\n",
    "print(\"  - margin_after_discount: (price_after_discount - wac_p) / price_after_discount\")\n",
    "print(f\"\\nSample data with discounts:\")\n",
    "pricing_with_discount[pricing_with_discount['discount_perc'] > 0][\n",
    "    ['product_id', 'warehouse_id', 'current_price', 'current_margin', \n",
    "     'discount_perc', 'price_after_discount', 'margin_after_discount']\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PRICE POSITION ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Price Position Distribution:\n",
      "price_position\n",
      "No Market Data    52235\n",
      "At 75th            2293\n",
      "At 50th            2235\n",
      "At Max             2164\n",
      "Above Market       2130\n",
      "At 25th            1194\n",
      "Below Market       1179\n",
      "At Min             1012\n",
      "Below Min           147\n",
      "\n",
      "Price Position Percentages:\n",
      "price_position\n",
      "No Market Data    80.87%\n",
      "At 75th            3.55%\n",
      "At 50th            3.46%\n",
      "At Max             3.35%\n",
      "Above Market        3.3%\n",
      "At 25th            1.85%\n",
      "Below Market       1.83%\n",
      "At Min             1.57%\n",
      "Below Min          0.23%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "Sample data with price position:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>current_price</th>\n",
       "      <th>discount_perc</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>minimum</th>\n",
       "      <th>maximum</th>\n",
       "      <th>price_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11769</td>\n",
       "      <td>337</td>\n",
       "      <td>   - 330 </td>\n",
       "      <td>186.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>186.750000</td>\n",
       "      <td>169.784363</td>\n",
       "      <td>190.0</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12473</td>\n",
       "      <td>337</td>\n",
       "      <td>    6 + 1   - 7 </td>\n",
       "      <td>25.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19964</td>\n",
       "      <td>501</td>\n",
       "      <td>     1 - 58 </td>\n",
       "      <td>271.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>271.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4966</td>\n",
       "      <td>337</td>\n",
       "      <td>-   - 300 </td>\n",
       "      <td>285.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18964</td>\n",
       "      <td>339</td>\n",
       "      <td>  - 6 </td>\n",
       "      <td>436.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23039</td>\n",
       "      <td>1</td>\n",
       "      <td>    - 365 </td>\n",
       "      <td>26.00</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>25.734800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6494</td>\n",
       "      <td>236</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>577.00</td>\n",
       "      <td>0.002678</td>\n",
       "      <td>575.454767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20486</td>\n",
       "      <td>337</td>\n",
       "      <td>      - 5 </td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>47.160000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24122</td>\n",
       "      <td>632</td>\n",
       "      <td>     7  -   7 </td>\n",
       "      <td>183.75</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>183.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>142</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>193.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>193.500000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>205.0</td>\n",
       "      <td>At 25th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>74</td>\n",
       "      <td>797</td>\n",
       "      <td> - 900 </td>\n",
       "      <td>162.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>144.986667</td>\n",
       "      <td>160.0</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11999</td>\n",
       "      <td>632</td>\n",
       "      <td>     - 185 </td>\n",
       "      <td>20.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11215</td>\n",
       "      <td>501</td>\n",
       "      <td>    - 125 </td>\n",
       "      <td>410.50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>410.500000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>415.0</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6494</td>\n",
       "      <td>632</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>581.75</td>\n",
       "      <td>0.005752</td>\n",
       "      <td>578.403744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12595</td>\n",
       "      <td>236</td>\n",
       "      <td> -   430 </td>\n",
       "      <td>525.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>525.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "0        11769           337   \n",
       "1        12473           337   \n",
       "2        19964           501   \n",
       "3         4966           337   \n",
       "4        18964           339   \n",
       "5        23039             1   \n",
       "6         6494           236   \n",
       "7        20486           337   \n",
       "8        24122           632   \n",
       "9          142           339   \n",
       "10          74           797   \n",
       "11       11999           632   \n",
       "12       11215           501   \n",
       "13        6494           632   \n",
       "14       12595           236   \n",
       "\n",
       "                                                 sku  current_price  \\\n",
       "0                            - 330          186.75   \n",
       "1       6 + 1   - 7           25.75   \n",
       "2          1 - 58          271.75   \n",
       "3                           -   - 300          285.00   \n",
       "4                                 - 6          436.00   \n",
       "5                      - 365           26.00   \n",
       "6                                - 700          577.00   \n",
       "7           - 5           50.00   \n",
       "8        7  -   7          183.75   \n",
       "9                            - 235          193.50   \n",
       "10                                   - 900          162.00   \n",
       "11            - 185           20.25   \n",
       "12                        - 125          410.50   \n",
       "13                               - 700          581.75   \n",
       "14                            -   430          525.25   \n",
       "\n",
       "    discount_perc  price_after_discount     minimum  maximum  price_position  \n",
       "0        0.000000            186.750000  169.784363    190.0         At 75th  \n",
       "1        0.000000             25.750000         NaN      NaN  No Market Data  \n",
       "2        0.000000            271.750000         NaN      NaN  No Market Data  \n",
       "3        0.000000            285.000000         NaN      NaN  No Market Data  \n",
       "4        0.000000            436.000000         NaN      NaN  No Market Data  \n",
       "5        0.010200             25.734800         NaN      NaN  No Market Data  \n",
       "6        0.002678            575.454767         NaN      NaN  No Market Data  \n",
       "7        0.000000             50.000000   47.160000     50.0          At Max  \n",
       "8        0.000000            183.750000         NaN      NaN  No Market Data  \n",
       "9        0.000000            193.500000  190.000000    205.0         At 25th  \n",
       "10       0.000000            162.000000  144.986667    160.0          At Max  \n",
       "11       0.000000             20.250000         NaN      NaN  No Market Data  \n",
       "12       0.000000            410.500000  395.000000    415.0         At 75th  \n",
       "13       0.005752            578.403744         NaN      NaN  No Market Data  \n",
       "14       0.000000            525.250000         NaN      NaN  No Market Data  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Price Position - Determine where price_after_discount falls in market tiers\n",
    "# =============================================================================\n",
    "\n",
    "def get_price_position(row):\n",
    "    \"\"\"Determine the price position relative to market price tiers.\"\"\"\n",
    "    price = row['price_after_discount']\n",
    "    wac = row['wac_p']\n",
    "    \n",
    "    # Check if we have market data (minimum price exists)\n",
    "    if pd.isna(row['minimum']) or pd.isna(price):\n",
    "        return \"No Market Data\"\n",
    "    \n",
    "    # Get price tiers\n",
    "    min_price = row['minimum']\n",
    "    p25 = row['percentile_25']\n",
    "    p50 = row['percentile_50']\n",
    "    p75 = row['percentile_75']\n",
    "    max_price = row['maximum']\n",
    "    \n",
    "    # Calculate below_market and above_market prices from margins\n",
    "    # margin = (price - wac) / price  =>  price = wac / (1 - margin)\n",
    "    below_market_margin = row['below_market']\n",
    "    above_market_margin = row['above_market']\n",
    "    \n",
    "    below_market_price = wac / (1 - below_market_margin) if below_market_margin < 1 else min_price\n",
    "    above_market_price = wac / (1 - above_market_margin) if above_market_margin < 1 else max_price\n",
    "    \n",
    "    # Determine position based on price tiers\n",
    "    if price < below_market_price:\n",
    "        return \"Below Market\"\n",
    "    elif price < min_price:\n",
    "        return \"Below Min\"\n",
    "    elif price < p25:\n",
    "        return \"At Min\"\n",
    "    elif price < p50:\n",
    "        return \"At 25th\"\n",
    "    elif price < p75:\n",
    "        return \"At 50th\"\n",
    "    elif price < max_price:\n",
    "        return \"At 75th\"\n",
    "    elif price < above_market_price:\n",
    "        return \"At Max\"\n",
    "    else:\n",
    "        return \"Above Market\"\n",
    "\n",
    "# Apply price position function\n",
    "pricing_with_discount['price_position'] = pricing_with_discount.apply(get_price_position, axis=1)\n",
    "\n",
    "# Summary of price positions\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PRICE POSITION ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(\"\\nPrice Position Distribution:\")\n",
    "print(pricing_with_discount['price_position'].value_counts().to_string())\n",
    "print(f\"\\nPrice Position Percentages:\")\n",
    "print((pricing_with_discount['price_position'].value_counts(normalize=True) * 100).round(2).astype(str) + '%')\n",
    "\n",
    "# Sample data showing price position\n",
    "print(f\"\\nSample data with price position:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'current_price', 'discount_perc', \n",
    "     'price_after_discount', 'minimum', 'maximum', 'price_position']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stock data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1837903 stock records\n",
      "\n",
      "Stock data merged!\n",
      "Records with stock (stocks > 0): 14100\n",
      "Records without stock (stocks = 0): 50489\n",
      "\n",
      "Sample data with stocks:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>stocks</th>\n",
       "      <th>price_after_discount</th>\n",
       "      <th>price_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11769</td>\n",
       "      <td>337</td>\n",
       "      <td>   - 330 </td>\n",
       "      <td>0</td>\n",
       "      <td>186.750000</td>\n",
       "      <td>At 75th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12473</td>\n",
       "      <td>337</td>\n",
       "      <td>    6 + 1   - 7 </td>\n",
       "      <td>0</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19964</td>\n",
       "      <td>501</td>\n",
       "      <td>     1 - 58 </td>\n",
       "      <td>39</td>\n",
       "      <td>271.750000</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4966</td>\n",
       "      <td>337</td>\n",
       "      <td>-   - 300 </td>\n",
       "      <td>10</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18964</td>\n",
       "      <td>339</td>\n",
       "      <td>  - 6 </td>\n",
       "      <td>29</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23039</td>\n",
       "      <td>1</td>\n",
       "      <td>    - 365 </td>\n",
       "      <td>133</td>\n",
       "      <td>25.734800</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6494</td>\n",
       "      <td>236</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>77</td>\n",
       "      <td>575.454767</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20486</td>\n",
       "      <td>337</td>\n",
       "      <td>      - 5 </td>\n",
       "      <td>76</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>At Max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24122</td>\n",
       "      <td>632</td>\n",
       "      <td>     7  -   7 </td>\n",
       "      <td>0</td>\n",
       "      <td>183.750000</td>\n",
       "      <td>No Market Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>142</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>67</td>\n",
       "      <td>193.500000</td>\n",
       "      <td>At 25th</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  warehouse_id                                               sku  \\\n",
       "0       11769           337                           - 330    \n",
       "1       12473           337      6 + 1   - 7    \n",
       "2       19964           501         1 - 58    \n",
       "3        4966           337                          -   - 300    \n",
       "4       18964           339                                - 6    \n",
       "5       23039             1                     - 365    \n",
       "6        6494           236                               - 700    \n",
       "7       20486           337          - 5    \n",
       "8       24122           632       7  -   7    \n",
       "9         142           339                           - 235    \n",
       "\n",
       "   stocks  price_after_discount  price_position  \n",
       "0       0            186.750000         At 75th  \n",
       "1       0             25.750000  No Market Data  \n",
       "2      39            271.750000  No Market Data  \n",
       "3      10            285.000000  No Market Data  \n",
       "4      29            436.000000  No Market Data  \n",
       "5     133             25.734800  No Market Data  \n",
       "6      77            575.454767  No Market Data  \n",
       "7      76             50.000000          At Max  \n",
       "8       0            183.750000  No Market Data  \n",
       "9      67            193.500000         At 25th  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Stock Query - Get available stock by warehouse and product\n",
    "# =============================================================================\n",
    "STOCK_QUERY = '''\n",
    "SELECT \n",
    "    pw.warehouse_id,\n",
    "    pw.product_id,\n",
    "    pw.available_stock::INTEGER AS stocks\n",
    "FROM product_warehouse pw\n",
    "WHERE pw.warehouse_id NOT IN (6, 9, 10)\n",
    "    AND pw.is_basic_unit = 1\n",
    "'''\n",
    "\n",
    "# Execute stock query\n",
    "print(\"Loading stock data...\")\n",
    "df_stocks = query_snowflake(STOCK_QUERY)\n",
    "df_stocks = convert_to_numeric(df_stocks)\n",
    "print(f\"Loaded {len(df_stocks)} stock records\")\n",
    "\n",
    "# Merge stock data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_stocks[['warehouse_id', 'product_id', 'stocks']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing stocks with 0\n",
    "pricing_with_discount['stocks'] = pricing_with_discount['stocks'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"\\nStock data merged!\")\n",
    "print(f\"Records with stock (stocks > 0): {len(pricing_with_discount[pricing_with_discount['stocks'] > 0])}\")\n",
    "print(f\"Records without stock (stocks = 0): {len(pricing_with_discount[pricing_with_discount['stocks'] == 0])}\")\n",
    "print(f\"\\nSample data with stocks:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'stocks', 'price_after_discount', 'price_position']\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading zero demand SKUs...\n",
      "Loaded 3915 zero demand SKU records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Zero Demand Query - Identify SKUs with zero/low demand\n",
    "# =============================================================================\n",
    "ZERO_DEMAND_QUERY = f'''\n",
    "WITH last_oss AS (\n",
    "    SELECT product_id, warehouse_id, TIMESTAMP AS last_in_stock_day\n",
    "    FROM (\n",
    "        SELECT *, ROW_NUMBER() OVER(PARTITION BY product_id, warehouse_id ORDER BY TIMESTAMP DESC) AS rnk \n",
    "        FROM materialized_views.STOCK_DAY_CLOSE\n",
    "        WHERE AVAILABLE_STOCK = 0 \n",
    "            AND TIMESTAMP >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "        QUALIFY rnk = 1 \n",
    "    )\n",
    "),\n",
    "\n",
    "current_stocks AS (\n",
    "    SELECT product_id, warehouse_id, AVAILABLE_STOCK, activation\n",
    "    FROM PRODUCT_WAREHOUSE\n",
    "    WHERE IS_BASIC_UNIT = 1\n",
    "        AND CASE WHEN product_id = 1309 THEN packing_unit_id <> 23 ELSE TRUE END\n",
    "),\n",
    "\n",
    "prs AS (\n",
    "    SELECT DISTINCT \n",
    "        product_purchased_receipts.product_id,\n",
    "        purchased_receipts.warehouse_id,\n",
    "        purchased_receipts.date::DATE AS date,\n",
    "        product_purchased_receipts.purchased_item_count * product_purchased_receipts.basic_unit_count AS purchase_min_count\n",
    "    FROM product_purchased_receipts\n",
    "    JOIN purchased_receipts ON purchased_receipts.id = product_purchased_receipts.purchased_receipt_id\n",
    "    JOIN last_oss lo ON product_purchased_receipts.product_id = lo.product_id \n",
    "        AND lo.warehouse_id = purchased_receipts.warehouse_id \n",
    "        AND purchased_receipts.date > lo.last_in_stock_day \n",
    "    WHERE product_purchased_receipts.purchased_item_count <> 0\n",
    "        AND purchased_receipts.purchased_receipt_status_id IN (4, 5, 7)\n",
    "        AND purchased_receipts.date::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "),\n",
    "\n",
    "main AS (\n",
    "    SELECT \n",
    "        prs.product_id, \n",
    "        prs.warehouse_id, \n",
    "        MIN(date) AS first_order_date, \n",
    "        SUM(purchase_min_count) AS total_recieved, \n",
    "        cs.AVAILABLE_STOCK, \n",
    "        cs.activation\n",
    "    FROM prs \n",
    "    JOIN current_stocks cs ON cs.product_id = prs.product_id AND prs.warehouse_id = cs.warehouse_id\n",
    "    GROUP BY prs.product_id, prs.warehouse_id, cs.AVAILABLE_STOCK, cs.activation\n",
    "),\n",
    "\n",
    "sold_days AS (\n",
    "    SELECT product_id, warehouse_id, COUNT(DISTINCT o_date) AS sales_days\n",
    "    FROM (\n",
    "        SELECT DISTINCT\n",
    "            so.created_at::DATE AS o_date,\n",
    "            pso.warehouse_id,\n",
    "            pso.product_id,\n",
    "            SUM(pso.purchased_item_count * basic_unit_count) AS daily_qty\n",
    "        FROM product_sales_order pso\n",
    "        JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "        JOIN main m ON m.product_id = pso.product_id \n",
    "            AND m.warehouse_id = pso.warehouse_id \n",
    "            AND so.created_at::DATE >= m.first_order_date\n",
    "        WHERE so.created_at::DATE BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120 \n",
    "            AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "            AND so.sales_order_status_id NOT IN (7, 12)\n",
    "            AND so.channel IN ('telesales', 'retailer')\n",
    "            AND pso.purchased_item_count <> 0\n",
    "        GROUP BY o_date, pso.warehouse_id, pso.product_id\n",
    "    )\n",
    "    GROUP BY product_id, warehouse_id\n",
    ")\n",
    "\n",
    "SELECT DISTINCT warehouse_id, product_id\n",
    "FROM (\n",
    "    SELECT m.product_id, m.warehouse_id, m.first_order_date, m.activation,\n",
    "        COALESCE(sd.sales_days, 0) AS sales_days,\n",
    "        COALESCE(sd.sales_days, 0)::FLOAT / NULLIF((CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1) - m.first_order_date, 0) AS perc_days\n",
    "    FROM main m \n",
    "    LEFT JOIN sold_days sd ON sd.product_id = m.product_id AND sd.warehouse_id = m.warehouse_id\n",
    "    WHERE m.first_order_date < CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 10\n",
    ")\n",
    "WHERE perc_days <= 0.3\n",
    "    AND activation = 'true'\n",
    "'''\n",
    "\n",
    "# Execute zero demand query\n",
    "print(\"Loading zero demand SKUs...\")\n",
    "df_zero_demand = query_snowflake(ZERO_DEMAND_QUERY)\n",
    "df_zero_demand = convert_to_numeric(df_zero_demand)\n",
    "print(f\"Loaded {len(df_zero_demand)} zero demand SKU records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero demand flag added!\n",
      "SKUs flagged as zero demand: 2766\n",
      "SKUs with normal demand: 61823\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Zero Demand Flag to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Add a marker column to identify zero demand SKUs\n",
    "df_zero_demand['zero_demand'] = 1\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_zero_demand[['warehouse_id', 'product_id', 'zero_demand']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values with 0 (not zero demand)\n",
    "pricing_with_discount['zero_demand'] = pricing_with_discount['zero_demand'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"Zero demand flag added!\")\n",
    "print(f\"SKUs flagged as zero demand: {len(pricing_with_discount[pricing_with_discount['zero_demand'] == 1])}\")\n",
    "print(f\"SKUs with normal demand: {len(pricing_with_discount[pricing_with_discount['zero_demand'] == 0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading OOS yesterday data...\n",
      "Loaded 1886200 OOS yesterday records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# OOS Yesterday Query - Identify SKUs out of stock yesterday\n",
    "# =============================================================================\n",
    "OOS_YESTERDAY_QUERY = f'''\n",
    "SELECT DISTINCT product_id, warehouse_id,\n",
    "    CASE WHEN opening_stocks = 0 AND closing_stocks = 0 THEN 1\n",
    "         ELSE 0 \n",
    "    END AS oos_yesterday\n",
    "FROM (\n",
    "    SELECT \n",
    "        timestamp,\n",
    "        product_id,\n",
    "        warehouse_id, \n",
    "        AVAILABLE_STOCK AS closing_stocks,\n",
    "        LAG(AVAILABLE_STOCK) OVER (PARTITION BY product_id, warehouse_id ORDER BY TIMESTAMP) AS opening_stocks\n",
    "    FROM materialized_views.stock_day_close\n",
    "    WHERE timestamp::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 2\n",
    "    QUALIFY opening_stocks IS NOT NULL\n",
    ")\n",
    "WHERE oos_yesterday = 1\n",
    "'''\n",
    "\n",
    "# Execute OOS yesterday query\n",
    "print(\"Loading OOS yesterday data...\")\n",
    "df_oos_yesterday = query_snowflake(OOS_YESTERDAY_QUERY)\n",
    "df_oos_yesterday = convert_to_numeric(df_oos_yesterday)\n",
    "print(f\"Loaded {len(df_oos_yesterday)} OOS yesterday records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOS yesterday flag added!\n",
      "SKUs out of stock yesterday: 50359\n",
      "SKUs in stock yesterday: 14230\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add OOS Yesterday Flag to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_oos_yesterday[['warehouse_id', 'product_id', 'oos_yesterday']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values with 0 (not OOS yesterday)\n",
    "pricing_with_discount['oos_yesterday'] = pricing_with_discount['oos_yesterday'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"OOS yesterday flag added!\")\n",
    "print(f\"SKUs out of stock yesterday: {len(pricing_with_discount[pricing_with_discount['oos_yesterday'] == 1])}\")\n",
    "print(f\"SKUs in stock yesterday: {len(pricing_with_discount[pricing_with_discount['oos_yesterday'] == 0])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading running rate data (this may take a moment)...\n",
      "Loaded 22486 running rate records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Running Rate Query - Get in-stock running rate by warehouse and product\n",
    "# =============================================================================\n",
    "RUNNING_RATE_QUERY = f'''\n",
    "WITH params AS (\n",
    "    SELECT\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE AS run_date,\n",
    "        DATEADD(month, -3, CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE) AS history_start\n",
    "),\n",
    "\n",
    "-- Daily sales aggregation\n",
    "sales_base AS (\n",
    "    SELECT\n",
    "        pso.product_id,\n",
    "        pso.warehouse_id,\n",
    "        DATE_TRUNC('day', pso.created_at)::DATE AS date,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count) AS sold_units,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count * pso.item_price)\n",
    "            / NULLIF(SUM(pso.purchased_item_count * pso.basic_unit_count), 0) AS avg_selling_price,\n",
    "        COUNT(DISTINCT so.retailer_id) AS retailer_count\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON pso.sales_order_id = so.id\n",
    "    WHERE DATE_TRUNC('day', pso.created_at)::DATE >= (SELECT history_start FROM params)\n",
    "    GROUP BY 1, 2, 3\n",
    "),\n",
    "\n",
    "-- Stock daily metrics\n",
    "stock_daily AS (\n",
    "    SELECT\n",
    "        product_id,\n",
    "        warehouse_id,\n",
    "        DATE_TRUNC('day', TIMESTAMP)::DATE AS date,\n",
    "        MAX_BY(available_stock, TIMESTAMP) AS stock_closing,\n",
    "        24 * SUM(CASE WHEN activation = FALSE OR available_stock = 0 THEN 1 ELSE 0 END)::FLOAT \n",
    "            / NULLIF(COUNT(*), 0) AS oos_hours,\n",
    "        MAX(CASE WHEN activation = TRUE AND available_stock > 0 THEN 1 ELSE 0 END) AS in_stock_flag\n",
    "    FROM materialized_views.STOCK_SNAP_SHOTS_RECENT\n",
    "    WHERE product_id IS NOT NULL\n",
    "    GROUP BY product_id, warehouse_id, date\n",
    "),\n",
    "\n",
    "-- Join sales + stock + WAC (only in-stock days)\n",
    "base_data AS (\n",
    "    SELECT\n",
    "        sb.product_id,\n",
    "        sb.warehouse_id,\n",
    "        sb.date,\n",
    "        sb.sold_units,\n",
    "        sb.avg_selling_price,\n",
    "        sb.retailer_count,\n",
    "        sd.oos_hours,\n",
    "        sd.in_stock_flag,\n",
    "        ac.wac_p AS wac,\n",
    "        CASE WHEN DAYOFWEEKISO(sb.date) IN (5, 6) THEN 1 ELSE 0 END AS is_weekend\n",
    "    FROM sales_base sb\n",
    "    LEFT JOIN stock_daily sd ON sb.product_id = sd.product_id \n",
    "        AND sb.warehouse_id = sd.warehouse_id AND sb.date = sd.date\n",
    "    LEFT JOIN finance.ALL_COGS ac ON sb.product_id = ac.product_id \n",
    "        AND sb.date BETWEEN ac.from_date AND ac.to_date\n",
    "    WHERE sd.in_stock_flag = 1\n",
    "),\n",
    "\n",
    "-- Stats per SKU x Warehouse\n",
    "sku_wh_stats AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY sold_units) AS med_units,\n",
    "        PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY sold_units) AS pct95_units,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY retailer_count) AS med_retailers,\n",
    "        PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY \n",
    "            CASE WHEN avg_selling_price IS NULL OR avg_selling_price = 0 THEN 0 \n",
    "            ELSE (avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0) END\n",
    "        ) AS med_margin\n",
    "    FROM base_data\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Cap outliers and adjust for retailer spikes\n",
    "adjusted AS (\n",
    "    SELECT\n",
    "        b.product_id, b.warehouse_id, b.date, b.in_stock_flag, b.oos_hours, b.is_weekend,\n",
    "        b.avg_selling_price, b.wac, s.med_margin,\n",
    "        CASE \n",
    "            WHEN b.retailer_count > GREATEST(2, s.med_retailers * 2) \n",
    "                AND b.retailer_count > 0 AND s.med_retailers IS NOT NULL\n",
    "            THEN ROUND(LEAST(b.sold_units, s.pct95_units) * (s.med_retailers::FLOAT / NULLIF(b.retailer_count::FLOAT, 0)), 0)\n",
    "            ELSE LEAST(b.sold_units, s.pct95_units)\n",
    "        END AS units_adjusted\n",
    "    FROM base_data b\n",
    "    LEFT JOIN sku_wh_stats s ON b.product_id = s.product_id AND b.warehouse_id = s.warehouse_id\n",
    "),\n",
    "\n",
    "-- Apply weights (recency, stock availability, weekend, margin)\n",
    "weighted AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id, date, units_adjusted,\n",
    "        (\n",
    "            -- Recency weight\n",
    "            CASE WHEN date >= DATEADD(day, -21, (SELECT run_date FROM params)) THEN 1.5\n",
    "                 WHEN date >= DATEADD(day, -90, (SELECT run_date FROM params)) THEN 1.0\n",
    "                 ELSE 0.5 END\n",
    "            -- In-stock weight\n",
    "            * CASE WHEN in_stock_flag = 1 AND COALESCE(oos_hours, 0) < 12 THEN 1.4\n",
    "                   WHEN in_stock_flag = 1 AND COALESCE(oos_hours, 0) >= 12 THEN 0.9\n",
    "                   ELSE 0.6 END\n",
    "            -- Weekend weight\n",
    "            * CASE WHEN is_weekend = 1 THEN 0.7 ELSE 1.0 END\n",
    "            -- Margin weight\n",
    "            * CASE WHEN avg_selling_price IS NULL OR avg_selling_price = 0 OR med_margin IS NULL THEN 1.0\n",
    "                   WHEN ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) < med_margin\n",
    "                   THEN 1.0 + LEAST((med_margin - ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0))) * 2.0, 0.6)\n",
    "                   WHEN ((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) > med_margin\n",
    "                   THEN 1.0 - LEAST((((avg_selling_price - COALESCE(wac, 0)) / NULLIF(avg_selling_price, 0)) - med_margin) * 2.0, 0.4)\n",
    "                   ELSE 1.0 END\n",
    "        ) AS final_weight\n",
    "    FROM adjusted\n",
    "    WHERE units_adjusted IS NOT NULL\n",
    "),\n",
    "\n",
    "-- Weighted average forecast\n",
    "forecast_base AS (\n",
    "    SELECT\n",
    "        product_id, warehouse_id,\n",
    "        SUM(units_adjusted * final_weight) / NULLIF(SUM(final_weight), 0) AS weighted_avg_units\n",
    "    FROM weighted\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Zero-sales last 4 days (with stock) exclusion flag\n",
    "last4_flag AS (\n",
    "    SELECT product_id, warehouse_id,\n",
    "        CASE WHEN COUNT(*) = 4 \n",
    "             AND SUM(CASE WHEN COALESCE(sold_units, 0) = 0 AND in_stock_flag = 1 THEN 1 ELSE 0 END) = 4\n",
    "        THEN 1 ELSE 0 END AS exclude_flag\n",
    "    FROM base_data\n",
    "    WHERE date >= DATEADD(day, -4, (SELECT run_date FROM params)) \n",
    "        AND date < (SELECT run_date FROM params)\n",
    "    GROUP BY product_id, warehouse_id\n",
    "),\n",
    "\n",
    "-- Zero sales excluded (in stock but no sales)\n",
    "zero_sales_excluded AS (\n",
    "    SELECT DISTINCT s.warehouse_id, s.product_id\n",
    "    FROM (\n",
    "        SELECT pw.warehouse_id, pw.product_id, SUM(pw.available_stock)::INT AS stocks\n",
    "        FROM product_warehouse pw\n",
    "        WHERE pw.warehouse_id NOT IN (6, 9, 10) AND pw.is_basic_unit = 1 AND pw.available_stock > 0\n",
    "        GROUP BY pw.warehouse_id, pw.product_id\n",
    "    ) s\n",
    "    LEFT JOIN (\n",
    "        SELECT pso.product_id, pso.warehouse_id, SUM(pso.total_price) AS nmv\n",
    "        FROM product_sales_order pso\n",
    "        JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "        WHERE so.created_at::date BETWEEN CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 5 \n",
    "            AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1\n",
    "            AND so.sales_order_status_id NOT IN (7, 12) AND so.channel IN ('telesales', 'retailer')\n",
    "            AND pso.purchased_item_count <> 0\n",
    "        GROUP BY pso.product_id, pso.warehouse_id\n",
    "    ) md ON md.product_id = s.product_id AND md.warehouse_id = s.warehouse_id\n",
    "    LEFT JOIN finance.all_cogs f ON f.product_id = s.product_id\n",
    "        AND f.from_date::date <= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "        AND f.to_date::date > CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "    LEFT JOIN (\n",
    "        SELECT pr.warehouse_id, ppr.product_id, SUM(ppr.final_price) AS total_prs\n",
    "        FROM product_purchased_receipts ppr\n",
    "        JOIN purchased_receipts pr ON pr.id = ppr.purchased_receipt_id\n",
    "        WHERE pr.date::date >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 4\n",
    "            AND pr.is_actual = 'true' AND pr.purchased_receipt_status_id IN (4, 5, 7)\n",
    "            AND ppr.purchased_item_count <> 0\n",
    "        GROUP BY pr.warehouse_id, ppr.product_id\n",
    "    ) prs ON prs.product_id = s.product_id AND prs.warehouse_id = s.warehouse_id\n",
    "    WHERE COALESCE(md.nmv, 0) = 0 \n",
    "        AND COALESCE(prs.total_prs, 0) < 0.7 * (COALESCE(f.wac_p, 0) * s.stocks)\n",
    "),\n",
    "\n",
    "-- First sale date for new products\n",
    "first_sale AS (\n",
    "    SELECT product_id, warehouse_id, MIN(date) AS first_sale_date\n",
    "    FROM base_data WHERE sold_units > 0\n",
    "    GROUP BY product_id, warehouse_id\n",
    ")\n",
    "\n",
    "-- Final output: running rate per warehouse/product\n",
    "SELECT\n",
    "    fb.warehouse_id,\n",
    "    fb.product_id,\n",
    "    CASE\n",
    "        WHEN l4.exclude_flag = 1 THEN 0\n",
    "        WHEN fs.first_sale_date >= DATEADD(day, -2, (SELECT run_date FROM params))\n",
    "        THEN GREATEST(CEIL(fb.weighted_avg_units), 1)\n",
    "        ELSE CEIL(fb.weighted_avg_units)\n",
    "    END AS In_stock_rr\n",
    "FROM forecast_base fb\n",
    "LEFT JOIN last4_flag l4 ON fb.product_id = l4.product_id AND fb.warehouse_id = l4.warehouse_id\n",
    "LEFT JOIN first_sale fs ON fb.product_id = fs.product_id AND fb.warehouse_id = fs.warehouse_id\n",
    "LEFT JOIN zero_sales_excluded zse ON fb.product_id = zse.product_id AND fb.warehouse_id = zse.warehouse_id\n",
    "WHERE zse.product_id IS NULL\n",
    "'''\n",
    "\n",
    "# Execute running rate query\n",
    "print(\"Loading running rate data (this may take a moment)...\")\n",
    "df_running_rate = query_snowflake(RUNNING_RATE_QUERY)\n",
    "df_running_rate = convert_to_numeric(df_running_rate)\n",
    "print(f\"Loaded {len(df_running_rate)} running rate records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Merge Running Rate and Calculate DOH (Days on Hand)\n",
    "# =============================================================================\n",
    "\n",
    "# Merge running rate data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_running_rate[['warehouse_id', 'product_id', 'in_stock_rr']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing running rate with 0\n",
    "pricing_with_discount['in_stock_rr'] = pricing_with_discount['in_stock_rr'].fillna(0)\n",
    "\n",
    "# Calculate DOH (Days on Hand) = stocks / in_stock_rr\n",
    "# Handle division by zero - if running rate is 0, DOH is infinite (use 999)\n",
    "pricing_with_discount['doh'] = np.select(\n",
    "    [\n",
    "        (pricing_with_discount['in_stock_rr'] > 0) & (pricing_with_discount['stocks'] > 0),\n",
    "        pricing_with_discount['stocks'] == 0\n",
    "    ],\n",
    "    [\n",
    "        pricing_with_discount['stocks'] / pricing_with_discount['in_stock_rr'],\n",
    "        0\n",
    "    ],\n",
    "    default=999\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading product classification data...\n",
      "Loaded 27477 product classification records\n",
      "\n",
      "Classification distribution:\n",
      "abc_class\n",
      "C    20840\n",
      "B     5480\n",
      "A     1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Product Classification Query - ABC Classification based on order contribution\n",
    "# =============================================================================\n",
    "PRODUCT_CLASSIFICATION_QUERY = f'''\n",
    "WITH order_counts AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        COUNT(DISTINCT pso.sales_order_id) AS order_count\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 90\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id\n",
    "),\n",
    "\n",
    "warehouse_totals AS (\n",
    "    SELECT \n",
    "        warehouse_id,\n",
    "        SUM(order_count) AS total_orders\n",
    "    FROM order_counts\n",
    "    GROUP BY warehouse_id\n",
    "),\n",
    "\n",
    "ranked_products AS (\n",
    "    SELECT \n",
    "        oc.warehouse_id,\n",
    "        oc.product_id,\n",
    "        oc.order_count,\n",
    "        wt.total_orders,\n",
    "        oc.order_count::FLOAT / NULLIF(wt.total_orders, 0) AS contribution,\n",
    "        SUM(oc.order_count::FLOAT / NULLIF(wt.total_orders, 0)) \n",
    "            OVER (PARTITION BY oc.warehouse_id ORDER BY oc.order_count DESC \n",
    "                  ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS cumulative_contribution\n",
    "    FROM order_counts oc\n",
    "    JOIN warehouse_totals wt ON oc.warehouse_id = wt.warehouse_id\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    warehouse_id,\n",
    "    product_id,\n",
    "    order_count,\n",
    "    contribution,\n",
    "    cumulative_contribution,\n",
    "    CASE \n",
    "        WHEN cumulative_contribution <= 0.4 THEN 'A'\n",
    "        WHEN cumulative_contribution <= 0.8 THEN 'B'\n",
    "        ELSE 'C'\n",
    "    END AS abc_class\n",
    "FROM ranked_products\n",
    "'''\n",
    "\n",
    "# Execute product classification query\n",
    "print(\"Loading product classification data...\")\n",
    "df_classification = query_snowflake(PRODUCT_CLASSIFICATION_QUERY)\n",
    "df_classification = convert_to_numeric(df_classification)\n",
    "print(f\"Loaded {len(df_classification)} product classification records\")\n",
    "print(f\"\\nClassification distribution:\")\n",
    "print(df_classification['abc_class'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABC Classification added!\n",
      "\n",
      "Classification in pricing_with_discount:\n",
      "abc_class\n",
      "C    60124\n",
      "B     3693\n",
      "A      772\n",
      "\n",
      "Sample data with classification:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>order_count</th>\n",
       "      <th>contribution</th>\n",
       "      <th>abc_class</th>\n",
       "      <th>stocks</th>\n",
       "      <th>doh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11769</td>\n",
       "      <td>337</td>\n",
       "      <td>   - 330 </td>\n",
       "      <td>241</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12473</td>\n",
       "      <td>337</td>\n",
       "      <td>    6 + 1   - 7 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19964</td>\n",
       "      <td>501</td>\n",
       "      <td>     1 - 58 </td>\n",
       "      <td>46</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>C</td>\n",
       "      <td>39</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4966</td>\n",
       "      <td>337</td>\n",
       "      <td>-   - 300 </td>\n",
       "      <td>27</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>C</td>\n",
       "      <td>10</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18964</td>\n",
       "      <td>339</td>\n",
       "      <td>  - 6 </td>\n",
       "      <td>131</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>B</td>\n",
       "      <td>29</td>\n",
       "      <td>9.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23039</td>\n",
       "      <td>1</td>\n",
       "      <td>    - 365 </td>\n",
       "      <td>209</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>C</td>\n",
       "      <td>133</td>\n",
       "      <td>10.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6494</td>\n",
       "      <td>236</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>356</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>B</td>\n",
       "      <td>77</td>\n",
       "      <td>12.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20486</td>\n",
       "      <td>337</td>\n",
       "      <td>      - 5 </td>\n",
       "      <td>230</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>B</td>\n",
       "      <td>76</td>\n",
       "      <td>8.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24122</td>\n",
       "      <td>632</td>\n",
       "      <td>     7  -   7 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>142</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>629</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>A</td>\n",
       "      <td>67</td>\n",
       "      <td>4.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>74</td>\n",
       "      <td>797</td>\n",
       "      <td> - 900 </td>\n",
       "      <td>91</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>B</td>\n",
       "      <td>36</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11999</td>\n",
       "      <td>632</td>\n",
       "      <td>     - 185 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11215</td>\n",
       "      <td>501</td>\n",
       "      <td>    - 125 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6494</td>\n",
       "      <td>632</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>237</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>B</td>\n",
       "      <td>66</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12595</td>\n",
       "      <td>236</td>\n",
       "      <td> -   430 </td>\n",
       "      <td>14</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>C</td>\n",
       "      <td>25</td>\n",
       "      <td>12.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "0        11769           337   \n",
       "1        12473           337   \n",
       "2        19964           501   \n",
       "3         4966           337   \n",
       "4        18964           339   \n",
       "5        23039             1   \n",
       "6         6494           236   \n",
       "7        20486           337   \n",
       "8        24122           632   \n",
       "9          142           339   \n",
       "10          74           797   \n",
       "11       11999           632   \n",
       "12       11215           501   \n",
       "13        6494           632   \n",
       "14       12595           236   \n",
       "\n",
       "                                                 sku  order_count  \\\n",
       "0                            - 330           241   \n",
       "1       6 + 1   - 7             0   \n",
       "2          1 - 58            46   \n",
       "3                           -   - 300            27   \n",
       "4                                 - 6           131   \n",
       "5                      - 365           209   \n",
       "6                                - 700           356   \n",
       "7           - 5           230   \n",
       "8        7  -   7             0   \n",
       "9                            - 235           629   \n",
       "10                                   - 900            91   \n",
       "11            - 185             0   \n",
       "12                        - 125             0   \n",
       "13                               - 700           237   \n",
       "14                            -   430            14   \n",
       "\n",
       "    contribution abc_class  stocks        doh  \n",
       "0       0.001105         B       0   0.000000  \n",
       "1       0.000000         C       0   0.000000  \n",
       "2       0.000355         C      39  13.000000  \n",
       "3       0.000124         C      10   5.000000  \n",
       "4       0.000497         B      29   9.666667  \n",
       "5       0.000231         C     133  10.230769  \n",
       "6       0.000649         B      77  12.833333  \n",
       "7       0.001054         B      76   8.444444  \n",
       "8       0.000000         C       0   0.000000  \n",
       "9       0.002385         A      67   4.785714  \n",
       "10      0.000585         B      36  12.000000  \n",
       "11      0.000000         C       0   0.000000  \n",
       "12      0.000000         C       0   0.000000  \n",
       "13      0.002554         B      66  11.000000  \n",
       "14      0.000026         C      25  12.500000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add ABC Classification to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge classification data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_classification[['warehouse_id', 'product_id', 'order_count', 'contribution', 'abc_class']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values - products without orders in last 3 months get class 'C'\n",
    "pricing_with_discount['order_count'] = pricing_with_discount['order_count'].fillna(0).astype(int)\n",
    "pricing_with_discount['contribution'] = pricing_with_discount['contribution'].fillna(0)\n",
    "pricing_with_discount['abc_class'] = pricing_with_discount['abc_class'].fillna('C')\n",
    "\n",
    "print(f\"ABC Classification added!\")\n",
    "print(f\"\\nClassification in pricing_with_discount:\")\n",
    "print(pricing_with_discount['abc_class'].value_counts().to_string())\n",
    "print(f\"\\nSample data with classification:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'order_count', 'contribution', 'abc_class', 'stocks', 'doh']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PO data...\n",
      "Loaded 17319 PO records\n",
      "\n",
      "Confirmation status distribution:\n",
      "confirmation_status\n",
      "yes    13190\n",
      "no      3809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PO (Purchase Order) Data Query - Last PO status and rejection count\n",
    "# =============================================================================\n",
    "PO_DATA_QUERY = '''\n",
    "WITH last_data AS (\n",
    "    SELECT product_id, warehouse_id, confirmation_status, PO_date::DATE AS last_po_date, ordered_qty\n",
    "    FROM (\n",
    "        SELECT \n",
    "            product_id,\n",
    "            Target_WAREHOUSE_ID AS warehouse_id,\n",
    "            confirmation_status,\n",
    "            created_at AS PO_date,\n",
    "            MIN_QUANTITY AS ordered_qty,\n",
    "            reason,\n",
    "            MAX(created_at) OVER (PARTITION BY product_id, Target_WAREHOUSE_ID) AS last_po\n",
    "        FROM retool.PO_INITIAL_PLAN\n",
    "        WHERE created_at::DATE >= CURRENT_DATE - 15 \n",
    "    ) x\n",
    "    WHERE last_po = PO_date\n",
    "),\n",
    "\n",
    "last_15_data AS (\n",
    "    SELECT \n",
    "        product_id,\n",
    "        target_WAREHOUSE_ID AS warehouse_id,\n",
    "        COUNT(DISTINCT CASE WHEN confirmation_status <> 'yes' THEN created_at END) AS no_last_15\n",
    "    FROM retool.PO_INITIAL_PLAN\n",
    "    WHERE created_at::DATE >= CURRENT_DATE - 15 \n",
    "    GROUP BY 1, 2\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    ld.product_id,\n",
    "    ld.warehouse_id,\n",
    "    ld.confirmation_status,\n",
    "    ld.last_po_date,\n",
    "    ld.ordered_qty,\n",
    "    COALESCE(lfd.no_last_15, 0) AS no_last_15\n",
    "FROM last_data ld \n",
    "LEFT JOIN last_15_data lfd \n",
    "    ON lfd.product_id = ld.product_id \n",
    "    AND lfd.warehouse_id = ld.warehouse_id\n",
    "'''\n",
    "\n",
    "# Execute PO data query using dwh_pg_query\n",
    "print(\"Loading PO data...\")\n",
    "df_po_data = setup_environment_2.dwh_pg_query(\n",
    "    PO_DATA_QUERY, \n",
    "    columns=['product_id', 'warehouse_id', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']\n",
    ")\n",
    "df_po_data.columns = df_po_data.columns.str.lower()\n",
    "df_po_data = convert_to_numeric(df_po_data)\n",
    "print(f\"Loaded {len(df_po_data)} PO records\")\n",
    "print(f\"\\nConfirmation status distribution:\")\n",
    "print(df_po_data['confirmation_status'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PO data added!\n",
      "\n",
      "Records with PO data: 11437\n",
      "Records without PO data: 53152\n",
      "\n",
      "Sample data with PO info:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>confirmation_status</th>\n",
       "      <th>last_po_date</th>\n",
       "      <th>ordered_qty</th>\n",
       "      <th>no_last_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4966</td>\n",
       "      <td>337</td>\n",
       "      <td>-   - 300 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18964</td>\n",
       "      <td>339</td>\n",
       "      <td>  - 6 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23039</td>\n",
       "      <td>1</td>\n",
       "      <td>    - 365 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20486</td>\n",
       "      <td>337</td>\n",
       "      <td>      - 5 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>142</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-14</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6494</td>\n",
       "      <td>632</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-04</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>161</td>\n",
       "      <td>632</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>8658.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>62</td>\n",
       "      <td>401</td>\n",
       "      <td>  - 1.8 </td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>161</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8636</td>\n",
       "      <td>501</td>\n",
       "      <td>   - 9 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3934</td>\n",
       "      <td>401</td>\n",
       "      <td>     - 2.5 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>143</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>yes</td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>252.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13336</td>\n",
       "      <td>797</td>\n",
       "      <td>   2  3    - 650...</td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-12</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13336</td>\n",
       "      <td>1</td>\n",
       "      <td>   2  3    - 650...</td>\n",
       "      <td>no</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "3         4966           337   \n",
       "4        18964           339   \n",
       "5        23039             1   \n",
       "7        20486           337   \n",
       "9          142           339   \n",
       "13        6494           632   \n",
       "17         161           632   \n",
       "18          62           401   \n",
       "19         161           339   \n",
       "25          28             1   \n",
       "26        8636           501   \n",
       "27        3934           401   \n",
       "28         143           797   \n",
       "29       13336           797   \n",
       "30       13336             1   \n",
       "\n",
       "                                                  sku confirmation_status  \\\n",
       "3                            -   - 300                  yes   \n",
       "4                                  - 6                  yes   \n",
       "5                       - 365                  yes   \n",
       "7            - 5                  yes   \n",
       "9                             - 235                  yes   \n",
       "13                                - 700                  yes   \n",
       "17                             - 8                  yes   \n",
       "18                              - 1.8                   no   \n",
       "19                             - 8                  yes   \n",
       "25                             - 1                  yes   \n",
       "26                              - 9                  yes   \n",
       "27                       - 2.5                  yes   \n",
       "28                               - 235                  yes   \n",
       "29     2  3    - 650...                  no   \n",
       "30     2  3    - 650...                  no   \n",
       "\n",
       "   last_po_date  ordered_qty  no_last_15  \n",
       "3    2026-01-15          2.0           0  \n",
       "4    2026-01-13          3.0           5  \n",
       "5    2026-01-15         12.0           0  \n",
       "7    2026-01-15         42.0           1  \n",
       "9    2026-01-14         20.0           2  \n",
       "13   2026-01-04         48.0           0  \n",
       "17   2026-01-13       8658.0           0  \n",
       "18   2026-01-15         48.0           1  \n",
       "19   2026-01-13         54.0           0  \n",
       "25   2026-01-05         26.0           0  \n",
       "26   2026-01-05         20.0           0  \n",
       "27   2026-01-13          4.0           0  \n",
       "28   2026-01-13        252.0           1  \n",
       "29   2026-01-12          7.0           2  \n",
       "30   2026-01-15         13.0           9  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add PO Data to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge PO data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_po_data[['warehouse_id', 'product_id', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing values\n",
    "pricing_with_discount['ordered_qty'] = pricing_with_discount['ordered_qty'].fillna(0)\n",
    "pricing_with_discount['no_last_15'] = pricing_with_discount['no_last_15'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"PO data added!\")\n",
    "print(f\"\\nRecords with PO data: {len(pricing_with_discount[~pricing_with_discount['confirmation_status'].isna()])}\")\n",
    "print(f\"Records without PO data: {len(pricing_with_discount[pricing_with_discount['confirmation_status'].isna()])}\")\n",
    "print(f\"\\nSample data with PO info:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', 'confirmation_status', 'last_po_date', 'ordered_qty', 'no_last_15']\n",
    "].dropna(subset=['confirmation_status']).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading leadtime data...\n",
      "Loaded 14817 leadtime records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Leadtime Query - Supplier leadtime by brand, category, and warehouse\n",
    "# =============================================================================\n",
    "LEADTIME_QUERY = '''\n",
    "SELECT brand, cat, warehouse_id, leadtime\n",
    "FROM (\n",
    "    SELECT a.*, b.name_ar AS brand, c.name_ar AS cat\n",
    "    FROM (\n",
    "        SELECT DISTINCT \n",
    "            sl.supplier_id, \n",
    "            warehouse_id, \n",
    "            category_id, \n",
    "            brand_id, \n",
    "            sl.updated_at, \n",
    "            leadtime,\n",
    "            MAX(sl.updated_at) OVER (PARTITION BY sl.supplier_id, warehouse_id) AS last_update\n",
    "        FROM retool.SUPPLIER_MOQ sl \n",
    "        JOIN retool.PO_SUPPLIER_MAPPING sm ON sl.supplier_id = sm.supplier_id \n",
    "    ) a\n",
    "    JOIN brands b ON b.id = a.brand_id \n",
    "    JOIN categories c ON c.id = a.category_id\n",
    "    WHERE a.updated_at = last_update\n",
    ") d\n",
    "'''\n",
    "\n",
    "# Execute leadtime query using dwh_pg_query\n",
    "print(\"Loading leadtime data...\")\n",
    "df_leadtime = setup_environment_2.dwh_pg_query(\n",
    "    LEADTIME_QUERY, \n",
    "    columns=['brand', 'cat', 'warehouse_id', 'leadtime']\n",
    ")\n",
    "df_leadtime.columns = df_leadtime.columns.str.lower()\n",
    "df_leadtime = convert_to_numeric(df_leadtime)\n",
    "print(f\"Loaded {len(df_leadtime)} leadtime records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leadtime data added!\n",
      "\n",
      "Records with leadtime: 68380\n",
      "Records without leadtime: 0\n",
      "\n",
      "Leadtime distribution:\n",
      "count    68380.000000\n",
      "mean        55.402164\n",
      "std         30.684771\n",
      "min         24.000000\n",
      "25%         48.000000\n",
      "50%         48.000000\n",
      "75%         72.000000\n",
      "max        168.000000\n",
      "Name: leadtime, dtype: float64\n",
      "\n",
      "Expected receiving day calculated!\n",
      "Records with expected receiving day: 12173\n",
      "\n",
      "Sample data with expected receiving day:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>last_po_date</th>\n",
       "      <th>leadtime</th>\n",
       "      <th>expected_receiving_day</th>\n",
       "      <th>doh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11769</td>\n",
       "      <td>337</td>\n",
       "      <td>   - 330 </td>\n",
       "      <td>2026-01-06</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2026-01-07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4966</td>\n",
       "      <td>337</td>\n",
       "      <td>-   - 300 </td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18964</td>\n",
       "      <td>339</td>\n",
       "      <td>  - 6 </td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>9.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23039</td>\n",
       "      <td>1</td>\n",
       "      <td>    - 365 </td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>10.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20486</td>\n",
       "      <td>337</td>\n",
       "      <td>      - 5 </td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2026-01-16</td>\n",
       "      <td>8.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>142</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>2026-01-14</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>4.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6494</td>\n",
       "      <td>632</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>2026-01-04</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2026-01-06</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>161</td>\n",
       "      <td>632</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>5.211692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>62</td>\n",
       "      <td>401</td>\n",
       "      <td>  - 1.8 </td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>161</td>\n",
       "      <td>339</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>6.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2026-01-07</td>\n",
       "      <td>18.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2026-01-07</td>\n",
       "      <td>18.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8636</td>\n",
       "      <td>501</td>\n",
       "      <td>   - 9 </td>\n",
       "      <td>2026-01-05</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2026-01-06</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3934</td>\n",
       "      <td>401</td>\n",
       "      <td>     - 2.5 </td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2026-01-15</td>\n",
       "      <td>5.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>143</td>\n",
       "      <td>797</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>2026-01-13</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2026-01-14</td>\n",
       "      <td>9.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id                                             sku  \\\n",
       "0        11769           337                         - 330    \n",
       "3         4966           337                        -   - 300    \n",
       "4        18964           339                              - 6    \n",
       "5        23039             1                   - 365    \n",
       "7        20486           337        - 5    \n",
       "9          142           339                         - 235    \n",
       "13        6494           632                             - 700    \n",
       "17         161           632                          - 8    \n",
       "18          62           401                           - 1.8    \n",
       "19         161           339                          - 8    \n",
       "25          28             1                          - 1    \n",
       "26          28             1                          - 1    \n",
       "27        8636           501                           - 9    \n",
       "28        3934           401                    - 2.5    \n",
       "29         143           797                            - 235    \n",
       "\n",
       "   last_po_date  leadtime expected_receiving_day        doh  \n",
       "0    2026-01-06      24.0             2026-01-07   0.000000  \n",
       "3    2026-01-15      48.0             2026-01-17   5.000000  \n",
       "4    2026-01-13      48.0             2026-01-15   9.666667  \n",
       "5    2026-01-15      48.0             2026-01-17  10.230769  \n",
       "7    2026-01-15      24.0             2026-01-16   8.444444  \n",
       "9    2026-01-14      24.0             2026-01-15   4.785714  \n",
       "13   2026-01-04      48.0             2026-01-06  11.000000  \n",
       "17   2026-01-13      48.0             2026-01-15   5.211692  \n",
       "18   2026-01-15      48.0             2026-01-17   0.000000  \n",
       "19   2026-01-13      48.0             2026-01-15   6.916667  \n",
       "25   2026-01-05      48.0             2026-01-07  18.400000  \n",
       "26   2026-01-05      48.0             2026-01-07  18.400000  \n",
       "27   2026-01-05      24.0             2026-01-06  10.000000  \n",
       "28   2026-01-13      48.0             2026-01-15   5.166667  \n",
       "29   2026-01-13      24.0             2026-01-14   9.642857  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Leadtime to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge leadtime data with pricing_with_discount (by brand, cat, warehouse_id)\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_leadtime[['brand', 'cat', 'warehouse_id', 'leadtime']], \n",
    "    on=['brand', 'cat', 'warehouse_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing leadtime with 0 or a default value\n",
    "pricing_with_discount['leadtime'] = pricing_with_discount['leadtime'].fillna(72)\n",
    "\n",
    "\n",
    "print(f\"Leadtime data added!\")\n",
    "print(f\"\\nRecords with leadtime: {len(pricing_with_discount[pricing_with_discount['leadtime'] > 0])}\")\n",
    "print(f\"Records without leadtime: {len(pricing_with_discount[pricing_with_discount['leadtime'] == 0])}\")\n",
    "print(f\"\\nLeadtime distribution:\")\n",
    "print(pricing_with_discount['leadtime'].describe())\n",
    "\n",
    "# =============================================================================\n",
    "# Calculate Expected Receiving Day\n",
    "# If confirmation_status is 'no': add 2 extra days (48 hours) before adding leadtime\n",
    "# expected_receiving_day = last_po_date + ((2 + leadtime) / 24) if not confirmed\n",
    "# expected_receiving_day = last_po_date + (leadtime / 24) if confirmed\n",
    "# =============================================================================\n",
    "\n",
    "# Convert last_po_date to datetime if not already\n",
    "pricing_with_discount['last_po_date'] = pd.to_datetime(pricing_with_discount['last_po_date'], errors='coerce')\n",
    "\n",
    "# Calculate adjusted leadtime: add 48 hours (2 days) if confirmation_status is 'no'\n",
    "pricing_with_discount['adjusted_leadtime'] = np.where(\n",
    "    pricing_with_discount['confirmation_status'].str.lower() == 'no',\n",
    "    pricing_with_discount['leadtime'] + 48,  # Add 2 days (48 hours) if not confirmed\n",
    "    pricing_with_discount['leadtime']\n",
    ")\n",
    "\n",
    "# Calculate expected receiving day (leadtime is in hours, divide by 24 for days)\n",
    "pricing_with_discount['expected_receiving_day'] = pricing_with_discount['last_po_date'] + pd.to_timedelta(\n",
    "    pricing_with_discount['adjusted_leadtime'] / 24, unit='D'\n",
    ")\n",
    "\n",
    "print(f\"\\nExpected receiving day calculated!\")\n",
    "print(f\"Records with expected receiving day: {len(pricing_with_discount[~pricing_with_discount['expected_receiving_day'].isna()])}\")\n",
    "print(f\"Records with confirmation_status='no' (added 2 extra days): {len(pricing_with_discount[pricing_with_discount['confirmation_status'].str.lower() == 'no'])}\")\n",
    "print(f\"\\nSample data with expected receiving day:\")\n",
    "pricing_with_discount[~pricing_with_discount['last_po_date'].isna()][\n",
    "    ['product_id', 'warehouse_id', 'sku', 'confirmation_status', 'last_po_date', 'leadtime', 'adjusted_leadtime', 'expected_receiving_day', 'doh']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading margin boundaries data...\n",
      "Loaded 17918 margin boundary records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Margin Boundaries Query - Get optimal, min, max boundaries from PRODUCT_STATISTICS\n",
    "# =============================================================================\n",
    "MARGIN_BOUNDARIES_QUERY = f'''\n",
    "SELECT \n",
    "    region,\n",
    "    product_id,\n",
    "    optimal_bm,\n",
    "    MIN_BOUNDARY,\n",
    "    MAX_BOUNDARY,\n",
    "    MEDIAN_BM\n",
    "FROM (\n",
    "    SELECT \n",
    "        region,\n",
    "        product_id,\n",
    "        target_bm,\n",
    "        optimal_bm,\n",
    "        MIN_BOUNDARY,\n",
    "        MAX_BOUNDARY,\n",
    "        MEDIAN_BM,\n",
    "        MAX(created_at) OVER (PARTITION BY product_id, region) AS max_date,\n",
    "        created_at\n",
    "    FROM materialized_views.PRODUCT_STATISTICS\n",
    "    WHERE created_at::DATE >= DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 60)\n",
    "    QUALIFY max_date = created_at\n",
    ")\n",
    "'''\n",
    "\n",
    "# Execute margin boundaries query\n",
    "print(\"Loading margin boundaries data...\")\n",
    "df_margin_boundaries = query_snowflake(MARGIN_BOUNDARIES_QUERY)\n",
    "df_margin_boundaries.columns = df_margin_boundaries.columns.str.lower()\n",
    "df_margin_boundaries = convert_to_numeric(df_margin_boundaries)\n",
    "print(f\"Loaded {len(df_margin_boundaries)} margin boundary records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin boundaries and tiers added!\n",
      "\n",
      "Records with margin boundaries: 25032\n",
      "Records without margin boundaries: 43348\n",
      "\n",
      "Margin Tier Structure:\n",
      "  margin_tier_below:   effective_min - step (1 below)\n",
      "  margin_tier_1:       effective_min_margin\n",
      "  margin_tier_2:       effective_min + 1*step\n",
      "  margin_tier_3:       effective_min + 2*step\n",
      "  margin_tier_4:       effective_min + 3*step\n",
      "  margin_tier_5:       max_boundary\n",
      "  margin_tier_above_1: max_boundary + 1*step\n",
      "  margin_tier_above_2: max_boundary + 2*step\n",
      "\n",
      "Sample margin tiers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>effective_min_margin</th>\n",
       "      <th>max_boundary</th>\n",
       "      <th>margin_step</th>\n",
       "      <th>margin_tier_below</th>\n",
       "      <th>margin_tier_1</th>\n",
       "      <th>margin_tier_3</th>\n",
       "      <th>margin_tier_5</th>\n",
       "      <th>margin_tier_above_1</th>\n",
       "      <th>margin_tier_above_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11769</td>\n",
       "      <td>   - 330 </td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.081426</td>\n",
       "      <td>0.009857</td>\n",
       "      <td>0.032143</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.061713</td>\n",
       "      <td>0.081426</td>\n",
       "      <td>0.091283</td>\n",
       "      <td>0.101139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12473</td>\n",
       "      <td>    6 + 1   - 7 </td>\n",
       "      <td>0.041076</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.035745</td>\n",
       "      <td>0.041076</td>\n",
       "      <td>0.051738</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>0.067731</td>\n",
       "      <td>0.073062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19964</td>\n",
       "      <td>     1 - 58 </td>\n",
       "      <td>0.030240</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.006990</td>\n",
       "      <td>0.023250</td>\n",
       "      <td>0.030240</td>\n",
       "      <td>0.044220</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.065190</td>\n",
       "      <td>0.072180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4966</td>\n",
       "      <td>-   - 300 </td>\n",
       "      <td>0.031189</td>\n",
       "      <td>0.064489</td>\n",
       "      <td>0.008325</td>\n",
       "      <td>0.022865</td>\n",
       "      <td>0.031189</td>\n",
       "      <td>0.047839</td>\n",
       "      <td>0.064489</td>\n",
       "      <td>0.072814</td>\n",
       "      <td>0.081139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18964</td>\n",
       "      <td>  - 6 </td>\n",
       "      <td>0.028548</td>\n",
       "      <td>0.058205</td>\n",
       "      <td>0.007414</td>\n",
       "      <td>0.021133</td>\n",
       "      <td>0.028548</td>\n",
       "      <td>0.043376</td>\n",
       "      <td>0.058205</td>\n",
       "      <td>0.065619</td>\n",
       "      <td>0.073034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23039</td>\n",
       "      <td>    - 365 </td>\n",
       "      <td>0.060180</td>\n",
       "      <td>0.110004</td>\n",
       "      <td>0.012456</td>\n",
       "      <td>0.047724</td>\n",
       "      <td>0.060180</td>\n",
       "      <td>0.085092</td>\n",
       "      <td>0.110004</td>\n",
       "      <td>0.122460</td>\n",
       "      <td>0.134916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6494</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>0.040856</td>\n",
       "      <td>0.084755</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.029881</td>\n",
       "      <td>0.040856</td>\n",
       "      <td>0.062805</td>\n",
       "      <td>0.084755</td>\n",
       "      <td>0.095730</td>\n",
       "      <td>0.106704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20486</td>\n",
       "      <td>      - 5 </td>\n",
       "      <td>0.064372</td>\n",
       "      <td>0.121066</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>0.050198</td>\n",
       "      <td>0.064372</td>\n",
       "      <td>0.092719</td>\n",
       "      <td>0.121066</td>\n",
       "      <td>0.135240</td>\n",
       "      <td>0.149414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>142</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>0.048477</td>\n",
       "      <td>0.070174</td>\n",
       "      <td>0.005424</td>\n",
       "      <td>0.043052</td>\n",
       "      <td>0.048477</td>\n",
       "      <td>0.059325</td>\n",
       "      <td>0.070174</td>\n",
       "      <td>0.075598</td>\n",
       "      <td>0.081023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>74</td>\n",
       "      <td> - 900 </td>\n",
       "      <td>0.132140</td>\n",
       "      <td>0.199122</td>\n",
       "      <td>0.016745</td>\n",
       "      <td>0.115395</td>\n",
       "      <td>0.132140</td>\n",
       "      <td>0.165631</td>\n",
       "      <td>0.199122</td>\n",
       "      <td>0.215867</td>\n",
       "      <td>0.232612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id                                               sku  \\\n",
       "0        11769                           - 330    \n",
       "1        12473      6 + 1   - 7    \n",
       "2        19964         1 - 58    \n",
       "3         4966                          -   - 300    \n",
       "4        18964                                - 6    \n",
       "5        23039                     - 365    \n",
       "6         6494                               - 700    \n",
       "7        20486          - 5    \n",
       "9          142                           - 235    \n",
       "10          74                                   - 900    \n",
       "\n",
       "    effective_min_margin  max_boundary  margin_step  margin_tier_below  \\\n",
       "0               0.042000      0.081426     0.009857           0.032143   \n",
       "1               0.041076      0.062400     0.005331           0.035745   \n",
       "2               0.030240      0.058200     0.006990           0.023250   \n",
       "3               0.031189      0.064489     0.008325           0.022865   \n",
       "4               0.028548      0.058205     0.007414           0.021133   \n",
       "5               0.060180      0.110004     0.012456           0.047724   \n",
       "6               0.040856      0.084755     0.010975           0.029881   \n",
       "7               0.064372      0.121066     0.014174           0.050198   \n",
       "9               0.048477      0.070174     0.005424           0.043052   \n",
       "10              0.132140      0.199122     0.016745           0.115395   \n",
       "\n",
       "    margin_tier_1  margin_tier_3  margin_tier_5  margin_tier_above_1  \\\n",
       "0        0.042000       0.061713       0.081426             0.091283   \n",
       "1        0.041076       0.051738       0.062400             0.067731   \n",
       "2        0.030240       0.044220       0.058200             0.065190   \n",
       "3        0.031189       0.047839       0.064489             0.072814   \n",
       "4        0.028548       0.043376       0.058205             0.065619   \n",
       "5        0.060180       0.085092       0.110004             0.122460   \n",
       "6        0.040856       0.062805       0.084755             0.095730   \n",
       "7        0.064372       0.092719       0.121066             0.135240   \n",
       "9        0.048477       0.059325       0.070174             0.075598   \n",
       "10       0.132140       0.165631       0.199122             0.215867   \n",
       "\n",
       "    margin_tier_above_2  \n",
       "0              0.101139  \n",
       "1              0.073062  \n",
       "2              0.072180  \n",
       "3              0.081139  \n",
       "4              0.073034  \n",
       "5              0.134916  \n",
       "6              0.106704  \n",
       "7              0.149414  \n",
       "9              0.081023  \n",
       "10             0.232612  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Margin Boundaries and Calculate Margin Tiers\n",
    "# Tiers: 1 below min + 5 equally spaced in range + 2 above max = 8 tiers\n",
    "# =============================================================================\n",
    "\n",
    "# Merge margin boundaries with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_margin_boundaries[['region','product_id', 'optimal_bm', 'min_boundary', 'max_boundary', 'median_bm']], \n",
    "    on=['product_id','region'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate the effective minimum margin (min of MIN_BOUNDARY and optimal_bm)\n",
    "pricing_with_discount['effective_min_margin'] = pricing_with_discount[['min_boundary', 'optimal_bm']].min(axis=1)\n",
    "\n",
    "# Calculate step size: (max_boundary - effective_min_margin) / 4\n",
    "# This gives 5 points including both endpoints\n",
    "pricing_with_discount['margin_step'] = (\n",
    "    pricing_with_discount['max_boundary'] - pricing_with_discount['effective_min_margin']\n",
    ") / 4\n",
    "\n",
    "# Calculate the 8 margin tiers:\n",
    "# Tier -1: 1 step below minimum (below_min)\n",
    "# Tiers 1-5: 5 equally spaced margins in [effective_min, max_boundary]\n",
    "# Tier 6-7: 2 steps above maximum\n",
    "\n",
    "# Below minimum (1 step below)\n",
    "pricing_with_discount['margin_tier_below'] = pricing_with_discount['effective_min_margin'] - pricing_with_discount['margin_step']\n",
    "\n",
    "# 5 tiers in range (equally spaced)\n",
    "pricing_with_discount['margin_tier_1'] = pricing_with_discount['effective_min_margin']  # Min\n",
    "pricing_with_discount['margin_tier_2'] = pricing_with_discount['effective_min_margin'] + pricing_with_discount['margin_step']\n",
    "pricing_with_discount['margin_tier_3'] = pricing_with_discount['effective_min_margin'] + 2 * pricing_with_discount['margin_step']\n",
    "pricing_with_discount['margin_tier_4'] = pricing_with_discount['effective_min_margin'] + 3 * pricing_with_discount['margin_step']\n",
    "pricing_with_discount['margin_tier_5'] = pricing_with_discount['max_boundary']  # Max\n",
    "\n",
    "# Above maximum (2 steps above)\n",
    "pricing_with_discount['margin_tier_above_1'] = pricing_with_discount['max_boundary'] + pricing_with_discount['margin_step']\n",
    "pricing_with_discount['margin_tier_above_2'] = pricing_with_discount['max_boundary'] + 2 * pricing_with_discount['margin_step']\n",
    "\n",
    "# Fill NaN values for products without margin boundaries\n",
    "margin_tier_cols = [\n",
    "    'margin_tier_below', 'margin_tier_1', 'margin_tier_2', 'margin_tier_3', \n",
    "    'margin_tier_4', 'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2'\n",
    "]\n",
    "\n",
    "print(f\"Margin boundaries and tiers added!\")\n",
    "print(f\"\\nRecords with margin boundaries: {len(pricing_with_discount[~pricing_with_discount['max_boundary'].isna()])}\")\n",
    "print(f\"Records without margin boundaries: {len(pricing_with_discount[pricing_with_discount['max_boundary'].isna()])}\")\n",
    "\n",
    "print(f\"\\nMargin Tier Structure:\")\n",
    "print(f\"  margin_tier_below:   effective_min - step (1 below)\")\n",
    "print(f\"  margin_tier_1:       effective_min_margin\")\n",
    "print(f\"  margin_tier_2:       effective_min + 1*step\")\n",
    "print(f\"  margin_tier_3:       effective_min + 2*step\")\n",
    "print(f\"  margin_tier_4:       effective_min + 3*step\")\n",
    "print(f\"  margin_tier_5:       max_boundary\")\n",
    "print(f\"  margin_tier_above_1: max_boundary + 1*step\")\n",
    "print(f\"  margin_tier_above_2: max_boundary + 2*step\")\n",
    "\n",
    "print(f\"\\nSample margin tiers:\")\n",
    "pricing_with_discount[~pricing_with_discount['max_boundary'].isna()][\n",
    "    ['product_id', 'sku', 'effective_min_margin', 'max_boundary', 'margin_step',\n",
    "     'margin_tier_below', 'margin_tier_1', 'margin_tier_3', 'margin_tier_5', \n",
    "     'margin_tier_above_1', 'margin_tier_above_2']\n",
    "].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading minimum selling quantity data...\n",
      "Loaded 3884 min selling qty records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Minimum Selling Quantity Query - Get min selling qty per product\n",
    "# =============================================================================\n",
    "MIN_SELLING_QTY_QUERY = f'''\n",
    "SELECT product_id, min_selling_qty\n",
    "FROM (\n",
    "    SELECT *, MIN(basic_unit_count) OVER (PARTITION BY product_id) AS min_selling_qty\n",
    "    FROM (\n",
    "        SELECT DISTINCT\n",
    "            pso.product_id,\n",
    "            pso.PACKING_UNIT_ID,\n",
    "            pup.basic_unit_count,\n",
    "            SUM(pso.total_price) AS nmv,\n",
    "            SUM(pso.total_price) / SUM(nmv) OVER (PARTITION BY pso.product_id) AS cntrb\n",
    "        FROM product_sales_order pso\n",
    "        JOIN PACKING_UNIT_PRODUCTS pup ON pup.product_id = pso.product_id \n",
    "            AND pup.PACKING_UNIT_ID = pso.PACKING_UNIT_ID\n",
    "        JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "        WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "            AND so.sales_order_status_id NOT IN (7, 12)\n",
    "            AND so.channel IN ('telesales', 'retailer')\n",
    "            AND pso.purchased_item_count <> 0\n",
    "        GROUP BY ALL\n",
    "        QUALIFY cntrb > 0.05\n",
    "    )\n",
    "    QUALIFY basic_unit_count = min_selling_qty\n",
    ")\n",
    "'''\n",
    "\n",
    "# Execute min selling qty query\n",
    "print(\"Loading minimum selling quantity data...\")\n",
    "df_min_selling_qty = query_snowflake(MIN_SELLING_QTY_QUERY)\n",
    "df_min_selling_qty = convert_to_numeric(df_min_selling_qty)\n",
    "print(f\"Loaded {len(df_min_selling_qty)} min selling qty records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min selling qty and below_min_stock_flag added!\n",
      "\n",
      "SKUs flagged (zero RR & stocks < min_selling_qty): 107\n",
      "SKUs not flagged: 68273\n",
      "\n",
      "Sample flagged SKUs:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>stocks</th>\n",
       "      <th>min_selling_qty</th>\n",
       "      <th>in_stock_rr</th>\n",
       "      <th>below_min_stock_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>9122</td>\n",
       "      <td>337</td>\n",
       "      <td>       ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>2709</td>\n",
       "      <td>632</td>\n",
       "      <td>     - 170 </td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>964</td>\n",
       "      <td>337</td>\n",
       "      <td>   - 130 </td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>71</td>\n",
       "      <td>632</td>\n",
       "      <td>   - 355 </td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756</th>\n",
       "      <td>2709</td>\n",
       "      <td>236</td>\n",
       "      <td>     - 170 </td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3278</th>\n",
       "      <td>3557</td>\n",
       "      <td>797</td>\n",
       "      <td>     - 150 </td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>9877</td>\n",
       "      <td>797</td>\n",
       "      <td>     - 170 </td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>633</td>\n",
       "      <td>339</td>\n",
       "      <td>     - 140 </td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4364</th>\n",
       "      <td>3558</td>\n",
       "      <td>703</td>\n",
       "      <td>      - 150 </td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>2215</td>\n",
       "      <td>797</td>\n",
       "      <td>      - 14 </td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4937</th>\n",
       "      <td>5343</td>\n",
       "      <td>797</td>\n",
       "      <td>    - 300 </td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>2215</td>\n",
       "      <td>501</td>\n",
       "      <td>      - 14 </td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5449</th>\n",
       "      <td>3558</td>\n",
       "      <td>1</td>\n",
       "      <td>      - 150 </td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5929</th>\n",
       "      <td>944</td>\n",
       "      <td>703</td>\n",
       "      <td>    - 185 </td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7030</th>\n",
       "      <td>2214</td>\n",
       "      <td>339</td>\n",
       "      <td>     3*1  - ...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id  warehouse_id  \\\n",
       "307         9122           337   \n",
       "652         2709           632   \n",
       "1137         964           337   \n",
       "2165          71           632   \n",
       "2756        2709           236   \n",
       "3278        3557           797   \n",
       "3492        9877           797   \n",
       "4239         633           339   \n",
       "4364        3558           703   \n",
       "4847        2215           797   \n",
       "4937        5343           797   \n",
       "5423        2215           501   \n",
       "5449        3558             1   \n",
       "5929         944           703   \n",
       "7030        2214           339   \n",
       "\n",
       "                                                    sku  stocks  \\\n",
       "307          ...       3   \n",
       "652                      - 170        4   \n",
       "1137                        - 130        2   \n",
       "2165                             - 355        4   \n",
       "2756                     - 170       11   \n",
       "3278                       - 150        3   \n",
       "3492                      - 170        6   \n",
       "4239                - 140        7   \n",
       "4364                 - 150        4   \n",
       "4847             - 14        3   \n",
       "4937           - 300        2   \n",
       "5423             - 14        2   \n",
       "5449                 - 150        8   \n",
       "5929                          - 185        3   \n",
       "7030       3*1  - ...       3   \n",
       "\n",
       "      min_selling_qty  in_stock_rr  below_min_stock_flag  \n",
       "307                 4          0.0                     1  \n",
       "652                15          0.0                     1  \n",
       "1137               10          0.0                     1  \n",
       "2165                6          0.0                     1  \n",
       "2756               15          0.0                     1  \n",
       "3278               12          0.0                     1  \n",
       "3492               12          0.0                     1  \n",
       "4239               12          0.0                     1  \n",
       "4364               12          0.0                     1  \n",
       "4847                4          0.0                     1  \n",
       "4937                3          0.0                     1  \n",
       "5423                4          0.0                     1  \n",
       "5449               12          0.0                     1  \n",
       "5929               12          0.0                     1  \n",
       "7030                4          0.0                     1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Min Selling Qty and Below Min Stock Flag to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge min selling qty with pricing_with_discount (by product_id)\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_min_selling_qty[['product_id', 'min_selling_qty']], \n",
    "    on='product_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill missing min_selling_qty with 1 (default)\n",
    "pricing_with_discount['min_selling_qty'] = pricing_with_discount['min_selling_qty'].fillna(1).astype(int)\n",
    "\n",
    "# Create flag: below_min_stock_flag = 1 if (RR = 0 AND stocks > 0 AND stocks < min_selling_qty)\n",
    "pricing_with_discount['below_min_stock_flag'] = np.where(\n",
    "    (pricing_with_discount['in_stock_rr'] == 0) & \n",
    "    (pricing_with_discount['stocks'] > 0) &\n",
    "    (pricing_with_discount['stocks'] < pricing_with_discount['min_selling_qty']),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "print(f\"Min selling qty and below_min_stock_flag added!\")\n",
    "print(f\"\\nSKUs flagged (zero RR & stocks < min_selling_qty): {len(pricing_with_discount[pricing_with_discount['below_min_stock_flag'] == 1])}\")\n",
    "print(f\"SKUs not flagged: {len(pricing_with_discount[pricing_with_discount['below_min_stock_flag'] == 0])}\")\n",
    "print(f\"\\nSample flagged SKUs:\")\n",
    "pricing_with_discount[pricing_with_discount['below_min_stock_flag'] == 1][\n",
    "    ['product_id', 'warehouse_id', 'sku', 'stocks', 'min_selling_qty', 'in_stock_rr', 'below_min_stock_flag']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading yesterday's discount analysis data...\n",
      "Loaded 9090 SKU discount records from yesterday\n",
      "\n",
      "============================================================\n",
      "YESTERDAY'S DISCOUNT ANALYSIS SUMMARY\n",
      "============================================================\n",
      "\n",
      "Total NMV yesterday: 21,827,914\n",
      "SKU Discount NMV: 4,746,944\n",
      "Quantity Discount NMV: 3,361,950\n",
      "\n",
      "NMV by Tier:\n",
      "  Tier 1: 700,080\n",
      "  Tier 2: 1,866,378\n",
      "  Tier 3: 743,998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>total_nmv</th>\n",
       "      <th>sku_discount_nmv</th>\n",
       "      <th>qty_discount_nmv</th>\n",
       "      <th>tier1_nmv</th>\n",
       "      <th>tier2_nmv</th>\n",
       "      <th>tier3_nmv</th>\n",
       "      <th>sku_discount_nmv_cntrb</th>\n",
       "      <th>qty_discount_nmv_cntrb</th>\n",
       "      <th>tier1_nmv_cntrb</th>\n",
       "      <th>tier2_nmv_cntrb</th>\n",
       "      <th>tier3_nmv_cntrb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>589</td>\n",
       "      <td>337758.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>228936.00</td>\n",
       "      <td>3609.25</td>\n",
       "      <td>66241.25</td>\n",
       "      <td>159085.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>67.78</td>\n",
       "      <td>1.07</td>\n",
       "      <td>19.61</td>\n",
       "      <td>47.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>797</td>\n",
       "      <td>589</td>\n",
       "      <td>140522.67</td>\n",
       "      <td>40645.75</td>\n",
       "      <td>121696.25</td>\n",
       "      <td>2802.25</td>\n",
       "      <td>13402.50</td>\n",
       "      <td>105491.5</td>\n",
       "      <td>28.92</td>\n",
       "      <td>86.60</td>\n",
       "      <td>1.99</td>\n",
       "      <td>9.54</td>\n",
       "      <td>75.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>501</td>\n",
       "      <td>161</td>\n",
       "      <td>125926.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>236</td>\n",
       "      <td>62</td>\n",
       "      <td>119986.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>326</td>\n",
       "      <td>99220.00</td>\n",
       "      <td>43013.75</td>\n",
       "      <td>40342.00</td>\n",
       "      <td>14879.00</td>\n",
       "      <td>25463.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.35</td>\n",
       "      <td>40.66</td>\n",
       "      <td>15.00</td>\n",
       "      <td>25.66</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>236</td>\n",
       "      <td>151</td>\n",
       "      <td>98383.75</td>\n",
       "      <td>46429.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>236</td>\n",
       "      <td>8915</td>\n",
       "      <td>98331.31</td>\n",
       "      <td>60296.50</td>\n",
       "      <td>47271.75</td>\n",
       "      <td>2906.75</td>\n",
       "      <td>44365.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.32</td>\n",
       "      <td>48.07</td>\n",
       "      <td>2.96</td>\n",
       "      <td>45.12</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>337</td>\n",
       "      <td>589</td>\n",
       "      <td>92817.25</td>\n",
       "      <td>91257.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>236</td>\n",
       "      <td>326</td>\n",
       "      <td>91280.00</td>\n",
       "      <td>49289.75</td>\n",
       "      <td>32770.25</td>\n",
       "      <td>5629.00</td>\n",
       "      <td>27141.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.00</td>\n",
       "      <td>35.90</td>\n",
       "      <td>6.17</td>\n",
       "      <td>29.73</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>236</td>\n",
       "      <td>7885</td>\n",
       "      <td>90384.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20040.00</td>\n",
       "      <td>6680.00</td>\n",
       "      <td>13360.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22.17</td>\n",
       "      <td>7.39</td>\n",
       "      <td>14.78</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warehouse_id  product_id  total_nmv  sku_discount_nmv  qty_discount_nmv  \\\n",
       "0             1         589  337758.56              0.00         228936.00   \n",
       "1           797         589  140522.67          40645.75         121696.25   \n",
       "2           501         161  125926.50              0.00              0.00   \n",
       "3           236          62  119986.75              0.00              0.00   \n",
       "4             1         326   99220.00          43013.75          40342.00   \n",
       "5           236         151   98383.75          46429.25              0.00   \n",
       "6           236        8915   98331.31          60296.50          47271.75   \n",
       "7           337         589   92817.25          91257.75              0.00   \n",
       "8           236         326   91280.00          49289.75          32770.25   \n",
       "9           236        7885   90384.75              0.00          20040.00   \n",
       "\n",
       "   tier1_nmv  tier2_nmv  tier3_nmv  sku_discount_nmv_cntrb  \\\n",
       "0    3609.25   66241.25   159085.5                    0.00   \n",
       "1    2802.25   13402.50   105491.5                   28.92   \n",
       "2       0.00       0.00        0.0                    0.00   \n",
       "3       0.00       0.00        0.0                    0.00   \n",
       "4   14879.00   25463.00        0.0                   43.35   \n",
       "5       0.00       0.00        0.0                   47.19   \n",
       "6    2906.75   44365.00        0.0                   61.32   \n",
       "7       0.00       0.00        0.0                   98.32   \n",
       "8    5629.00   27141.25        0.0                   54.00   \n",
       "9    6680.00   13360.00        0.0                    0.00   \n",
       "\n",
       "   qty_discount_nmv_cntrb  tier1_nmv_cntrb  tier2_nmv_cntrb  tier3_nmv_cntrb  \n",
       "0                   67.78             1.07            19.61            47.10  \n",
       "1                   86.60             1.99             9.54            75.07  \n",
       "2                    0.00             0.00             0.00             0.00  \n",
       "3                    0.00             0.00             0.00             0.00  \n",
       "4                   40.66            15.00            25.66             0.00  \n",
       "5                    0.00             0.00             0.00             0.00  \n",
       "6                   48.07             2.96            45.12             0.00  \n",
       "7                    0.00             0.00             0.00             0.00  \n",
       "8                   35.90             6.17            29.73             0.00  \n",
       "9                   22.17             7.39            14.78             0.00  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Yesterday's Discount Analysis Query\n",
    "# Gets: SKU discount, Quantity discount, Tier 1/2/3 NMV breakdown and contributions\n",
    "# =============================================================================\n",
    "YESTERDAY_DISCOUNT_QUERY = f'''\n",
    "WITH qd_det AS (\n",
    "    -- Map dynamic tags to warehouse IDs using name matching\n",
    "    SELECT DISTINCT \n",
    "        dt.id AS tag_id, \n",
    "        dt.name AS tag_name,\n",
    "        REPLACE(w.name, ' ', '') AS warehouse_name,\n",
    "        w.id AS warehouse_id,\n",
    "        warehouse_name ILIKE '%' || CASE \n",
    "            WHEN SPLIT_PART(tag_name, '_', 1) = 'El' THEN SPLIT_PART(tag_name, '_', 2) \n",
    "            ELSE SPLIT_PART(tag_name, '_', 1) \n",
    "        END || '%' AS contains_flag\n",
    "    FROM dynamic_tags dt\n",
    "    JOIN dynamic_taggables dta ON dt.id = dta.dynamic_tag_id \n",
    "    CROSS JOIN warehouses w \n",
    "    WHERE dt.id > 3000\n",
    "        AND dt.name LIKE '%QD_rets%'\n",
    "        AND w.id IN (1, 236, 337, 8, 339, 170, 501, 401, 703, 632, 797, 962)\n",
    "        AND contains_flag = 'true'\n",
    "),\n",
    "\n",
    "qd_config AS (\n",
    "    SELECT * \n",
    "    FROM (\n",
    "        SELECT \n",
    "            product_id,\n",
    "            start_at,\n",
    "            end_at,\n",
    "            packing_unit_id,\n",
    "            id AS qd_id,\n",
    "            qd.warehouse_id,\n",
    "            MAX(CASE WHEN tier = 1 THEN quantity END) AS tier_1_qty,\n",
    "            MAX(CASE WHEN tier = 1 THEN discount_percentage END) AS tier_1_discount_pct,\n",
    "            MAX(CASE WHEN tier = 2 THEN quantity END) AS tier_2_qty,\n",
    "            MAX(CASE WHEN tier = 2 THEN discount_percentage END) AS tier_2_discount_pct,\n",
    "            MAX(CASE WHEN tier = 3 THEN quantity END) AS tier_3_qty,\n",
    "            MAX(CASE WHEN tier = 3 THEN discount_percentage END) AS tier_3_discount_pct\n",
    "        FROM (\n",
    "            SELECT \n",
    "                qd.id,\n",
    "                qdv.product_id,\n",
    "                qdv.packing_unit_id,\n",
    "                qdv.quantity,\n",
    "                qdv.discount_percentage,\n",
    "                qd.dynamic_tag_id,\n",
    "                qd.start_at,\n",
    "                qd.end_at,\n",
    "                ROW_NUMBER() OVER (\n",
    "                    PARTITION BY qdv.product_id, qdv.packing_unit_id, qd.id \n",
    "                    ORDER BY qdv.quantity\n",
    "                ) AS tier\n",
    "            FROM quantity_discounts qd \n",
    "            JOIN quantity_discount_values qdv ON qd.id = qdv.quantity_discount_id \n",
    "            WHERE CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1 \n",
    "                  BETWEEN qd.start_at::DATE AND qd.end_at::DATE\n",
    "                AND qd.start_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 5\n",
    "        ) qd_tiers\n",
    "        JOIN qd_det qd ON qd.tag_id = qd_tiers.dynamic_tag_id\n",
    "        GROUP BY ALL\n",
    "    )\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY product_id, packing_unit_id, warehouse_id ORDER BY start_at DESC) = 1\n",
    "),\n",
    "\n",
    "-- Get all sales from yesterday\n",
    "yesterday_sales AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        so.retailer_id,\n",
    "        pso.packing_unit_id,\n",
    "        pso.purchased_item_count AS qty,\n",
    "        pso.total_price AS nmv,\n",
    "        pso.item_price / pso.basic_unit_count AS unit_price,\n",
    "        pso.ITEM_DISCOUNT_VALUE AS sku_discount_per_unit,\n",
    "        pso.ITEM_QUANTITY_DISCOUNT_VALUE AS qty_discount_per_unit,\n",
    "        pso.ITEM_DISCOUNT_VALUE * pso.purchased_item_count AS sku_discount_total,\n",
    "        pso.ITEM_QUANTITY_DISCOUNT_VALUE * pso.purchased_item_count AS qty_discount_total,\n",
    "        qd.tier_1_qty,\n",
    "        qd.tier_2_qty,\n",
    "        qd.tier_3_qty,\n",
    "        qd.tier_1_discount_pct,\n",
    "        qd.tier_2_discount_pct,\n",
    "        qd.tier_3_discount_pct,\n",
    "        -- Determine tier used\n",
    "        CASE \n",
    "            WHEN pso.ITEM_QUANTITY_DISCOUNT_VALUE = 0 OR qd.tier_1_qty IS NULL THEN 'Base'\n",
    "            WHEN qd.tier_3_qty IS NOT NULL AND pso.purchased_item_count >= qd.tier_3_qty THEN 'Tier 3'\n",
    "            WHEN qd.tier_2_qty IS NOT NULL AND pso.purchased_item_count >= qd.tier_2_qty THEN 'Tier 2'\n",
    "            WHEN qd.tier_1_qty IS NOT NULL AND pso.purchased_item_count >= qd.tier_1_qty THEN 'Tier 1'\n",
    "            ELSE 'Base'\n",
    "        END AS tier_used\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    LEFT JOIN qd_config qd \n",
    "        ON qd.product_id = pso.product_id \n",
    "        AND qd.packing_unit_id = pso.packing_unit_id\n",
    "        AND qd.warehouse_id = so.warehouse_id\n",
    "    WHERE so.created_at::DATE = CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    warehouse_id,\n",
    "    product_id,\n",
    "    SUM(nmv) AS total_nmv,\n",
    "    SUM(CASE WHEN sku_discount_per_unit > 0 THEN nmv ELSE 0 END) AS sku_discount_nmv,\n",
    "    SUM(CASE WHEN qty_discount_per_unit > 0 THEN nmv ELSE 0 END) AS qty_discount_nmv,\n",
    "    SUM(CASE WHEN tier_used = 'Tier 1' THEN nmv ELSE 0 END) AS tier1_nmv,\n",
    "    SUM(CASE WHEN tier_used = 'Tier 2' THEN nmv ELSE 0 END) AS tier2_nmv,\n",
    "    SUM(CASE WHEN tier_used = 'Tier 3' THEN nmv ELSE 0 END) AS tier3_nmv\n",
    "FROM yesterday_sales\n",
    "GROUP BY warehouse_id, product_id\n",
    "HAVING SUM(nmv) > 0\n",
    "ORDER BY total_nmv DESC\n",
    "'''\n",
    "\n",
    "# Execute yesterday discount query\n",
    "print(\"Loading yesterday's discount analysis data...\")\n",
    "df_yesterday_discount = query_snowflake(YESTERDAY_DISCOUNT_QUERY)\n",
    "df_yesterday_discount = convert_to_numeric(df_yesterday_discount)\n",
    "print(f\"Loaded {len(df_yesterday_discount)} SKU discount records from yesterday\")\n",
    "\n",
    "# Calculate contributions in Python\n",
    "df_yesterday_discount['sku_discount_nmv_cntrb'] = (\n",
    "    df_yesterday_discount['sku_discount_nmv'] / df_yesterday_discount['total_nmv'] * 100\n",
    ").round(2)\n",
    "df_yesterday_discount['qty_discount_nmv_cntrb'] = (\n",
    "    df_yesterday_discount['qty_discount_nmv'] / df_yesterday_discount['total_nmv'] * 100\n",
    ").round(2)\n",
    "df_yesterday_discount['tier1_nmv_cntrb'] = (\n",
    "    df_yesterday_discount['tier1_nmv'] / df_yesterday_discount['total_nmv'] * 100\n",
    ").round(2)\n",
    "df_yesterday_discount['tier2_nmv_cntrb'] = (\n",
    "    df_yesterday_discount['tier2_nmv'] / df_yesterday_discount['total_nmv'] * 100\n",
    ").round(2)\n",
    "df_yesterday_discount['tier3_nmv_cntrb'] = (\n",
    "    df_yesterday_discount['tier3_nmv'] / df_yesterday_discount['total_nmv'] * 100\n",
    ").round(2)\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"YESTERDAY'S DISCOUNT ANALYSIS SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nTotal NMV yesterday: {df_yesterday_discount['total_nmv'].sum():,.0f}\")\n",
    "print(f\"SKU Discount NMV: {df_yesterday_discount['sku_discount_nmv'].sum():,.0f}\")\n",
    "print(f\"Quantity Discount NMV: {df_yesterday_discount['qty_discount_nmv'].sum():,.0f}\")\n",
    "print(f\"\\nNMV by Tier:\")\n",
    "print(f\"  Tier 1: {df_yesterday_discount['tier1_nmv'].sum():,.0f}\")\n",
    "print(f\"  Tier 2: {df_yesterday_discount['tier2_nmv'].sum():,.0f}\")\n",
    "print(f\"  Tier 3: {df_yesterday_discount['tier3_nmv'].sum():,.0f}\")\n",
    "\n",
    "df_yesterday_discount.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yesterday's discount contributions added!\n",
      "\n",
      "SKUs with discount data: 3011\n",
      "\n",
      "Sample data with yesterday's discount contributions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>yesterday_sku_disc_cntrb</th>\n",
       "      <th>yesterday_qty_disc_cntrb</th>\n",
       "      <th>yesterday_t1_cntrb</th>\n",
       "      <th>yesterday_t2_cntrb</th>\n",
       "      <th>yesterday_t3_cntrb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11769</td>\n",
       "      <td>337</td>\n",
       "      <td>   - 330 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12473</td>\n",
       "      <td>337</td>\n",
       "      <td>    6 + 1   - 7 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19964</td>\n",
       "      <td>501</td>\n",
       "      <td>     1 - 58 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4966</td>\n",
       "      <td>337</td>\n",
       "      <td>-   - 300 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18964</td>\n",
       "      <td>339</td>\n",
       "      <td>  - 6 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23039</td>\n",
       "      <td>1</td>\n",
       "      <td>    - 365 </td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6494</td>\n",
       "      <td>236</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>20.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20486</td>\n",
       "      <td>337</td>\n",
       "      <td>      - 5 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24122</td>\n",
       "      <td>632</td>\n",
       "      <td>     7  -   7 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>142</td>\n",
       "      <td>339</td>\n",
       "      <td>   - 235 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>74</td>\n",
       "      <td>797</td>\n",
       "      <td> - 900 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11999</td>\n",
       "      <td>632</td>\n",
       "      <td>     - 185 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11215</td>\n",
       "      <td>501</td>\n",
       "      <td>    - 125 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6494</td>\n",
       "      <td>632</td>\n",
       "      <td>   - 700 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12595</td>\n",
       "      <td>236</td>\n",
       "      <td> -   430 </td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "0        11769           337   \n",
       "1        12473           337   \n",
       "2        19964           501   \n",
       "3         4966           337   \n",
       "4        18964           339   \n",
       "5        23039             1   \n",
       "6         6494           236   \n",
       "7        20486           337   \n",
       "8        24122           632   \n",
       "9          142           339   \n",
       "10          74           797   \n",
       "11       11999           632   \n",
       "12       11215           501   \n",
       "13        6494           632   \n",
       "14       12595           236   \n",
       "\n",
       "                                                 sku  \\\n",
       "0                            - 330    \n",
       "1       6 + 1   - 7    \n",
       "2          1 - 58    \n",
       "3                           -   - 300    \n",
       "4                                 - 6    \n",
       "5                      - 365    \n",
       "6                                - 700    \n",
       "7           - 5    \n",
       "8        7  -   7    \n",
       "9                            - 235    \n",
       "10                                   - 900    \n",
       "11            - 185    \n",
       "12                        - 125    \n",
       "13                               - 700    \n",
       "14                            -   430    \n",
       "\n",
       "    yesterday_sku_disc_cntrb  yesterday_qty_disc_cntrb  yesterday_t1_cntrb  \\\n",
       "0                       0.00                       0.0                 0.0   \n",
       "1                       0.00                       0.0                 0.0   \n",
       "2                       0.00                       0.0                 0.0   \n",
       "3                       0.00                       0.0                 0.0   \n",
       "4                       0.00                       0.0                 0.0   \n",
       "5                      60.00                       0.0                 0.0   \n",
       "6                      20.22                       0.0                 0.0   \n",
       "7                       0.00                       0.0                 0.0   \n",
       "8                       0.00                       0.0                 0.0   \n",
       "9                       0.00                       0.0                 0.0   \n",
       "10                      0.00                       0.0                 0.0   \n",
       "11                      0.00                       0.0                 0.0   \n",
       "12                      0.00                       0.0                 0.0   \n",
       "13                      0.00                       0.0                 0.0   \n",
       "14                      0.00                       0.0                 0.0   \n",
       "\n",
       "    yesterday_t2_cntrb  yesterday_t3_cntrb  \n",
       "0                  0.0                 0.0  \n",
       "1                  0.0                 0.0  \n",
       "2                  0.0                 0.0  \n",
       "3                  0.0                 0.0  \n",
       "4                  0.0                 0.0  \n",
       "5                  0.0                 0.0  \n",
       "6                  0.0                 0.0  \n",
       "7                  0.0                 0.0  \n",
       "8                  0.0                 0.0  \n",
       "9                  0.0                 0.0  \n",
       "10                 0.0                 0.0  \n",
       "11                 0.0                 0.0  \n",
       "12                 0.0                 0.0  \n",
       "13                 0.0                 0.0  \n",
       "14                 0.0                 0.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Yesterday's Discount Analysis to pricing_with_discount (Contributions Only)\n",
    "# =============================================================================\n",
    "\n",
    "# Merge yesterday discount data with pricing_with_discount - only contribution columns\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_yesterday_discount[[\n",
    "        'warehouse_id', 'product_id', \n",
    "        'sku_discount_nmv_cntrb', 'qty_discount_nmv_cntrb',\n",
    "        'tier1_nmv_cntrb', 'tier2_nmv_cntrb', 'tier3_nmv_cntrb'\n",
    "    ]].rename(columns={\n",
    "        'sku_discount_nmv_cntrb': 'yesterday_sku_disc_cntrb',\n",
    "        'qty_discount_nmv_cntrb': 'yesterday_qty_disc_cntrb',\n",
    "        'tier1_nmv_cntrb': 'yesterday_t1_cntrb',\n",
    "        'tier2_nmv_cntrb': 'yesterday_t2_cntrb',\n",
    "        'tier3_nmv_cntrb': 'yesterday_t3_cntrb'\n",
    "    }), \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN for SKUs that had no sales yesterday\n",
    "contrib_cols = [\n",
    "    'yesterday_sku_disc_cntrb', 'yesterday_qty_disc_cntrb',\n",
    "    'yesterday_t1_cntrb', 'yesterday_t2_cntrb', 'yesterday_t3_cntrb'\n",
    "]\n",
    "for col in contrib_cols:\n",
    "    if col in pricing_with_discount.columns:\n",
    "        pricing_with_discount[col] = pricing_with_discount[col].fillna(0)\n",
    "\n",
    "print(f\"Yesterday's discount contributions added!\")\n",
    "print(f\"\\nSKUs with discount data: {len(pricing_with_discount[pricing_with_discount['yesterday_sku_disc_cntrb'] > 0]) + len(pricing_with_discount[pricing_with_discount['yesterday_qty_disc_cntrb'] > 0])}\")\n",
    "print(f\"\\nSample data with yesterday's discount contributions:\")\n",
    "pricing_with_discount[\n",
    "    ['product_id', 'warehouse_id', 'sku', \n",
    "     'yesterday_sku_disc_cntrb', 'yesterday_qty_disc_cntrb',\n",
    "     'yesterday_t1_cntrb', 'yesterday_t2_cntrb', 'yesterday_t3_cntrb']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading performance benchmark data (this may take a moment due to 240-day history)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 293725 benchmark records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>yesterday_qty</th>\n",
       "      <th>recent_7d_qty</th>\n",
       "      <th>recent_7d_in_stock_days</th>\n",
       "      <th>mtd_qty</th>\n",
       "      <th>p80_daily_240d</th>\n",
       "      <th>avg_daily_240d</th>\n",
       "      <th>in_stock_days_240d</th>\n",
       "      <th>p80_7d_sum_240d</th>\n",
       "      <th>p80_mtd_12mo</th>\n",
       "      <th>yesterday_ratio</th>\n",
       "      <th>recent_ratio</th>\n",
       "      <th>mtd_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>337</td>\n",
       "      <td>23251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>703</td>\n",
       "      <td>20030</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>703</td>\n",
       "      <td>19724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>501</td>\n",
       "      <td>5182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>797</td>\n",
       "      <td>7232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>15896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>339</td>\n",
       "      <td>25251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>170</td>\n",
       "      <td>22095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>9379</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>339</td>\n",
       "      <td>103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   warehouse_id  product_id  yesterday_qty  recent_7d_qty  \\\n",
       "0           337       23251              0              0   \n",
       "1           703       20030              0              0   \n",
       "2           703       19724              0              0   \n",
       "3           501        5182              0              0   \n",
       "4           797        7232              0              0   \n",
       "5             8       15896              0              0   \n",
       "6           339       25251              0              0   \n",
       "7           170       22095              0              0   \n",
       "8           501        9379              1              3   \n",
       "9           339         103              0              0   \n",
       "\n",
       "   recent_7d_in_stock_days  mtd_qty  p80_daily_240d  avg_daily_240d  \\\n",
       "0                        0        0             1.0             0.0   \n",
       "1                        0        0             1.0             0.0   \n",
       "2                        0        0             1.0             0.0   \n",
       "3                        0        0             1.0             0.0   \n",
       "4                        0        0             1.0             0.0   \n",
       "5                        0        0             1.0             0.0   \n",
       "6                        0        0             1.0             0.0   \n",
       "7                        0        0             1.0             0.0   \n",
       "8                        7        3             0.0             0.0   \n",
       "9                        0        0             1.0             0.0   \n",
       "\n",
       "   in_stock_days_240d  p80_7d_sum_240d  p80_mtd_12mo  yesterday_ratio  \\\n",
       "0                   0              1.0           0.0              0.0   \n",
       "1                   0              1.0           0.0              0.0   \n",
       "2                   0              1.0           0.0              0.0   \n",
       "3                   0              1.0           0.0              0.0   \n",
       "4                   0              1.0           0.0              0.0   \n",
       "5                   0              1.0           0.0              0.0   \n",
       "6                   0              1.0           1.0              0.0   \n",
       "7                   0              1.0           0.0              0.0   \n",
       "8                 142              0.0           0.0              NaN   \n",
       "9                   0              1.0           0.0              0.0   \n",
       "\n",
       "   recent_ratio  mtd_ratio  \n",
       "0           0.0        NaN  \n",
       "1           0.0        NaN  \n",
       "2           0.0        NaN  \n",
       "3           0.0        NaN  \n",
       "4           0.0        NaN  \n",
       "5           0.0        NaN  \n",
       "6           0.0        0.0  \n",
       "7           0.0        NaN  \n",
       "8           NaN        NaN  \n",
       "9           0.0        NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Performance Benchmark Query\n",
    "# Gets: Yesterday qty, Recent 7d qty, MTD qty, and P80 benchmarks (240 days)\n",
    "# Uses materialized_views.stock_day_close for in-stock determination\n",
    "# =============================================================================\n",
    "PERFORMANCE_BENCHMARK_QUERY = f'''\n",
    "WITH params AS (\n",
    "    SELECT\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE AS today,\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 1 AS yesterday,\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 240 AS history_start,\n",
    "        DATE_TRUNC('month', CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE) AS current_month_start,\n",
    "        DAY(CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE) AS current_day_of_month\n",
    "),\n",
    "\n",
    "-- Daily sales aggregation (240 days)\n",
    "daily_sales AS (\n",
    "    SELECT\n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        so.created_at::DATE AS sale_date,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count) AS daily_qty\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    CROSS JOIN params p\n",
    "    WHERE so.created_at::DATE >= p.history_start\n",
    "        AND so.created_at::DATE < p.today\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id, so.created_at::DATE\n",
    "),\n",
    "\n",
    "-- Daily stock status using stock_day_close\n",
    "-- In-stock = opening (prev day close) > 0 AND closing > 0\n",
    "daily_stock AS (\n",
    "    SELECT\n",
    "        sdc.warehouse_id,\n",
    "        sdc.product_id,\n",
    "        sdc.TIMESTAMP::DATE AS stock_date,\n",
    "        sdc.available_stock,\n",
    "        LAG(sdc.available_stock, 1) OVER (\n",
    "            PARTITION BY sdc.warehouse_id, sdc.product_id \n",
    "            ORDER BY sdc.TIMESTAMP::DATE\n",
    "        ) AS opening_stock,\n",
    "        CASE \n",
    "            WHEN LAG(sdc.available_stock, 1) OVER (\n",
    "                    PARTITION BY sdc.warehouse_id, sdc.product_id ORDER BY sdc.TIMESTAMP::DATE\n",
    "                 ) > 0 \n",
    "                 AND sdc.available_stock > 0 \n",
    "            THEN 1 \n",
    "            ELSE 0 \n",
    "        END AS in_stock_flag\n",
    "    FROM materialized_views.stock_day_close sdc\n",
    "    CROSS JOIN params p\n",
    "    WHERE sdc.TIMESTAMP::DATE >= p.history_start - 1  -- Need one extra day for LAG\n",
    "        AND sdc.TIMESTAMP::DATE < p.today\n",
    "),\n",
    "\n",
    "-- Combine sales with stock status\n",
    "daily_with_stock AS (\n",
    "    SELECT\n",
    "        COALESCE(ds.warehouse_id, st.warehouse_id) AS warehouse_id,\n",
    "        COALESCE(ds.product_id, st.product_id) AS product_id,\n",
    "        COALESCE(ds.sale_date, st.stock_date) AS the_date,\n",
    "        COALESCE(ds.daily_qty, 0) AS daily_qty,\n",
    "        COALESCE(st.in_stock_flag, 0) AS in_stock_flag\n",
    "    FROM daily_sales ds\n",
    "    FULL OUTER JOIN daily_stock st \n",
    "        ON ds.warehouse_id = st.warehouse_id \n",
    "        AND ds.product_id = st.product_id \n",
    "        AND ds.sale_date = st.stock_date\n",
    "    WHERE COALESCE(ds.sale_date, st.stock_date) >= (SELECT history_start FROM params)\n",
    "),\n",
    "\n",
    "-- Calculate P80 benchmark (in-stock days only, 240 days, EXCLUDING last 7 days)\n",
    "p80_daily_benchmark AS (\n",
    "    SELECT\n",
    "        warehouse_id,\n",
    "        product_id,\n",
    "        PERCENTILE_CONT(0.8) WITHIN GROUP (ORDER BY daily_qty) AS p80_daily_240d,\n",
    "        AVG(daily_qty) AS avg_daily_240d,\n",
    "        STDDEV(daily_qty) AS std_daily_240d,\n",
    "        COUNT(*) AS in_stock_days_240d\n",
    "    FROM daily_with_stock\n",
    "    CROSS JOIN params p\n",
    "    WHERE in_stock_flag = 1\n",
    "        AND the_date >= p.history_start\n",
    "        AND the_date < p.today - 7  -- Exclude last 7 days from benchmark\n",
    "    GROUP BY warehouse_id, product_id\n",
    "),\n",
    "\n",
    "-- Calculate 7-day rolling SUM for P80 recent benchmark\n",
    "rolling_7d AS (\n",
    "    SELECT\n",
    "        warehouse_id,\n",
    "        product_id,\n",
    "        the_date,\n",
    "        SUM(daily_qty) OVER (\n",
    "            PARTITION BY warehouse_id, product_id \n",
    "            ORDER BY the_date \n",
    "            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
    "        ) AS rolling_7d_sum,\n",
    "        SUM(in_stock_flag) OVER (\n",
    "            PARTITION BY warehouse_id, product_id \n",
    "            ORDER BY the_date \n",
    "            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW\n",
    "        ) AS in_stock_days_7d\n",
    "    FROM daily_with_stock\n",
    "),\n",
    "\n",
    "p80_7d_benchmark AS (\n",
    "    SELECT\n",
    "        warehouse_id,\n",
    "        product_id,\n",
    "        PERCENTILE_CONT(0.8) WITHIN GROUP (ORDER BY rolling_7d_sum) AS p80_7d_rolling_240d\n",
    "    FROM rolling_7d\n",
    "    CROSS JOIN params p\n",
    "    WHERE the_date >= p.history_start + 7  -- Need 7 days for rolling\n",
    "        AND the_date < p.today - 7  -- Exclude last 7 days from benchmark\n",
    "        AND in_stock_days_7d >= 4  -- At least 4 of 7 days in stock\n",
    "    GROUP BY warehouse_id, product_id\n",
    "),\n",
    "\n",
    "-- MTD benchmark: P80 of same MTD period totals (last 12 months)\n",
    "-- Sum all sales from day 1 to current day of month for each historical month\n",
    "mtd_historical AS (\n",
    "    SELECT\n",
    "        dws.warehouse_id,\n",
    "        dws.product_id,\n",
    "        DATE_TRUNC('month', dws.the_date) AS period_month_start,\n",
    "        SUM(dws.daily_qty) AS mtd_total_qty  -- Sum of all days from 1 to current_day_of_month\n",
    "    FROM daily_with_stock dws\n",
    "    CROSS JOIN params p\n",
    "    WHERE DAY(dws.the_date) <= p.current_day_of_month  -- Only days up to current day of month\n",
    "    GROUP BY dws.warehouse_id, dws.product_id, DATE_TRUNC('month', dws.the_date)\n",
    "),\n",
    "\n",
    "mtd_by_period AS (\n",
    "    SELECT\n",
    "        mh.warehouse_id,\n",
    "        mh.product_id,\n",
    "        mh.period_month_start,\n",
    "        mh.mtd_total_qty AS mtd_qty_at_day  -- Total MTD qty for that month\n",
    "    FROM mtd_historical mh\n",
    "    CROSS JOIN params p\n",
    "    WHERE mh.period_month_start >= DATEADD(month, -12, p.current_month_start)\n",
    "        AND mh.period_month_start < p.current_month_start\n",
    "),\n",
    "\n",
    "p80_mtd_benchmark AS (\n",
    "    SELECT\n",
    "        warehouse_id,\n",
    "        product_id,\n",
    "        PERCENTILE_CONT(0.8) WITHIN GROUP (ORDER BY mtd_qty_at_day) AS p80_mtd_12mo,\n",
    "        AVG(mtd_qty_at_day) AS avg_mtd_12mo\n",
    "    FROM mtd_by_period\n",
    "    GROUP BY warehouse_id, product_id\n",
    "    HAVING COUNT(*) >= 3  -- At least 3 months of data\n",
    "),\n",
    "\n",
    "-- Current period quantities\n",
    "current_metrics AS (\n",
    "    SELECT\n",
    "        warehouse_id,\n",
    "        product_id,\n",
    "        -- Yesterday\n",
    "        SUM(CASE WHEN the_date = (SELECT yesterday FROM params) THEN daily_qty ELSE 0 END) AS yesterday_qty,\n",
    "        -- Recent 7 days\n",
    "        SUM(CASE WHEN the_date >= (SELECT today FROM params) - 7 AND the_date < (SELECT today FROM params) THEN daily_qty ELSE 0 END) AS recent_7d_qty,\n",
    "        SUM(CASE WHEN the_date >= (SELECT today FROM params) - 7 AND the_date < (SELECT today FROM params) AND in_stock_flag = 1 THEN 1 ELSE 0 END) AS recent_7d_in_stock_days,\n",
    "        -- MTD\n",
    "        SUM(CASE WHEN the_date >= (SELECT current_month_start FROM params) AND the_date < (SELECT today FROM params) THEN daily_qty ELSE 0 END) AS mtd_qty\n",
    "    FROM daily_with_stock\n",
    "    GROUP BY warehouse_id, product_id\n",
    ")\n",
    "\n",
    "-- Final output\n",
    "SELECT\n",
    "    cm.warehouse_id,\n",
    "    cm.product_id,\n",
    "    \n",
    "    -- Current period quantities\n",
    "    cm.yesterday_qty,\n",
    "    cm.recent_7d_qty,\n",
    "    cm.recent_7d_in_stock_days,\n",
    "    cm.mtd_qty,\n",
    "    \n",
    "    -- Benchmarks\n",
    "    COALESCE(pb.p80_daily_240d, 1) AS p80_daily_240d,\n",
    "    COALESCE(pb.avg_daily_240d, 0) AS avg_daily_240d,\n",
    "    COALESCE(pb.in_stock_days_240d, 0) AS in_stock_days_240d,\n",
    "    COALESCE(p7.p80_7d_rolling_240d, pb.p80_daily_240d * 7, 1) AS p80_7d_sum_240d,\n",
    "    COALESCE(pm.p80_mtd_12mo, pb.p80_daily_240d * (SELECT current_day_of_month FROM params), 1) AS p80_mtd_12mo,\n",
    "    \n",
    "    -- Performance ratios (all comparing sums to sums)\n",
    "    -- Yesterday: daily qty vs P80 daily\n",
    "    ROUND(cm.yesterday_qty / NULLIF(COALESCE(pb.p80_daily_240d, 1), 0), 2) AS yesterday_ratio,\n",
    "    -- Recent 7d: 7-day sum vs P80 of 7-day sums\n",
    "    ROUND(cm.recent_7d_qty / NULLIF(COALESCE(p7.p80_7d_rolling_240d, pb.p80_daily_240d * 7, 1), 0), 2) AS recent_ratio,\n",
    "    -- MTD: MTD sum vs P80 of historical MTD sums\n",
    "    ROUND(cm.mtd_qty / NULLIF(COALESCE(pm.p80_mtd_12mo, pb.p80_daily_240d * (SELECT current_day_of_month FROM params), 1), 0), 2) AS mtd_ratio\n",
    "\n",
    "FROM current_metrics cm\n",
    "LEFT JOIN p80_daily_benchmark pb ON cm.warehouse_id = pb.warehouse_id AND cm.product_id = pb.product_id\n",
    "LEFT JOIN p80_7d_benchmark p7 ON cm.warehouse_id = p7.warehouse_id AND cm.product_id = p7.product_id\n",
    "LEFT JOIN p80_mtd_benchmark pm ON cm.warehouse_id = pm.warehouse_id AND cm.product_id = pm.product_id\n",
    "where cm.warehouse_id in (1, 236, 337, 8, 339, 170, 501, 401, 703, 632, 797, 962)\n",
    "'''\n",
    "\n",
    "# Execute benchmark query\n",
    "print(\"Loading performance benchmark data (this may take a moment due to 240-day history)...\")\n",
    "df_benchmarks = query_snowflake(PERFORMANCE_BENCHMARK_QUERY)\n",
    "df_benchmarks = convert_to_numeric(df_benchmarks)\n",
    "print(f\"Loaded {len(df_benchmarks)} benchmark records\")\n",
    "\n",
    "# Preview\n",
    "df_benchmarks.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance benchmarks added!\n",
      "\n",
      "============================================================\n",
      "PERFORMANCE STATUS DISTRIBUTION\n",
      "============================================================\n",
      "\n",
      "Yesterday Status:\n",
      "yesterday_status\n",
      "No Data            62272\n",
      "Critical            1568\n",
      "Struggling          1374\n",
      "On Track            1331\n",
      "Star Performer      1001\n",
      "Underperforming      516\n",
      "Over Achiever        318\n",
      "\n",
      "Recent 7d Status:\n",
      "recent_status\n",
      "No Data            56343\n",
      "Critical            3374\n",
      "Struggling          3197\n",
      "On Track            2159\n",
      "Underperforming     1742\n",
      "Star Performer       934\n",
      "Over Achiever        631\n",
      "\n",
      "MTD Status:\n",
      "mtd_status\n",
      "No Data            54863\n",
      "Struggling          3207\n",
      "Critical            3069\n",
      "Underperforming     2439\n",
      "On Track            2430\n",
      "Star Performer      1477\n",
      "Over Achiever        895\n",
      "\n",
      "Combined Status:\n",
      "combined_status\n",
      "No Data            54192\n",
      "Critical            4506\n",
      "Struggling          3759\n",
      "Underperforming     2362\n",
      "On Track            2157\n",
      "Over Achiever        849\n",
      "Star Performer       555\n",
      "\n",
      "============================================================\n",
      "HIGH PERFORMERS (Action Candidates)\n",
      "============================================================\n",
      "High Performers (flag=1): 367\n",
      "Star Performers (flag=1): 234\n",
      "\n",
      "Top 15 Star Performers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>yesterday_ratio</th>\n",
       "      <th>recent_ratio</th>\n",
       "      <th>mtd_ratio</th>\n",
       "      <th>combined_perf_ratio</th>\n",
       "      <th>yesterday_status</th>\n",
       "      <th>combined_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1234</td>\n",
       "      <td>236</td>\n",
       "      <td>   - 350 </td>\n",
       "      <td>7.50</td>\n",
       "      <td>3.09</td>\n",
       "      <td>14.58</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>19687</td>\n",
       "      <td>703</td>\n",
       "      <td>   - 9 </td>\n",
       "      <td>4.00</td>\n",
       "      <td>5.17</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11332</th>\n",
       "      <td>22087</td>\n",
       "      <td>1</td>\n",
       "      <td>     - 460 </td>\n",
       "      <td>20.50</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13476</th>\n",
       "      <td>25288</td>\n",
       "      <td>337</td>\n",
       "      <td>    - 5 </td>\n",
       "      <td>10.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13477</th>\n",
       "      <td>25288</td>\n",
       "      <td>337</td>\n",
       "      <td>    - 5 </td>\n",
       "      <td>10.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13478</th>\n",
       "      <td>25288</td>\n",
       "      <td>337</td>\n",
       "      <td>    - 5 </td>\n",
       "      <td>10.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17826</th>\n",
       "      <td>25286</td>\n",
       "      <td>1</td>\n",
       "      <td>.    - 700 </td>\n",
       "      <td>7.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19794</th>\n",
       "      <td>7573</td>\n",
       "      <td>339</td>\n",
       "      <td>    5  - 30 </td>\n",
       "      <td>5.36</td>\n",
       "      <td>5.67</td>\n",
       "      <td>7.02</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21892</th>\n",
       "      <td>24618</td>\n",
       "      <td>337</td>\n",
       "      <td>   - 24 </td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22578</th>\n",
       "      <td>13486</td>\n",
       "      <td>236</td>\n",
       "      <td>   - 1 </td>\n",
       "      <td>5.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3.83</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23525</th>\n",
       "      <td>161</td>\n",
       "      <td>501</td>\n",
       "      <td>    - 8 </td>\n",
       "      <td>38.34</td>\n",
       "      <td>10.43</td>\n",
       "      <td>6.49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24013</th>\n",
       "      <td>25287</td>\n",
       "      <td>337</td>\n",
       "      <td>  - 60 </td>\n",
       "      <td>9.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24014</th>\n",
       "      <td>25287</td>\n",
       "      <td>337</td>\n",
       "      <td>  - 60 </td>\n",
       "      <td>9.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24015</th>\n",
       "      <td>25287</td>\n",
       "      <td>337</td>\n",
       "      <td>  - 60 </td>\n",
       "      <td>9.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29876</th>\n",
       "      <td>13866</td>\n",
       "      <td>1</td>\n",
       "      <td>     - 15 </td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Star Performer</td>\n",
       "      <td>Star Performer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id  warehouse_id                                      sku  \\\n",
       "541          1234           236                        - 350    \n",
       "4691        19687           703                - 9    \n",
       "11332       22087             1           - 460    \n",
       "13476       25288           337           - 5    \n",
       "13477       25288           337           - 5    \n",
       "13478       25288           337           - 5    \n",
       "17826       25286             1           .    - 700    \n",
       "19794        7573           339      5  - 30    \n",
       "21892       24618           337                  - 24    \n",
       "22578       13486           236                  - 1    \n",
       "23525         161           501                   - 8    \n",
       "24013       25287           337                    - 60    \n",
       "24014       25287           337                    - 60    \n",
       "24015       25287           337                    - 60    \n",
       "29876       13866             1            - 15    \n",
       "\n",
       "       yesterday_ratio  recent_ratio  mtd_ratio  combined_perf_ratio  \\\n",
       "541               7.50          3.09      14.58                  3.0   \n",
       "4691              4.00          5.17       3.53                  3.0   \n",
       "11332            20.50          3.21       3.75                  3.0   \n",
       "13476            10.00         13.00      13.00                  3.0   \n",
       "13477            10.00         13.00      13.00                  3.0   \n",
       "13478            10.00         13.00      13.00                  3.0   \n",
       "17826             7.00          8.00       8.00                  3.0   \n",
       "19794             5.36          5.67       7.02                  3.0   \n",
       "21892             3.00          3.00       3.00                  3.0   \n",
       "22578             5.50          3.50       3.83                  3.0   \n",
       "23525            38.34         10.43       6.49                  3.0   \n",
       "24013             9.00         13.00      13.00                  3.0   \n",
       "24014             9.00         13.00      13.00                  3.0   \n",
       "24015             9.00         13.00      13.00                  3.0   \n",
       "29876             6.00          3.75       3.26                  3.0   \n",
       "\n",
       "      yesterday_status combined_status  \n",
       "541     Star Performer  Star Performer  \n",
       "4691    Star Performer  Star Performer  \n",
       "11332   Star Performer  Star Performer  \n",
       "13476   Star Performer  Star Performer  \n",
       "13477   Star Performer  Star Performer  \n",
       "13478   Star Performer  Star Performer  \n",
       "17826   Star Performer  Star Performer  \n",
       "19794   Star Performer  Star Performer  \n",
       "21892   Star Performer  Star Performer  \n",
       "22578   Star Performer  Star Performer  \n",
       "23525   Star Performer  Star Performer  \n",
       "24013   Star Performer  Star Performer  \n",
       "24014   Star Performer  Star Performer  \n",
       "24015   Star Performer  Star Performer  \n",
       "29876   Star Performer  Star Performer  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Add Performance Benchmarks and Tags to pricing_with_discount\n",
    "# =============================================================================\n",
    "\n",
    "# Merge benchmark data with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_benchmarks[[\n",
    "        'warehouse_id', 'product_id',\n",
    "        'yesterday_qty', 'recent_7d_qty', 'recent_7d_in_stock_days', 'mtd_qty',\n",
    "        'p80_daily_240d', 'avg_daily_240d', 'in_stock_days_240d',\n",
    "        'p80_7d_sum_240d', 'p80_mtd_12mo',\n",
    "        'yesterday_ratio', 'recent_ratio', 'mtd_ratio'\n",
    "    ]], \n",
    "    on=['warehouse_id', 'product_id'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values\n",
    "qty_cols = ['yesterday_qty', 'recent_7d_qty', 'recent_7d_in_stock_days', 'mtd_qty']\n",
    "for col in qty_cols:\n",
    "    pricing_with_discount[col] = pricing_with_discount[col].fillna(0)\n",
    "\n",
    "benchmark_cols = ['p80_daily_240d', 'p80_7d_sum_240d', 'p80_mtd_12mo']\n",
    "for col in benchmark_cols:\n",
    "    pricing_with_discount[col] = pricing_with_discount[col].fillna(1)  # Default to 1 to avoid division issues\n",
    "\n",
    "ratio_cols = ['yesterday_ratio', 'recent_ratio', 'mtd_ratio']\n",
    "for col in ratio_cols:\n",
    "    pricing_with_discount[col] = pricing_with_discount[col].fillna(0)\n",
    "\n",
    "pricing_with_discount['avg_daily_240d'] = pricing_with_discount['avg_daily_240d'].fillna(0)\n",
    "pricing_with_discount['in_stock_days_240d'] = pricing_with_discount['in_stock_days_240d'].fillna(0)\n",
    "\n",
    "# =============================================================================\n",
    "# Performance Tags - Classify each ratio\n",
    "# =============================================================================\n",
    "def get_performance_tag(ratio):\n",
    "    \"\"\"Classify performance based on ratio to benchmark\"\"\"\n",
    "    if pd.isna(ratio) or ratio == 0:\n",
    "        return 'No Data'\n",
    "    elif ratio >= 2.0:\n",
    "        return 'Star Performer'      #  100%+ above benchmark\n",
    "    elif ratio >= 1.5:\n",
    "        return 'Over Achiever'       #  50%+ above benchmark  \n",
    "    elif ratio >= 1.0:\n",
    "        return 'On Track'            #  Meeting benchmark\n",
    "    elif ratio >= 0.7:\n",
    "        return 'Underperforming'     #  Below benchmark\n",
    "    elif ratio >= 0.4:\n",
    "        return 'Struggling'          #  Significantly below\n",
    "    else:\n",
    "        return 'Critical'            #  Needs intervention\n",
    "\n",
    "# Apply tags to each timeframe\n",
    "pricing_with_discount['yesterday_status'] = pricing_with_discount['yesterday_ratio'].apply(get_performance_tag)\n",
    "pricing_with_discount['recent_status'] = pricing_with_discount['recent_ratio'].apply(get_performance_tag)\n",
    "pricing_with_discount['mtd_status'] = pricing_with_discount['mtd_ratio'].apply(get_performance_tag)\n",
    "\n",
    "# =============================================================================\n",
    "# Combined Performance Score (weighted average of ratios)\n",
    "# =============================================================================\n",
    "# Weight: Yesterday 20%, Recent 7d 40%, MTD 40%\n",
    "pricing_with_discount['combined_perf_ratio'] = (\n",
    "    0.2 * pricing_with_discount['yesterday_ratio'].clip(upper=3) +  # Cap at 3x to limit outlier impact\n",
    "    0.4 * pricing_with_discount['recent_ratio'].clip(upper=3) +\n",
    "    0.4 * pricing_with_discount['mtd_ratio'].clip(upper=3)\n",
    ")\n",
    "\n",
    "pricing_with_discount['combined_status'] = pricing_with_discount['combined_perf_ratio'].apply(get_performance_tag)\n",
    "\n",
    "# =============================================================================\n",
    "# High Performer Flag (for immediate action consideration)\n",
    "# =============================================================================\n",
    "# Flag SKUs that are significantly over-achieving and may need action (price increase, etc.)\n",
    "pricing_with_discount['high_performer_flag'] = np.where(\n",
    "    (pricing_with_discount['yesterday_ratio'] >= 1.5) & \n",
    "    (pricing_with_discount['recent_ratio'] >= 1.3) &\n",
    "    (pricing_with_discount['mtd_ratio'] >= 1.2),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "# Star performer flag (exceptional - all metrics 2x+ benchmark)\n",
    "pricing_with_discount['star_performer_flag'] = np.where(\n",
    "    (pricing_with_discount['yesterday_ratio'] >= 2.0) & \n",
    "    (pricing_with_discount['recent_ratio'] >= 1.5) &\n",
    "    (pricing_with_discount['mtd_ratio'] >= 1.5),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# Summary\n",
    "# =============================================================================\n",
    "print(f\"Performance benchmarks added!\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PERFORMANCE STATUS DISTRIBUTION\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nYesterday Status:\")\n",
    "print(pricing_with_discount['yesterday_status'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\nRecent 7d Status:\")\n",
    "print(pricing_with_discount['recent_status'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\nMTD Status:\")\n",
    "print(pricing_with_discount['mtd_status'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\nCombined Status:\")\n",
    "print(pricing_with_discount['combined_status'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"HIGH PERFORMERS (Action Candidates)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"High Performers (flag=1): {len(pricing_with_discount[pricing_with_discount['high_performer_flag'] == 1])}\")\n",
    "print(f\"Star Performers (flag=1): {len(pricing_with_discount[pricing_with_discount['star_performer_flag'] == 1])}\")\n",
    "\n",
    "# Show top performers\n",
    "print(f\"\\nTop 15 Star Performers:\")\n",
    "pricing_with_discount[pricing_with_discount['star_performer_flag'] == 1].nlargest(15, 'combined_perf_ratio')[\n",
    "    ['product_id', 'warehouse_id', 'sku', \n",
    "     'yesterday_ratio', 'recent_ratio', 'mtd_ratio', 'combined_perf_ratio',\n",
    "     'yesterday_status', 'combined_status']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SKUs with NMV in last 4 months...\n",
      "Found 28612 SKU-warehouse combinations with NMV in last 4 months\n",
      "\n",
      "============================================================\n",
      "NO NMV IN LAST 4 MONTHS ANALYSIS\n",
      "============================================================\n",
      "Total records: 68380\n",
      "SKUs with NO NMV in 4 months (no_nmv_4m=1): 48056\n",
      "SKUs with NMV in 4 months (no_nmv_4m=0): 20324\n",
      "\n",
      "Sample SKUs with no NMV in last 4 months:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25983/3044313561.py:18: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[col] = pd.to_numeric(df[col], errors='ignore')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>stocks</th>\n",
       "      <th>in_stock_rr</th>\n",
       "      <th>zero_demand</th>\n",
       "      <th>no_nmv_4m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12473</td>\n",
       "      <td>337</td>\n",
       "      <td>    6 + 1   - 7 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24122</td>\n",
       "      <td>632</td>\n",
       "      <td>     7  -   7 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11999</td>\n",
       "      <td>632</td>\n",
       "      <td>     - 185 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11215</td>\n",
       "      <td>501</td>\n",
       "      <td>    - 125 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1512</td>\n",
       "      <td>401</td>\n",
       "      <td>   - 400 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11</td>\n",
       "      <td>501</td>\n",
       "      <td>    - 55 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>313</td>\n",
       "      <td>797</td>\n",
       "      <td>  - 170 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>286</td>\n",
       "      <td>703</td>\n",
       "      <td>    - 45 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2736</td>\n",
       "      <td>632</td>\n",
       "      <td>   - 50 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>170</td>\n",
       "      <td>337</td>\n",
       "      <td> - 40 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5852</td>\n",
       "      <td>703</td>\n",
       "      <td>    - 400 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20963</td>\n",
       "      <td>401</td>\n",
       "      <td>      - 10 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6224</td>\n",
       "      <td>632</td>\n",
       "      <td>     20  - 1 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>582</td>\n",
       "      <td>337</td>\n",
       "      <td>   - Delisted 16 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>582</td>\n",
       "      <td>337</td>\n",
       "      <td>   - Delisted 16 </td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product_id  warehouse_id  \\\n",
       "1        12473           337   \n",
       "8        24122           632   \n",
       "11       11999           632   \n",
       "12       11215           501   \n",
       "15        1512           401   \n",
       "16          11           501   \n",
       "21         313           797   \n",
       "22         286           703   \n",
       "24        2736           632   \n",
       "32         170           337   \n",
       "33        5852           703   \n",
       "47       20963           401   \n",
       "48        6224           632   \n",
       "50         582           337   \n",
       "51         582           337   \n",
       "\n",
       "                                                  sku  stocks  in_stock_rr  \\\n",
       "1        6 + 1   - 7        0          0.0   \n",
       "8         7  -   7        0          0.0   \n",
       "11             - 185        0          0.0   \n",
       "12                         - 125        0          0.0   \n",
       "15                         - 400        0          0.0   \n",
       "16                           - 55        0          0.0   \n",
       "21                             - 170        0          0.0   \n",
       "22                           - 45        0          0.0   \n",
       "24                         - 50        0          0.0   \n",
       "32                                   - 40        0          0.0   \n",
       "33                       - 400        0          0.0   \n",
       "47        - 10 ...       0          0.0   \n",
       "48             20  - 1        0          0.0   \n",
       "50                      - Delisted 16        0          0.0   \n",
       "51                      - Delisted 16        0          0.0   \n",
       "\n",
       "    zero_demand  no_nmv_4m  \n",
       "1             0          1  \n",
       "8             0          1  \n",
       "11            0          1  \n",
       "12            0          1  \n",
       "15            0          1  \n",
       "16            0          1  \n",
       "21            0          1  \n",
       "22            0          1  \n",
       "24            0          1  \n",
       "32            0          1  \n",
       "33            0          1  \n",
       "47            0          1  \n",
       "48            0          1  \n",
       "50            0          1  \n",
       "51            0          1  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# No NMV in Last 4 Months Flag\n",
    "# Identifies SKUs that have not generated any NMV in the past 4 months (120 days)\n",
    "# =============================================================================\n",
    "NO_NMV_4M_QUERY = f'''\n",
    "WITH nmv_last_4m AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        SUM(pso.total_price) AS total_nmv_4m\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    WHERE so.created_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120\n",
    "        AND so.created_at::DATE < CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id\n",
    "    HAVING SUM(pso.total_price) > 0\n",
    ")\n",
    "SELECT \n",
    "    warehouse_id,\n",
    "    product_id,\n",
    "    total_nmv_4m\n",
    "FROM nmv_last_4m\n",
    "'''\n",
    "\n",
    "# Execute query\n",
    "print(\"Loading SKUs with NMV in last 4 months...\")\n",
    "df_nmv_4m = query_snowflake(NO_NMV_4M_QUERY)\n",
    "df_nmv_4m = convert_to_numeric(df_nmv_4m)\n",
    "print(f\"Found {len(df_nmv_4m)} SKU-warehouse combinations with NMV in last 4 months\")\n",
    "\n",
    "# Merge and create no_nmv_4m flag\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_nmv_4m[['warehouse_id', 'product_id', 'total_nmv_4m']],\n",
    "    on=['warehouse_id', 'product_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Flag SKUs with no NMV in last 4 months\n",
    "# 1 = No NMV (should potentially be filtered), 0 = Has NMV\n",
    "pricing_with_discount['no_nmv_4m'] = np.where(\n",
    "    pricing_with_discount['total_nmv_4m'].isna() | (pricing_with_discount['total_nmv_4m'] == 0),\n",
    "    1, 0\n",
    ")\n",
    "\n",
    "# Fill NaN for total_nmv_4m\n",
    "pricing_with_discount['total_nmv_4m'] = pricing_with_discount['total_nmv_4m'].fillna(0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"NO NMV IN LAST 4 MONTHS ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total records: {len(pricing_with_discount)}\")\n",
    "print(f\"SKUs with NO NMV in 4 months (no_nmv_4m=1): {len(pricing_with_discount[pricing_with_discount['no_nmv_4m'] == 1])}\")\n",
    "print(f\"SKUs with NMV in 4 months (no_nmv_4m=0): {len(pricing_with_discount[pricing_with_discount['no_nmv_4m'] == 0])}\")\n",
    "\n",
    "# Show sample of SKUs with no NMV\n",
    "print(f\"\\nSample SKUs with no NMV in last 4 months:\")\n",
    "pricing_with_discount[pricing_with_discount['no_nmv_4m'] == 1][\n",
    "    ['product_id', 'warehouse_id', 'sku', 'stocks', 'in_stock_rr', 'zero_demand', 'no_nmv_4m']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Normal Refill Query - Avg qty & stddev for frequent retailers (last 120 days)\n",
    "# Frequent retailer definition based on ABC classification (from existing dataframe):\n",
    "#   - Class A: bought 4+ times\n",
    "#   - Class B: bought 3+ times\n",
    "#   - Class C: bought 2+ times\n",
    "# =============================================================================\n",
    "NORMAL_REFILL_QUERY = f'''\n",
    "WITH params AS (\n",
    "    SELECT \n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE AS today,\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE - 120 AS history_start\n",
    "),\n",
    "\n",
    "-- Get retailer order counts per product-warehouse (last 120 days)\n",
    "retailer_orders AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        so.retailer_id,\n",
    "        COUNT(DISTINCT so.id) AS order_count\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    CROSS JOIN params p\n",
    "    WHERE so.created_at::DATE >= p.history_start\n",
    "        AND so.created_at::DATE < p.today\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id, so.retailer_id\n",
    "),\n",
    "\n",
    "-- Get individual order quantities per retailer\n",
    "order_quantities AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        so.retailer_id,\n",
    "        so.id AS order_id,\n",
    "        SUM(pso.purchased_item_count * pso.basic_unit_count) AS order_qty\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    CROSS JOIN params p\n",
    "    WHERE so.created_at::DATE >= p.history_start\n",
    "        AND so.created_at::DATE < p.today\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    "    GROUP BY pso.warehouse_id, pso.product_id, so.retailer_id, so.id\n",
    ")\n",
    "\n",
    "-- Return retailer-level data with order counts for Python filtering\n",
    "SELECT \n",
    "    oq.warehouse_id,\n",
    "    oq.product_id,\n",
    "    oq.retailer_id,\n",
    "    ro.order_count,\n",
    "    oq.order_id,\n",
    "    oq.order_qty\n",
    "FROM order_quantities oq\n",
    "JOIN retailer_orders ro \n",
    "    ON ro.warehouse_id = oq.warehouse_id \n",
    "    AND ro.product_id = oq.product_id \n",
    "    AND ro.retailer_id = oq.retailer_id\n",
    "'''\n",
    "\n",
    "# Execute normal refill query\n",
    "print(\"Loading retailer order data for normal refill calculation (last 120 days)...\")\n",
    "df_retailer_orders = query_snowflake(NORMAL_REFILL_QUERY)\n",
    "df_retailer_orders = convert_to_numeric(df_retailer_orders)\n",
    "print(f\"Loaded {len(df_retailer_orders)} retailer order records\")\n",
    "\n",
    "# Get ABC classification from existing dataframe\n",
    "abc_mapping = pricing_with_discount[['warehouse_id', 'product_id', 'abc_class']].drop_duplicates()\n",
    "print(f\"ABC classification mapping: {len(abc_mapping)} product-warehouse combinations\")\n",
    "\n",
    "# Merge ABC classification into retailer orders\n",
    "df_retailer_orders = df_retailer_orders.merge(\n",
    "    abc_mapping,\n",
    "    on=['warehouse_id', 'product_id'],\n",
    "    how='inner'\n",
    ")\n",
    "print(f\"Records after ABC merge: {len(df_retailer_orders)}\")\n",
    "\n",
    "# Filter frequent retailers based on ABC class thresholds\n",
    "# Class A: 4+ orders, Class B: 3+ orders, Class C: 2+ orders\n",
    "df_frequent = df_retailer_orders[\n",
    "    ((df_retailer_orders['abc_class'] == 'A') & (df_retailer_orders['order_count'] >= 4)) |\n",
    "    ((df_retailer_orders['abc_class'] == 'B') & (df_retailer_orders['order_count'] >= 3)) |\n",
    "    ((df_retailer_orders['abc_class'] == 'C') & (df_retailer_orders['order_count'] >= 2))\n",
    "].copy()\n",
    "print(f\"Records from frequent retailers: {len(df_frequent)}\")\n",
    "\n",
    "# Calculate normal_refill (avg qty) and refill_stddev per product-warehouse\n",
    "df_normal_refill = df_frequent.groupby(['warehouse_id', 'product_id']).agg(\n",
    "    frequent_retailer_count=('retailer_id', 'nunique'),\n",
    "    frequent_order_count=('order_id', 'nunique'),\n",
    "    normal_refill=('order_qty', 'mean'),\n",
    "    refill_stddev=('order_qty', 'std')\n",
    ").reset_index()\n",
    "\n",
    "# Round values and fill NaN stddev (when only 1 order)\n",
    "df_normal_refill['normal_refill'] = df_normal_refill['normal_refill'].round(2)\n",
    "df_normal_refill['refill_stddev'] = df_normal_refill['refill_stddev'].fillna(0).round(2)\n",
    "\n",
    "# Filter to products with at least 2 orders for meaningful stats\n",
    "df_normal_refill = df_normal_refill[df_normal_refill['frequent_order_count'] >= 2]\n",
    "print(f\"Final normal refill records (min 2 orders): {len(df_normal_refill)}\")\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_normal_refill[['warehouse_id', 'product_id', 'frequent_retailer_count', \n",
    "                      'frequent_order_count', 'normal_refill', 'refill_stddev']],\n",
    "    on=['warehouse_id', 'product_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN values\n",
    "pricing_with_discount['frequent_retailer_count'] = pricing_with_discount['frequent_retailer_count'].fillna(0)\n",
    "pricing_with_discount['frequent_order_count'] = pricing_with_discount['frequent_order_count'].fillna(0)\n",
    "pricing_with_discount['normal_refill'] = pricing_with_discount['normal_refill'].fillna(0)\n",
    "pricing_with_discount['refill_stddev'] = pricing_with_discount['refill_stddev'].fillna(0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"NORMAL REFILL ANALYSIS (Frequent Retailers - 120 days)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Records with normal_refill data: {len(pricing_with_discount[pricing_with_discount['normal_refill'] > 0])}\")\n",
    "print(f\"Records without normal_refill data: {len(pricing_with_discount[pricing_with_discount['normal_refill'] == 0])}\")\n",
    "print(f\"\\nNormal refill distribution:\")\n",
    "print(pricing_with_discount[pricing_with_discount['normal_refill'] > 0]['normal_refill'].describe())\n",
    "print(f\"\\nSample data:\")\n",
    "pricing_with_discount[pricing_with_discount['normal_refill'] > 0][\n",
    "    ['product_id', 'warehouse_id', 'sku', 'abc_class', 'frequent_retailer_count', \n",
    "     'frequent_order_count', 'normal_refill', 'refill_stddev', 'in_stock_rr']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Live Cart Rules Query - Get current cart rules from the system\n",
    "# Merges on product_id and cohort_id\n",
    "# =============================================================================\n",
    "LIVE_CART_RULES_QUERY = f'''\n",
    "SELECT \n",
    "    cppu.cohort_id,\n",
    "    pup.product_id,\n",
    "    pup.packing_unit_id,\n",
    "    pup.basic_unit_count,\n",
    "    COALESCE(cppu.MAX_PER_SALES_ORDER, cppu2.MAX_PER_SALES_ORDER) AS current_cart_rule\n",
    "FROM COHORT_PRODUCT_PACKING_UNITS cppu \n",
    "JOIN PACKING_UNIT_PRODUCTS pup ON cppu.PRODUCT_PACKING_UNIT_ID = pup.id \n",
    "JOIN cohorts c ON c.id = cppu.cohort_id\n",
    "LEFT JOIN COHORT_PRODUCT_PACKING_UNITS cppu2 \n",
    "    ON cppu.PRODUCT_PACKING_UNIT_ID = cppu2.PRODUCT_PACKING_UNIT_ID \n",
    "    AND cppu2.cohort_id = c.FALLBACK_COHORT_ID\n",
    "WHERE cppu.cohort_id IN ({','.join(map(str, COHORT_IDS))})\n",
    "'''\n",
    "\n",
    "# Execute live cart rules query\n",
    "print(\"Loading live cart rules...\")\n",
    "df_cart_rules = query_snowflake(LIVE_CART_RULES_QUERY)\n",
    "df_cart_rules = convert_to_numeric(df_cart_rules)\n",
    "print(f\"Loaded {len(df_cart_rules)} cart rule records\")\n",
    "\n",
    "# Aggregate to product-cohort level (take the cart rule for basic unit, or min if multiple)\n",
    "# Filter to basic unit (packing_unit_id where basic_unit_count = 1) for simpler merging\n",
    "df_cart_rules_basic = df_cart_rules[df_cart_rules['basic_unit_count'] == 1].copy()\n",
    "print(f\"Basic unit cart rules: {len(df_cart_rules_basic)}\")\n",
    "\n",
    "# If no basic unit, take the minimum cart rule per product-cohort\n",
    "df_cart_rules_agg = df_cart_rules.groupby(['cohort_id', 'product_id']).agg(\n",
    "    current_cart_rule=('current_cart_rule', 'min')\n",
    ").reset_index()\n",
    "\n",
    "# Prefer basic unit cart rule, fallback to aggregated\n",
    "df_cart_rules_final = df_cart_rules_basic[['cohort_id', 'product_id', 'current_cart_rule']].drop_duplicates()\n",
    "df_cart_rules_final = df_cart_rules_final.merge(\n",
    "    df_cart_rules_agg[['cohort_id', 'product_id', 'current_cart_rule']].rename(columns={'current_cart_rule': 'cart_rule_agg'}),\n",
    "    on=['cohort_id', 'product_id'],\n",
    "    how='outer'\n",
    ")\n",
    "df_cart_rules_final['current_cart_rule'] = df_cart_rules_final['current_cart_rule'].fillna(df_cart_rules_final['cart_rule_agg'])\n",
    "df_cart_rules_final = df_cart_rules_final[['cohort_id', 'product_id', 'current_cart_rule']].drop_duplicates()\n",
    "print(f\"Final cart rules (product-cohort level): {len(df_cart_rules_final)}\")\n",
    "\n",
    "# Merge with pricing_with_discount\n",
    "pricing_with_discount = pricing_with_discount.merge(\n",
    "    df_cart_rules_final,\n",
    "    on=['cohort_id', 'product_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Fill NaN cart rules with 0 (no cart rule set)\n",
    "pricing_with_discount['current_cart_rule'] = pricing_with_discount['current_cart_rule'].fillna(0)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"LIVE CART RULES ANALYSIS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Records with cart rule > 0: {len(pricing_with_discount[pricing_with_discount['current_cart_rule'] > 0])}\")\n",
    "print(f\"Records without cart rule: {len(pricing_with_discount[pricing_with_discount['current_cart_rule'] == 0])}\")\n",
    "print(f\"\\nCart rule distribution:\")\n",
    "print(pricing_with_discount[pricing_with_discount['current_cart_rule'] > 0]['current_cart_rule'].describe())\n",
    "print(f\"\\nSample data with cart rules:\")\n",
    "pricing_with_discount[pricing_with_discount['current_cart_rule'] > 0][\n",
    "    ['product_id', 'cohort_id', 'warehouse_id', 'sku', 'current_price', 'current_cart_rule', 'in_stock_rr']\n",
    "].head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pricing_with_discount[(pricing_with_discount['no_nmv_4m']==0)|(pricing_with_discount['stocks']>0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
