{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientific Marketplace Pricing Analysis\n",
    "\n",
    "This notebook fetches marketplace prices, normalizes them to **unit prices** (per basic unit), and applies scientific outlier detection using **MAD (Median Absolute Deviation)** to produce clean, valid price ranges per product-region.\n",
    "\n",
    "## Key Features:\n",
    "- **Unit price normalization**: All packing units converted to basic unit price (price / BUC)\n",
    "- **Larger sample pools**: All PUs contribute to each product-region analysis\n",
    "- **MAD-based outlier detection**: Robust to up to 50% outliers (Iglewicz & Hoaglin, 1993)\n",
    "- **5 percentile price points**: P10, P25, P50, P75, P90 for full distribution\n",
    "- **WAC validation**: Filter prices within acceptable cost margins\n",
    "\n",
    "## Output Format:\n",
    "- Grouped by **(region, product_id)** only - NO packing unit\n",
    "- All prices are **unit prices** (per basic unit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully!\n",
      "  - MAD Threshold: 3.5\n",
      "  - WAC Range: -40% to 40%\n",
      "  - Percentiles: [10, 25, 50, 75, 90]\n",
      "  - Min Price Points: 3\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - All adjustable parameters in one place\n",
    "# =============================================================================\n",
    "\n",
    "# MAD Outlier Detection Settings\n",
    "# Threshold of 3.5 is the standard recommendation by Iglewicz and Hoaglin (1993)\n",
    "# Lower values = more aggressive outlier removal, Higher values = more permissive\n",
    "MAD_THRESHOLD = 3.5\n",
    "\n",
    "# WAC (Weighted Average Cost) Filter Settings\n",
    "# Prices outside this percentage range from WAC4 will be excluded\n",
    "WAC_LOWER_BOUND = -40  # Minimum acceptable % difference from WAC4\n",
    "WAC_UPPER_BOUND = 40   # Maximum acceptable % difference from WAC4\n",
    "\n",
    "# Percentile Settings for Price Bounds\n",
    "# Define multiple percentiles to get a full price distribution (4-5 price points)\n",
    "PERCENTILES = [10, 25, 50, 75, 90]  # P10, P25, P50 (median), P75, P90\n",
    "\n",
    "# Minimum Price Points Threshold\n",
    "# Product-regions with fewer price points than this will be excluded\n",
    "MIN_PRICE_POINTS = 3  # Minimum for reliable statistics\n",
    "\n",
    "# Sales Data Settings\n",
    "SALES_LOOKBACK_DAYS = 100  # Days to look back for historical sales\n",
    "RECENT_SALES_DAYS = 5      # Days to consider as \"recent\" sales\n",
    "\n",
    "# Display Settings\n",
    "SAMPLE_PRODUCT_ID = 1309  # Product ID to use for sample output verification\n",
    "\n",
    "print(\"Configuration loaded successfully!\")\n",
    "print(f\"  - MAD Threshold: {MAD_THRESHOLD}\")\n",
    "print(f\"  - WAC Range: {WAC_LOWER_BOUND}% to {WAC_UPPER_BOUND}%\")\n",
    "print(f\"  - Percentiles: {PERCENTILES}\")\n",
    "print(f\"  - Min Price Points: {MIN_PRICE_POINTS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n",
      "Environment initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND ENVIRONMENT SETUP\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Initialize environment (for Snowflake credentials)\n",
    "import setup_environment_2\n",
    "import importlib\n",
    "importlib.reload(setup_environment_2)\n",
    "setup_environment_2.initialize_env()\n",
    "\n",
    "print(\"Environment initialized successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def query_snowflake(query, columns=[]):\n",
    "    \"\"\"\n",
    "    Execute a Snowflake query and return results as a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    query : str\n",
    "        SQL query to execute\n",
    "    columns : list\n",
    "        Column names for the resulting DataFrame\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Query results\n",
    "    \"\"\"\n",
    "    import snowflake.connector\n",
    "    \n",
    "    con = snowflake.connector.connect(\n",
    "        user=os.environ[\"SNOWFLAKE_USERNAME\"],\n",
    "        account=os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
    "        password=os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
    "        database=os.environ[\"SNOWFLAKE_DATABASE\"]\n",
    "    )\n",
    "    try:\n",
    "        cur = con.cursor()\n",
    "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
    "        cur.execute(query)\n",
    "        if len(columns) == 0:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()))\n",
    "        else:\n",
    "            out = pd.DataFrame(np.array(cur.fetchall()), columns=columns)\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        cur.close()\n",
    "        con.close()\n",
    "\n",
    "\n",
    "def mad_filter(data, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Apply MAD (Median Absolute Deviation) outlier detection.\n",
    "    \n",
    "    MAD is more robust than standard deviation for non-normal distributions.\n",
    "    It can handle up to 50% outliers, while std breaks down at ~25%.\n",
    "    \n",
    "    The modified Z-score formula:\n",
    "        M_i = 0.6745 * (x_i - median) / MAD\n",
    "    \n",
    "    Where 0.6745 is the consistency constant that makes MAD comparable \n",
    "    to standard deviation for normally distributed data.\n",
    "    \n",
    "    Reference: Iglewicz, B. and Hoaglin, D. (1993), \n",
    "               \"How to Detect and Handle Outliers\"\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array-like\n",
    "        Numeric data to filter\n",
    "    threshold : float\n",
    "        Modified Z-score threshold (default 3.5 per Iglewicz & Hoaglin)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray\n",
    "        Boolean mask where True = inlier, False = outlier\n",
    "    \"\"\"\n",
    "    data = np.array(data, dtype=float)\n",
    "    median = np.median(data)\n",
    "    mad = np.median(np.abs(data - median))\n",
    "    \n",
    "    # Handle edge case where MAD is 0 (all values are the same)\n",
    "    if mad == 0:\n",
    "        return np.ones(len(data), dtype=bool)\n",
    "    \n",
    "    # Calculate modified Z-scores\n",
    "    # 0.6745 is the consistency constant for normal distribution\n",
    "    modified_z_scores = 0.6745 * (data - median) / mad\n",
    "    \n",
    "    return np.abs(modified_z_scores) < threshold\n",
    "\n",
    "\n",
    "def apply_mad_filter_to_group(group, column, threshold=3.5):\n",
    "    \"\"\"\n",
    "    Apply MAD filter to a specific column within a group.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    group : pd.DataFrame\n",
    "        Grouped DataFrame\n",
    "    column : str\n",
    "        Column name to filter on\n",
    "    threshold : float\n",
    "        MAD threshold\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Filtered group with outliers removed\n",
    "    \"\"\"\n",
    "    if len(group) < 3:\n",
    "        # Not enough data points for meaningful outlier detection\n",
    "        return group\n",
    "    \n",
    "    mask = mad_filter(group[column].values, threshold)\n",
    "    return group[mask]\n",
    "\n",
    "\n",
    "def get_percentile_prices(group, column='unit_price', percentiles=[10, 25, 50, 75, 90]):\n",
    "    \"\"\"\n",
    "    Calculate multiple percentile-based unit prices for a group.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    group : pd.DataFrame\n",
    "        Grouped DataFrame\n",
    "    column : str\n",
    "        Column to calculate percentiles on (default: unit_price)\n",
    "    percentiles : list\n",
    "        List of percentiles to calculate (e.g., [10, 25, 50, 75, 90])\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.Series\n",
    "        Statistics including all percentile values and count\n",
    "    \"\"\"\n",
    "    values = group[column].astype(float)\n",
    "    \n",
    "    # Build result dictionary with percentile unit prices\n",
    "    result = {}\n",
    "    for p in percentiles:\n",
    "        result[f'unit_price_p{p}'] = values.quantile(p / 100)\n",
    "    \n",
    "    # Add additional statistics\n",
    "    result['price_count'] = len(values)\n",
    "    result['true_min'] = np.nan\n",
    "    result['true_max'] = values.max()\n",
    "    \n",
    "    return pd.Series(result)\n",
    "\n",
    "\n",
    "def log_filtering_step(df_before, df_after, step_name):\n",
    "    \"\"\"\n",
    "    Log the results of a filtering step.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_before : pd.DataFrame\n",
    "        DataFrame before filtering\n",
    "    df_after : pd.DataFrame\n",
    "        DataFrame after filtering\n",
    "    step_name : str\n",
    "        Name of the filtering step\n",
    "    \"\"\"\n",
    "    rows_removed = len(df_before) - len(df_after)\n",
    "    pct_removed = (rows_removed / len(df_before) * 100) if len(df_before) > 0 else 0\n",
    "    \n",
    "    print(f\"  {step_name}:\")\n",
    "    print(f\"    - Before: {len(df_before):,} rows\")\n",
    "    print(f\"    - After: {len(df_after):,} rows\")\n",
    "    print(f\"    - Removed: {rows_removed:,} rows ({pct_removed:.2f}%)\")\n",
    "\n",
    "\n",
    "print(\"Helper functions loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Fetching\n",
    "\n",
    "Fetch marketplace prices, packing unit mappings, and WAC (cost) data from Snowflake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching marketplace prices...\n",
      "  Fetched 134,632 marketplace price records\n",
      "  Unique products: 6,978\n",
      "  Unique sellers: 131\n",
      "  Regions: ['Delta West', 'Giza', 'Cairo', 'Upper Egypt', 'Delta East', 'Alexandria']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FETCH MARKETPLACE PRICES\n",
    "# =============================================================================\n",
    "# Get active seller prices with region mapping\n",
    "\n",
    "print(\"Fetching marketplace prices...\")\n",
    "\n",
    "mp_query = '''\n",
    "WITH seller_region AS (\n",
    "    SELECT \n",
    "        seller_retailer.retailer_id,\n",
    "        CASE \n",
    "            WHEN regions.name_en = 'Greater Cairo' THEN cities.name_en \n",
    "            ELSE regions.name_en \n",
    "        END AS region,\n",
    "        seller_id,\n",
    "        seller_retailer.POLYGON_ID\n",
    "    FROM MATERIALIZED_VIEWS.SELLERS_RETAILERS_MAPPING seller_retailer\n",
    "    JOIN retailers ON retailers.id = seller_retailer.retailer_id\n",
    "    JOIN materialized_views.retailer_polygon ON materialized_views.retailer_polygon.retailer_id = retailers.id\n",
    "    JOIN districts ON districts.id = materialized_views.retailer_polygon.district_id\n",
    "    JOIN cities ON cities.id = districts.city_id\n",
    "    JOIN states ON states.id = cities.state_id\n",
    "    JOIN regions ON regions.id = states.region_id\n",
    "    JOIN egypt_marketplace.sellers ON sellers.id = seller_retailer.seller_id AND sellers.status = 'ACTIVE'\n",
    "),\n",
    "\n",
    "recent_price AS (\n",
    "    SELECT\n",
    "        wp.product_id AS product_id,\n",
    "        wp.packing_unit_id AS product_pu,\n",
    "        wp.price AS price,\n",
    "        wp.max_per_order,\n",
    "        warehouses.seller_id AS seller_id,\n",
    "        warehouses.MIN_TICKET_SIZE\n",
    "    FROM egypt_marketplace.warehouse_products wp\n",
    "    LEFT JOIN egypt_marketplace.warehouses ON warehouses.id = wp.warehouse_id \n",
    "    WHERE wp.AVAILABLE > 0 \n",
    "        AND wp.total_stock > 0\n",
    "        AND activation = 'true'\n",
    ")\n",
    "\n",
    "SELECT DISTINCT\n",
    "    seller_region.region,\n",
    "    recent_price.*\n",
    "FROM recent_price\n",
    "JOIN seller_region ON seller_region.seller_id = recent_price.seller_id\n",
    "'''\n",
    "\n",
    "mp_raw = query_snowflake(\n",
    "    mp_query, \n",
    "    columns=['region', 'product_id', 'product_pu', 'price', 'max_per_order', 'seller_id', 'min_ticket_size']\n",
    ")\n",
    "\n",
    "# Convert data types\n",
    "for col in ['product_id', 'product_pu', 'price', 'max_per_order', 'seller_id', 'min_ticket_size']:\n",
    "    mp_raw[col] = pd.to_numeric(mp_raw[col])\n",
    "\n",
    "print(f\"  Fetched {len(mp_raw):,} marketplace price records\")\n",
    "print(f\"  Unique products: {mp_raw['product_id'].nunique():,}\")\n",
    "print(f\"  Unique sellers: {mp_raw['seller_id'].nunique():,}\")\n",
    "print(f\"  Regions: {mp_raw['region'].unique().tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching packing unit data...\n",
      "  Fetched 35,071 packing unit mappings\n",
      "  Unique products: 24,774\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FETCH PACKING UNIT DATA\n",
    "# =============================================================================\n",
    "# Get packing unit to product mapping with basic unit count (BUC)\n",
    "\n",
    "print(\"Fetching packing unit data...\")\n",
    "\n",
    "pu_query = '''\n",
    "SELECT\n",
    "    product_id,\n",
    "    PACKING_UNIT_ID AS pu_id,\n",
    "    BASIC_UNIT_COUNT AS buc\n",
    "FROM PACKING_UNIT_PRODUCTS\n",
    "'''\n",
    "\n",
    "packing_units = query_snowflake(pu_query, columns=['product_id', 'pu_id', 'buc'])\n",
    "\n",
    "# Convert data types\n",
    "packing_units['product_id'] = pd.to_numeric(packing_units['product_id'])\n",
    "packing_units['pu_id'] = pd.to_numeric(packing_units['pu_id'])\n",
    "packing_units['buc'] = pd.to_numeric(packing_units['buc'])\n",
    "\n",
    "print(f\"  Fetched {len(packing_units):,} packing unit mappings\")\n",
    "print(f\"  Unique products: {packing_units['product_id'].nunique():,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching WAC data...\n",
      "  Fetched WAC data for 8,157 products\n",
      "  Created PU-level WAC for 35,071 product-PU combinations\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FETCH WAC (WEIGHTED AVERAGE COST) DATA\n",
    "# =============================================================================\n",
    "# Get current cost data for price validation\n",
    "\n",
    "print(\"Fetching WAC data...\")\n",
    "\n",
    "wac_query = '''\n",
    "SELECT \n",
    "    f.product_id,\n",
    "    f.wac1,\n",
    "    f.wac4,\n",
    "    f.wac_p\n",
    "FROM finance.all_cogs f\n",
    "WHERE current_timestamp BETWEEN f.from_date AND f.to_date\n",
    "'''\n",
    "\n",
    "wac_data = query_snowflake(wac_query, columns=['product_id', 'wac1', 'wac4', 'wac_p'])\n",
    "\n",
    "# Convert data types\n",
    "wac_data['product_id'] = pd.to_numeric(wac_data['product_id'])\n",
    "wac_data['wac1'] = pd.to_numeric(wac_data['wac1'])\n",
    "wac_data['wac4'] = pd.to_numeric(wac_data['wac4'])\n",
    "wac_data['wac_p'] = pd.to_numeric(wac_data['wac_p'])\n",
    "\n",
    "print(f\"  Fetched WAC data for {len(wac_data):,} products\")\n",
    "\n",
    "# Create packing unit WAC by joining with BUC\n",
    "pu_wac = pd.merge(packing_units, wac_data, on='product_id', how='left')\n",
    "pu_wac['pu_wac1'] = pu_wac['buc'] * pu_wac['wac1']\n",
    "pu_wac['pu_wac4'] = pu_wac['buc'] * pu_wac['wac4']\n",
    "\n",
    "print(f\"  Created PU-level WAC for {len(pu_wac):,} product-PU combinations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: WAC Mapping and Initial Filtering\n",
    "\n",
    "Map prices to packing units and filter based on WAC4 percentage bounds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2: WAC Mapping and Initial Filtering\n",
      "============================================================\n",
      "\n",
      "After joining with WAC data: 182,624 rows\n",
      "\n",
      "Applying WAC4 filter: -40% to 40%\n",
      "  WAC4 Filter:\n",
      "    - Before: 182,624 rows\n",
      "    - After: 71,111 rows\n",
      "    - Removed: 111,513 rows (61.06%)\n",
      "\n",
      "============================================================\n",
      "STEP 2b: Price Normalization to Basic Unit\n",
      "============================================================\n",
      "Converted 71,111 prices to unit prices\n",
      "  - Original price range: 13.00 - 9600.00\n",
      "  - Unit price range: 3.1998 - 1925.0000\n",
      "\n",
      "Data ready for outlier detection: 71,111 rows\n",
      "Unique products per region: 11,625\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# WAC MAPPING AND INITIAL FILTER\n",
    "# =============================================================================\n",
    "# Join marketplace prices with WAC data and filter by acceptable cost margins\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2: WAC Mapping and Initial Filtering\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Rename column for clarity\n",
    "mp_data = mp_raw.copy()\n",
    "mp_data.rename(columns={'product_pu': 'mp_pu_id'}, inplace=True)\n",
    "\n",
    "# Join with packing unit WAC data\n",
    "mp_with_wac = pd.merge(\n",
    "    mp_data,\n",
    "    pu_wac,\n",
    "    how='inner',\n",
    "    on='product_id'\n",
    ")\n",
    "\n",
    "print(f\"\\nAfter joining with WAC data: {len(mp_with_wac):,} rows\")\n",
    "\n",
    "# Calculate percentage difference from WAC4\n",
    "# Formula: (price - pu_wac4) / pu_wac4 * 100\n",
    "mp_with_wac['wac4_pct_diff'] = (\n",
    "    (mp_with_wac['price'].astype(float) - mp_with_wac['pu_wac4'].astype(float)) \n",
    "    / mp_with_wac['pu_wac4'].astype(float) * 100\n",
    ").round(2)\n",
    "\n",
    "# Apply WAC filter using configurable bounds\n",
    "print(f\"\\nApplying WAC4 filter: {WAC_LOWER_BOUND}% to {WAC_UPPER_BOUND}%\")\n",
    "\n",
    "before_wac_filter = len(mp_with_wac)\n",
    "mp_wac_filtered = mp_with_wac[\n",
    "    (mp_with_wac['wac4_pct_diff'] >= WAC_LOWER_BOUND) & \n",
    "    (mp_with_wac['wac4_pct_diff'] <= WAC_UPPER_BOUND)\n",
    "].copy()\n",
    "\n",
    "log_filtering_step(mp_with_wac, mp_wac_filtered, \"WAC4 Filter\")\n",
    "\n",
    "# =============================================================================\n",
    "# NORMALIZE PRICES TO BASIC UNIT\n",
    "# =============================================================================\n",
    "# Convert all prices to unit price: unit_price = price / basic_unit_count\n",
    "# This pools all packing units into a single analysis per (region, product_id)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 2b: Price Normalization to Basic Unit\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "mp_wac_filtered['unit_price'] = (\n",
    "    mp_wac_filtered['price'].astype(float) / mp_wac_filtered['buc'].astype(float)\n",
    ").round(4)\n",
    "\n",
    "print(f\"Converted {len(mp_wac_filtered):,} prices to unit prices\")\n",
    "print(f\"  - Original price range: {mp_wac_filtered['price'].min():.2f} - {mp_wac_filtered['price'].max():.2f}\")\n",
    "print(f\"  - Unit price range: {mp_wac_filtered['unit_price'].min():.4f} - {mp_wac_filtered['unit_price'].max():.4f}\")\n",
    "\n",
    "# Select relevant columns for further processing (NO pu_id - grouped by product only)\n",
    "mp_clean = mp_wac_filtered[[\n",
    "    'region', 'product_id', 'unit_price', 'max_per_order', \n",
    "    'seller_id', 'min_ticket_size'\n",
    "]].copy()\n",
    "\n",
    "print(f\"\\nData ready for outlier detection: {len(mp_clean):,} rows\")\n",
    "print(f\"Unique products per region: {mp_clean.groupby('region')['product_id'].nunique().sum():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Scientific Outlier Removal (MAD)\n",
    "\n",
    "Apply MAD-based outlier detection to ticket size, max order, and price columns.\n",
    "MAD (Median Absolute Deviation) is robust to up to 50% outliers, making it ideal for marketplace data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3: Scientific Outlier Removal (MAD)\n",
      "============================================================\n",
      "Using MAD threshold: 3.5\n",
      "\n",
      "3.1 Filtering min_ticket_size outliers...\n",
      "  MAD filter on min_ticket_size:\n",
      "    - Before: 71,111 rows\n",
      "    - After: 67,065 rows\n",
      "    - Removed: 4,046 rows (5.69%)\n",
      "\n",
      "3.2 Filtering max_per_order outliers...\n",
      "  MAD filter on max_per_order:\n",
      "    - Before: 67,065 rows\n",
      "    - After: 63,945 rows\n",
      "    - Removed: 3,120 rows (4.65%)\n",
      "\n",
      "3.3 Filtering unit_price outliers...\n",
      "  MAD filter on unit_price:\n",
      "    - Before: 63,945 rows\n",
      "    - After: 61,782 rows\n",
      "    - Removed: 2,163 rows (3.38%)\n",
      "\n",
      "============================================================\n",
      "OUTLIER REMOVAL SUMMARY\n",
      "============================================================\n",
      "Initial records: 71,111\n",
      "Final records: 61,782\n",
      "Total removed: 9,329 (13.12%)\n",
      "Unique products (region-product): 11,625\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SCIENTIFIC OUTLIER REMOVAL USING MAD\n",
    "# =============================================================================\n",
    "# Apply MAD filter to each metric per group (region, product_id)\n",
    "# MAD is more robust than IQR for non-normal distributions\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3: Scientific Outlier Removal (MAD)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Using MAD threshold: {MAD_THRESHOLD}\")\n",
    "\n",
    "# Define grouping columns - NO pu_id since we normalized to unit prices\n",
    "GROUP_COLS = ['region', 'product_id']\n",
    "\n",
    "# Start with WAC-filtered data\n",
    "df = mp_clean.copy()\n",
    "initial_count = len(df)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3.1 Filter outliers in min_ticket_size\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n3.1 Filtering min_ticket_size outliers...\")\n",
    "\n",
    "df_before = df.copy()\n",
    "df = df.groupby(GROUP_COLS, group_keys=False).apply(\n",
    "    lambda g: apply_mad_filter_to_group(g, 'min_ticket_size', MAD_THRESHOLD)\n",
    ")\n",
    "log_filtering_step(df_before, df, \"MAD filter on min_ticket_size\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3.2 Filter outliers in max_per_order\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n3.2 Filtering max_per_order outliers...\")\n",
    "\n",
    "df_before = df.copy()\n",
    "df = df.groupby(GROUP_COLS, group_keys=False).apply(\n",
    "    lambda g: apply_mad_filter_to_group(g, 'max_per_order', MAD_THRESHOLD)\n",
    ")\n",
    "log_filtering_step(df_before, df, \"MAD filter on max_per_order\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3.3 Filter outliers in unit_price\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n3.3 Filtering unit_price outliers...\")\n",
    "\n",
    "df_before = df.copy()\n",
    "df = df.groupby(GROUP_COLS, group_keys=False).apply(\n",
    "    lambda g: apply_mad_filter_to_group(g, 'unit_price', MAD_THRESHOLD)\n",
    ")\n",
    "log_filtering_step(df_before, df, \"MAD filter on unit_price\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Summary\n",
    "# -----------------------------------------------------------------------------\n",
    "mp_filtered = df.copy()\n",
    "final_count = len(mp_filtered)\n",
    "total_removed = initial_count - final_count\n",
    "total_pct = (total_removed / initial_count * 100) if initial_count > 0 else 0\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OUTLIER REMOVAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Initial records: {initial_count:,}\")\n",
    "print(f\"Final records: {final_count:,}\")\n",
    "print(f\"Total removed: {total_removed:,} ({total_pct:.2f}%)\")\n",
    "print(f\"Unique products (region-product): {mp_filtered.groupby(GROUP_COLS).ngroups:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Multi-Percentile Unit Price Calculation\n",
    "\n",
    "Calculate 5 percentile-based **unit prices** (P10, P25, P50, P75, P90) for each product-region. All packing units are pooled together for a larger sample size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4: Unit Price Range Calculation\n",
      "============================================================\n",
      "Calculating percentiles: [10, 25, 50, 75, 90]\n",
      "Grouping by: ['region', 'product_id'] (no packing unit)\n",
      "\n",
      "Generated unit price ranges for 11,625 product-regions\n",
      "\n",
      "Output columns: ['region', 'product_id', 'unit_price_p10', 'unit_price_p25', 'unit_price_p50', 'unit_price_p75', 'unit_price_p90', 'price_count', 'true_min', 'true_max', 'unit_price_mode']\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CALCULATE UNIT PRICE RANGES (MULTIPLE PERCENTILES)\n",
    "# =============================================================================\n",
    "# Compute multiple percentile-based unit prices per product-region\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 4: Unit Price Range Calculation\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Calculating percentiles: {PERCENTILES}\")\n",
    "print(f\"Grouping by: {GROUP_COLS} (no packing unit)\")\n",
    "\n",
    "# Calculate unit price statistics per group with multiple percentiles\n",
    "price_bounds = (\n",
    "    mp_filtered\n",
    "    .groupby(GROUP_COLS)\n",
    "    .apply(lambda g: get_percentile_prices(\n",
    "        g, \n",
    "        column='unit_price', \n",
    "        percentiles=PERCENTILES\n",
    "    ))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Calculate mode unit price per group (most common price point)\n",
    "def calculate_mode_price(group):\n",
    "    \"\"\"Get the mode (most frequent) unit price for a group.\"\"\"\n",
    "    mode_result = group['unit_price'].mode()\n",
    "    return mode_result.iloc[0] if len(mode_result) > 0 else np.nan\n",
    "\n",
    "mode_prices = (\n",
    "    mp_filtered\n",
    "    .groupby(GROUP_COLS)\n",
    "    .apply(calculate_mode_price)\n",
    "    .reset_index(name='unit_price_mode')\n",
    ")\n",
    "\n",
    "# Merge mode prices into price bounds\n",
    "price_bounds = pd.merge(price_bounds, mode_prices, on=GROUP_COLS, how='left')\n",
    "\n",
    "# Round all numeric columns\n",
    "numeric_cols = [f'unit_price_p{p}' for p in PERCENTILES] + ['true_min', 'true_max', 'unit_price_mode']\n",
    "for col in numeric_cols:\n",
    "    if col in price_bounds.columns:\n",
    "        price_bounds[col] = price_bounds[col].round(4)\n",
    "\n",
    "print(f\"\\nGenerated unit price ranges for {len(price_bounds):,} product-regions\")\n",
    "print(f\"\\nOutput columns: {price_bounds.columns.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Sales-Weighted Average (Optional)\n",
    "\n",
    "Calculate weighted average prices based on actual sales NMV to understand market-validated pricing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 5: Sales-Weighted Average Calculation\n",
      "============================================================\n",
      "\n",
      "Fetching historical sales (last 100 days)...\n",
      "  Fetched 51,598 historical sales records\n",
      "\n",
      "Fetching recent sales (last 5 days)...\n",
      "  Fetched 6,112 recent sales records\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FETCH SALES DATA FOR WEIGHTED AVERAGES\n",
    "# =============================================================================\n",
    "# Get historical and recent sales to calculate NMV-weighted average prices\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 5: Sales-Weighted Average Calculation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5.1 Fetch historical sales data\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\nFetching historical sales (last {SALES_LOOKBACK_DAYS} days)...\")\n",
    "\n",
    "historical_sales_query = f'''\n",
    "SELECT\n",
    "    seller_id,\n",
    "    product_id,\n",
    "    packing_unit_id AS pu_id,\n",
    "    item_price,\n",
    "    SUM(sop.total_price) AS nmv\n",
    "FROM egypt_marketplace.sales_orders so\n",
    "JOIN egypt_marketplace.sales_order_products sop ON sop.order_id = so.id\n",
    "WHERE so.status = 6 \n",
    "    AND so.created_at::date >= current_date - {SALES_LOOKBACK_DAYS}\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "mp_sales_historical = query_snowflake(\n",
    "    historical_sales_query, \n",
    "    columns=['seller_id', 'product_id', 'pu_id', 'item_price', 'nmv']\n",
    ")\n",
    "\n",
    "for col in ['seller_id', 'product_id', 'pu_id', 'item_price', 'nmv']:\n",
    "    mp_sales_historical[col] = pd.to_numeric(mp_sales_historical[col])\n",
    "\n",
    "print(f\"  Fetched {len(mp_sales_historical):,} historical sales records\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5.2 Fetch recent sales data\n",
    "# -----------------------------------------------------------------------------\n",
    "print(f\"\\nFetching recent sales (last {RECENT_SALES_DAYS} days)...\")\n",
    "\n",
    "recent_sales_query = f'''\n",
    "SELECT\n",
    "    seller_id,\n",
    "    product_id,\n",
    "    packing_unit_id AS pu_id,\n",
    "    item_price,\n",
    "    SUM(sop.total_price) AS nmv\n",
    "FROM egypt_marketplace.sales_orders so\n",
    "JOIN egypt_marketplace.sales_order_products sop ON sop.order_id = so.id\n",
    "WHERE so.status NOT IN (3, 7, 8)\n",
    "    AND so.created_at::date >= current_date - {RECENT_SALES_DAYS}\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "mp_sales_recent = query_snowflake(\n",
    "    recent_sales_query, \n",
    "    columns=['seller_id', 'product_id', 'pu_id', 'item_price', 'nmv']\n",
    ")\n",
    "\n",
    "for col in ['seller_id', 'product_id', 'pu_id', 'item_price', 'nmv']:\n",
    "    mp_sales_recent[col] = pd.to_numeric(mp_sales_recent[col])\n",
    "\n",
    "print(f\"  Fetched {len(mp_sales_recent):,} recent sales records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating historical weighted average unit prices...\n",
      "  Calculated weighted average for 9,453 product-regions\n",
      "\n",
      "Calculating recent weighted average unit prices...\n",
      "  Calculated recent weighted average for 4,784 product-regions\n",
      "\n",
      "Merged weighted averages: 9,453 product-regions\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CALCULATE WEIGHTED AVERAGE UNIT PRICES\n",
    "# =============================================================================\n",
    "# Join sales with filtered MP data and compute NMV-weighted averages\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5.3 Calculate historical weighted average (using unit_price)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nCalculating historical weighted average unit prices...\")\n",
    "\n",
    "# Join filtered data with historical sales (on seller_id and product_id only)\n",
    "filtered_with_sales = pd.merge(\n",
    "    mp_filtered,\n",
    "    mp_sales_historical,\n",
    "    how='inner',\n",
    "    on=['seller_id', 'product_id']\n",
    ")\n",
    "\n",
    "# Calculate weighted average: sum(unit_price * nmv) / sum(nmv)\n",
    "filtered_with_sales['unit_price'] = pd.to_numeric(filtered_with_sales['unit_price'])\n",
    "filtered_with_sales['nmv'] = pd.to_numeric(filtered_with_sales['nmv'])\n",
    "\n",
    "weighted_avg_historical = (\n",
    "    filtered_with_sales\n",
    "    .groupby(GROUP_COLS)\n",
    "    .apply(lambda g: (g['unit_price'] * g['nmv']).sum() / g['nmv'].sum())\n",
    "    .reset_index(name='weighted_avg_unit_price')\n",
    ")\n",
    "\n",
    "print(f\"  Calculated weighted average for {len(weighted_avg_historical):,} product-regions\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5.4 Calculate recent weighted average (using unit_price)\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\nCalculating recent weighted average unit prices...\")\n",
    "\n",
    "# Join filtered data with recent sales\n",
    "filtered_with_recent = pd.merge(\n",
    "    mp_filtered,\n",
    "    mp_sales_recent,\n",
    "    how='inner',\n",
    "    on=['seller_id', 'product_id']\n",
    ")\n",
    "\n",
    "filtered_with_recent['unit_price'] = pd.to_numeric(filtered_with_recent['unit_price'])\n",
    "filtered_with_recent['nmv'] = pd.to_numeric(filtered_with_recent['nmv'])\n",
    "\n",
    "weighted_avg_recent = (\n",
    "    filtered_with_recent\n",
    "    .groupby(GROUP_COLS)\n",
    "    .apply(lambda g: (g['unit_price'] * g['nmv']).sum() / g['nmv'].sum())\n",
    "    .reset_index(name='weighted_avg_unit_price_recent')\n",
    ")\n",
    "\n",
    "print(f\"  Calculated recent weighted average for {len(weighted_avg_recent):,} product-regions\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5.5 Merge weighted averages\n",
    "# -----------------------------------------------------------------------------\n",
    "weighted_averages = pd.merge(\n",
    "    weighted_avg_historical, \n",
    "    weighted_avg_recent, \n",
    "    on=GROUP_COLS, \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Round values\n",
    "weighted_averages['weighted_avg_unit_price'] = weighted_averages['weighted_avg_unit_price'].round(4)\n",
    "weighted_averages['weighted_avg_unit_price_recent'] = weighted_averages['weighted_avg_unit_price_recent'].round(4)\n",
    "\n",
    "print(f\"\\nMerged weighted averages: {len(weighted_averages):,} product-regions\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Final Output and Validation\n",
    "\n",
    "Merge all data and produce the final clean marketplace price dataset with validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 6: Final Output Generation\n",
      "============================================================\n",
      "\n",
      "Minimum price points filter (>= 3):\n",
      "  - Before: 11,625 product-regions\n",
      "  - After: 5,852 product-regions\n",
      "  - Removed: 5,773 (49.7%)\n",
      "\n",
      "Final dataset: 5,852 product-regions (NO packing unit)\n",
      "\n",
      "Column summary:\n",
      "  - region: 0 nulls (0.0%)\n",
      "  - product_id: 0 nulls (0.0%)\n",
      "  - unit_price_p10: 0 nulls (0.0%)\n",
      "  - unit_price_p25: 0 nulls (0.0%)\n",
      "  - unit_price_p50: 0 nulls (0.0%)\n",
      "  - unit_price_p75: 0 nulls (0.0%)\n",
      "  - unit_price_p90: 0 nulls (0.0%)\n",
      "  - price_count: 0 nulls (0.0%)\n",
      "  - true_min: 5,852 nulls (100.0%)\n",
      "  - true_max: 0 nulls (0.0%)\n",
      "  - unit_price_mode: 0 nulls (0.0%)\n",
      "  - weighted_avg_unit_price: 166 nulls (2.8%)\n",
      "  - weighted_avg_unit_price_recent: 2,261 nulls (38.6%)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL OUTPUT: MERGE ALL DATA\n",
    "# =============================================================================\n",
    "# Combine price bounds with weighted averages for the final dataset\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 6: Final Output Generation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Merge price bounds with weighted averages\n",
    "mp_final = pd.merge(\n",
    "    price_bounds, \n",
    "    weighted_averages, \n",
    "    on=GROUP_COLS, \n",
    "    how='left'  # Keep all price bounds, even without sales data\n",
    ")\n",
    "\n",
    "# Remove duplicates if any\n",
    "mp_final = mp_final.drop_duplicates()\n",
    "\n",
    "# =============================================================================\n",
    "# FILTER BY MINIMUM PRICE POINTS\n",
    "# =============================================================================\n",
    "# Remove product-regions with too few price points for reliable statistics\n",
    "\n",
    "before_min_filter = len(mp_final)\n",
    "mp_final = mp_final[mp_final['price_count'] >= MIN_PRICE_POINTS].copy()\n",
    "after_min_filter = len(mp_final)\n",
    "removed_count = before_min_filter - after_min_filter\n",
    "\n",
    "print(f\"\\nMinimum price points filter (>= {MIN_PRICE_POINTS}):\")\n",
    "print(f\"  - Before: {before_min_filter:,} product-regions\")\n",
    "print(f\"  - After: {after_min_filter:,} product-regions\")\n",
    "print(f\"  - Removed: {removed_count:,} ({(removed_count/before_min_filter*100):.1f}%)\")\n",
    "\n",
    "# Final rounding for unit prices (4 decimal places)\n",
    "numeric_cols = mp_final.select_dtypes(include=[np.number]).columns\n",
    "mp_final[numeric_cols] = mp_final[numeric_cols].round(4)\n",
    "\n",
    "print(f\"\\nFinal dataset: {len(mp_final):,} product-regions (NO packing unit)\")\n",
    "print(f\"\\nColumn summary:\")\n",
    "for col in mp_final.columns:\n",
    "    null_count = mp_final[col].isnull().sum()\n",
    "    null_pct = (null_count / len(mp_final) * 100)\n",
    "    print(f\"  - {col}: {null_count:,} nulls ({null_pct:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDATION: Sample Output\n",
      "============================================================\n",
      "\n",
      "1. Sample output for product_id = 1309:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>product_id</th>\n",
       "      <th>unit_price_p10</th>\n",
       "      <th>unit_price_p25</th>\n",
       "      <th>unit_price_p50</th>\n",
       "      <th>unit_price_p75</th>\n",
       "      <th>unit_price_p90</th>\n",
       "      <th>price_count</th>\n",
       "      <th>true_min</th>\n",
       "      <th>true_max</th>\n",
       "      <th>unit_price_mode</th>\n",
       "      <th>weighted_avg_unit_price</th>\n",
       "      <th>weighted_avg_unit_price_recent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>1309</td>\n",
       "      <td>46.1750</td>\n",
       "      <td>46.5625</td>\n",
       "      <td>46.8750</td>\n",
       "      <td>48.5625</td>\n",
       "      <td>50.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.6667</td>\n",
       "      <td>47.0969</td>\n",
       "      <td>46.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>Cairo</td>\n",
       "      <td>1309</td>\n",
       "      <td>45.9333</td>\n",
       "      <td>46.6667</td>\n",
       "      <td>47.0833</td>\n",
       "      <td>48.0625</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.6667</td>\n",
       "      <td>47.2378</td>\n",
       "      <td>46.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>Delta East</td>\n",
       "      <td>1309</td>\n",
       "      <td>46.3167</td>\n",
       "      <td>46.6667</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>49.1090</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5975</th>\n",
       "      <td>Delta West</td>\n",
       "      <td>1309</td>\n",
       "      <td>46.0083</td>\n",
       "      <td>46.5208</td>\n",
       "      <td>48.0833</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0000</td>\n",
       "      <td>48.5621</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820</th>\n",
       "      <td>Giza</td>\n",
       "      <td>1309</td>\n",
       "      <td>45.9000</td>\n",
       "      <td>46.2500</td>\n",
       "      <td>46.6667</td>\n",
       "      <td>48.0833</td>\n",
       "      <td>50.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.6667</td>\n",
       "      <td>47.1840</td>\n",
       "      <td>46.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9886</th>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>1309</td>\n",
       "      <td>45.9333</td>\n",
       "      <td>46.6667</td>\n",
       "      <td>47.0833</td>\n",
       "      <td>48.0625</td>\n",
       "      <td>50.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>46.6667</td>\n",
       "      <td>47.2378</td>\n",
       "      <td>46.1667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           region  product_id  unit_price_p10  unit_price_p25  unit_price_p50  \\\n",
       "310    Alexandria        1309         46.1750         46.5625         46.8750   \n",
       "2322        Cairo        1309         45.9333         46.6667         47.0833   \n",
       "4362   Delta East        1309         46.3167         46.6667         50.0000   \n",
       "5975   Delta West        1309         46.0083         46.5208         48.0833   \n",
       "7820         Giza        1309         45.9000         46.2500         46.6667   \n",
       "9886  Upper Egypt        1309         45.9333         46.6667         47.0833   \n",
       "\n",
       "      unit_price_p75  unit_price_p90  price_count  true_min  true_max  \\\n",
       "310          48.5625            50.0         12.0       NaN      50.0   \n",
       "2322         48.0625            50.0         14.0       NaN      50.0   \n",
       "4362         50.0000            50.0          5.0       NaN      50.0   \n",
       "5975         50.0000            50.0          8.0       NaN      50.0   \n",
       "7820         48.0833            50.0         13.0       NaN      50.0   \n",
       "9886         48.0625            50.0         14.0       NaN      50.0   \n",
       "\n",
       "      unit_price_mode  weighted_avg_unit_price  weighted_avg_unit_price_recent  \n",
       "310           46.6667                  47.0969                         46.1667  \n",
       "2322          46.6667                  47.2378                         46.1667  \n",
       "4362          50.0000                  49.1090                             NaN  \n",
       "5975          50.0000                  48.5621                             NaN  \n",
       "7820          46.6667                  47.1840                         46.1667  \n",
       "9886          46.6667                  47.2378                         46.1667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Overall unit price range statistics:\n",
      "   - Min P10 unit price: 3.1998\n",
      "   - Max P90 unit price: 1289.0000\n",
      "   - Average spread (P90-P10): 10.6595\n",
      "\n",
      "3. Products per region:\n",
      "   - Cairo: 1,161\n",
      "   - Giza: 1,113\n",
      "   - Upper Egypt: 1,107\n",
      "   - Alexandria: 1,023\n",
      "   - Delta West: 830\n",
      "   - Delta East: 618\n",
      "\n",
      "4. Data quality metrics:\n",
      "   - Total product-regions with unit price ranges: 5,852\n",
      "   - With weighted avg unit price: 5,686\n",
      "   - With recent weighted avg: 3,591\n",
      "   - Average price points per product: 9.2\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# VALIDATION: SAMPLE OUTPUT\n",
    "# =============================================================================\n",
    "# Display sample data for verification\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VALIDATION: Sample Output\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Show sample for a specific product\n",
    "print(f\"\\n1. Sample output for product_id = {SAMPLE_PRODUCT_ID}:\")\n",
    "sample_product = mp_final[mp_final['product_id'] == SAMPLE_PRODUCT_ID]\n",
    "if len(sample_product) > 0:\n",
    "    display(sample_product)\n",
    "else:\n",
    "    print(f\"   No data found for product_id {SAMPLE_PRODUCT_ID}\")\n",
    "\n",
    "# Show summary statistics using min and max percentiles\n",
    "p_min, p_max = PERCENTILES[0], PERCENTILES[-1]\n",
    "print(\"\\n2. Overall unit price range statistics:\")\n",
    "print(f\"   - Min P{p_min} unit price: {mp_final[f'unit_price_p{p_min}'].min():.4f}\")\n",
    "print(f\"   - Max P{p_max} unit price: {mp_final[f'unit_price_p{p_max}'].max():.4f}\")\n",
    "print(f\"   - Average spread (P{p_max}-P{p_min}): {(mp_final[f'unit_price_p{p_max}'] - mp_final[f'unit_price_p{p_min}']).mean():.4f}\")\n",
    "\n",
    "# Show region distribution\n",
    "print(\"\\n3. Products per region:\")\n",
    "region_counts = mp_final.groupby('region').size().sort_values(ascending=False)\n",
    "for region, count in region_counts.items():\n",
    "    print(f\"   - {region}: {count:,}\")\n",
    "\n",
    "# Show data quality metrics\n",
    "print(\"\\n4. Data quality metrics:\")\n",
    "print(f\"   - Total product-regions with unit price ranges: {len(mp_final):,}\")\n",
    "print(f\"   - With weighted avg unit price: {mp_final['weighted_avg_unit_price'].notna().sum():,}\")\n",
    "print(f\"   - With recent weighted avg: {mp_final['weighted_avg_unit_price_recent'].notna().sum():,}\")\n",
    "print(f\"   - Average price points per product: {mp_final['price_count'].mean():.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FINAL OUTPUT: mp_final\n",
      "============================================================\n",
      "\n",
      "DataFrame shape: (5852, 13)\n",
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>product_id</th>\n",
       "      <th>unit_price_p10</th>\n",
       "      <th>unit_price_p25</th>\n",
       "      <th>unit_price_p50</th>\n",
       "      <th>unit_price_p75</th>\n",
       "      <th>unit_price_p90</th>\n",
       "      <th>price_count</th>\n",
       "      <th>true_min</th>\n",
       "      <th>true_max</th>\n",
       "      <th>unit_price_mode</th>\n",
       "      <th>weighted_avg_unit_price</th>\n",
       "      <th>weighted_avg_unit_price_recent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>3</td>\n",
       "      <td>253.0</td>\n",
       "      <td>255.00</td>\n",
       "      <td>255.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>255.1701</td>\n",
       "      <td>252.4904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>9</td>\n",
       "      <td>837.2</td>\n",
       "      <td>840.50</td>\n",
       "      <td>846.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>849.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>850.0</td>\n",
       "      <td>835.0</td>\n",
       "      <td>838.4034</td>\n",
       "      <td>835.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>10</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.00</td>\n",
       "      <td>270.0</td>\n",
       "      <td>272.5</td>\n",
       "      <td>274.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>270.0846</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>17</td>\n",
       "      <td>598.5</td>\n",
       "      <td>603.75</td>\n",
       "      <td>613.5</td>\n",
       "      <td>620.0</td>\n",
       "      <td>625.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>639.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>599.4625</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>18</td>\n",
       "      <td>597.0</td>\n",
       "      <td>601.00</td>\n",
       "      <td>605.0</td>\n",
       "      <td>613.5</td>\n",
       "      <td>620.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>620.0</td>\n",
       "      <td>605.0</td>\n",
       "      <td>604.7631</td>\n",
       "      <td>595.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>23</td>\n",
       "      <td>258.0</td>\n",
       "      <td>260.00</td>\n",
       "      <td>260.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>266.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>259.5825</td>\n",
       "      <td>259.2253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>24</td>\n",
       "      <td>257.7</td>\n",
       "      <td>260.00</td>\n",
       "      <td>260.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>258.3969</td>\n",
       "      <td>259.1697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>25</td>\n",
       "      <td>257.8</td>\n",
       "      <td>260.00</td>\n",
       "      <td>260.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>258.3889</td>\n",
       "      <td>258.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>26</td>\n",
       "      <td>258.0</td>\n",
       "      <td>260.00</td>\n",
       "      <td>262.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>265.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>258.9631</td>\n",
       "      <td>257.7495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Alexandria</td>\n",
       "      <td>27</td>\n",
       "      <td>258.0</td>\n",
       "      <td>260.00</td>\n",
       "      <td>262.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>266.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>259.2696</td>\n",
       "      <td>259.6293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        region  product_id  unit_price_p10  unit_price_p25  unit_price_p50  \\\n",
       "0   Alexandria           3           253.0          255.00           255.0   \n",
       "1   Alexandria           9           837.2          840.50           846.0   \n",
       "2   Alexandria          10           270.0          270.00           270.0   \n",
       "5   Alexandria          17           598.5          603.75           613.5   \n",
       "6   Alexandria          18           597.0          601.00           605.0   \n",
       "7   Alexandria          23           258.0          260.00           260.0   \n",
       "8   Alexandria          24           257.7          260.00           260.0   \n",
       "9   Alexandria          25           257.8          260.00           260.0   \n",
       "10  Alexandria          26           258.0          260.00           262.0   \n",
       "11  Alexandria          27           258.0          260.00           262.0   \n",
       "\n",
       "    unit_price_p75  unit_price_p90  price_count  true_min  true_max  \\\n",
       "0            263.0           265.0          7.0       NaN     265.0   \n",
       "1            848.0           849.2          3.0       NaN     850.0   \n",
       "2            272.5           274.0          3.0       NaN     275.0   \n",
       "5            620.0           625.7          8.0       NaN     639.0   \n",
       "6            613.5           620.0         15.0       NaN     620.0   \n",
       "7            265.0           266.8         22.0       NaN     270.0   \n",
       "8            265.0           267.0         25.0       NaN     270.0   \n",
       "9            264.0           265.0         27.0       NaN     270.0   \n",
       "10           265.0           265.8         27.0       NaN     270.0   \n",
       "11           265.0           266.2         25.0       NaN     270.0   \n",
       "\n",
       "    unit_price_mode  weighted_avg_unit_price  weighted_avg_unit_price_recent  \n",
       "0             255.0                 255.1701                        252.4904  \n",
       "1             835.0                 838.4034                        835.0000  \n",
       "2             270.0                 270.0846                             NaN  \n",
       "5             620.0                 599.4625                             NaN  \n",
       "6             605.0                 604.7631                        595.0000  \n",
       "7             260.0                 259.5825                        259.2253  \n",
       "8             260.0                 258.3969                        259.1697  \n",
       "9             260.0                 258.3889                        258.0507  \n",
       "10            260.0                 258.9631                        257.7495  \n",
       "11            260.0                 259.2696                        259.6293  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "NOTEBOOK COMPLETE\n",
      "============================================================\n",
      "\n",
      "The mp_final DataFrame is ready for use in pricing logic.\n",
      "\n",
      "OUTPUT: Unit prices per (region, product_id) - NO packing unit\n",
      "\n",
      "Key outputs (5 unit price points per product):\n",
      "- unit_price_p10: Floor unit price (10th percentile)\n",
      "- unit_price_p25: Low unit price (25th percentile)  \n",
      "- unit_price_p50: Median unit price (50th percentile)\n",
      "- unit_price_p75: High unit price (75th percentile)\n",
      "- unit_price_p90: Ceiling unit price (90th percentile)\n",
      "- unit_price_mode: Most common unit price\n",
      "- weighted_avg_unit_price: Market-validated based on actual sales\n",
      "\n",
      "Note: All prices are per BASIC UNIT (price / basic_unit_count)\n",
      "      This pools all packing units into one analysis per product.\n",
      "\n",
      "Configuration used:\n",
      "- MAD Threshold: 3.5\n",
      "- WAC Range: -40% to 40%\n",
      "- Percentiles: [10, 25, 50, 75, 90]\n",
      "- Min Price Points: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL OUTPUT: mp_final DataFrame\n",
    "# =============================================================================\n",
    "# The main output is the mp_final DataFrame containing:\n",
    "#   - region: Geographic region\n",
    "#   - product_id: Product identifier\n",
    "#   - unit_price_p10, p25, p50, p75, p90: Percentile unit prices (per basic unit)\n",
    "#   - price_count: Number of price points (from all packing units)\n",
    "#   - true_min: Actual minimum unit price\n",
    "#   - true_max: Actual maximum unit price\n",
    "#   - unit_price_mode: Most common unit price\n",
    "#   - weighted_avg_unit_price: NMV-weighted average (historical)\n",
    "#   - weighted_avg_unit_price_recent: NMV-weighted average (recent)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL OUTPUT: mp_final\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nDataFrame shape: {mp_final.shape}\")\n",
    "print(f\"\\nFirst 10 rows:\")\n",
    "display(mp_final.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NOTEBOOK COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "The mp_final DataFrame is ready for use in pricing logic.\n",
    "\n",
    "OUTPUT: Unit prices per (region, product_id) - NO packing unit\n",
    "\n",
    "Key outputs (5 unit price points per product):\n",
    "- unit_price_p10: Floor unit price (10th percentile)\n",
    "- unit_price_p25: Low unit price (25th percentile)  \n",
    "- unit_price_p50: Median unit price (50th percentile)\n",
    "- unit_price_p75: High unit price (75th percentile)\n",
    "- unit_price_p90: Ceiling unit price (90th percentile)\n",
    "- unit_price_mode: Most common unit price\n",
    "- weighted_avg_unit_price: Market-validated based on actual sales\n",
    "\n",
    "Note: All prices are per BASIC UNIT (price / basic_unit_count)\n",
    "      This pools all packing units into one analysis per product.\n",
    "\n",
    "Configuration used:\n",
    "- MAD Threshold: {MAD_THRESHOLD}\n",
    "- WAC Range: {WAC_LOWER_BOUND}% to {WAC_UPPER_BOUND}%\n",
    "- Percentiles: {PERCENTILES}\n",
    "- Min Price Points: {MIN_PRICE_POINTS}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>product_id</th>\n",
       "      <th>unit_price_p10</th>\n",
       "      <th>unit_price_p25</th>\n",
       "      <th>unit_price_p50</th>\n",
       "      <th>unit_price_p75</th>\n",
       "      <th>unit_price_p90</th>\n",
       "      <th>price_count</th>\n",
       "      <th>true_min</th>\n",
       "      <th>true_max</th>\n",
       "      <th>unit_price_mode</th>\n",
       "      <th>weighted_avg_unit_price</th>\n",
       "      <th>weighted_avg_unit_price_recent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2209</th>\n",
       "      <td>Cairo</td>\n",
       "      <td>615</td>\n",
       "      <td>279.2</td>\n",
       "      <td>281.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>304.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>310.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     region  product_id  unit_price_p10  unit_price_p25  unit_price_p50  \\\n",
       "2209  Cairo         615           279.2           281.0           284.0   \n",
       "\n",
       "      unit_price_p75  unit_price_p90  price_count  true_min  true_max  \\\n",
       "2209           297.0           304.8          3.0       NaN     310.0   \n",
       "\n",
       "      unit_price_mode  weighted_avg_unit_price  weighted_avg_unit_price_recent  \n",
       "2209            278.0                    284.0                             NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_final[mp_final['product_id']==615]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
