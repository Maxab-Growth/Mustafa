{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Hourly Updates\n",
    "\n",
    "## Purpose\n",
    "This module runs hourly to monitor and adjust prices based on:\n",
    "1. **UTH (Up-Till-Hour) Performance**: Cumulative qty/retailers from start of day until current hour\n",
    "2. **Last Hour Performance**: Qty/retailers for the most recent hour only\n",
    "\n",
    "## Schedule\n",
    "- Runs hourly from 12 PM to 12 AM (midnight), **except** Module 3 hours (12 PM, 3 PM, 6 PM, 9 PM)\n",
    "- Also runs once at 3 AM\n",
    "- Active hours: 1 PM, 2 PM, 4 PM, 5 PM, 7 PM, 8 PM, 10 PM, 11 PM, 12 AM, 3 AM\n",
    "\n",
    "## Data Flow\n",
    "```\n",
    "data_extraction.ipynb → Snowflake (Pricing_data_extraction)\n",
    "                              ↓\n",
    "                        Module 4 (this module)\n",
    "                           ├── Load p80_qty, p70_retailers, std columns\n",
    "                           ├── Fetch fresh: cart rules, stocks, WAC\n",
    "                           ├── Calculate new_wac (from today's PRS)\n",
    "                           ├── Query UTH performance (today)\n",
    "                           ├── Query Last Hour performance (today)\n",
    "                           ├── Query historical hour contributions\n",
    "                           ├── Calculate targets & statuses (±3 std)\n",
    "                           └── Generate actions (TBD)\n",
    "```\n",
    "\n",
    "## New WAC Calculation\n",
    "To avoid database lag, we calculate a fresh WAC from today's purchase receipts:\n",
    "- `new_wac1` = ((stocks + reflected_qty) × wac1 + unreflected_qty × item_price) / total_qty\n",
    "- `new_wac_p` = wac_p × (1 + wac1_change)\n",
    "- `new_wac` = new_wac_p (with fallback to current_wac)\n",
    "\n",
    "## Status Logic (±3 Standard Deviations)\n",
    "SKU status is determined by comparing actual performance to target ± 3 std:\n",
    "- **Growing**: actual > target + 3×std\n",
    "- **On Track**: target - 3×std ≤ actual ≤ target + 3×std\n",
    "- **Dropping**: actual < target - 3×std (minimum threshold = 1)\n",
    "\n",
    "Standard deviation columns used:\n",
    "- Qty: `std_daily_240d`\n",
    "- Retailers: `std_daily_retailers_240d`\n",
    "\n",
    "## Status Outputs\n",
    "- `uth_qty_status`: growing / dropping / on_track\n",
    "- `uth_rets_status`: growing / dropping / on_track\n",
    "- `last_hour_qty_status`: growing / dropping / on_track\n",
    "- `last_hour_rets_status`: growing / dropping / on_track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.12/site-packages/snowflake/connector/options.py:104: UserWarning: You have an incompatible version of 'pyarrow' installed (20.0.0), please install a version that adheres to: 'pyarrow<19.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n",
      "Queries Module | Timezone: America/Los_Angeles\n",
      "✅ UTH and Last Hour functions defined\n",
      "\n",
      "==================================================\n",
      "QUERIES MODULE READY\n",
      "==================================================\n",
      "\n",
      "Live Data Functions:\n",
      "  • get_current_stocks()\n",
      "  • get_packing_units()\n",
      "  • get_current_prices()\n",
      "  • get_current_wac()\n",
      "  • get_current_cart_rules()\n",
      "\n",
      "UTH Performance Functions:\n",
      "  • get_uth_performance()         - UTH qty/retailers (Snowflake)\n",
      "  • get_hourly_distribution()     - Historical hour contributions (Snowflake)\n",
      "  • get_last_hour_performance()   - Last hour qty/retailers (DWH)\n",
      "\n",
      "Note: Market prices use MODULE_1_INPUT data\n",
      "Retailer Selection Queries defined ✓\n",
      "  - get_churned_dropped_retailers()\n",
      "  - get_category_not_product_retailers()\n",
      "  - get_out_of_cycle_retailers()\n",
      "  - get_view_no_orders_retailers()\n",
      "  - get_excluded_retailers()\n",
      "  - get_retailers_with_quantity_discount()\n",
      "  - get_retailer_main_warehouse()\n",
      "Module 4: Hourly Updates\n",
      "Current Cairo Time: 2026-01-27 10:35:15\n",
      "Current Hour: 10\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import setup_environment_2\n",
    "# Import queries module for Snowflake access\n",
    "%run queries_module.ipynb\n",
    "\n",
    "# Cairo timezone\n",
    "CAIRO_TZ = pytz.timezone('Africa/Cairo')\n",
    "CAIRO_NOW = datetime.now(CAIRO_TZ)\n",
    "CURRENT_HOUR = CAIRO_NOW.hour\n",
    "\n",
    "print(f\"Module 4: Hourly Updates\")\n",
    "print(f\"Current Cairo Time: {CAIRO_NOW.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Current Hour: {CURRENT_HOUR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:04:46.887263Z",
     "iopub.status.busy": "2026-01-26T18:04:46.887007Z",
     "iopub.status.idle": "2026-01-26T18:04:46.891960Z",
     "shell.execute_reply": "2026-01-26T18:04:46.891136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: MATERIALIZED_VIEWS.Pricing_data_extraction (today's data)\n",
      "Output: module_4_output_20260126_2004.xlsx\n",
      "Status Thresholds: ±3 std (Dropping minimum = 1)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Input/Output configuration\n",
    "# Data is now loaded from Snowflake instead of Excel\n",
    "INPUT_TABLE = 'MATERIALIZED_VIEWS.Pricing_data_extraction'\n",
    "OUTPUT_FILE = f'module_4_output_{CAIRO_NOW.strftime(\"%Y%m%d_%H%M\")}.xlsx'\n",
    "\n",
    "# Status thresholds (±3 std from target)\n",
    "# - Growing: actual > target + 3*std\n",
    "# - On Track: target - 3*std <= actual <= target + 3*std\n",
    "# - Dropping: actual < target - 3*std (minimum threshold = 1)\n",
    "STD_THRESHOLD = 3  # Number of standard deviations\n",
    "MIN_DROPPING_THRESHOLD = 1  # Minimum threshold for dropping status\n",
    "\n",
    "# Module 3 hours (skip these)\n",
    "MODULE_3_HOURS = [12, 15, 18, 21]  # 12 PM, 3 PM, 6 PM, 9 PM\n",
    "\n",
    "print(f\"Input: {INPUT_TABLE} (today's data)\")\n",
    "print(f\"Output: {OUTPUT_FILE}\")\n",
    "print(f\"Status Thresholds: ±{STD_THRESHOLD} std (Dropping minimum = {MIN_DROPPING_THRESHOLD})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:04:46.894113Z",
     "iopub.status.busy": "2026-01-26T18:04:46.893884Z",
     "iopub.status.idle": "2026-01-26T18:07:16.396553Z",
     "shell.execute_reply": "2026-01-26T18:07:16.395699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Snowflake...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28491 records from Snowflake\n",
      "\n",
      "P80 Qty Stats: min=5.0, max=1652.8, mean=12.6\n",
      "P70 Retailers Stats: min=2.0, max=146.6, mean=3.6\n",
      "Std Qty Stats: min=0.0, max=2574.8, mean=6.3\n",
      "Std Retailers Stats: min=0.0, max=76.2, mean=1.4\n",
      "Fetching current cart rules...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 72968 records\n",
      "✅ Merged cart rules: 28491 records\n",
      "Fetching current stocks...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 1848628 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged stocks: 28491 records\n",
      "Fetching current WAC...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 8147 records\n",
      "✅ Merged WAC: 28491 records\n",
      "Fetching current prices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 116392 records\n",
      "✅ Merged current prices: 28491 records\n",
      "\n",
      "Current Stock Stats: min=0, max=28179, mean=99.5\n",
      "Current WAC Stats: min=0.01, max=2082.02, mean=227.21\n",
      "Current Price Stats: min=0.00, max=2203.25, mean=239.42\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD DATA FROM SNOWFLAKE (Instead of Excel file)\n",
    "# =============================================================================\n",
    "print(\"Loading data from Snowflake...\")\n",
    "\n",
    "# Query to get today's data from Pricing_data_extraction\n",
    "LOAD_QUERY = f\"\"\"\n",
    "SELECT * FROM {INPUT_TABLE}\n",
    "WHERE created_at = '{datetime.now(CAIRO_TZ).date()}'\n",
    "\"\"\"\n",
    "\n",
    "df = query_snowflake(LOAD_QUERY)\n",
    "print(f\"Loaded {len(df)} records from Snowflake\")\n",
    "\n",
    "# Ensure required columns exist with proper types\n",
    "df['p80_daily_240d'] = pd.to_numeric(df.get('p80_daily_240d', 0), errors='coerce').fillna(0)\n",
    "df['p70_daily_retailers_240d'] = pd.to_numeric(df.get('p70_daily_retailers_240d', 1), errors='coerce').fillna(1)\n",
    "df['std_daily_240d'] = pd.to_numeric(df.get('std_daily_240d', 0), errors='coerce').fillna(0)\n",
    "df['std_daily_retailers_240d'] = pd.to_numeric(df.get('std_daily_retailers_240d', 0), errors='coerce').fillna(0)\n",
    "df['warehouse_id'] = df['warehouse_id'].astype(int)\n",
    "df['product_id'] = df['product_id'].astype(int)\n",
    "df['cohort_id'] = df['cohort_id'].astype(int) if 'cohort_id' in df.columns else None\n",
    "\n",
    "# Get category for hourly distribution merge\n",
    "if 'cat' not in df.columns and 'category' in df.columns:\n",
    "    df['cat'] = df['category']\n",
    "\n",
    "print(f\"\\nP80 Qty Stats: min={df['p80_daily_240d'].min():.1f}, max={df['p80_daily_240d'].max():.1f}, mean={df['p80_daily_240d'].mean():.1f}\")\n",
    "print(f\"P70 Retailers Stats: min={df['p70_daily_retailers_240d'].min():.1f}, max={df['p70_daily_retailers_240d'].max():.1f}, mean={df['p70_daily_retailers_240d'].mean():.1f}\")\n",
    "print(f\"Std Qty Stats: min={df['std_daily_240d'].min():.1f}, max={df['std_daily_240d'].max():.1f}, mean={df['std_daily_240d'].mean():.1f}\")\n",
    "print(f\"Std Retailers Stats: min={df['std_daily_retailers_240d'].min():.1f}, max={df['std_daily_retailers_240d'].max():.1f}, mean={df['std_daily_retailers_240d'].mean():.1f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# GET FRESH DATA FROM QUERIES MODULE (Snowflake)\n",
    "# =============================================================================\n",
    "\n",
    "# 1. Current Cart Rules\n",
    "df_cart_rules = get_current_cart_rules()\n",
    "\n",
    "# Merge with main df (by cohort_id + product_id)\n",
    "if 'cohort_id' in df.columns and len(df_cart_rules) > 0:\n",
    "    df = df.drop(columns=['current_cart_rule'], errors='ignore')\n",
    "    df = df.merge(df_cart_rules, on=['cohort_id', 'product_id'], how='left')\n",
    "    df['current_cart_rule'] = df['current_cart_rule'].fillna(999)\n",
    "    print(f\"✅ Merged cart rules: {len(df)} records\")\n",
    "else:\n",
    "    df['current_cart_rule'] = df.get('current_cart_rule', 999)\n",
    "\n",
    "# 2. Current Stocks\n",
    "df_stocks = get_current_stocks()\n",
    "\n",
    "# Merge stocks (by warehouse_id + product_id)\n",
    "if len(df_stocks) > 0:\n",
    "    df = df.drop(columns=['stocks'], errors='ignore')\n",
    "    df = df.merge(df_stocks, on=['warehouse_id', 'product_id'], how='left')\n",
    "    df['stocks'] = df['stocks'].fillna(0)\n",
    "    print(f\"✅ Merged stocks: {len(df)} records\")\n",
    "else:\n",
    "    df['stocks'] = df.get('stocks', 0)\n",
    "\n",
    "# 3. Current WAC (Weighted Average Cost)\n",
    "df_wac = get_current_wac()\n",
    "\n",
    "# Merge WAC (by warehouse_id + product_id)\n",
    "if len(df_wac) > 0:\n",
    "    df = df.drop(columns=['wac_p'], errors='ignore')\n",
    "    df = df.merge(df_wac, on=['product_id'], how='left')\n",
    "    df['wac_p'] = df['wac_p'].fillna(0)\n",
    "    print(f\"✅ Merged WAC: {len(df)} records\")\n",
    "else:\n",
    "    df['wac_p'] = df.get('wac_p', 0)\n",
    "\n",
    "# 4. Current Prices\n",
    "df_prices = get_current_prices()\n",
    "\n",
    "# Merge prices (by cohort_id + product_id)\n",
    "if len(df_prices) > 0:\n",
    "    df = df.drop(columns=['current_price'], errors='ignore')\n",
    "    df = df.merge(df_prices[['cohort_id', 'product_id', 'current_price']], on=['cohort_id', 'product_id'], how='left')\n",
    "    df['current_price'] = df['current_price'].fillna(0)\n",
    "    print(f\"✅ Merged current prices: {len(df)} records\")\n",
    "else:\n",
    "    df['current_price'] = df.get('current_price', 0)\n",
    "\n",
    "print(f\"\\nCurrent Stock Stats: min={df['stocks'].min():.0f}, max={df['stocks'].max():.0f}, mean={df['stocks'].mean():.1f}\")\n",
    "print(f\"Current WAC Stats: min={df['wac_p'].min():.2f}, max={df['wac_p'].max():.2f}, mean={df['wac_p'].mean():.2f}\")\n",
    "print(f\"Current Price Stats: min={df['current_price'].min():.2f}, max={df['current_price'].max():.2f}, mean={df['current_price'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:07:16.398936Z",
     "iopub.status.busy": "2026-01-26T18:07:16.398711Z",
     "iopub.status.idle": "2026-01-26T18:07:49.597136Z",
     "shell.execute_reply": "2026-01-26T18:07:49.596156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating new WAC from today's purchase receipts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 900 PRS records (today's purchases)\n",
      "  Loaded 562 WAC tracker records (already reflected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 7688 base WAC records from all_cogs\n",
      "\n",
      "✅ New WAC calculated: 28491 records\n",
      "   Products with unreflected purchases: 7046\n",
      "   New WAC Stats: min=0.01, max=2082.02, mean=227.22\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CALCULATE NEW WAC (Accounting for Today's Unreflected Purchases)\n",
    "# =============================================================================\n",
    "# This calculates a fresh WAC that accounts for today's purchase receipts\n",
    "# that haven't been reflected in the database yet (to avoid lag)\n",
    "\n",
    "print(\"Calculating new WAC from today's purchase receipts...\")\n",
    "\n",
    "# 1. Query today's PRS data (purchases by product_id)\n",
    "prs_query = '''\n",
    "WITH prs AS (\n",
    "    SELECT DISTINCT \n",
    "        product_purchased_receipts.purchased_receipt_id,\n",
    "        products.id AS product_id,\n",
    "        product_purchased_receipts.basic_unit_count,\n",
    "        product_purchased_receipts.purchased_item_count * product_purchased_receipts.basic_unit_count AS purchase_min_count,\n",
    "        product_purchased_receipts.final_price / product_purchased_receipts.purchased_item_count AS final_item_price\n",
    "    FROM product_purchased_receipts\n",
    "    LEFT JOIN products ON products.id = product_purchased_receipts.product_id\n",
    "    LEFT JOIN purchased_receipts ON purchased_receipts.id = product_purchased_receipts.purchased_receipt_id\n",
    "    WHERE product_purchased_receipts.purchased_item_count <> 0\n",
    "        AND purchased_receipts.purchased_receipt_status_id IN (4,5,7)\n",
    "        AND purchased_receipts.date::date >= current_date\n",
    "        AND product_purchased_receipts.final_price > 0 \n",
    ")\n",
    "SELECT \n",
    "    product_id,\n",
    "    SUM(purchase_min_count) AS all_day_qty,\n",
    "    AVG(final_item_price / basic_unit_count) AS item_price\n",
    "FROM prs\n",
    "GROUP BY 1\n",
    "'''\n",
    "df_prs = setup_environment_2.dwh_pg_query(prs_query, columns=['product_id', 'all_day_qty', 'item_price'])\n",
    "df_prs['product_id'] = pd.to_numeric(df_prs['product_id'])\n",
    "df_prs['all_day_qty'] = pd.to_numeric(df_prs['all_day_qty'])\n",
    "df_prs['item_price'] = pd.to_numeric(df_prs['item_price'])\n",
    "print(f\"  Loaded {len(df_prs)} PRS records (today's purchases)\")\n",
    "\n",
    "# 2. Query what's already reflected in WAC tracker\n",
    "reflected_query = '''\n",
    "SELECT\n",
    "    t_product_id AS product_id,\n",
    "    s_beg_stock AS av_stocks,\n",
    "    p_purchased_item_count AS pr_qty\n",
    "FROM finance.wac_tracker wt\n",
    "WHERE wt.t_date::date = CURRENT_DATE\n",
    "    AND p_purchased_item_count > 0 \n",
    "'''\n",
    "try:\n",
    "    df_reflected = setup_environment_2.dwh_pg_query(reflected_query, columns=['product_id', 'av_stocks', 'pr_qty'])\n",
    "    df_reflected['product_id'] = pd.to_numeric(df_reflected['product_id'])\n",
    "    df_reflected['av_stocks'] = pd.to_numeric(df_reflected['av_stocks'])\n",
    "    df_reflected['pr_qty'] = pd.to_numeric(df_reflected['pr_qty'])\n",
    "    print(f\"  Loaded {len(df_reflected)} WAC tracker records (already reflected)\")\n",
    "except:\n",
    "    df_reflected = pd.DataFrame(columns=['product_id', 'av_stocks', 'pr_qty'])\n",
    "    print(\"  No WAC tracker records found for today\")\n",
    "\n",
    "# 3. Query base WAC (wac1, wac_p) from all_cogs\n",
    "wac_base_query = '''\n",
    "SELECT \n",
    "    f.product_id,\n",
    "    f.wac1,\n",
    "    f.wac_p\n",
    "FROM finance.all_cogs f\n",
    "JOIN products ON products.id = f.product_id\n",
    "JOIN categories ON products.category_id = categories.id\n",
    "WHERE current_timestamp BETWEEN f.from_date AND f.to_date \n",
    "    AND NOT categories.name_ar IN (\n",
    "        SELECT categories.name_ar AS cat\n",
    "        FROM categories\n",
    "        JOIN sections s ON s.id = categories.section_id\n",
    "        WHERE categories.name_ar LIKE '%سايب%'\n",
    "            OR categories.name_ar LIKE '%بالتة%'\n",
    "            OR categories.section_id IN (225, 318, 285, 121, 87, 351, 417)\n",
    "    )\n",
    "'''\n",
    "df_wac_base = query_snowflake(wac_base_query)\n",
    "df_wac_base['product_id'] = pd.to_numeric(df_wac_base['product_id'])\n",
    "df_wac_base['wac1'] = pd.to_numeric(df_wac_base['wac1'])\n",
    "df_wac_base['wac_p'] = pd.to_numeric(df_wac_base['wac_p'])\n",
    "print(f\"  Loaded {len(df_wac_base)} base WAC records from all_cogs\")\n",
    "\n",
    "# 4. Merge and calculate new WAC\n",
    "df_wac_calc = df_wac_base.merge(df_prs, on='product_id', how='left')\n",
    "df_wac_calc = df_wac_calc.merge(df_reflected, on='product_id', how='left')\n",
    "df_wac_calc = df_wac_calc.fillna(0)\n",
    "\n",
    "# Use current_stock from main df if av_stocks is 0\n",
    "df_stock_lookup = df[['product_id', 'stocks']].drop_duplicates()\n",
    "df_stock_lookup = df_stock_lookup.groupby(['product_id'])['stocks'].sum().reset_index()\n",
    "df_wac_calc = df_wac_calc.merge(df_stock_lookup, on='product_id', how='left')\n",
    "df_wac_calc['av_stocks'] = df_wac_calc.apply(\n",
    "    lambda row: row['stocks'] if row['av_stocks'] == 0 else row['av_stocks'], axis=1)\n",
    "\n",
    "# Calculate not reflected qty (purchases not yet in WAC tracker)\n",
    "df_wac_calc['not_reflected_qty'] = df_wac_calc['all_day_qty'] - df_wac_calc['pr_qty']\n",
    "df_wac_calc['not_reflected_qty'] = df_wac_calc['not_reflected_qty'].clip(lower=0)  # Can't be negative\n",
    "\n",
    "# Calculate new WAC\n",
    "# new_wac1 = ((stocks + pr_qty) * wac1 + not_reflected_qty * item_price) / (stocks + pr_qty + not_reflected_qty)\n",
    "denominator = df_wac_calc['av_stocks'] + df_wac_calc['pr_qty'] + df_wac_calc['not_reflected_qty']\n",
    "numerator = ((df_wac_calc['av_stocks'] + df_wac_calc['pr_qty']) * df_wac_calc['wac1'] + \n",
    "             df_wac_calc['not_reflected_qty'] * df_wac_calc['item_price'])\n",
    "\n",
    "df_wac_calc['new_wac1'] = np.where(denominator > 0, numerator / denominator, df_wac_calc['wac1'])\n",
    "\n",
    "# Calculate wac1 change and new_wac_p\n",
    "df_wac_calc['wac1_change'] = np.where(\n",
    "    df_wac_calc['wac1'] > 0,\n",
    "    (df_wac_calc['new_wac1'] - df_wac_calc['wac1']) / df_wac_calc['wac1'],\n",
    "    0\n",
    ")\n",
    "df_wac_calc['new_wac_p'] = df_wac_calc['wac_p'] * (1 + df_wac_calc['wac1_change'])\n",
    "df_wac_calc['new_wac_p'] = df_wac_calc['new_wac_p'].fillna(df_wac_calc['wac_p'])\n",
    "\n",
    "# Prepare final new_wac dataframe\n",
    "df_new_wac = df_wac_calc[['product_id','new_wac_p', 'not_reflected_qty']].copy()\n",
    "df_new_wac=df_new_wac.drop_duplicates()\n",
    "\n",
    "# 5. Merge new_wac into main dataframe\n",
    "df = df.drop(columns=['new_wac_p','not_reflected_qty'], errors='ignore')\n",
    "df = df.merge(df_new_wac, on='product_id', how='left')\n",
    "df['new_wac'] = df['new_wac_p'].fillna(df['wac_p'])  # Fallback to current_wac if no new_wac\n",
    "\n",
    "print(f\"\\n✅ New WAC calculated: {len(df)} records\")\n",
    "print(f\"   Products with unreflected purchases: {(df['not_reflected_qty'] > 0).sum()}\")\n",
    "print(f\"   New WAC Stats: min={df['new_wac'].min():.2f}, max={df['new_wac'].max():.2f}, mean={df['new_wac'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:07:49.599285Z",
     "iopub.status.busy": "2026-01-26T18:07:49.598933Z",
     "iopub.status.idle": "2026-01-26T18:08:28.331161Z",
     "shell.execute_reply": "2026-01-26T18:08:28.330165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching UTH performance from Snowflake...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 9121 UTH records\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# QUERY 1: TODAY'S UTH (Up-Till-Hour) PERFORMANCE\n",
    "# =============================================================================\n",
    "# Gets cumulative qty and retailers from start of day until current hour\n",
    "# Uses get_uth_performance() from queries_module\n",
    "\n",
    "df_uth_today = get_uth_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:08:28.333325Z",
     "iopub.status.busy": "2026-01-26T18:08:28.333097Z",
     "iopub.status.idle": "2026-01-26T18:09:03.450816Z",
     "shell.execute_reply": "2026-01-26T18:09:03.449955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching last hour performance from DWH...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 2182 last hour records from DWH\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# QUERY 2: TODAY'S LAST HOUR PERFORMANCE (from DWH)\n",
    "# =============================================================================\n",
    "# Gets qty and retailers for the PREVIOUS hour only (not cumulative)\n",
    "# Uses get_last_hour_performance() from queries_module (DWH/PostgreSQL)\n",
    "\n",
    "df_last_hour = get_last_hour_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:09:03.452969Z",
     "iopub.status.busy": "2026-01-26T18:09:03.452742Z",
     "iopub.status.idle": "2026-01-26T18:09:09.334886Z",
     "shell.execute_reply": "2026-01-26T18:09:09.334054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching hourly distribution from Snowflake...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 771 hourly distribution records\n",
      "\n",
      "Avg UTH % (qty): 75.0%\n",
      "Avg Last Hour % (qty): 6.5%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# QUERY 3: HISTORICAL HOURLY DISTRIBUTION (Last 4 Months) - By Category & Warehouse\n",
    "# =============================================================================\n",
    "# Gets:\n",
    "# - avg_uth_pct_qty/retailers: Average contribution of hours 0 to (current_hour-1) to daily total\n",
    "# - avg_last_hour_pct_qty/retailers: Average contribution of (current_hour-1) alone to daily total\n",
    "# Uses get_hourly_distribution() from queries_module\n",
    "\n",
    "df_hourly_dist = get_hourly_distribution()\n",
    "print(f\"\\nAvg UTH % (qty): {df_hourly_dist['avg_uth_pct_qty'].mean()*100:.1f}%\")\n",
    "print(f\"Avg Last Hour % (qty): {df_hourly_dist['avg_last_hour_pct_qty'].mean()*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:09:09.337412Z",
     "iopub.status.busy": "2026-01-26T18:09:09.337163Z",
     "iopub.status.idle": "2026-01-26T18:09:09.460108Z",
     "shell.execute_reply": "2026-01-26T18:09:09.459320Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging performance data with base data...\n",
      "✅ Merged data: 28491 records\n",
      "\n",
      "UTH Qty Stats: min=0, max=9916, mean=3.3\n",
      "Last Hour Qty Stats: min=0, max=199, mean=0.3\n",
      "Current Cart Rule Stats: min=1, max=10000, mean=79.0\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MERGE DATA\n",
    "# =============================================================================\n",
    "print(\"Merging performance data with base data...\")\n",
    "\n",
    "# Merge UTH today data\n",
    "if len(df_uth_today) > 0:\n",
    "    df = df.merge(df_uth_today, on=['warehouse_id', 'product_id'], how='left')\n",
    "else:\n",
    "    df['uth_qty'] = 0\n",
    "    df['uth_nmv'] = 0\n",
    "    df['uth_retailers'] = 0\n",
    "\n",
    "# Merge last hour data\n",
    "if len(df_last_hour) > 0:\n",
    "    df = df.merge(df_last_hour, on=['warehouse_id', 'product_id'], how='left')\n",
    "else:\n",
    "    df['last_hour_qty'] = 0\n",
    "    df['last_hour_nmv'] = 0\n",
    "    df['last_hour_retailers'] = 0\n",
    "\n",
    "# Merge hourly distribution (by warehouse_id + cat)\n",
    "if len(df_hourly_dist) > 0:\n",
    "    df = df.merge(df_hourly_dist, on=['warehouse_id', 'cat'], how='left')\n",
    "else:\n",
    "    df['avg_uth_pct_qty'] = 0.5\n",
    "    df['avg_uth_pct_retailers'] = 0.5\n",
    "    df['avg_last_hour_pct_qty'] = 0.05\n",
    "    df['avg_last_hour_pct_retailers'] = 0.05\n",
    "\n",
    "# Fill NaN values\n",
    "df['uth_qty'] = df['uth_qty'].fillna(0)\n",
    "df['uth_nmv'] = df['uth_nmv'].fillna(0)\n",
    "df['uth_retailers'] = df['uth_retailers'].fillna(0)\n",
    "df['last_hour_qty'] = df['last_hour_qty'].fillna(0)\n",
    "df['last_hour_nmv'] = df['last_hour_nmv'].fillna(0)\n",
    "df['last_hour_retailers'] = df['last_hour_retailers'].fillna(0)\n",
    "df['avg_uth_pct_qty'] = df['avg_uth_pct_qty'].fillna(0.5)\n",
    "df['avg_uth_pct_retailers'] = df['avg_uth_pct_retailers'].fillna(0.5)\n",
    "df['avg_last_hour_pct_qty'] = df['avg_last_hour_pct_qty'].fillna(0.05)\n",
    "df['avg_last_hour_pct_retailers'] = df['avg_last_hour_pct_retailers'].fillna(0.05)\n",
    "\n",
    "print(f\"✅ Merged data: {len(df)} records\")\n",
    "print(f\"\\nUTH Qty Stats: min={df['uth_qty'].min():.0f}, max={df['uth_qty'].max():.0f}, mean={df['uth_qty'].mean():.1f}\")\n",
    "print(f\"Last Hour Qty Stats: min={df['last_hour_qty'].min():.0f}, max={df['last_hour_qty'].max():.0f}, mean={df['last_hour_qty'].mean():.1f}\")\n",
    "print(f\"Current Cart Rule Stats: min={df['current_cart_rule'].min():.0f}, max={df['current_cart_rule'].max():.0f}, mean={df['current_cart_rule'].mean():.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:09:09.462376Z",
     "iopub.status.busy": "2026-01-26T18:09:09.462143Z",
     "iopub.status.idle": "2026-01-26T18:09:11.422804Z",
     "shell.execute_reply": "2026-01-26T18:09:11.421870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating UTH and Last Hour targets and statuses...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Targets and statuses calculated using ±3 std thresholds\n",
      "\n",
      "============================================================\n",
      "UTH STATUS DISTRIBUTION\n",
      "============================================================\n",
      "\n",
      "UTH Qty Status:\n",
      "uth_qty_status\n",
      "dropping    20957\n",
      "on_track     7230\n",
      "growing       304\n",
      "\n",
      "UTH Retailers Status:\n",
      "uth_rets_status\n",
      "dropping    20041\n",
      "on_track     8224\n",
      "growing       226\n",
      "\n",
      "============================================================\n",
      "LAST HOUR STATUS DISTRIBUTION\n",
      "============================================================\n",
      "\n",
      "Last Hour Qty Status:\n",
      "last_hour_qty_status\n",
      "dropping    26400\n",
      "on_track     1199\n",
      "growing       892\n",
      "\n",
      "Last Hour Retailers Status:\n",
      "last_hour_rets_status\n",
      "dropping    26399\n",
      "growing      1271\n",
      "on_track      821\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CALCULATE TARGETS AND STATUSES\n",
    "# =============================================================================\n",
    "print(\"Calculating UTH and Last Hour targets and statuses...\")\n",
    "\n",
    "def get_status_std(actual, target, std, is_qty=True):\n",
    "    \"\"\"\n",
    "    Determine status based on ±3 std from target.\n",
    "    - Growing: actual > target + 3*std\n",
    "    - On Track: target - 3*std <= actual <= target + 3*std\n",
    "    - Dropping: actual < target - 3*std (minimum threshold = 1)\n",
    "    \n",
    "    Parameters:\n",
    "    - actual: actual performance value\n",
    "    - target: target value (p80 for qty, p70 for retailers)\n",
    "    - std: standard deviation (std_daily_240d or std_daily_retailers_240d)\n",
    "    - is_qty: True for qty metrics, False for retailer metrics\n",
    "    \"\"\"\n",
    "    upper_bound = target + STD_THRESHOLD * std\n",
    "    lower_bound = max(target - STD_THRESHOLD * std, MIN_DROPPING_THRESHOLD)\n",
    "    \n",
    "    if actual > upper_bound:\n",
    "        return 'growing'\n",
    "    elif actual < lower_bound:\n",
    "        return 'dropping'\n",
    "    else:\n",
    "        return 'on_track'\n",
    "\n",
    "# Calculate UTH targets\n",
    "# UTH target = p80_qty * avg_uth_pct (historical % of day that should be done by now)\n",
    "df['uth_qty_target'] = df['p80_daily_240d'] * df['avg_uth_pct_qty']\n",
    "df['uth_rets_target'] = df['p70_daily_retailers_240d'] * df['avg_uth_pct_retailers']\n",
    "\n",
    "# Calculate UTH std thresholds (scaled by UTH percentage)\n",
    "df['uth_qty_std'] = df['std_daily_240d'] * df['avg_uth_pct_qty']\n",
    "df['uth_rets_std'] = df['std_daily_retailers_240d'] * df['avg_uth_pct_retailers']\n",
    "\n",
    "# Calculate Last Hour targets\n",
    "# Last hour target = p80_qty * avg_last_hour_pct (historical % of day for this hour)\n",
    "df['last_hour_qty_target'] = df['p80_daily_240d'] * df['avg_last_hour_pct_qty']\n",
    "df['last_hour_rets_target'] = df['p70_daily_retailers_240d'] * df['avg_last_hour_pct_retailers']\n",
    "\n",
    "# Calculate Last Hour std thresholds (scaled by last hour percentage)\n",
    "df['last_hour_qty_std'] = df['std_daily_240d'] * df['avg_last_hour_pct_qty']\n",
    "df['last_hour_rets_std'] = df['std_daily_retailers_240d'] * df['avg_last_hour_pct_retailers']\n",
    "\n",
    "# Calculate statuses using ±3 std thresholds\n",
    "df['uth_qty_status'] = df.apply(\n",
    "    lambda row: get_status_std(row['uth_qty'], row['uth_qty_target'], row['uth_qty_std'], is_qty=True), axis=1)\n",
    "df['uth_rets_status'] = df.apply(\n",
    "    lambda row: get_status_std(row['uth_retailers'], row['uth_rets_target'], row['uth_rets_std'], is_qty=False), axis=1)\n",
    "df['last_hour_qty_status'] = df.apply(\n",
    "    lambda row: get_status_std(row['last_hour_qty'], row['last_hour_qty_target'], row['last_hour_qty_std'], is_qty=True), axis=1)\n",
    "df['last_hour_rets_status'] = df.apply(\n",
    "    lambda row: get_status_std(row['last_hour_retailers'], row['last_hour_rets_target'], row['last_hour_rets_std'], is_qty=False), axis=1)\n",
    "\n",
    "print(f\"✅ Targets and statuses calculated using ±{STD_THRESHOLD} std thresholds\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"UTH STATUS DISTRIBUTION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nUTH Qty Status:\")\n",
    "print(df['uth_qty_status'].value_counts().to_string())\n",
    "print(f\"\\nUTH Retailers Status:\")\n",
    "print(df['uth_rets_status'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"LAST HOUR STATUS DISTRIBUTION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nLast Hour Qty Status:\")\n",
    "print(df['last_hour_qty_status'].value_counts().to_string())\n",
    "print(f\"\\nLast Hour Retailers Status:\")\n",
    "print(df['last_hour_rets_status'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:09:11.424983Z",
     "iopub.status.busy": "2026-01-26T18:09:11.424759Z",
     "iopub.status.idle": "2026-01-26T18:10:44.987929Z",
     "shell.execute_reply": "2026-01-26T18:10:44.987021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching market data and margin tiers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Data Module loaded at 2026-01-26 20:09:12 Cairo time\n",
      "Snowflake timezone: America/Los_Angeles\n",
      "All queries defined ✓\n",
      "Helper functions defined ✓\n",
      "get_market_data() function defined ✓\n",
      "get_margin_tiers() function defined ✓\n",
      "\n",
      "======================================================================\n",
      "MARKET DATA MODULE READY\n",
      "======================================================================\n",
      "\n",
      "Available functions (NO INPUT REQUIRED):\n",
      "  - get_market_data()   : Fetch and process all market prices\n",
      "  - get_margin_tiers()  : Fetch and calculate margin tiers\n",
      "\n",
      "Usage:\n",
      "  %run market_data_module.ipynb\n",
      "  df_market = get_market_data()\n",
      "  df_tiers = get_margin_tiers()\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "FETCHING MARGIN TIERS\n",
      "======================================================================\n",
      "Timestamp: 2026-01-26 20:09:13 Cairo time\n",
      "\n",
      "Step 1: Fetching margin boundaries from PRODUCT_STATISTICS...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loaded 18307 records\n",
      "\n",
      "Step 2: Adding cohort IDs...\n",
      "    Records with cohorts: 25243\n",
      "\n",
      "Step 3: Calculating margin tiers...\n",
      "\n",
      "======================================================================\n",
      "MARGIN TIERS COMPLETE\n",
      "======================================================================\n",
      "Total records: 25243\n",
      "\n",
      "Margin Tier Structure:\n",
      "  margin_tier_below:   effective_min - step (1 below)\n",
      "  margin_tier_1:       effective_min_margin\n",
      "  margin_tier_2:       effective_min + 1*step\n",
      "  margin_tier_3:       effective_min + 2*step\n",
      "  margin_tier_4:       effective_min + 3*step\n",
      "  margin_tier_5:       max_boundary\n",
      "  margin_tier_above_1: max_boundary + 1*step\n",
      "  margin_tier_above_2: max_boundary + 2*step\n",
      "✅ Loaded 25243 margin tier records\n",
      "\n",
      "======================================================================\n",
      "FETCHING MARKET DATA\n",
      "======================================================================\n",
      "Timestamp: 2026-01-26 20:09:15 Cairo time\n",
      "\n",
      "Step 1: Fetching raw price data...\n",
      "  1.1 Ben Soliman prices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 1562 records\n",
      "  1.2 Marketplace prices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 11453 records\n",
      "  1.3 Scrapped prices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 5165 records\n",
      "  1.4 Product groups...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 1599 records\n",
      "  1.5 Sales data (for NMV weighting)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 20978 records\n",
      "  1.6 Margin stats...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 29609 records\n",
      "  1.7 Target margins...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 478 records\n",
      "  1.8 Product base (WAC)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 65277 records\n",
      "\n",
      "Step 2: Joining all market price sources (outer join)...\n",
      "    Market prices base: 16152 records\n",
      "\n",
      "Step 3: Adding cohort IDs and supporting data...\n",
      "    Records after adding cohorts: 24156\n",
      "\n",
      "Step 4: Processing group-level prices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_343/1916930114.py:138: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Records after group processing: 25511\n",
      "\n",
      "Step 5: Adding WAC and margin data...\n",
      "    Records with WAC: 25295\n",
      "\n",
      "Step 6: Filtering by price coverage...\n",
      "    Records after price coverage filter: 13572\n",
      "\n",
      "Step 7: Calculating price percentiles...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Records after price analysis: 12821\n",
      "\n",
      "Step 8: Converting prices to margins...\n",
      "\n",
      "======================================================================\n",
      "MARKET DATA COMPLETE\n",
      "======================================================================\n",
      "Total records: 12821\n",
      "  - With marketplace prices: 12252\n",
      "  - With scrapped prices: 6360\n",
      "  - With Ben Soliman prices: 8734\n",
      "✅ Loaded 12821 market data records\n",
      "\n",
      "Checking cohort_id availability:\n",
      "  - df has cohort_id: True\n",
      "  - df_margin_tiers has cohort_id: True\n",
      "  - df_market has cohort_id: True\n",
      "\n",
      "✅ Merged margin tiers: 28491 records\n",
      "   Margin tier columns added: ['region', 'optimal_bm', 'min_boundary', 'max_boundary', 'median_bm', 'effective_min_margin', 'margin_step', 'margin_tier_below', 'margin_tier_1', 'margin_tier_2', 'margin_tier_3', 'margin_tier_4', 'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2']\n",
      "✅ Merged market data: 28491 records\n",
      "   Market columns added: ['region', 'ben_soliman_price', 'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max', 'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped', 'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum', 'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market']\n",
      "\n",
      "Margin Stats: min=-inf%, max=60.11%, mean=-inf%\n",
      "Filtering SKUs for action...\n",
      "\n",
      "============================================================\n",
      "SKUs FILTERED FOR ACTION\n",
      "============================================================\n",
      "\n",
      "Total SKUs needing action: 157 out of 28491 (0.6%)\n",
      "\n",
      "Breakdown by reason:\n",
      "action_reason\n",
      "wac_increase           122\n",
      "growing_performance     35\n",
      "\n",
      "--- Condition A (WAC increase > 0.5%): 122 SKUs\n",
      "--- Condition B (Last hour growing + UTH good + qty > 5): 35 SKUs\n",
      "\n",
      "============================================================\n",
      "SAMPLE ACTION SKUs\n",
      "============================================================\n",
      "\n",
      "Total columns in df_action: 44\n",
      "Columns: ['warehouse_id', 'product_id', 'cohort_id', 'sku', 'region', 'brand', 'cat', 'current_price', 'wac_p', 'new_wac', 'current_margin', 'stocks', 'current_cart_rule', 'p80_daily_240d', 'p70_daily_retailers_240d', 'std_daily_240d', 'std_daily_retailers_240d', 'normal_refill', 'refill_stddev', 'target_margin', 'uth_qty', 'uth_qty_status', 'uth_retailers', 'uth_rets_status', 'last_hour_qty', 'last_hour_qty_status', 'last_hour_retailers', 'last_hour_rets_status', 'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market', 'margin_tier_1', 'margin_tier_2', 'margin_tier_3', 'margin_tier_4', 'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2', 'needs_action', 'action_reason']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>region</th>\n",
       "      <th>brand</th>\n",
       "      <th>cat</th>\n",
       "      <th>current_price</th>\n",
       "      <th>wac_p</th>\n",
       "      <th>new_wac</th>\n",
       "      <th>...</th>\n",
       "      <th>above_market</th>\n",
       "      <th>margin_tier_1</th>\n",
       "      <th>margin_tier_2</th>\n",
       "      <th>margin_tier_3</th>\n",
       "      <th>margin_tier_4</th>\n",
       "      <th>margin_tier_5</th>\n",
       "      <th>margin_tier_above_1</th>\n",
       "      <th>margin_tier_above_2</th>\n",
       "      <th>needs_action</th>\n",
       "      <th>action_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>797</td>\n",
       "      <td>22407</td>\n",
       "      <td>702</td>\n",
       "      <td>ديفا منظف ايدى الترا فريش - 500 مل</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>ديفا</td>\n",
       "      <td>صابون</td>\n",
       "      <td>432.00</td>\n",
       "      <td>391.412637</td>\n",
       "      <td>393.756565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097712</td>\n",
       "      <td>0.029994</td>\n",
       "      <td>0.036521</td>\n",
       "      <td>0.043047</td>\n",
       "      <td>0.049574</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.062626</td>\n",
       "      <td>0.069153</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>501</td>\n",
       "      <td>22407</td>\n",
       "      <td>1124</td>\n",
       "      <td>ديفا منظف ايدى الترا فريش - 500 مل</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>ديفا</td>\n",
       "      <td>صابون</td>\n",
       "      <td>432.00</td>\n",
       "      <td>391.412637</td>\n",
       "      <td>393.756565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097712</td>\n",
       "      <td>0.028770</td>\n",
       "      <td>0.036990</td>\n",
       "      <td>0.045210</td>\n",
       "      <td>0.053430</td>\n",
       "      <td>0.061650</td>\n",
       "      <td>0.069870</td>\n",
       "      <td>0.078090</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>337</td>\n",
       "      <td>10780</td>\n",
       "      <td>703</td>\n",
       "      <td>بطارية ريموت افيريدى ازرق - 20 حجر</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>افيريدي</td>\n",
       "      <td>بطاريات ولمبات</td>\n",
       "      <td>77.00</td>\n",
       "      <td>64.410110</td>\n",
       "      <td>66.337161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216898</td>\n",
       "      <td>0.079309</td>\n",
       "      <td>0.096982</td>\n",
       "      <td>0.114655</td>\n",
       "      <td>0.132327</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.167673</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>8</td>\n",
       "      <td>10780</td>\n",
       "      <td>703</td>\n",
       "      <td>بطارية ريموت افيريدى ازرق - 20 حجر</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>افيريدي</td>\n",
       "      <td>بطاريات ولمبات</td>\n",
       "      <td>77.00</td>\n",
       "      <td>64.410110</td>\n",
       "      <td>66.337161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.216898</td>\n",
       "      <td>0.079309</td>\n",
       "      <td>0.096982</td>\n",
       "      <td>0.114655</td>\n",
       "      <td>0.132327</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.167673</td>\n",
       "      <td>0.185345</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>339</td>\n",
       "      <td>3891</td>\n",
       "      <td>704</td>\n",
       "      <td>عصير سن توب مانجو الفونسو - 250 مل</td>\n",
       "      <td>Delta East</td>\n",
       "      <td>سن توب</td>\n",
       "      <td>عصاير</td>\n",
       "      <td>255.00</td>\n",
       "      <td>227.378722</td>\n",
       "      <td>229.441645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161788</td>\n",
       "      <td>0.046694</td>\n",
       "      <td>0.054401</td>\n",
       "      <td>0.062109</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>0.077523</td>\n",
       "      <td>0.085231</td>\n",
       "      <td>0.092938</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>170</td>\n",
       "      <td>3891</td>\n",
       "      <td>704</td>\n",
       "      <td>عصير سن توب مانجو الفونسو - 250 مل</td>\n",
       "      <td>Delta East</td>\n",
       "      <td>سن توب</td>\n",
       "      <td>عصاير</td>\n",
       "      <td>255.00</td>\n",
       "      <td>227.378722</td>\n",
       "      <td>229.441645</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161788</td>\n",
       "      <td>0.046694</td>\n",
       "      <td>0.054401</td>\n",
       "      <td>0.062109</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>0.077523</td>\n",
       "      <td>0.085231</td>\n",
       "      <td>0.092938</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>236</td>\n",
       "      <td>3893</td>\n",
       "      <td>701</td>\n",
       "      <td>عصير سن توب برتقال - 250 مل</td>\n",
       "      <td>Giza</td>\n",
       "      <td>سن توب</td>\n",
       "      <td>عصاير</td>\n",
       "      <td>255.50</td>\n",
       "      <td>227.653222</td>\n",
       "      <td>229.673664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202914</td>\n",
       "      <td>0.056264</td>\n",
       "      <td>0.062754</td>\n",
       "      <td>0.069243</td>\n",
       "      <td>0.075732</td>\n",
       "      <td>0.082221</td>\n",
       "      <td>0.088711</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>962</td>\n",
       "      <td>3893</td>\n",
       "      <td>701</td>\n",
       "      <td>عصير سن توب برتقال - 250 مل</td>\n",
       "      <td>Giza</td>\n",
       "      <td>سن توب</td>\n",
       "      <td>عصاير</td>\n",
       "      <td>255.50</td>\n",
       "      <td>227.653222</td>\n",
       "      <td>229.673664</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202914</td>\n",
       "      <td>0.056264</td>\n",
       "      <td>0.062754</td>\n",
       "      <td>0.069243</td>\n",
       "      <td>0.075732</td>\n",
       "      <td>0.082221</td>\n",
       "      <td>0.088711</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>236</td>\n",
       "      <td>1052</td>\n",
       "      <td>701</td>\n",
       "      <td>مربى الرشيدى الميزان تين - 700 جم</td>\n",
       "      <td>NaN</td>\n",
       "      <td>الرشيدي الميزان</td>\n",
       "      <td>مربي</td>\n",
       "      <td>537.25</td>\n",
       "      <td>516.521091</td>\n",
       "      <td>519.600652</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033560</td>\n",
       "      <td>0.038407</td>\n",
       "      <td>0.043255</td>\n",
       "      <td>0.048102</td>\n",
       "      <td>0.052950</td>\n",
       "      <td>0.057797</td>\n",
       "      <td>0.062644</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>962</td>\n",
       "      <td>1052</td>\n",
       "      <td>701</td>\n",
       "      <td>مربى الرشيدى الميزان تين - 700 جم</td>\n",
       "      <td>NaN</td>\n",
       "      <td>الرشيدي الميزان</td>\n",
       "      <td>مربي</td>\n",
       "      <td>537.25</td>\n",
       "      <td>516.521091</td>\n",
       "      <td>519.600652</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033560</td>\n",
       "      <td>0.038407</td>\n",
       "      <td>0.043255</td>\n",
       "      <td>0.048102</td>\n",
       "      <td>0.052950</td>\n",
       "      <td>0.057797</td>\n",
       "      <td>0.062644</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      warehouse_id  product_id  cohort_id                                 sku  \\\n",
       "480            797       22407        702  ديفا منظف ايدى الترا فريش - 500 مل   \n",
       "963            501       22407       1124  ديفا منظف ايدى الترا فريش - 500 مل   \n",
       "1036           337       10780        703  بطارية ريموت افيريدى ازرق - 20 حجر   \n",
       "1037             8       10780        703  بطارية ريموت افيريدى ازرق - 20 حجر   \n",
       "1125           339        3891        704  عصير سن توب مانجو الفونسو - 250 مل   \n",
       "1126           170        3891        704  عصير سن توب مانجو الفونسو - 250 مل   \n",
       "1127           236        3893        701         عصير سن توب برتقال - 250 مل   \n",
       "1128           962        3893        701         عصير سن توب برتقال - 250 مل   \n",
       "1275           236        1052        701   مربى الرشيدى الميزان تين - 700 جم   \n",
       "1276           962        1052        701   مربى الرشيدى الميزان تين - 700 جم   \n",
       "\n",
       "           region            brand             cat  current_price       wac_p  \\\n",
       "480    Alexandria             ديفا           صابون         432.00  391.412637   \n",
       "963   Upper Egypt             ديفا           صابون         432.00  391.412637   \n",
       "1036   Delta West          افيريدي  بطاريات ولمبات          77.00   64.410110   \n",
       "1037   Delta West          افيريدي  بطاريات ولمبات          77.00   64.410110   \n",
       "1125   Delta East           سن توب           عصاير         255.00  227.378722   \n",
       "1126   Delta East           سن توب           عصاير         255.00  227.378722   \n",
       "1127         Giza           سن توب           عصاير         255.50  227.653222   \n",
       "1128         Giza           سن توب           عصاير         255.50  227.653222   \n",
       "1275          NaN  الرشيدي الميزان            مربي         537.25  516.521091   \n",
       "1276          NaN  الرشيدي الميزان            مربي         537.25  516.521091   \n",
       "\n",
       "         new_wac  ...  above_market  margin_tier_1  margin_tier_2  \\\n",
       "480   393.756565  ...      0.097712       0.029994       0.036521   \n",
       "963   393.756565  ...      0.097712       0.028770       0.036990   \n",
       "1036   66.337161  ...      0.216898       0.079309       0.096982   \n",
       "1037   66.337161  ...      0.216898       0.079309       0.096982   \n",
       "1125  229.441645  ...      0.161788       0.046694       0.054401   \n",
       "1126  229.441645  ...      0.161788       0.046694       0.054401   \n",
       "1127  229.673664  ...      0.202914       0.056264       0.062754   \n",
       "1128  229.673664  ...      0.202914       0.056264       0.062754   \n",
       "1275  519.600652  ...           NaN       0.033560       0.038407   \n",
       "1276  519.600652  ...           NaN       0.033560       0.038407   \n",
       "\n",
       "      margin_tier_3  margin_tier_4  margin_tier_5  margin_tier_above_1  \\\n",
       "480        0.043047       0.049574       0.056100             0.062626   \n",
       "963        0.045210       0.053430       0.061650             0.069870   \n",
       "1036       0.114655       0.132327       0.150000             0.167673   \n",
       "1037       0.114655       0.132327       0.150000             0.167673   \n",
       "1125       0.062109       0.069816       0.077523             0.085231   \n",
       "1126       0.062109       0.069816       0.077523             0.085231   \n",
       "1127       0.069243       0.075732       0.082221             0.088711   \n",
       "1128       0.069243       0.075732       0.082221             0.088711   \n",
       "1275       0.043255       0.048102       0.052950             0.057797   \n",
       "1276       0.043255       0.048102       0.052950             0.057797   \n",
       "\n",
       "      margin_tier_above_2  needs_action  action_reason  \n",
       "480              0.069153          True   wac_increase  \n",
       "963              0.078090          True   wac_increase  \n",
       "1036             0.185345          True   wac_increase  \n",
       "1037             0.185345          True   wac_increase  \n",
       "1125             0.092938          True   wac_increase  \n",
       "1126             0.092938          True   wac_increase  \n",
       "1127             0.095200          True   wac_increase  \n",
       "1128             0.095200          True   wac_increase  \n",
       "1275             0.062644          True   wac_increase  \n",
       "1276             0.062644          True   wac_increase  \n",
       "\n",
       "[10 rows x 44 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FETCH MARKET DATA AND MARGIN TIERS\n",
    "# =============================================================================\n",
    "print(\"Fetching market data and margin tiers...\")\n",
    "\n",
    "# Import market_data_module for get_market_data()\n",
    "%run market_data_module.ipynb\n",
    "\n",
    "# 1. Get margin tiers (already available from queries_module)\n",
    "df_margin_tiers = get_margin_tiers()\n",
    "print(f\"✅ Loaded {len(df_margin_tiers)} margin tier records\")\n",
    "\n",
    "# 2. Get market data\n",
    "df_market = get_market_data()\n",
    "print(f\"✅ Loaded {len(df_market)} market data records\")\n",
    "\n",
    "# Verify cohort_id is available in all dataframes\n",
    "print(f\"\\nChecking cohort_id availability:\")\n",
    "print(f\"  - df has cohort_id: {'cohort_id' in df.columns}\")\n",
    "print(f\"  - df_margin_tiers has cohort_id: {'cohort_id' in df_margin_tiers.columns}\")\n",
    "print(f\"  - df_market has cohort_id: {'cohort_id' in df_market.columns}\")\n",
    "\n",
    "# 3. Merge margin tiers with df (by cohort_id + product_id) - ALL COLUMNS\n",
    "merge_keys = ['cohort_id', 'product_id']\n",
    "df = df.drop(columns=[c for c in df_margin_tiers.columns if c in df.columns and c not in merge_keys], errors='ignore')\n",
    "df = df.merge(df_margin_tiers, on=merge_keys, how='left')\n",
    "print(f\"\\n✅ Merged margin tiers: {len(df)} records\")\n",
    "print(f\"   Margin tier columns added: {[c for c in df_margin_tiers.columns if c not in merge_keys]}\")\n",
    "\n",
    "# 4. Merge market data with df (by cohort_id + product_id) - ALL COLUMNS\n",
    "df = df.drop(columns=[c for c in df_market.columns if c in df.columns and c not in merge_keys], errors='ignore')\n",
    "df = df.merge(df_market, on=merge_keys, how='left')\n",
    "print(f\"✅ Merged market data: {len(df)} records\")\n",
    "print(f\"   Market columns added: {[c for c in df_market.columns if c not in merge_keys]}\")\n",
    "\n",
    "# 5. Calculate current margin based on current_price and new_wac\n",
    "df['current_margin'] = (df['current_price'] - df['new_wac']) / df['current_price']\n",
    "df['current_margin'] = df['current_margin'].fillna(0)\n",
    "\n",
    "print(f\"\\nMargin Stats: min={df['current_margin'].min():.2%}, max={df['current_margin'].max():.2%}, mean={df['current_margin'].mean():.2%}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FILTER SKUS FOR ACTION\n",
    "# =============================================================================\n",
    "# Filter SKUs that need action based on:\n",
    "# Pre-condition: below_min_stock_flag != 1 (must be sellable)\n",
    "# Condition A: new_wac > wac_p * 1.005 (WAC increased by more than 0.5%)\n",
    "# Condition B: Last hour growing (qty OR rets) AND UTH (one growing + other on_track/growing) AND last_hour_qty > 5\n",
    "\n",
    "print(\"Filtering SKUs for action...\")\n",
    "\n",
    "# Skip SKUs with below_min_stock_flag (stock < min selling unit qty)\n",
    "can_sell = df['below_min_stock_flag'].fillna(0) != 1\n",
    "\n",
    "# Condition A: WAC increased significantly\n",
    "condition_a = (df['new_wac'] > df['wac_p'] * 1.005)\n",
    "\n",
    "# Condition B: Last hour growing AND UTH performing well AND last_hour_qty > 5\n",
    "# UTH good = one must be 'growing' AND the other must be 'on_track' or 'growing'\n",
    "last_hour_growing = (df['last_hour_qty_status'] == 'growing') | (df['last_hour_rets_status'] == 'growing')\n",
    "uth_good = (\n",
    "    ((df['uth_qty_status'] == 'growing') & (df['uth_rets_status'].isin(['on_track', 'growing']))) |\n",
    "    ((df['uth_rets_status'] == 'growing') & (df['uth_qty_status'].isin(['on_track', 'growing'])))\n",
    ")\n",
    "last_hour_qty_threshold = df['last_hour_qty'] > 5\n",
    "condition_b = last_hour_growing & uth_good & last_hour_qty_threshold & can_sell\n",
    "\n",
    "# Combine conditions (A OR B)\n",
    "df['needs_action'] = condition_a | condition_b\n",
    "df['action_reason'] = 'none'\n",
    "df.loc[condition_a & ~condition_b, 'action_reason'] = 'wac_increase'\n",
    "df.loc[~condition_a & condition_b, 'action_reason'] = 'growing_performance'\n",
    "df.loc[condition_a & condition_b, 'action_reason'] = 'both'\n",
    "\n",
    "# Define important columns for df_action\n",
    "action_columns = [\n",
    "    # Identification\n",
    "    'warehouse_id', 'product_id', 'cohort_id', 'sku', 'region', 'brand', 'cat',\n",
    "    # Price & Cost\n",
    "    'current_price', 'wac_p', 'new_wac', 'current_margin',\n",
    "    # Inventory & Rules\n",
    "    'stocks', 'current_cart_rule',\n",
    "    # Performance Targets\n",
    "    'p80_daily_240d', 'p70_daily_retailers_240d', 'std_daily_240d', 'std_daily_retailers_240d',\n",
    "    # Refill columns for cart rule calculation\n",
    "    'normal_refill', 'refill_stddev', 'target_margin',\n",
    "    # UTH Status\n",
    "    'uth_qty', 'uth_qty_status', 'uth_retailers', 'uth_rets_status',\n",
    "    # Last Hour Status\n",
    "    'last_hour_qty', 'last_hour_qty_status', 'last_hour_retailers', 'last_hour_rets_status',\n",
    "    # Market Margins\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market',\n",
    "    # Margin Tiers (excluding: effective_min_margin, max_boundary, margin_step, margin_tier_below)\n",
    "    'margin_tier_1', 'margin_tier_2', 'margin_tier_3', 'margin_tier_4', 'margin_tier_5',\n",
    "    'margin_tier_above_1', 'margin_tier_above_2',\n",
    "    # Action Flags\n",
    "    'needs_action', 'action_reason'\n",
    "]\n",
    "\n",
    "# Filter to only columns that exist in df\n",
    "action_columns = [c for c in action_columns if c in df.columns]\n",
    "\n",
    "# Filter to action SKUs with selected columns only\n",
    "df_action = df[df['needs_action']][action_columns].copy()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SKUs FILTERED FOR ACTION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nTotal SKUs needing action: {len(df_action)} out of {len(df)} ({len(df_action)/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nBreakdown by reason:\")\n",
    "print(df_action['action_reason'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\n--- Condition A (WAC increase > 0.5%): {condition_a.sum()} SKUs\")\n",
    "print(f\"--- Condition B (Last hour growing + UTH good + qty > 5): {condition_b.sum()} SKUs\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SAMPLE ACTION SKUs\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nTotal columns in df_action: {len(df_action.columns)}\")\n",
    "print(f\"Columns: {df_action.columns.tolist()}\")\n",
    "display(df_action.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:10:44.990205Z",
     "iopub.status.busy": "2026-01-26T18:10:44.989970Z",
     "iopub.status.idle": "2026-01-26T18:10:45.060868Z",
     "shell.execute_reply": "2026-01-26T18:10:45.060000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating actions for filtered SKUs...\n",
      "  WAC increase actions: 0 SKUs\n",
      "    (SKUs where wac_p < current_price < new_wac)\n",
      "  Rets growing actions (price increase): 29 SKUs\n",
      "  Qty growing actions (cart rule change): 6 SKUs\n",
      "    (Cart rule: rounded, min=2, max=150)\n",
      "\n",
      "============================================================\n",
      "ACTION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Price Actions:\n",
      "price_action\n",
      "none            128\n",
      "rets_growing     29\n",
      "\n",
      "Cart Rule Actions:\n",
      "cart_rule_action\n",
      "none           151\n",
      "qty_growing      6\n",
      "\n",
      "SKUs with new price: 29\n",
      "  Avg price change: inf%\n",
      "\n",
      "SKUs with new cart rule: 6\n",
      "  Avg cart rule change: -70.1%\n",
      "\n",
      "============================================================\n",
      "SAMPLE OUTPUT\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>current_price</th>\n",
       "      <th>new_price</th>\n",
       "      <th>current_cart_rule</th>\n",
       "      <th>new_cart_rule</th>\n",
       "      <th>price_action</th>\n",
       "      <th>cart_rule_action</th>\n",
       "      <th>action_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>كيك شيف دريم - 23 جم</td>\n",
       "      <td>125.75</td>\n",
       "      <td>127.955000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2839</th>\n",
       "      <td>سمنة قوت القلوب ابيض - 650 جم</td>\n",
       "      <td>392.00</td>\n",
       "      <td>394.262623</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3102</th>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>204.00</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4430</th>\n",
       "      <td>تورتا رولز ديلايتس كيـك كاكاو محشو بكريمه الفا...</td>\n",
       "      <td>47.00</td>\n",
       "      <td>47.468064</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>مكرونة بساطة اسباجيتى - 1 كجم</td>\n",
       "      <td>238.00</td>\n",
       "      <td>241.330702</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>ارز حبوبة رفيع - 1 كجم</td>\n",
       "      <td>247.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>none</td>\n",
       "      <td>qty_growing</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>عصير تانج مانجو ظرف - 20 جم</td>\n",
       "      <td>100.75</td>\n",
       "      <td>101.757500</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5497</th>\n",
       "      <td>سمنة حبوبة نباتى صفراء - 300 جم</td>\n",
       "      <td>336.25</td>\n",
       "      <td>339.293422</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>عصير كل يوم كوكتيل- 225 مل</td>\n",
       "      <td>120.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>none</td>\n",
       "      <td>qty_growing</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6811</th>\n",
       "      <td>مبروووووك لقيت الفنان و كسبت 30 جنيه - 1 ق</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>999.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6925</th>\n",
       "      <td>عصير بيتى جوافة - 1 لتر</td>\n",
       "      <td>310.00</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7575</th>\n",
       "      <td>سفن اب ستار كانز - 320 مل</td>\n",
       "      <td>336.00</td>\n",
       "      <td>340.675000</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8270</th>\n",
       "      <td>عصير تانج مانجو ظرف - 20 جم</td>\n",
       "      <td>96.50</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>329.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8481</th>\n",
       "      <td>فيبا سائل أطباق تفاح- 3 كجم</td>\n",
       "      <td>396.00</td>\n",
       "      <td>399.581134</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9856</th>\n",
       "      <td>فيبا سائل أطباق ليمون- 3 كجم</td>\n",
       "      <td>396.00</td>\n",
       "      <td>398.726309</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    sku  current_price  \\\n",
       "1491                               كيك شيف دريم - 23 جم         125.75   \n",
       "2839                      سمنة قوت القلوب ابيض - 650 جم         392.00   \n",
       "3102                                   بيبسى - 2.43 لتر         204.00   \n",
       "4430  تورتا رولز ديلايتس كيـك كاكاو محشو بكريمه الفا...          47.00   \n",
       "4605                      مكرونة بساطة اسباجيتى - 1 كجم         238.00   \n",
       "5107                             ارز حبوبة رفيع - 1 كجم         247.00   \n",
       "5179                        عصير تانج مانجو ظرف - 20 جم         100.75   \n",
       "5497                    سمنة حبوبة نباتى صفراء - 300 جم         336.25   \n",
       "5561                         عصير كل يوم كوكتيل- 225 مل         120.00   \n",
       "6811         مبروووووك لقيت الفنان و كسبت 30 جنيه - 1 ق           0.00   \n",
       "6925                            عصير بيتى جوافة - 1 لتر         310.00   \n",
       "7575                          سفن اب ستار كانز - 320 مل         336.00   \n",
       "8270                        عصير تانج مانجو ظرف - 20 جم          96.50   \n",
       "8481                        فيبا سائل أطباق تفاح- 3 كجم         396.00   \n",
       "9856                       فيبا سائل أطباق ليمون- 3 كجم         396.00   \n",
       "\n",
       "       new_price  current_cart_rule  new_cart_rule  price_action  \\\n",
       "1491  127.955000               12.0            NaN  rets_growing   \n",
       "2839  394.262623               25.0            NaN  rets_growing   \n",
       "3102  210.000000              150.0            NaN  rets_growing   \n",
       "4430   47.468064               25.0            NaN  rets_growing   \n",
       "4605  241.330702               28.0            NaN  rets_growing   \n",
       "5107         NaN              150.0            7.0          none   \n",
       "5179  101.757500               10.0            NaN  rets_growing   \n",
       "5497  339.293422               13.0            NaN  rets_growing   \n",
       "5561         NaN              150.0            4.0          none   \n",
       "6811    0.010000              999.0            NaN  rets_growing   \n",
       "6925  330.000000                6.0            NaN  rets_growing   \n",
       "7575  340.675000               92.0            NaN  rets_growing   \n",
       "8270   97.500000              329.0            NaN  rets_growing   \n",
       "8481  399.581134               25.0            NaN  rets_growing   \n",
       "9856  398.726309               25.0            NaN  rets_growing   \n",
       "\n",
       "     cart_rule_action        action_reason  \n",
       "1491             none  growing_performance  \n",
       "2839             none  growing_performance  \n",
       "3102             none  growing_performance  \n",
       "4430             none  growing_performance  \n",
       "4605             none  growing_performance  \n",
       "5107      qty_growing  growing_performance  \n",
       "5179             none  growing_performance  \n",
       "5497             none  growing_performance  \n",
       "5561      qty_growing  growing_performance  \n",
       "6811             none  growing_performance  \n",
       "6925             none  growing_performance  \n",
       "7575             none  growing_performance  \n",
       "8270             none  growing_performance  \n",
       "8481             none  growing_performance  \n",
       "9856             none  growing_performance  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ACTION LOGIC\n",
    "# =============================================================================\n",
    "print(\"Calculating actions for filtered SKUs...\")\n",
    "\n",
    "# Step 0: Preparation - Calculate normal_refill_3std\n",
    "df_action['normal_refill_3std'] = df_action['normal_refill'] + 3 * df_action['refill_stddev']\n",
    "\n",
    "# Initialize output columns\n",
    "df_action['new_price'] = np.nan\n",
    "df_action['new_cart_rule'] = np.nan\n",
    "df_action['price_action'] = 'none'\n",
    "df_action['cart_rule_action'] = 'none'\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER: Calculate all price tiers from margins using wac_p\n",
    "# =============================================================================\n",
    "def calculate_price_from_margin(wac, margin):\n",
    "    \"\"\"Calculate price from WAC and margin: price = wac / (1 - margin)\"\"\"\n",
    "    if pd.isna(margin) or margin >= 1:\n",
    "        return np.nan\n",
    "    return wac / (1 - margin)\n",
    "\n",
    "# Calculate market prices (using wac_p)\n",
    "market_margin_cols = ['market_min', 'market_25', 'market_50', 'market_75', 'market_max']\n",
    "for col in market_margin_cols:\n",
    "    price_col = f'{col}_price'\n",
    "    df_action[price_col] = df_action.apply(\n",
    "        lambda row: calculate_price_from_margin(row['wac_p'], row[col]), axis=1)\n",
    "\n",
    "# Calculate margin tier prices (using wac_p)\n",
    "tier_margin_cols = ['margin_tier_1', 'margin_tier_2', 'margin_tier_3', 'margin_tier_4', 'margin_tier_5',\n",
    "                    'margin_tier_above_1', 'margin_tier_above_2']\n",
    "for col in tier_margin_cols:\n",
    "    price_col = f'{col}_price'\n",
    "    df_action[price_col] = df_action.apply(\n",
    "        lambda row: calculate_price_from_margin(row['wac_p'], row[col]), axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER: Find first price above threshold\n",
    "# =============================================================================\n",
    "def find_first_price_above(row, threshold, price_cols):\n",
    "    \"\"\"Find the first price in price_cols that is above threshold.\"\"\"\n",
    "    for col in price_cols:\n",
    "        price = row.get(col, np.nan)\n",
    "        if pd.notna(price) and price > threshold:\n",
    "            return price\n",
    "    return np.nan\n",
    "\n",
    "# Define price column order (market first, then tiers)\n",
    "market_price_cols = ['market_min_price', 'market_25_price', 'market_50_price', 'market_75_price', 'market_max_price']\n",
    "tier_price_cols = ['margin_tier_1_price', 'margin_tier_2_price', 'margin_tier_3_price', \n",
    "                   'margin_tier_4_price', 'margin_tier_5_price', \n",
    "                   'margin_tier_above_1_price', 'margin_tier_above_2_price']\n",
    "all_price_cols = market_price_cols + tier_price_cols\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: WAC Increase Actions (action_reason = 'both' or 'wac_increase')\n",
    "# =============================================================================\n",
    "# Only apply if: current_price < new_wac AND current_price > wac_p\n",
    "# (price is squeezed between old and new WAC)\n",
    "wac_increase_mask = (\n",
    "    df_action['action_reason'].isin(['both', 'wac_increase']) &\n",
    "    (df_action['current_price'] < df_action['new_wac']) &\n",
    "    (df_action['current_price'] > df_action['wac_p'])\n",
    ")\n",
    "\n",
    "def get_wac_increase_price(row):\n",
    "    \"\"\"Find first market/tier price above current_price.\"\"\"\n",
    "    # Find first price above current_price (not new_wac)\n",
    "    new_price = find_first_price_above(row, row['current_price'], all_price_cols)\n",
    "    return new_price\n",
    "\n",
    "df_action.loc[wac_increase_mask, 'new_price'] = df_action[wac_increase_mask].apply(get_wac_increase_price, axis=1)\n",
    "df_action.loc[wac_increase_mask, 'price_action'] = 'wac_increase'\n",
    "\n",
    "print(f\"  WAC increase actions: {wac_increase_mask.sum()} SKUs\")\n",
    "print(f\"    (SKUs where wac_p < current_price < new_wac)\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: Growing Performance Actions (action_reason = 'growing_performance')\n",
    "# =============================================================================\n",
    "growing_mask = df_action['action_reason'] == 'growing_performance'\n",
    "\n",
    "# Case A: Retailers growing (with or without qty)\n",
    "rets_growing_mask = growing_mask & (df_action['last_hour_rets_status'] == 'growing')\n",
    "\n",
    "def get_rets_growing_price(row):\n",
    "    \"\"\"Find price for rets growing: market/tier >= current_price * 1.005, or fallback to target margin.\"\"\"\n",
    "    min_price = row['current_price'] * 1.005\n",
    "    \n",
    "    # Try market prices first\n",
    "    new_price = find_first_price_above(row, min_price, market_price_cols)\n",
    "    if pd.notna(new_price):\n",
    "        return new_price\n",
    "    \n",
    "    # Try tier prices\n",
    "    new_price = find_first_price_above(row, min_price, tier_price_cols)\n",
    "    if pd.notna(new_price):\n",
    "        return new_price\n",
    "    \n",
    "    # Fallback: wac_p / (1 - (target_margin * 1.15))\n",
    "    target_margin = row.get('target_margin', 0)\n",
    "    if pd.notna(target_margin) and target_margin * 1.15 < 1:\n",
    "        fallback_price = row['wac_p'] / (1 - (target_margin * 1.15))\n",
    "        # If fallback price is lower than current price, use current_price * 1.01\n",
    "        if fallback_price < row['current_price']:\n",
    "            return row['current_price'] * 1.01\n",
    "        return fallback_price\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "df_action.loc[rets_growing_mask, 'new_price'] = df_action[rets_growing_mask].apply(get_rets_growing_price, axis=1)\n",
    "df_action.loc[rets_growing_mask, 'price_action'] = 'rets_growing'\n",
    "\n",
    "print(f\"  Rets growing actions (price increase): {rets_growing_mask.sum()} SKUs\")\n",
    "\n",
    "# Case B: Qty growing only (rets NOT growing)\n",
    "qty_only_growing_mask = growing_mask & (df_action['last_hour_qty_status'] == 'growing') & (df_action['last_hour_rets_status'] != 'growing')\n",
    "\n",
    "def get_qty_growing_cart_rule(row):\n",
    "    \"\"\"Calculate new cart rule for qty growing only.\"\"\"\n",
    "    # Calculate qty per retailer\n",
    "    uth_retailers = row.get('uth_retailers', 0)\n",
    "    if uth_retailers == 0:\n",
    "        qty_per_retailer = np.inf\n",
    "    else:\n",
    "        qty_per_retailer = row['uth_qty'] / uth_retailers\n",
    "    \n",
    "    # Get the three options\n",
    "    option1 = row.get('normal_refill_3std', np.inf)\n",
    "    option2 = qty_per_retailer\n",
    "    option3 = row.get('current_cart_rule', np.inf) * 0.85\n",
    "    \n",
    "    # Return minimum of the three (excluding inf/nan)\n",
    "    options = [opt for opt in [option1, option2, option3] if pd.notna(opt) and opt != np.inf]\n",
    "    if options:\n",
    "        return min(options)\n",
    "    return np.nan\n",
    "\n",
    "df_action.loc[qty_only_growing_mask, 'new_cart_rule'] = df_action[qty_only_growing_mask].apply(get_qty_growing_cart_rule, axis=1)\n",
    "\n",
    "# Round and apply min/max constraints to new_cart_rule\n",
    "df_action['new_cart_rule'] = df_action['new_cart_rule'].round()\n",
    "df_action['new_cart_rule'] = df_action['new_cart_rule'].clip(lower=2, upper=150)\n",
    "\n",
    "df_action.loc[qty_only_growing_mask, 'cart_rule_action'] = 'qty_growing'\n",
    "\n",
    "print(f\"  Qty growing actions (cart rule change): {qty_only_growing_mask.sum()} SKUs\")\n",
    "print(f\"    (Cart rule: rounded, min=2, max=150)\")\n",
    "\n",
    "# =============================================================================\n",
    "# SUMMARY\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ACTION SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nPrice Actions:\")\n",
    "print(df_action['price_action'].value_counts().to_string())\n",
    "print(f\"\\nCart Rule Actions:\")\n",
    "print(df_action['cart_rule_action'].value_counts().to_string())\n",
    "\n",
    "# Show SKUs with new prices\n",
    "price_changes = df_action[df_action['new_price'].notna()]\n",
    "print(f\"\\nSKUs with new price: {len(price_changes)}\")\n",
    "if len(price_changes) > 0:\n",
    "    print(f\"  Avg price change: {((price_changes['new_price'] - price_changes['current_price']) / price_changes['current_price']).mean()*100:.1f}%\")\n",
    "\n",
    "# Show SKUs with new cart rules\n",
    "cart_changes = df_action[df_action['new_cart_rule'].notna()]\n",
    "print(f\"\\nSKUs with new cart rule: {len(cart_changes)}\")\n",
    "if len(cart_changes) > 0:\n",
    "    print(f\"  Avg cart rule change: {((cart_changes['new_cart_rule'] - cart_changes['current_cart_rule']) / cart_changes['current_cart_rule']).mean()*100:.1f}%\")\n",
    "\n",
    "# Display sample\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SAMPLE OUTPUT\")\n",
    "print(f\"{'='*60}\")\n",
    "output_cols = ['sku', 'current_price', 'new_price', 'current_cart_rule', 'new_cart_rule', \n",
    "               'price_action', 'cart_rule_action', 'action_reason']\n",
    "output_cols = [c for c in output_cols if c in df_action.columns]\n",
    "display(df_action[df_action['new_price'].notna() | df_action['new_cart_rule'].notna()][output_cols].head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:10:45.063014Z",
     "iopub.status.busy": "2026-01-26T18:10:45.062653Z",
     "iopub.status.idle": "2026-01-26T18:10:45.067171Z",
     "shell.execute_reply": "2026-01-26T18:10:45.066412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PUSH MODE: LIVE\n",
      "============================================================\n",
      "🚀 Live mode - files will be uploaded to MaxAB API\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PUSH CONFIGURATION\n",
    "# =============================================================================\n",
    "# Mode: 'testing' = prepare files only, 'live' = actually upload to API\n",
    "PUSH_MODE = 'live'  # Change to 'live' when ready to push\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PUSH MODE: {PUSH_MODE.upper()}\")\n",
    "print(f\"{'='*60}\")\n",
    "if PUSH_MODE == 'testing':\n",
    "    print(\"⚠️ Testing mode - files will be prepared but NOT uploaded\")\n",
    "else:\n",
    "    print(\"🚀 Live mode - files will be uploaded to MaxAB API\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:10:45.069081Z",
     "iopub.status.busy": "2026-01-26T18:10:45.068873Z",
     "iopub.status.idle": "2026-01-26T18:10:45.900815Z",
     "shell.execute_reply": "2026-01-26T18:10:45.899897Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push Cart Rules Handler loaded at 2026-01-26 20:10:45 Cairo time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API credentials loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push Prices Handler loaded at 2026-01-26 20:10:45 Cairo time\n",
      "✓ API credentials loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Google Sheets client initialized\n",
      "✅ Push handlers loaded\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORT PUSH HANDLERS\n",
    "# =============================================================================\n",
    "%run push_cart_rules_handler.ipynb\n",
    "%run push_prices_handler.ipynb\n",
    "\n",
    "print(\"✅ Push handlers loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:10:45.902942Z",
     "iopub.status.busy": "2026-01-26T18:10:45.902593Z",
     "iopub.status.idle": "2026-01-26T18:10:48.021315Z",
     "shell.execute_reply": "2026-01-26T18:10:48.020513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching packing_units ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 34849 records\n",
      "✅ Loaded 34849 packing units\n",
      "\n",
      "📊 Push Summary:\n",
      "  Price changes: 29 SKUs\n",
      "  Cart rule changes: 6 SKUs\n",
      "  Mode: live\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PREPARE DATA FOR PUSH\n",
    "# =============================================================================\n",
    "# Get packing units for push handlers\n",
    "pus = get_packing_units()\n",
    "print(f\"✅ Loaded {len(pus)} packing units\")\n",
    "\n",
    "# Prepare df_action with required columns for push functions\n",
    "# Prices need: product_id, sku, new_price, warehouse_id, cohort_id, stocks, current_price\n",
    "# Cart rules need: product_id, sku, new_cart_rule, warehouse_id, cohort_id, stocks, current_cart_rule\n",
    "\n",
    "# Rename stocks column if needed\n",
    "if 'current_stocks' in df_action.columns and 'stocks' not in df_action.columns:\n",
    "    df_action['stocks'] = df_action['current_stocks']\n",
    "\n",
    "# Summary of what will be pushed\n",
    "price_changes = df_action[df_action['new_price'].notna() & (df_action['new_price'] != df_action['current_price'])]\n",
    "cart_changes = df_action[df_action['new_cart_rule'].notna() & (df_action['new_cart_rule'] != df_action['current_cart_rule'])]\n",
    "\n",
    "print(f\"\\n📊 Push Summary:\")\n",
    "print(f\"  Price changes: {len(price_changes)} SKUs\")\n",
    "print(f\"  Cart rule changes: {len(cart_changes)} SKUs\")\n",
    "print(f\"  Mode: {PUSH_MODE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:10:48.023708Z",
     "iopub.status.busy": "2026-01-26T18:10:48.023487Z",
     "iopub.status.idle": "2026-01-26T18:11:03.592110Z",
     "shell.execute_reply": "2026-01-26T18:11:03.591203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 1: PUSH CART RULES\n",
      "============================================================\n",
      "\n",
      "🚀 MODE: LIVE\n",
      "   Files will be prepared AND uploaded to API\n",
      "\n",
      "============================================================\n",
      "PUSH CART RULES - Source: module_4\n",
      "============================================================\n",
      "Total received: 157\n",
      "Cart rule changes to push: 6\n",
      "Skipped (no change): 151\n",
      "\n",
      "Cart rule changes summary:\n",
      "  Increases: 0\n",
      "  Decreases: 6\n",
      "\n",
      "📋 Prepared 6 packing unit cart rules\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 704\n",
      "==================================================\n",
      "  Saved: uploads/module_4_cart_rules_704.xlsx (1 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 234.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing cohort: 700\n",
      "==================================================\n",
      "  Saved: uploads/module_4_cart_rules_700.xlsx (1 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 239.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 702\n",
      "==================================================\n",
      "  Saved: uploads/module_4_cart_rules_702.xlsx (1 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 224.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 701\n",
      "==================================================\n",
      "  Saved: uploads/module_4_cart_rules_701.xlsx (1 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 235.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 1125\n",
      "==================================================\n",
      "  Saved: uploads/module_4_cart_rules_1125.xlsx (1 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 234.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 1124\n",
      "==================================================\n",
      "  Saved: uploads/module_4_cart_rules_1124.xlsx (1 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 235.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "============================================================\n",
      "🚀 UPLOAD COMPLETE\n",
      "============================================================\n",
      "Mode: live\n",
      "Total prepared: 6\n",
      "Total failed: 0\n",
      "\n",
      "📊 Cart Rules Push Result:\n",
      "  Total received: 157\n",
      "  Cart rule changes: 6\n",
      "  Pushed: 6\n",
      "  Skipped: 151\n",
      "  Failed: 0\n",
      "  Mode: live\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: PUSH CART RULES\n",
    "# =============================================================================\n",
    "# Push cart rules first - if any cohorts fail, we'll skip them for prices too\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"STEP 1: PUSH CART RULES\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "cart_result = push_cart_rules(df_action, pus, source_module='module_4', mode=PUSH_MODE)\n",
    "\n",
    "# Track failed cohorts to skip in price push\n",
    "failed_cohorts = cart_result.get('failed_cohorts', [])\n",
    "\n",
    "print(f\"\\n📊 Cart Rules Push Result:\")\n",
    "print(f\"  Total received: {cart_result['total_received']}\")\n",
    "print(f\"  Cart rule changes: {cart_result['cart_rule_changes']}\")\n",
    "print(f\"  Pushed: {cart_result['pushed']}\")\n",
    "print(f\"  Skipped: {cart_result['skipped']}\")\n",
    "print(f\"  Failed: {cart_result['failed']}\")\n",
    "print(f\"  Mode: {cart_result['mode']}\")\n",
    "\n",
    "if failed_cohorts:\n",
    "    print(f\"  ⚠️ Failed cohorts: {failed_cohorts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:11:03.594103Z",
     "iopub.status.busy": "2026-01-26T18:11:03.593874Z",
     "iopub.status.idle": "2026-01-26T18:11:32.290355Z",
     "shell.execute_reply": "2026-01-26T18:11:32.289422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 2: PUSH PRICES\n",
      "============================================================\n",
      "\n",
      "🚀 MODE: LIVE\n",
      "   Files will be prepared AND uploaded to API\n",
      "Loading disable_pu_visibility from Google Sheets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Loaded 89 products to disable min PU visibility\n",
      "\n",
      "============================================================\n",
      "PUSH PRICES - Source: module_4\n",
      "============================================================\n",
      "Total received: 157\n",
      "Price changes to push: 29\n",
      "Skipped (no change): 128\n",
      "\n",
      "Price changes summary:\n",
      "  Increases: 29\n",
      "  Decreases: 0\n",
      "\n",
      "📋 Prepared 35 packing unit prices\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 700\n",
      "==================================================\n",
      "  Saved: uploads/module_4_700.xlsx (6 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 199.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 701\n",
      "==================================================\n",
      "  Saved: uploads/module_4_701.xlsx (12 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 149.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 703\n",
      "==================================================\n",
      "  Saved: uploads/module_4_703.xlsx (4 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 204.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 1123\n",
      "==================================================\n",
      "  Saved: uploads/module_4_1123.xlsx (3 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 205.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 1125\n",
      "==================================================\n",
      "  Saved: uploads/module_4_1125.xlsx (2 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 213.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 1124\n",
      "==================================================\n",
      "  Saved: uploads/module_4_1124.xlsx (2 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 211.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 702\n",
      "==================================================\n",
      "  Saved: uploads/module_4_702.xlsx (2 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 212.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 704\n",
      "==================================================\n",
      "  Saved: uploads/module_4_704.xlsx (2 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 211.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "============================================================\n",
      "🚀 UPLOAD COMPLETE\n",
      "============================================================\n",
      "Mode: live\n",
      "Total prepared: 33\n",
      "Total failed: 0\n",
      "\n",
      "📊 Prices Push Result:\n",
      "  Total received: 157\n",
      "  Price changes: 29\n",
      "  Pushed: 33\n",
      "  Skipped: 128\n",
      "  Failed: 0\n",
      "  Mode: live\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: PUSH PRICES (skip failed cohorts from cart rules)\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"STEP 2: PUSH PRICES\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Push prices, skipping any cohorts that failed during cart rules push\n",
    "push_result = push_prices(df_action, pus, source_module='module_4', mode=PUSH_MODE, skip_cohorts=failed_cohorts)\n",
    "\n",
    "print(f\"\\n📊 Prices Push Result:\")\n",
    "print(f\"  Total received: {push_result['total_received']}\")\n",
    "print(f\"  Price changes: {push_result['price_changes']}\")\n",
    "print(f\"  Pushed: {push_result['pushed']}\")\n",
    "print(f\"  Skipped: {push_result['skipped']}\")\n",
    "print(f\"  Failed: {push_result['failed']}\")\n",
    "print(f\"  Mode: {push_result['mode']}\")\n",
    "\n",
    "if push_result.get('skipped_cohorts'):\n",
    "    print(f\"  ⚠️ Skipped cohorts: {push_result['skipped_cohorts']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:11:32.292371Z",
     "iopub.status.busy": "2026-01-26T18:11:32.292141Z",
     "iopub.status.idle": "2026-01-26T18:11:32.303922Z",
     "shell.execute_reply": "2026-01-26T18:11:32.303065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODULE 4 - HOURLY UPDATES COMPLETE\n",
      "============================================================\n",
      "\n",
      "📅 Timestamp: 2026-01-26 20:11:32\n",
      "🔧 Mode: LIVE\n",
      "\n",
      "📊 ACTIONS TAKEN:\n",
      "  Total SKUs analyzed: 28491\n",
      "  SKUs requiring action: 157\n",
      "\n",
      "💰 PRICE ACTIONS:\n",
      "  Total price changes: 29\n",
      "    - rets_growing: 29\n",
      "\n",
      "🛒 CART RULE ACTIONS:\n",
      "  Total cart rule changes: 6\n",
      "    - qty_growing: 6\n",
      "\n",
      "📤 PUSH RESULTS:\n",
      "  Cart Rules - Pushed: 6, Failed: 0\n",
      "  Prices - Pushed: 33, Failed: 0\n",
      "\n",
      "✅ LIVE MODE - Changes have been pushed to production!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL SUMMARY\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODULE 4 - HOURLY UPDATES COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\n📅 Timestamp: {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"🔧 Mode: {PUSH_MODE.upper()}\")\n",
    "\n",
    "print(f\"\\n📊 ACTIONS TAKEN:\")\n",
    "print(f\"  Total SKUs analyzed: {len(df)}\")\n",
    "print(f\"  SKUs requiring action: {len(df_action)}\")\n",
    "\n",
    "# Price actions breakdown\n",
    "print(f\"\\n💰 PRICE ACTIONS:\")\n",
    "if 'price_action' in df_action.columns:\n",
    "    price_actions = df_action[df_action['price_action'] != 'none']\n",
    "    print(f\"  Total price changes: {len(price_actions)}\")\n",
    "    for action_type in df_action['price_action'].unique():\n",
    "        if action_type != 'none':\n",
    "            count = len(df_action[df_action['price_action'] == action_type])\n",
    "            print(f\"    - {action_type}: {count}\")\n",
    "else:\n",
    "    print(f\"  Total price changes: 0\")\n",
    "\n",
    "# Cart rule actions breakdown  \n",
    "print(f\"\\n🛒 CART RULE ACTIONS:\")\n",
    "if 'cart_rule_action' in df_action.columns:\n",
    "    cart_actions = df_action[df_action['cart_rule_action'] != 'none']\n",
    "    print(f\"  Total cart rule changes: {len(cart_actions)}\")\n",
    "    for action_type in df_action['cart_rule_action'].unique():\n",
    "        if action_type != 'none':\n",
    "            count = len(df_action[df_action['cart_rule_action'] == action_type])\n",
    "            print(f\"    - {action_type}: {count}\")\n",
    "else:\n",
    "    print(f\"  Total cart rule changes: 0\")\n",
    "\n",
    "# Push results\n",
    "print(f\"\\n📤 PUSH RESULTS:\")\n",
    "print(f\"  Cart Rules - Pushed: {cart_result.get('pushed', 0)}, Failed: {cart_result.get('failed', 0)}\")\n",
    "print(f\"  Prices - Pushed: {push_result.get('pushed', 0)}, Failed: {push_result.get('failed', 0)}\")\n",
    "\n",
    "if PUSH_MODE == 'testing':\n",
    "    print(f\"\\n⚠️ TESTING MODE - No changes were actually pushed to production!\")\n",
    "    print(f\"   Change PUSH_MODE to 'live' to execute actual pushes.\")\n",
    "else:\n",
    "    print(f\"\\n✅ LIVE MODE - Changes have been pushed to production!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:11:32.305870Z",
     "iopub.status.busy": "2026-01-26T18:11:32.305631Z",
     "iopub.status.idle": "2026-01-26T18:11:32.340179Z",
     "shell.execute_reply": "2026-01-26T18:11:32.339286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAMPLE DATA (First 10 rows with UTH > 0)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>wac1</th>\n",
       "      <th>wac_p</th>\n",
       "      <th>new_wac</th>\n",
       "      <th>p80_daily_240d</th>\n",
       "      <th>std_daily_240d</th>\n",
       "      <th>p70_daily_retailers_240d</th>\n",
       "      <th>std_daily_retailers_240d</th>\n",
       "      <th>...</th>\n",
       "      <th>uth_rets_std</th>\n",
       "      <th>uth_rets_status</th>\n",
       "      <th>last_hour_qty</th>\n",
       "      <th>last_hour_qty_target</th>\n",
       "      <th>last_hour_qty_std</th>\n",
       "      <th>last_hour_qty_status</th>\n",
       "      <th>last_hour_retailers</th>\n",
       "      <th>last_hour_rets_target</th>\n",
       "      <th>last_hour_rets_std</th>\n",
       "      <th>last_hour_rets_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>339</td>\n",
       "      <td>448</td>\n",
       "      <td>زيت كريستال الممتاز خليط - 700 مل</td>\n",
       "      <td>617.798191</td>\n",
       "      <td>598.901102</td>\n",
       "      <td>598.916179</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.848537</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.258166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.937896</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.330279</td>\n",
       "      <td>0.122106</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146650</td>\n",
       "      <td>0.092255</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>170</td>\n",
       "      <td>448</td>\n",
       "      <td>زيت كريستال الممتاز خليط - 700 مل</td>\n",
       "      <td>617.798191</td>\n",
       "      <td>598.901102</td>\n",
       "      <td>598.916179</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.190741</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.692191</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523227</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.361557</td>\n",
       "      <td>0.086104</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141013</td>\n",
       "      <td>0.048804</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>339</td>\n",
       "      <td>13045</td>\n",
       "      <td>تمور القصيم كيس شفاف - 10 كجم</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.877897</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068590</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070106</td>\n",
       "      <td>0.049572</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>170</td>\n",
       "      <td>13045</td>\n",
       "      <td>تمور القصيم كيس شفاف - 10 كجم</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.313347</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1414</td>\n",
       "      <td>تونة دولفين مفتتة حار - 140 جم</td>\n",
       "      <td>25.163039</td>\n",
       "      <td>23.275102</td>\n",
       "      <td>23.274426</td>\n",
       "      <td>480.0</td>\n",
       "      <td>201.200085</td>\n",
       "      <td>20.0</td>\n",
       "      <td>8.449520</td>\n",
       "      <td>...</td>\n",
       "      <td>6.360444</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.547028</td>\n",
       "      <td>13.223468</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.323233</td>\n",
       "      <td>0.559034</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>236</td>\n",
       "      <td>9609</td>\n",
       "      <td>سمن جنة - 2.5 كجم</td>\n",
       "      <td>937.853327</td>\n",
       "      <td>900.768818</td>\n",
       "      <td>900.768818</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.591723</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.458219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346919</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339709</td>\n",
       "      <td>0.040203</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132245</td>\n",
       "      <td>0.030299</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>632</td>\n",
       "      <td>1703</td>\n",
       "      <td>مناديل فاميليا تواليت 2 طبقة - 2 رول</td>\n",
       "      <td>181.408066</td>\n",
       "      <td>165.621677</td>\n",
       "      <td>165.621674</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.006122</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.422587</td>\n",
       "      <td>...</td>\n",
       "      <td>1.114808</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.441010</td>\n",
       "      <td>0.265146</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177567</td>\n",
       "      <td>0.126302</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>22922</td>\n",
       "      <td>لمبادا فانيليا x5 - 5 جنية</td>\n",
       "      <td>46.530047</td>\n",
       "      <td>45.837060</td>\n",
       "      <td>45.835095</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.048270</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.377410</td>\n",
       "      <td>...</td>\n",
       "      <td>1.039320</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413510</td>\n",
       "      <td>0.239143</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125720</td>\n",
       "      <td>0.086584</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>9910</td>\n",
       "      <td>حفاضات مولفيكس جونيور مقاس 5 - 70 حفاضة</td>\n",
       "      <td>429.153057</td>\n",
       "      <td>385.217958</td>\n",
       "      <td>385.217943</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.689380</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.839433</td>\n",
       "      <td>...</td>\n",
       "      <td>1.391840</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.486820</td>\n",
       "      <td>0.224508</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256884</td>\n",
       "      <td>0.118130</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>10082</td>\n",
       "      <td>شوكولاتة دريم خام للطبخ حليب - 200 جم</td>\n",
       "      <td>49.989000</td>\n",
       "      <td>48.989220</td>\n",
       "      <td>48.989220</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.381082</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    warehouse_id  product_id                                      sku  \\\n",
       "4            339         448        زيت كريستال الممتاز خليط - 700 مل   \n",
       "5            170         448        زيت كريستال الممتاز خليط - 700 مل   \n",
       "6            339       13045            تمور القصيم كيس شفاف - 10 كجم   \n",
       "7            170       13045            تمور القصيم كيس شفاف - 10 كجم   \n",
       "10             1        1414           تونة دولفين مفتتة حار - 140 جم   \n",
       "12           236        9609                        سمن جنة - 2.5 كجم   \n",
       "14           632        1703     مناديل فاميليا تواليت 2 طبقة - 2 رول   \n",
       "15             1       22922               لمبادا فانيليا x5 - 5 جنية   \n",
       "16             1        9910  حفاضات مولفيكس جونيور مقاس 5 - 70 حفاضة   \n",
       "18             8       10082    شوكولاتة دريم خام للطبخ حليب - 200 جم   \n",
       "\n",
       "          wac1       wac_p     new_wac  p80_daily_240d  std_daily_240d  \\\n",
       "4   617.798191  598.901102  598.916179             5.0        1.848537   \n",
       "5   617.798191  598.901102  598.916179             5.0        1.190741   \n",
       "6   714.000000  714.000000  714.000000             5.0        1.414214   \n",
       "7   714.000000  714.000000  714.000000             5.0        0.000000   \n",
       "10   25.163039   23.275102   23.274426           480.0      201.200085   \n",
       "12  937.853327  900.768818  900.768818             5.0        0.591723   \n",
       "14  181.408066  165.621677  165.621674             5.0        3.006122   \n",
       "15   46.530047   45.837060   45.835095             7.0        4.048270   \n",
       "16  429.153057  385.217958  385.217943             8.0        3.689380   \n",
       "18   49.989000   48.989220   48.989220            17.0        0.000000   \n",
       "\n",
       "    p70_daily_retailers_240d  std_daily_retailers_240d  ...  uth_rets_std  \\\n",
       "4                        2.0                  1.258166  ...      0.937896   \n",
       "5                        2.0                  0.692191  ...      0.523227   \n",
       "6                        2.0                  1.414214  ...      0.877897   \n",
       "7                        2.0                  0.000000  ...      0.000000   \n",
       "10                      20.0                  8.449520  ...      6.360444   \n",
       "12                       2.0                  0.458219  ...      0.346919   \n",
       "14                       2.0                  1.422587  ...      1.114808   \n",
       "15                       2.0                  1.377410  ...      1.039320   \n",
       "16                       4.0                  1.839433  ...      1.391840   \n",
       "18                       3.0                  0.000000  ...      0.000000   \n",
       "\n",
       "    uth_rets_status  last_hour_qty  last_hour_qty_target last_hour_qty_std  \\\n",
       "4          on_track            0.0              0.330279          0.122106   \n",
       "5          on_track            0.0              0.361557          0.086104   \n",
       "6          on_track            0.0              0.068590          0.019400   \n",
       "7          dropping            0.0              0.313347          0.000000   \n",
       "10         on_track            0.0             31.547028         13.223468   \n",
       "12         on_track            0.0              0.339709          0.040203   \n",
       "14         on_track            0.0              0.441010          0.265146   \n",
       "15         on_track            0.0              0.413510          0.239143   \n",
       "16         on_track            0.0              0.486820          0.224508   \n",
       "18         dropping            0.0              1.381082          0.000000   \n",
       "\n",
       "    last_hour_qty_status  last_hour_retailers  last_hour_rets_target  \\\n",
       "4               dropping                  0.0               0.146650   \n",
       "5               dropping                  0.0               0.141013   \n",
       "6               dropping                  0.0               0.070106   \n",
       "7               dropping                  0.0               0.138889   \n",
       "10              dropping                  0.0               1.323233   \n",
       "12              dropping                  0.0               0.132245   \n",
       "14              dropping                  0.0               0.177567   \n",
       "15              dropping                  0.0               0.125720   \n",
       "16              dropping                  0.0               0.256884   \n",
       "18              dropping                  0.0               0.233732   \n",
       "\n",
       "   last_hour_rets_std  last_hour_rets_status  \n",
       "4            0.092255               dropping  \n",
       "5            0.048804               dropping  \n",
       "6            0.049572               dropping  \n",
       "7            0.000000               dropping  \n",
       "10           0.559034               dropping  \n",
       "12           0.030299               dropping  \n",
       "14           0.126302               dropping  \n",
       "15           0.086584               dropping  \n",
       "16           0.118130               dropping  \n",
       "18           0.000000               dropping  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAMPLE OUTPUT - Current Status\n",
    "# =============================================================================\n",
    "# Show sample of data with all calculated fields\n",
    "\n",
    "sample_cols = [\n",
    "    'warehouse_id', 'product_id', 'sku','wac1','wac_p','new_wac',\n",
    "    # P80/P70 benchmarks and std\n",
    "    'p80_daily_240d', 'std_daily_240d', 'p70_daily_retailers_240d', 'std_daily_retailers_240d',\n",
    "    # Current cart rule\n",
    "    'current_cart_rule',\n",
    "    # UTH performance (with std thresholds)\n",
    "    'uth_qty', 'uth_qty_target', 'uth_qty_std', 'uth_qty_status',\n",
    "    'uth_retailers', 'uth_rets_target', 'uth_rets_std', 'uth_rets_status',\n",
    "    # Last hour performance (with std thresholds)\n",
    "    'last_hour_qty', 'last_hour_qty_target', 'last_hour_qty_std', 'last_hour_qty_status',\n",
    "    'last_hour_retailers', 'last_hour_rets_target', 'last_hour_rets_std', 'last_hour_rets_status'\n",
    "]\n",
    "\n",
    "# Filter to columns that exist\n",
    "sample_cols = [c for c in sample_cols if c in df.columns]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SAMPLE DATA (First 10 rows with UTH > 0)\")\n",
    "print(f\"{'='*60}\")\n",
    "sample = df[df['uth_qty'] > 0][sample_cols].head(10)\n",
    "display(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:11:32.342043Z",
     "iopub.status.busy": "2026-01-26T18:11:32.341796Z",
     "iopub.status.idle": "2026-01-26T18:11:32.351399Z",
     "shell.execute_reply": "2026-01-26T18:11:32.350450Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODULE 4 - DATA PREPARATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Ready for action definition. Available statuses:\n",
      "  - uth_qty_status: ['dropping', 'on_track', 'growing']\n",
      "  - uth_rets_status: ['dropping', 'on_track', 'growing']\n",
      "  - last_hour_qty_status: ['dropping', 'on_track', 'growing']\n",
      "  - last_hour_rets_status: ['dropping', 'on_track', 'growing']\n",
      "\n",
      "Total records: 28491\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ACTION ENGINE (TO BE DEFINED)\n",
    "# =============================================================================\n",
    "# This section will contain the action logic based on:\n",
    "# - uth_qty_status, uth_rets_status\n",
    "# - last_hour_qty_status, last_hour_rets_status\n",
    "#\n",
    "# Placeholder for now - actions will be defined by user\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODULE 4 - DATA PREPARATION COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nReady for action definition. Available statuses:\")\n",
    "print(f\"  - uth_qty_status: {df['uth_qty_status'].unique().tolist()}\")\n",
    "print(f\"  - uth_rets_status: {df['uth_rets_status'].unique().tolist()}\")\n",
    "print(f\"  - last_hour_qty_status: {df['last_hour_qty_status'].unique().tolist()}\")\n",
    "print(f\"  - last_hour_rets_status: {df['last_hour_rets_status'].unique().tolist()}\")\n",
    "print(f\"\\nTotal records: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-26T18:11:32.353336Z",
     "iopub.status.busy": "2026-01-26T18:11:32.353121Z",
     "iopub.status.idle": "2026-01-26T18:11:44.572088Z",
     "shell.execute_reply": "2026-01-26T18:11:44.571219Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "UPLOADING RESULTS TO SNOWFLAKE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/Pricing Runs/Prediction_Scripts_2/Happy_hour/git/Mustafa/Pricing Logic/modules/../common_functions.py:698: UserWarning: Pandas Dataframe has non-standard index of type <class 'pandas.core.indexes.base.Index'> which will not be written. Consider changing the index to pd.RangeIndex(start=0,...,step=1) or call reset_index() to keep index as column(s)\n",
      "  success, _, _, _ = write_pandas(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Sent\n",
      "✅ Slack notification sent!\n",
      "✅ 157 records uploaded to Snowflake\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# UPLOAD RESULTS TO SNOWFLAKE AND SEND SLACK NOTIFICATION\n",
    "# =============================================================================\n",
    "from common_functions import upload_dataframe_to_snowflake, send_text_slack\n",
    "\n",
    "# Add created_at as TIMESTAMP (module runs hourly)\n",
    "df_action['created_at'] = datetime.now(CAIRO_TZ).replace(second=0, microsecond=0)\n",
    "\n",
    "# Upload to Snowflake\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"UPLOADING RESULTS TO SNOWFLAKE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "upload_status = upload_dataframe_to_snowflake(\n",
    "    \"Egypt\", \n",
    "    df_action, \n",
    "    \"MATERIALIZED_VIEWS\", \n",
    "    \"pricing_hourly_push\", \n",
    "    \"append\", \n",
    "    auto_create_table=True, \n",
    "    conn=None\n",
    ")\n",
    "\n",
    "# Prepare status variables\n",
    "prices_pushed = push_result.get('pushed', 0) if 'push_result' in dir() else 0\n",
    "prices_failed = push_result.get('failed', 0) if 'push_result' in dir() else 0\n",
    "cart_rules_pushed = cart_result.get('pushed', 0) if 'cart_result' in dir() else 0\n",
    "cart_rules_failed = cart_result.get('failed', 0) if 'cart_result' in dir() else 0\n",
    "\n",
    "# Count price and cart rule actions\n",
    "price_changes = len(df_action[df_action['price_action'] != 'none']) if 'price_action' in df_action.columns else 0\n",
    "cart_changes = len(df_action[df_action['cart_rule_action'] != 'none']) if 'cart_rule_action' in df_action.columns else 0\n",
    "\n",
    "if upload_status:\n",
    "    slack_message = f\"\"\"✅ *Module 4 - Hourly Updates Completed*\n",
    "\n",
    "📅 Date: {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d')}\n",
    "⏰ Hour: {datetime.now(CAIRO_TZ).strftime('%H:%M:%S')} Cairo time\n",
    "🔧 Mode: {PUSH_MODE.upper()}\n",
    "\n",
    "📊 *Results:*\n",
    "• Total SKUs analyzed: {len(df):,}\n",
    "• SKUs requiring action: {len(df_action):,}\n",
    "• Price changes: {price_changes:,}\n",
    "• Cart rule changes: {cart_changes:,}\n",
    "\n",
    "📤 *Push Status:*\n",
    "• 💰 Prices: ✅ {prices_pushed} pushed | ❌ {prices_failed} failed\n",
    "• 🛒 Cart Rules: ✅ {cart_rules_pushed} pushed | ❌ {cart_rules_failed} failed\n",
    "\n",
    "🗄️ Results uploaded to: MATERIALIZED_VIEWS.pricing_hourly_push\"\"\"\n",
    "    \n",
    "    send_text_slack('new-pricing-logic', slack_message)\n",
    "    print(\"✅ Slack notification sent!\")\n",
    "    print(f\"✅ {len(df_action)} records uploaded to Snowflake\")\n",
    "else:\n",
    "    error_message = f\"\"\"❌ *Module 4 - Hourly Updates Failed*\n",
    "\n",
    "📅 Date: {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d')}\n",
    "⏰ Hour: {datetime.now(CAIRO_TZ).strftime('%H:%M:%S')} Cairo time\n",
    "⚠️ Upload to Snowflake failed - please check logs\n",
    "\n",
    "📤 *Push Status (before upload failure):*\n",
    "• 💰 Prices: ✅ {prices_pushed} pushed | ❌ {prices_failed} failed\n",
    "• 🛒 Cart Rules: ✅ {cart_rules_pushed} pushed | ❌ {cart_rules_failed} failed\"\"\"\n",
    "    \n",
    "    send_text_slack('new-pricing-logic', error_message)\n",
    "    print(\"❌ Error notification sent to Slack!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
