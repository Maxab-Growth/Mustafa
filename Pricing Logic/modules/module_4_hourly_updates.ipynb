{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4: Hourly Updates\n",
    "\n",
    "## Purpose\n",
    "This module runs hourly to monitor and adjust prices based on:\n",
    "1. **UTH (Up-Till-Hour) Performance**: Cumulative qty/retailers from start of day until current hour\n",
    "2. **Last Hour Performance**: Qty/retailers for the most recent hour only\n",
    "\n",
    "## Schedule\n",
    "- Runs hourly from 12 PM to 12 AM (midnight), **except** Module 3 hours (12 PM, 3 PM, 6 PM, 9 PM)\n",
    "- Also runs once at 3 AM\n",
    "- Active hours: 1 PM, 2 PM, 4 PM, 5 PM, 7 PM, 8 PM, 10 PM, 11 PM, 12 AM, 3 AM\n",
    "\n",
    "## Data Flow\n",
    "```\n",
    "data_extraction.ipynb → Snowflake (Pricing_data_extraction)\n",
    "                              ↓\n",
    "                        Module 4 (this module)\n",
    "                           ├── Load p80_qty, p70_retailers, std columns\n",
    "                           ├── Fetch fresh: cart rules, stocks, WAC\n",
    "                           ├── Calculate new_wac (from today's PRS)\n",
    "                           ├── Query UTH performance (today)\n",
    "                           ├── Query Last Hour performance (today)\n",
    "                           ├── Query historical hour contributions\n",
    "                           ├── Calculate targets & statuses (±3 std)\n",
    "                           └── Generate actions (TBD)\n",
    "```\n",
    "\n",
    "## New WAC Calculation\n",
    "To avoid database lag, we calculate a fresh WAC from today's purchase receipts:\n",
    "- `new_wac1` = ((stocks + reflected_qty) × wac1 + unreflected_qty × item_price) / total_qty\n",
    "- `new_wac_p` = wac_p × (1 + wac1_change)\n",
    "- `new_wac` = new_wac_p (with fallback to current_wac)\n",
    "\n",
    "## Status Logic (±3 Standard Deviations)\n",
    "SKU status is determined by comparing actual performance to target ± 3 std:\n",
    "- **Growing**: actual > target + 3×std\n",
    "- **On Track**: target - 3×std ≤ actual ≤ target + 3×std\n",
    "- **Dropping**: actual < target - 3×std (minimum threshold = 1)\n",
    "\n",
    "Standard deviation columns used:\n",
    "- Qty: `std_daily_240d`\n",
    "- Retailers: `std_daily_retailers_240d`\n",
    "\n",
    "## Status Outputs\n",
    "- `uth_qty_status`: growing / dropping / on_track\n",
    "- `uth_rets_status`: growing / dropping / on_track\n",
    "- `last_hour_qty_status`: growing / dropping / on_track\n",
    "- `last_hour_rets_status`: growing / dropping / on_track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:01:59.667819Z",
     "iopub.status.busy": "2026-02-10T12:01:59.667597Z",
     "iopub.status.idle": "2026-02-10T12:02:03.717022Z",
     "shell.execute_reply": "2026-02-10T12:02:03.716290Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.12/site-packages/snowflake/connector/options.py:104: UserWarning: You have an incompatible version of 'pyarrow' installed (20.0.0), please install a version that adheres to: 'pyarrow<19.0.0; extra == \"pandas\"'\n",
      "  warn_incompatible_dep(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries Module | Timezone: America/Los_Angeles\n",
      "✅ UTH and Last Hour functions defined\n",
      "\n",
      "==================================================\n",
      "QUERIES MODULE READY\n",
      "==================================================\n",
      "\n",
      "Live Data Functions:\n",
      "  • get_current_stocks()\n",
      "  • get_packing_units()\n",
      "  • get_current_prices()\n",
      "  • get_current_wac()\n",
      "  • get_current_cart_rules()\n",
      "\n",
      "UTH Performance Functions:\n",
      "  • get_uth_performance()         - UTH qty/retailers (Snowflake)\n",
      "  • get_hourly_distribution()     - Historical hour contributions (Snowflake)\n",
      "  • get_last_hour_performance()   - Last hour qty/retailers (DWH)\n",
      "\n",
      "Note: Market prices use MODULE_1_INPUT data\n",
      "Retailer Selection Queries defined ✓\n",
      "  - get_churned_dropped_retailers()\n",
      "  - get_category_not_product_retailers()\n",
      "  - get_out_of_cycle_retailers()\n",
      "  - get_view_no_orders_retailers()\n",
      "  - get_excluded_retailers()\n",
      "  - get_retailers_with_quantity_discount()\n",
      "  - get_retailer_main_warehouse()\n",
      "Module 4: Hourly Updates\n",
      "Current Cairo Time: 2026-02-10 14:02:03\n",
      "Current Hour: 14\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import setup_environment_2\n",
    "# Import queries module for Snowflake access\n",
    "%run queries_module.ipynb\n",
    "\n",
    "# Cairo timezone\n",
    "CAIRO_TZ = pytz.timezone('Africa/Cairo')\n",
    "CAIRO_NOW = datetime.now(CAIRO_TZ)\n",
    "CURRENT_HOUR = CAIRO_NOW.hour\n",
    "\n",
    "print(f\"Module 4: Hourly Updates\")\n",
    "print(f\"Current Cairo Time: {CAIRO_NOW.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Current Hour: {CURRENT_HOUR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:02:03.719380Z",
     "iopub.status.busy": "2026-02-10T12:02:03.719038Z",
     "iopub.status.idle": "2026-02-10T12:02:03.723959Z",
     "shell.execute_reply": "2026-02-10T12:02:03.723126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: MATERIALIZED_VIEWS.Pricing_data_extraction (today's data)\n",
      "Output: module_4_output_20260210_1402.xlsx\n",
      "Status Thresholds: ±3 std (Dropping minimum = 1)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Input/Output configuration\n",
    "# Data is now loaded from Snowflake instead of Excel\n",
    "INPUT_TABLE = 'MATERIALIZED_VIEWS.Pricing_data_extraction'\n",
    "OUTPUT_FILE = f'module_4_output_{CAIRO_NOW.strftime(\"%Y%m%d_%H%M\")}.xlsx'\n",
    "\n",
    "# Status thresholds (±3 std from target)\n",
    "# - Growing: actual > target + 3*std\n",
    "# - On Track: target - 3*std <= actual <= target + 3*std\n",
    "# - Dropping: actual < target - 3*std (minimum threshold = 1)\n",
    "STD_THRESHOLD = 3  # Number of standard deviations\n",
    "MIN_DROPPING_THRESHOLD = 1  # Minimum threshold for dropping status\n",
    "LOW_STOCK_DOH_THRESHOLD = 2  # SKUs with DOH <= this are protected from price reduction\n",
    "\n",
    "# Qty growing price step limit (max 2 times per day per SKU)\n",
    "MAX_QTY_GROWING_PRICE_STEPS_PER_DAY = 2\n",
    "\n",
    "# Module 3 hours (skip these)\n",
    "MODULE_3_HOURS = [12, 15, 18, 21]  # 12 PM, 3 PM, 6 PM, 9 PM\n",
    "\n",
    "print(f\"Input: {INPUT_TABLE} (today's data)\")\n",
    "print(f\"Output: {OUTPUT_FILE}\")\n",
    "print(f\"Status Thresholds: ±{STD_THRESHOLD} std (Dropping minimum = {MIN_DROPPING_THRESHOLD})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:02:03.725724Z",
     "iopub.status.busy": "2026-02-10T12:02:03.725519Z",
     "iopub.status.idle": "2026-02-10T12:02:04.471008Z",
     "shell.execute_reply": "2026-02-10T12:02:04.470249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previous hourly actions from today...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 previous qty_growing_price_step actions\n",
      "  Unique SKUs with price steps: 2\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD PREVIOUS ACTIONS (Track qty_growing_price_step per day)\n",
    "# =============================================================================\n",
    "print(\"Loading previous hourly actions from today...\")\n",
    "\n",
    "def load_previous_hourly_actions():\n",
    "    \"\"\"Load previous Module 4 outputs from today to track qty_growing_price_step actions.\"\"\"\n",
    "    try:\n",
    "        query = \"\"\"\n",
    "        SELECT product_id, warehouse_id, price_action\n",
    "        FROM MATERIALIZED_VIEWS.pricing_hourly_push\n",
    "        WHERE DATE(created_at) = CURRENT_DATE\n",
    "          AND price_action = 'qty_growing_price_step'\n",
    "        \"\"\"\n",
    "        df = query_snowflake(query)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"  Note: Could not load previous actions: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "df_previous_hourly = load_previous_hourly_actions()\n",
    "\n",
    "# Count qty_growing_price_step actions per SKU today\n",
    "if len(df_previous_hourly) > 0:\n",
    "    qty_price_step_counts = (\n",
    "        df_previous_hourly\n",
    "        .groupby(['product_id', 'warehouse_id'])\n",
    "        .size()\n",
    "        .reset_index(name='qty_price_step_count')\n",
    "    )\n",
    "    print(f\"Loaded {len(df_previous_hourly)} previous qty_growing_price_step actions\")\n",
    "    print(f\"  Unique SKUs with price steps: {len(qty_price_step_counts)}\")\n",
    "else:\n",
    "    qty_price_step_counts = pd.DataFrame(columns=['product_id', 'warehouse_id', 'qty_price_step_count'])\n",
    "    print(\"No previous qty_growing_price_step actions found for today (first run or none triggered)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:02:04.473184Z",
     "iopub.status.busy": "2026-02-10T12:02:04.472968Z",
     "iopub.status.idle": "2026-02-10T12:03:29.942042Z",
     "shell.execute_reply": "2026-02-10T12:03:29.941315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from Snowflake...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28116 records from Snowflake\n",
      "\n",
      "P80 Qty Stats: min=5.0, max=1906.0, mean=13.4\n",
      "P70 Retailers Stats: min=5.0, max=150.2, mean=6.1\n",
      "Std Qty Stats: min=0.0, max=2574.8, mean=6.4\n",
      "Std Retailers Stats: min=0.0, max=75.6, mean=1.4\n",
      "Fetching current cart rules...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 73120 records\n",
      "✅ Merged cart rules: 28116 records\n",
      "Fetching current stocks...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 1866178 records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged stocks: 28116 records\n",
      "Fetching current WAC...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 8192 records\n",
      "✅ Merged WAC: 28116 records\n",
      "Fetching current prices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 116554 records\n",
      "✅ Merged current prices: 28124 records\n",
      "\n",
      "Current Stock Stats: min=0, max=23903, mean=47.2\n",
      "Current WAC Stats: min=0.01, max=2082.02, mean=228.48\n",
      "Current Price Stats: min=0.01, max=2208.25, mean=238.84\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# LOAD DATA FROM SNOWFLAKE (Instead of Excel file)\n",
    "# =============================================================================\n",
    "print(\"Loading data from Snowflake...\")\n",
    "\n",
    "# Query to get today's data from Pricing_data_extraction\n",
    "LOAD_QUERY = f\"\"\"\n",
    "SELECT distinct * FROM {INPUT_TABLE}\n",
    "WHERE created_at = '{datetime.now(CAIRO_TZ).date()}'\n",
    "\"\"\"\n",
    "\n",
    "df = query_snowflake(LOAD_QUERY)\n",
    "print(f\"Loaded {len(df)} records from Snowflake\")\n",
    "\n",
    "# Early exit if no data (data extraction hasn't run yet for today)\n",
    "if len(df) == 0:\n",
    "    print(f\"\\n⚠️ No data found for today ({datetime.now(CAIRO_TZ).date()})\")\n",
    "    print(\"Data extraction may not have run yet. Exiting Module 4 gracefully...\")\n",
    "    try:\n",
    "        sys.path.insert(0, '..')\n",
    "        from common_functions import send_text_slack\n",
    "        send_text_slack('new-pricing-logic', f\"⚠️ Module 4 skipped at {CAIRO_NOW.strftime('%H:%M')} Cairo - no data for today (data extraction not yet run)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not send Slack notification: {e}\")\n",
    "    raise SystemExit(\"No data available - exiting gracefully\")\n",
    "\n",
    "# Ensure required columns exist with proper types\n",
    "df['p80_daily_240d'] = pd.to_numeric(df.get('p80_daily_240d', 0), errors='coerce').fillna(0)\n",
    "df['p70_daily_retailers_240d'] = pd.to_numeric(df.get('p70_daily_retailers_240d', 1), errors='coerce').fillna(1)\n",
    "df['std_daily_240d'] = pd.to_numeric(df.get('std_daily_240d', 0), errors='coerce').fillna(0)\n",
    "df['std_daily_retailers_240d'] = pd.to_numeric(df.get('std_daily_retailers_240d', 0), errors='coerce').fillna(0)\n",
    "df['warehouse_id'] = df['warehouse_id'].astype(int)\n",
    "df['product_id'] = df['product_id'].astype(int)\n",
    "df['cohort_id'] = df['cohort_id'].astype(int) if 'cohort_id' in df.columns else None\n",
    "df['commercial_min_price'] = pd.to_numeric(df.get('commercial_min_price', 0), errors='coerce')\n",
    "df['commercial_min_price'] = np.round(df['commercial_min_price']*4)/4\n",
    "# Get category for hourly distribution merge\n",
    "if 'cat' not in df.columns and 'category' in df.columns:\n",
    "    df['cat'] = df['category']\n",
    "\n",
    "print(f\"\\nP80 Qty Stats: min={df['p80_daily_240d'].min():.1f}, max={df['p80_daily_240d'].max():.1f}, mean={df['p80_daily_240d'].mean():.1f}\")\n",
    "print(f\"P70 Retailers Stats: min={df['p70_daily_retailers_240d'].min():.1f}, max={df['p70_daily_retailers_240d'].max():.1f}, mean={df['p70_daily_retailers_240d'].mean():.1f}\")\n",
    "print(f\"Std Qty Stats: min={df['std_daily_240d'].min():.1f}, max={df['std_daily_240d'].max():.1f}, mean={df['std_daily_240d'].mean():.1f}\")\n",
    "print(f\"Std Retailers Stats: min={df['std_daily_retailers_240d'].min():.1f}, max={df['std_daily_retailers_240d'].max():.1f}, mean={df['std_daily_retailers_240d'].mean():.1f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# GET FRESH DATA FROM QUERIES MODULE (Snowflake)\n",
    "# =============================================================================\n",
    "\n",
    "# 1. Current Cart Rules\n",
    "df_cart_rules = get_current_cart_rules()\n",
    "\n",
    "# Merge with main df (by cohort_id + product_id)\n",
    "if 'cohort_id' in df.columns and len(df_cart_rules) > 0:\n",
    "    df = df.drop(columns=['current_cart_rule'], errors='ignore')\n",
    "    df = df.merge(df_cart_rules, on=['cohort_id', 'product_id'], how='left')\n",
    "    df['current_cart_rule'] = df['current_cart_rule'].fillna(999)\n",
    "    print(f\"✅ Merged cart rules: {len(df)} records\")\n",
    "else:\n",
    "    df['current_cart_rule'] = df.get('current_cart_rule', 999)\n",
    "\n",
    "# 2. Current Stocks\n",
    "df_stocks = get_current_stocks()\n",
    "\n",
    "# Merge stocks (by warehouse_id + product_id)\n",
    "if len(df_stocks) > 0:\n",
    "    df = df.drop(columns=['stocks'], errors='ignore')\n",
    "    df = df.merge(df_stocks, on=['warehouse_id', 'product_id'], how='left')\n",
    "    df['stocks'] = df['stocks'].fillna(0)\n",
    "    print(f\"✅ Merged stocks: {len(df)} records\")\n",
    "else:\n",
    "    df['stocks'] = df.get('stocks', 0)\n",
    "\n",
    "# 3. Current WAC (Weighted Average Cost)\n",
    "df_wac = get_current_wac()\n",
    "\n",
    "# Merge WAC (by warehouse_id + product_id)\n",
    "if len(df_wac) > 0:\n",
    "    df = df.drop(columns=['wac_p'], errors='ignore')\n",
    "    df = df.merge(df_wac, on=['product_id'], how='left')\n",
    "    df['wac_p'] = df['wac_p'].fillna(0)\n",
    "    print(f\"✅ Merged WAC: {len(df)} records\")\n",
    "else:\n",
    "    df['wac_p'] = df.get('wac_p', 0)\n",
    "\n",
    "# 4. Current Prices\n",
    "df_prices = get_current_prices()\n",
    "\n",
    "# Merge prices (by cohort_id + product_id)\n",
    "if len(df_prices) > 0:\n",
    "    df = df.drop(columns=['current_price'], errors='ignore')\n",
    "    df = df.merge(df_prices[['cohort_id', 'product_id', 'current_price']], on=['cohort_id', 'product_id'], how='left')\n",
    "    df['current_price'] = df['current_price'].fillna(0)\n",
    "    print(f\"✅ Merged current prices: {len(df)} records\")\n",
    "else:\n",
    "    df['current_price'] = df.get('current_price', 0)\n",
    "\n",
    "print(f\"\\nCurrent Stock Stats: min={df['stocks'].min():.0f}, max={df['stocks'].max():.0f}, mean={df['stocks'].mean():.1f}\")\n",
    "print(f\"Current WAC Stats: min={df['wac_p'].min():.2f}, max={df['wac_p'].max():.2f}, mean={df['wac_p'].mean():.2f}\")\n",
    "print(f\"Current Price Stats: min={df['current_price'].min():.2f}, max={df['current_price'].max():.2f}, mean={df['current_price'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:03:29.944324Z",
     "iopub.status.busy": "2026-02-10T12:03:29.944113Z",
     "iopub.status.idle": "2026-02-10T12:05:42.363115Z",
     "shell.execute_reply": "2026-02-10T12:05:42.362280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating new WAC from today's purchase receipts...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 519 PRS records (today's purchases)\n",
      "  Loaded 18 WAC tracker records (already reflected)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 7728 base WAC records from all_cogs\n",
      "\n",
      "✅ New WAC calculated: 28124 records\n",
      "   Products with unreflected purchases: 4658\n",
      "   New WAC Stats: min=0.01, max=2082.02, mean=228.48\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CALCULATE NEW WAC (Accounting for Today's Unreflected Purchases)\n",
    "# =============================================================================\n",
    "# This calculates a fresh WAC that accounts for today's purchase receipts\n",
    "# that haven't been reflected in the database yet (to avoid lag)\n",
    "\n",
    "print(\"Calculating new WAC from today's purchase receipts...\")\n",
    "\n",
    "# 1. Query today's PRS data (purchases by product_id)\n",
    "prs_query = '''\n",
    "WITH prs AS (\n",
    "    SELECT DISTINCT \n",
    "        product_purchased_receipts.purchased_receipt_id,\n",
    "        products.id AS product_id,\n",
    "        product_purchased_receipts.basic_unit_count,\n",
    "        product_purchased_receipts.purchased_item_count * product_purchased_receipts.basic_unit_count AS purchase_min_count,\n",
    "        product_purchased_receipts.final_price / product_purchased_receipts.purchased_item_count AS final_item_price\n",
    "    FROM product_purchased_receipts\n",
    "    LEFT JOIN products ON products.id = product_purchased_receipts.product_id\n",
    "    LEFT JOIN purchased_receipts ON purchased_receipts.id = product_purchased_receipts.purchased_receipt_id\n",
    "    WHERE product_purchased_receipts.purchased_item_count <> 0\n",
    "        AND purchased_receipts.purchased_receipt_status_id IN (4,5,7)\n",
    "        AND purchased_receipts.date::date >= current_date\n",
    "        AND product_purchased_receipts.final_price > 0 \n",
    ")\n",
    "SELECT \n",
    "    product_id,\n",
    "    SUM(purchase_min_count) AS all_day_qty,\n",
    "    AVG(final_item_price / basic_unit_count) AS item_price\n",
    "FROM prs\n",
    "GROUP BY 1\n",
    "'''\n",
    "df_prs = setup_environment_2.dwh_pg_query(prs_query, columns=['product_id', 'all_day_qty', 'item_price'])\n",
    "try:\n",
    "    df_prs['product_id'] = pd.to_numeric(df_prs['product_id'])\n",
    "    df_prs['all_day_qty'] = pd.to_numeric(df_prs['all_day_qty'])\n",
    "    df_prs['item_price'] = pd.to_numeric(df_prs['item_price'])\n",
    "except:\n",
    "    df_prs=pd.DataFrame(columns=['product_id', 'all_day_qty', 'item_price'])\n",
    "print(f\"  Loaded {len(df_prs)} PRS records (today's purchases)\")\n",
    "\n",
    "# 2. Query what's already reflected in WAC tracker\n",
    "reflected_query = '''\n",
    "SELECT\n",
    "    t_product_id AS product_id,\n",
    "    s_beg_stock AS av_stocks,\n",
    "    p_purchased_item_count AS pr_qty\n",
    "FROM finance.wac_tracker wt\n",
    "WHERE wt.t_date::date = CURRENT_DATE\n",
    "    AND p_purchased_item_count > 0 \n",
    "'''\n",
    "try:\n",
    "    df_reflected = setup_environment_2.dwh_pg_query(reflected_query, columns=['product_id', 'av_stocks', 'pr_qty'])\n",
    "    df_reflected['product_id'] = pd.to_numeric(df_reflected['product_id'])\n",
    "    df_reflected['av_stocks'] = pd.to_numeric(df_reflected['av_stocks'])\n",
    "    df_reflected['pr_qty'] = pd.to_numeric(df_reflected['pr_qty'])\n",
    "    print(f\"  Loaded {len(df_reflected)} WAC tracker records (already reflected)\")\n",
    "except:\n",
    "    df_reflected = pd.DataFrame(columns=['product_id', 'av_stocks', 'pr_qty'])\n",
    "    print(\"  No WAC tracker records found for today\")\n",
    "\n",
    "# 3. Query base WAC (wac1, wac_p) from all_cogs\n",
    "wac_base_query = '''\n",
    "SELECT \n",
    "    f.product_id,\n",
    "    f.wac1,\n",
    "    f.wac_p\n",
    "FROM finance.all_cogs f\n",
    "JOIN products ON products.id = f.product_id\n",
    "JOIN categories ON products.category_id = categories.id\n",
    "WHERE current_timestamp BETWEEN f.from_date AND f.to_date \n",
    "    AND NOT categories.name_ar IN (\n",
    "        SELECT categories.name_ar AS cat\n",
    "        FROM categories\n",
    "        JOIN sections s ON s.id = categories.section_id\n",
    "        WHERE categories.name_ar LIKE '%سايب%'\n",
    "            OR categories.name_ar LIKE '%بالتة%'\n",
    "            OR categories.section_id IN (225, 318, 285, 121, 87, 351, 417)\n",
    "    )\n",
    "'''\n",
    "df_wac_base = query_snowflake(wac_base_query)\n",
    "df_wac_base['product_id'] = pd.to_numeric(df_wac_base['product_id'])\n",
    "df_wac_base['wac1'] = pd.to_numeric(df_wac_base['wac1'])\n",
    "df_wac_base['wac_p'] = pd.to_numeric(df_wac_base['wac_p'])\n",
    "print(f\"  Loaded {len(df_wac_base)} base WAC records from all_cogs\")\n",
    "\n",
    "# 4. Merge and calculate new WAC\n",
    "df_wac_calc = df_wac_base.merge(df_prs, on='product_id', how='left')\n",
    "df_wac_calc = df_wac_calc.merge(df_reflected, on='product_id', how='left')\n",
    "df_wac_calc = df_wac_calc.fillna(0)\n",
    "\n",
    "# Use current_stock from main df if av_stocks is 0\n",
    "df_stock_lookup = df[['product_id', 'stocks']].drop_duplicates()\n",
    "df_stock_lookup = df_stock_lookup.groupby(['product_id'])['stocks'].sum().reset_index()\n",
    "df_wac_calc = df_wac_calc.merge(df_stock_lookup, on='product_id', how='left')\n",
    "df_wac_calc['av_stocks'] = df_wac_calc.apply(\n",
    "    lambda row: row['stocks'] if row['av_stocks'] == 0 else row['av_stocks'], axis=1)\n",
    "\n",
    "# Calculate not reflected qty (purchases not yet in WAC tracker)\n",
    "df_wac_calc['not_reflected_qty'] = df_wac_calc['all_day_qty'] - df_wac_calc['pr_qty']\n",
    "df_wac_calc['not_reflected_qty'] = df_wac_calc['not_reflected_qty'].clip(lower=0)  # Can't be negative\n",
    "\n",
    "# Calculate new WAC\n",
    "# new_wac1 = ((stocks + pr_qty) * wac1 + not_reflected_qty * item_price) / (stocks + pr_qty + not_reflected_qty)\n",
    "denominator = df_wac_calc['av_stocks'] + df_wac_calc['pr_qty'] + df_wac_calc['not_reflected_qty']\n",
    "numerator = ((df_wac_calc['av_stocks'] + df_wac_calc['pr_qty']) * df_wac_calc['wac1'] + \n",
    "             df_wac_calc['not_reflected_qty'] * df_wac_calc['item_price'])\n",
    "\n",
    "df_wac_calc['new_wac1'] = np.where(denominator > 0, numerator / denominator, df_wac_calc['wac1'])\n",
    "\n",
    "# Calculate wac1 change and new_wac_p\n",
    "df_wac_calc['wac1_change'] = np.where(\n",
    "    df_wac_calc['wac1'] > 0,\n",
    "    (df_wac_calc['new_wac1'] - df_wac_calc['wac1']) / df_wac_calc['wac1'],\n",
    "    0\n",
    ")\n",
    "df_wac_calc['new_wac_p'] = df_wac_calc['wac_p'] * (1 + df_wac_calc['wac1_change'])\n",
    "df_wac_calc['new_wac_p'] = df_wac_calc['new_wac_p'].fillna(df_wac_calc['wac_p'])\n",
    "\n",
    "# Prepare final new_wac dataframe\n",
    "df_new_wac = df_wac_calc[['product_id','new_wac_p', 'not_reflected_qty']].copy()\n",
    "df_new_wac=df_new_wac.drop_duplicates()\n",
    "\n",
    "# 5. Merge new_wac into main dataframe\n",
    "df = df.drop(columns=['new_wac_p','not_reflected_qty'], errors='ignore')\n",
    "df = df.merge(df_new_wac, on='product_id', how='left')\n",
    "df['new_wac'] = df['new_wac_p'].fillna(df['wac_p'])  # Fallback to current_wac if no new_wac\n",
    "\n",
    "print(f\"\\n✅ New WAC calculated: {len(df)} records\")\n",
    "print(f\"   Products with unreflected purchases: {(df['not_reflected_qty'] > 0).sum()}\")\n",
    "print(f\"   New WAC Stats: min={df['new_wac'].min():.2f}, max={df['new_wac'].max():.2f}, mean={df['new_wac'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:05:42.365145Z",
     "iopub.status.busy": "2026-02-10T12:05:42.364800Z",
     "iopub.status.idle": "2026-02-10T12:06:13.082067Z",
     "shell.execute_reply": "2026-02-10T12:06:13.081223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching UTH performance from Snowflake...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 7376 UTH records\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# QUERY 1: TODAY'S UTH (Up-Till-Hour) PERFORMANCE\n",
    "# =============================================================================\n",
    "# Gets cumulative qty and retailers from start of day until current hour\n",
    "# Uses get_uth_performance() from queries_module\n",
    "\n",
    "\n",
    "df_uth_today = get_uth_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:06:13.084286Z",
     "iopub.status.busy": "2026-02-10T12:06:13.084068Z",
     "iopub.status.idle": "2026-02-10T12:06:48.390045Z",
     "shell.execute_reply": "2026-02-10T12:06:48.389314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching last hour performance from DWH...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 1761 last hour records from DWH\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# QUERY 2: TODAY'S LAST HOUR PERFORMANCE (from DWH)\n",
    "# =============================================================================\n",
    "# Gets qty and retailers for the PREVIOUS hour only (not cumulative)\n",
    "# Uses get_last_hour_performance() from queries_module (DWH/PostgreSQL)\n",
    "\n",
    "df_last_hour = get_last_hour_performance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:06:48.392349Z",
     "iopub.status.busy": "2026-02-10T12:06:48.392135Z",
     "iopub.status.idle": "2026-02-10T12:09:50.986330Z",
     "shell.execute_reply": "2026-02-10T12:09:50.985550Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching hourly distribution from Snowflake...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 770 hourly distribution records\n",
      "\n",
      "Avg UTH % (qty): 37.2%\n",
      "Avg Last Hour % (qty): 5.2%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# QUERY 3: HISTORICAL HOURLY DISTRIBUTION (Last 4 Months) - By Category & Warehouse\n",
    "# =============================================================================\n",
    "# Gets:\n",
    "# - avg_uth_pct_qty/retailers: Average contribution of hours 0 to (current_hour-1) to daily total\n",
    "# - avg_last_hour_pct_qty/retailers: Average contribution of (current_hour-1) alone to daily total\n",
    "# Uses get_hourly_distribution() from queries_module\n",
    "\n",
    "df_hourly_dist = get_hourly_distribution()\n",
    "print(f\"\\nAvg UTH % (qty): {df_hourly_dist['avg_uth_pct_qty'].mean()*100:.1f}%\")\n",
    "print(f\"Avg Last Hour % (qty): {df_hourly_dist['avg_last_hour_pct_qty'].mean()*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:09:50.988404Z",
     "iopub.status.busy": "2026-02-10T12:09:50.988196Z",
     "iopub.status.idle": "2026-02-10T12:09:51.106522Z",
     "shell.execute_reply": "2026-02-10T12:09:51.105792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging performance data with base data...\n",
      "✅ Merged data: 28124 records\n",
      "\n",
      "UTH Qty Stats: min=0, max=336, mean=1.7\n",
      "Last Hour Qty Stats: min=0, max=85, mean=0.2\n",
      "Current Cart Rule Stats: min=2, max=1943, mean=18.1\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# MERGE DATA\n",
    "# =============================================================================\n",
    "print(\"Merging performance data with base data...\")\n",
    "\n",
    "# Merge UTH today data\n",
    "if len(df_uth_today) > 0:\n",
    "    df = df.merge(df_uth_today, on=['warehouse_id', 'product_id'], how='left')\n",
    "else:\n",
    "    df['uth_qty'] = 0\n",
    "    df['uth_nmv'] = 0\n",
    "    df['uth_retailers'] = 0\n",
    "\n",
    "# Merge last hour data\n",
    "if len(df_last_hour) > 0:\n",
    "    df = df.merge(df_last_hour, on=['warehouse_id', 'product_id'], how='left')\n",
    "else:\n",
    "    df['last_hour_qty'] = 0\n",
    "    df['last_hour_nmv'] = 0\n",
    "    df['last_hour_retailers'] = 0\n",
    "\n",
    "# Merge hourly distribution (by warehouse_id + cat)\n",
    "if len(df_hourly_dist) > 0:\n",
    "    df = df.merge(df_hourly_dist, on=['warehouse_id', 'cat'], how='left')\n",
    "else:\n",
    "    df['avg_uth_pct_qty'] = 0.5\n",
    "    df['avg_uth_pct_retailers'] = 0.5\n",
    "    df['avg_last_hour_pct_qty'] = 0.05\n",
    "    df['avg_last_hour_pct_retailers'] = 0.05\n",
    "\n",
    "# Fill NaN values\n",
    "df['uth_qty'] = df['uth_qty'].fillna(0)\n",
    "df['uth_nmv'] = df['uth_nmv'].fillna(0)\n",
    "df['uth_retailers'] = df['uth_retailers'].fillna(0)\n",
    "df['last_hour_qty'] = df['last_hour_qty'].fillna(0)\n",
    "df['last_hour_nmv'] = df['last_hour_nmv'].fillna(0)\n",
    "df['last_hour_retailers'] = df['last_hour_retailers'].fillna(0)\n",
    "df['avg_uth_pct_qty'] = df['avg_uth_pct_qty'].fillna(0.5)\n",
    "df['avg_uth_pct_retailers'] = df['avg_uth_pct_retailers'].fillna(0.5)\n",
    "df['avg_last_hour_pct_qty'] = df['avg_last_hour_pct_qty'].fillna(0.05)\n",
    "df['avg_last_hour_pct_retailers'] = df['avg_last_hour_pct_retailers'].fillna(0.05)\n",
    "\n",
    "print(f\"✅ Merged data: {len(df)} records\")\n",
    "print(f\"\\nUTH Qty Stats: min={df['uth_qty'].min():.0f}, max={df['uth_qty'].max():.0f}, mean={df['uth_qty'].mean():.1f}\")\n",
    "print(f\"Last Hour Qty Stats: min={df['last_hour_qty'].min():.0f}, max={df['last_hour_qty'].max():.0f}, mean={df['last_hour_qty'].mean():.1f}\")\n",
    "print(f\"Current Cart Rule Stats: min={df['current_cart_rule'].min():.0f}, max={df['current_cart_rule'].max():.0f}, mean={df['current_cart_rule'].mean():.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:09:51.108577Z",
     "iopub.status.busy": "2026-02-10T12:09:51.108368Z",
     "iopub.status.idle": "2026-02-10T12:09:52.758748Z",
     "shell.execute_reply": "2026-02-10T12:09:52.757916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating UTH and Last Hour targets and statuses...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Targets and statuses calculated using ±3 std thresholds\n",
      "\n",
      "============================================================\n",
      "UTH STATUS DISTRIBUTION\n",
      "============================================================\n",
      "\n",
      "UTH Qty Status:\n",
      "uth_qty_status\n",
      "dropping    21472\n",
      "on_track     6081\n",
      "growing       571\n",
      "\n",
      "UTH Retailers Status:\n",
      "uth_rets_status\n",
      "dropping    22136\n",
      "on_track     5671\n",
      "growing       317\n",
      "\n",
      "============================================================\n",
      "LAST HOUR STATUS DISTRIBUTION\n",
      "============================================================\n",
      "\n",
      "Last Hour Qty Status:\n",
      "last_hour_qty_status\n",
      "dropping    26470\n",
      "on_track      914\n",
      "growing       740\n",
      "\n",
      "Last Hour Retailers Status:\n",
      "last_hour_rets_status\n",
      "dropping    26469\n",
      "growing      1135\n",
      "on_track      520\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CALCULATE TARGETS AND STATUSES\n",
    "# =============================================================================\n",
    "print(\"Calculating UTH and Last Hour targets and statuses...\")\n",
    "\n",
    "def get_status_std(actual, target, std, is_qty=True):\n",
    "    \"\"\"\n",
    "    Determine status based on ±3 std from target.\n",
    "    - Growing: actual > target + 3*std\n",
    "    - On Track: target - 3*std <= actual <= target + 3*std\n",
    "    - Dropping: actual < target - 3*std (minimum threshold = 1)\n",
    "    \n",
    "    Parameters:\n",
    "    - actual: actual performance value\n",
    "    - target: target value (p80 for qty, p70 for retailers)\n",
    "    - std: standard deviation (std_daily_240d or std_daily_retailers_240d)\n",
    "    - is_qty: True for qty metrics, False for retailer metrics\n",
    "    \"\"\"\n",
    "    upper_bound = target + STD_THRESHOLD * std\n",
    "    lower_bound = max(target - STD_THRESHOLD * std, MIN_DROPPING_THRESHOLD)\n",
    "    \n",
    "    if actual > upper_bound:\n",
    "        return 'growing'\n",
    "    elif actual < lower_bound:\n",
    "        return 'dropping'\n",
    "    else:\n",
    "        return 'on_track'\n",
    "\n",
    "# Calculate UTH targets\n",
    "# UTH target = p80_qty * avg_uth_pct (historical % of day that should be done by now)\n",
    "df['uth_qty_target'] = df['p80_daily_240d'] * df['avg_uth_pct_qty']\n",
    "df['uth_rets_target'] = df['p70_daily_retailers_240d'] * df['avg_uth_pct_retailers']\n",
    "\n",
    "# Calculate UTH std thresholds (scaled by UTH percentage)\n",
    "df['uth_qty_std'] = df['std_daily_240d'] * df['avg_uth_pct_qty']\n",
    "df['uth_rets_std'] = df['std_daily_retailers_240d'] * df['avg_uth_pct_retailers']\n",
    "\n",
    "# Calculate Last Hour targets\n",
    "# Last hour target = p80_qty * avg_last_hour_pct (historical % of day for this hour)\n",
    "df['last_hour_qty_target'] = df['p80_daily_240d'] * df['avg_last_hour_pct_qty']\n",
    "df['last_hour_rets_target'] = df['p70_daily_retailers_240d'] * df['avg_last_hour_pct_retailers']\n",
    "\n",
    "# Calculate Last Hour std thresholds (scaled by last hour percentage)\n",
    "df['last_hour_qty_std'] = df['std_daily_240d'] * df['avg_last_hour_pct_qty']\n",
    "df['last_hour_rets_std'] = df['std_daily_retailers_240d'] * df['avg_last_hour_pct_retailers']\n",
    "\n",
    "# Calculate statuses using ±3 std thresholds\n",
    "df['uth_qty_status'] = df.apply(\n",
    "    lambda row: get_status_std(row['uth_qty'], row['uth_qty_target'], row['uth_qty_std'], is_qty=True), axis=1)\n",
    "df['uth_rets_status'] = df.apply(\n",
    "    lambda row: get_status_std(row['uth_retailers'], row['uth_rets_target'], row['uth_rets_std'], is_qty=False), axis=1)\n",
    "df['last_hour_qty_status'] = df.apply(\n",
    "    lambda row: get_status_std(row['last_hour_qty'], row['last_hour_qty_target'], row['last_hour_qty_std'], is_qty=True), axis=1)\n",
    "df['last_hour_rets_status'] = df.apply(\n",
    "    lambda row: get_status_std(row['last_hour_retailers'], row['last_hour_rets_target'], row['last_hour_rets_std'], is_qty=False), axis=1)\n",
    "\n",
    "print(f\"✅ Targets and statuses calculated using ±{STD_THRESHOLD} std thresholds\")\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"UTH STATUS DISTRIBUTION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nUTH Qty Status:\")\n",
    "print(df['uth_qty_status'].value_counts().to_string())\n",
    "print(f\"\\nUTH Retailers Status:\")\n",
    "print(df['uth_rets_status'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"LAST HOUR STATUS DISTRIBUTION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nLast Hour Qty Status:\")\n",
    "print(df['last_hour_qty_status'].value_counts().to_string())\n",
    "print(f\"\\nLast Hour Retailers Status:\")\n",
    "print(df['last_hour_rets_status'].value_counts().to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:09:52.760603Z",
     "iopub.status.busy": "2026-02-10T12:09:52.760398Z",
     "iopub.status.idle": "2026-02-10T12:09:52.782503Z",
     "shell.execute_reply": "2026-02-10T12:09:52.781851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>region</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>warehouse</th>\n",
       "      <th>sku</th>\n",
       "      <th>brand</th>\n",
       "      <th>cat</th>\n",
       "      <th>wac1</th>\n",
       "      <th>current_margin</th>\n",
       "      <th>...</th>\n",
       "      <th>uth_qty_std</th>\n",
       "      <th>uth_rets_std</th>\n",
       "      <th>last_hour_qty_target</th>\n",
       "      <th>last_hour_rets_target</th>\n",
       "      <th>last_hour_qty_std</th>\n",
       "      <th>last_hour_rets_std</th>\n",
       "      <th>uth_qty_status</th>\n",
       "      <th>uth_rets_status</th>\n",
       "      <th>last_hour_qty_status</th>\n",
       "      <th>last_hour_rets_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>701</td>\n",
       "      <td>589</td>\n",
       "      <td>Giza</td>\n",
       "      <td>236</td>\n",
       "      <td>Barageel</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>0.060368</td>\n",
       "      <td>...</td>\n",
       "      <td>30.901745</td>\n",
       "      <td>5.447604</td>\n",
       "      <td>8.122690</td>\n",
       "      <td>1.888534</td>\n",
       "      <td>3.536872</td>\n",
       "      <td>0.637695</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>702</td>\n",
       "      <td>589</td>\n",
       "      <td>Alexandria</td>\n",
       "      <td>797</td>\n",
       "      <td>Khorshed Alex</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>0.072467</td>\n",
       "      <td>...</td>\n",
       "      <td>21.292856</td>\n",
       "      <td>3.138452</td>\n",
       "      <td>8.171759</td>\n",
       "      <td>1.721993</td>\n",
       "      <td>4.060505</td>\n",
       "      <td>0.562417</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>1123</td>\n",
       "      <td>589</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>703</td>\n",
       "      <td>Menya Samalot</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>0.060368</td>\n",
       "      <td>...</td>\n",
       "      <td>19.939911</td>\n",
       "      <td>3.987910</td>\n",
       "      <td>5.367271</td>\n",
       "      <td>1.186739</td>\n",
       "      <td>3.186451</td>\n",
       "      <td>0.626599</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5197</th>\n",
       "      <td>1124</td>\n",
       "      <td>589</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>501</td>\n",
       "      <td>Assiut FC</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>0.039488</td>\n",
       "      <td>...</td>\n",
       "      <td>6.193743</td>\n",
       "      <td>1.520737</td>\n",
       "      <td>1.726096</td>\n",
       "      <td>0.483791</td>\n",
       "      <td>0.908653</td>\n",
       "      <td>0.238163</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "      <td>growing</td>\n",
       "      <td>growing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>704</td>\n",
       "      <td>589</td>\n",
       "      <td>Delta East</td>\n",
       "      <td>339</td>\n",
       "      <td>Mansoura FC</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>0.017658</td>\n",
       "      <td>...</td>\n",
       "      <td>17.873006</td>\n",
       "      <td>2.705215</td>\n",
       "      <td>3.514452</td>\n",
       "      <td>1.159695</td>\n",
       "      <td>2.519557</td>\n",
       "      <td>0.435375</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12663</th>\n",
       "      <td>704</td>\n",
       "      <td>589</td>\n",
       "      <td>Delta East</td>\n",
       "      <td>170</td>\n",
       "      <td>Sharqya</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>0.017658</td>\n",
       "      <td>...</td>\n",
       "      <td>20.832336</td>\n",
       "      <td>3.389188</td>\n",
       "      <td>4.713716</td>\n",
       "      <td>1.213036</td>\n",
       "      <td>2.473835</td>\n",
       "      <td>0.436721</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13386</th>\n",
       "      <td>1126</td>\n",
       "      <td>589</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>401</td>\n",
       "      <td>Bani sweif</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>0.060368</td>\n",
       "      <td>...</td>\n",
       "      <td>10.939846</td>\n",
       "      <td>2.008901</td>\n",
       "      <td>2.462864</td>\n",
       "      <td>0.661886</td>\n",
       "      <td>1.679763</td>\n",
       "      <td>0.347421</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15589</th>\n",
       "      <td>1125</td>\n",
       "      <td>589</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>632</td>\n",
       "      <td>Sohag</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>0.052126</td>\n",
       "      <td>...</td>\n",
       "      <td>4.689122</td>\n",
       "      <td>1.279299</td>\n",
       "      <td>1.324861</td>\n",
       "      <td>0.467801</td>\n",
       "      <td>0.776216</td>\n",
       "      <td>0.255388</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18428</th>\n",
       "      <td>701</td>\n",
       "      <td>589</td>\n",
       "      <td>Giza</td>\n",
       "      <td>962</td>\n",
       "      <td>Sakkarah</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>0.060368</td>\n",
       "      <td>...</td>\n",
       "      <td>29.974012</td>\n",
       "      <td>5.567829</td>\n",
       "      <td>8.795759</td>\n",
       "      <td>2.039358</td>\n",
       "      <td>3.304369</td>\n",
       "      <td>0.656523</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19232</th>\n",
       "      <td>703</td>\n",
       "      <td>589</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>337</td>\n",
       "      <td>El-Mahala</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>-0.063298</td>\n",
       "      <td>...</td>\n",
       "      <td>16.267523</td>\n",
       "      <td>3.797542</td>\n",
       "      <td>5.211820</td>\n",
       "      <td>1.852577</td>\n",
       "      <td>2.387815</td>\n",
       "      <td>0.645624</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22752</th>\n",
       "      <td>703</td>\n",
       "      <td>589</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>8</td>\n",
       "      <td>Tanta</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>-0.063298</td>\n",
       "      <td>...</td>\n",
       "      <td>23.398870</td>\n",
       "      <td>4.682885</td>\n",
       "      <td>7.152715</td>\n",
       "      <td>2.255827</td>\n",
       "      <td>3.642722</td>\n",
       "      <td>0.896015</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27887</th>\n",
       "      <td>700</td>\n",
       "      <td>589</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>1</td>\n",
       "      <td>Mostorod</td>\n",
       "      <td>بيبسى - 2.43 لتر</td>\n",
       "      <td>بيبسي</td>\n",
       "      <td>حاجه ساقعه</td>\n",
       "      <td>220.525805</td>\n",
       "      <td>0.060368</td>\n",
       "      <td>...</td>\n",
       "      <td>77.544807</td>\n",
       "      <td>9.559919</td>\n",
       "      <td>15.668577</td>\n",
       "      <td>3.461829</td>\n",
       "      <td>9.311902</td>\n",
       "      <td>1.197758</td>\n",
       "      <td>on_track</td>\n",
       "      <td>on_track</td>\n",
       "      <td>dropping</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cohort_id  product_id       region  warehouse_id      warehouse  \\\n",
       "935          701         589         Giza           236       Barageel   \n",
       "3500         702         589   Alexandria           797  Khorshed Alex   \n",
       "4356        1123         589  Upper Egypt           703  Menya Samalot   \n",
       "5197        1124         589  Upper Egypt           501      Assiut FC   \n",
       "5596         704         589   Delta East           339    Mansoura FC   \n",
       "12663        704         589   Delta East           170        Sharqya   \n",
       "13386       1126         589  Upper Egypt           401     Bani sweif   \n",
       "15589       1125         589  Upper Egypt           632          Sohag   \n",
       "18428        701         589         Giza           962       Sakkarah   \n",
       "19232        703         589   Delta West           337      El-Mahala   \n",
       "22752        703         589   Delta West             8          Tanta   \n",
       "27887        700         589        Cairo             1       Mostorod   \n",
       "\n",
       "                    sku  brand         cat        wac1  current_margin  ...  \\\n",
       "935    بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805        0.060368  ...   \n",
       "3500   بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805        0.072467  ...   \n",
       "4356   بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805        0.060368  ...   \n",
       "5197   بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805        0.039488  ...   \n",
       "5596   بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805        0.017658  ...   \n",
       "12663  بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805        0.017658  ...   \n",
       "13386  بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805        0.060368  ...   \n",
       "15589  بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805        0.052126  ...   \n",
       "18428  بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805        0.060368  ...   \n",
       "19232  بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805       -0.063298  ...   \n",
       "22752  بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805       -0.063298  ...   \n",
       "27887  بيبسى - 2.43 لتر  بيبسي  حاجه ساقعه  220.525805        0.060368  ...   \n",
       "\n",
       "       uth_qty_std  uth_rets_std  last_hour_qty_target  last_hour_rets_target  \\\n",
       "935      30.901745      5.447604              8.122690               1.888534   \n",
       "3500     21.292856      3.138452              8.171759               1.721993   \n",
       "4356     19.939911      3.987910              5.367271               1.186739   \n",
       "5197      6.193743      1.520737              1.726096               0.483791   \n",
       "5596     17.873006      2.705215              3.514452               1.159695   \n",
       "12663    20.832336      3.389188              4.713716               1.213036   \n",
       "13386    10.939846      2.008901              2.462864               0.661886   \n",
       "15589     4.689122      1.279299              1.324861               0.467801   \n",
       "18428    29.974012      5.567829              8.795759               2.039358   \n",
       "19232    16.267523      3.797542              5.211820               1.852577   \n",
       "22752    23.398870      4.682885              7.152715               2.255827   \n",
       "27887    77.544807      9.559919             15.668577               3.461829   \n",
       "\n",
       "       last_hour_qty_std last_hour_rets_std  uth_qty_status  uth_rets_status  \\\n",
       "935             3.536872           0.637695        on_track         on_track   \n",
       "3500            4.060505           0.562417        dropping         dropping   \n",
       "4356            3.186451           0.626599        on_track         on_track   \n",
       "5197            0.908653           0.238163        on_track         on_track   \n",
       "5596            2.519557           0.435375        on_track         on_track   \n",
       "12663           2.473835           0.436721        on_track         on_track   \n",
       "13386           1.679763           0.347421        on_track         on_track   \n",
       "15589           0.776216           0.255388        dropping         dropping   \n",
       "18428           3.304369           0.656523        on_track         on_track   \n",
       "19232           2.387815           0.645624        on_track         on_track   \n",
       "22752           3.642722           0.896015        on_track         on_track   \n",
       "27887           9.311902           1.197758        on_track         on_track   \n",
       "\n",
       "       last_hour_qty_status  last_hour_rets_status  \n",
       "935                dropping               dropping  \n",
       "3500               dropping               dropping  \n",
       "4356               dropping               dropping  \n",
       "5197                growing                growing  \n",
       "5596               dropping               dropping  \n",
       "12663              dropping               dropping  \n",
       "13386              dropping               dropping  \n",
       "15589              dropping               dropping  \n",
       "18428              on_track               on_track  \n",
       "19232              dropping               dropping  \n",
       "22752              dropping               dropping  \n",
       "27887              dropping               dropping  \n",
       "\n",
       "[12 rows x 157 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['product_id']==589]#[['region','uth_qty_status','new_price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:09:52.784605Z",
     "iopub.status.busy": "2026-02-10T12:09:52.784407Z",
     "iopub.status.idle": "2026-02-10T12:18:20.856870Z",
     "shell.execute_reply": "2026-02-10T12:18:20.855989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching market data and margin tiers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.Renviron\n",
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Data Module loaded at 2026-02-10 14:09:53 Cairo time\n",
      "Snowflake timezone: America/Los_Angeles\n",
      "All queries defined ✓\n",
      "Helper functions defined ✓\n",
      "get_market_data() function defined ✓\n",
      "get_margin_tiers() function defined ✓\n",
      "\n",
      "======================================================================\n",
      "MARKET DATA MODULE READY\n",
      "======================================================================\n",
      "\n",
      "Available functions (NO INPUT REQUIRED):\n",
      "  - get_market_data()   : Fetch and process all market prices\n",
      "  - get_margin_tiers()  : Fetch and calculate margin tiers\n",
      "\n",
      "Usage:\n",
      "  %run market_data_module.ipynb\n",
      "  df_market = get_market_data()\n",
      "  df_tiers = get_margin_tiers()\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "FETCHING MARGIN TIERS\n",
      "======================================================================\n",
      "Timestamp: 2026-02-10 14:09:54 Cairo time\n",
      "\n",
      "Step 1: Fetching margin boundaries from PRODUCT_STATISTICS...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loaded 18067 records\n",
      "\n",
      "Step 2: Adding cohort IDs...\n",
      "    Records with cohorts: 24928\n",
      "\n",
      "Step 3: Calculating margin tiers...\n",
      "\n",
      "======================================================================\n",
      "MARGIN TIERS COMPLETE\n",
      "======================================================================\n",
      "Total records: 24928\n",
      "\n",
      "Margin Tier Structure:\n",
      "  margin_tier_below:   effective_min - step (1 below)\n",
      "  margin_tier_1:       effective_min_margin\n",
      "  margin_tier_2:       effective_min + 1*step\n",
      "  margin_tier_3:       effective_min + 2*step\n",
      "  margin_tier_4:       effective_min + 3*step\n",
      "  margin_tier_5:       max_boundary\n",
      "  margin_tier_above_1: max_boundary + 1*step\n",
      "  margin_tier_above_2: max_boundary + 2*step\n",
      "✅ Loaded 24928 margin tier records\n",
      "\n",
      "======================================================================\n",
      "FETCHING MARKET DATA\n",
      "======================================================================\n",
      "Timestamp: 2026-02-10 14:09:56 Cairo time\n",
      "\n",
      "Step 1: Fetching raw price data...\n",
      "  1.1 Ben Soliman prices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 1542 records\n",
      "  1.2 Marketplace prices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 10736 records\n",
      "  1.3 Scrapped prices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 3085 records\n",
      "  1.4 Product groups...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 1580 records\n",
      "  1.5 Sales data (for NMV weighting)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 20916 records\n",
      "  1.6 Margin stats...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 29000 records\n",
      "  1.7 Target margins...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 469 records\n",
      "  1.8 Product base (WAC)...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Loaded 65358 records\n",
      "\n",
      "Step 2: Joining all market price sources (outer join)...\n",
      "    Market prices base: 15275 records\n",
      "\n",
      "Step 3: Adding cohort IDs and supporting data...\n",
      "    Records after adding cohorts: 22883\n",
      "\n",
      "Step 4: Processing group-level prices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25692/3245917641.py:139: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: pd.Series({\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Records after group processing: 24374\n",
      "\n",
      "Step 5: Adding WAC and margin data...\n",
      "    Records with WAC: 23978\n",
      "\n",
      "Step 6: Filtering by price coverage...\n",
      "    Records after price coverage filter: 12075\n",
      "\n",
      "Step 7: Calculating price percentiles...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Records after price analysis: 11556\n",
      "\n",
      "Step 8: Converting prices to margins...\n",
      "\n",
      "======================================================================\n",
      "MARKET DATA COMPLETE\n",
      "======================================================================\n",
      "Total records: 11556\n",
      "  - With marketplace prices: 11361\n",
      "  - With scrapped prices: 3774\n",
      "  - With Ben Soliman prices: 8010\n",
      "✅ Loaded 11556 market data records\n",
      "\n",
      "Checking cohort_id availability:\n",
      "  - df has cohort_id: True\n",
      "  - df_margin_tiers has cohort_id: True\n",
      "  - df_market has cohort_id: True\n",
      "\n",
      "✅ Merged margin tiers: 28124 records\n",
      "   Margin tier columns added: ['region', 'optimal_bm', 'min_boundary', 'max_boundary', 'median_bm', 'effective_min_margin', 'margin_step', 'margin_tier_below', 'margin_tier_1', 'margin_tier_2', 'margin_tier_3', 'margin_tier_4', 'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2']\n",
      "✅ Merged market data: 28124 records\n",
      "   Market columns added: ['region', 'ben_soliman_price', 'final_min_price', 'final_max_price', 'final_mod_price', 'final_true_min', 'final_true_max', 'min_scrapped', 'scrapped25', 'scrapped50', 'scrapped75', 'max_scrapped', 'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum', 'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market']\n",
      "\n",
      "Margin Stats: min=-57.58%, max=45.20%, mean=4.91%\n",
      "Fetching high DOH SKUs from Module 3...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 262 high DOH SKUs from Module 3\n",
      "  SKUs marked as high DOH: 262\n",
      "Filtering SKUs for action...\n",
      "\n",
      "============================================================\n",
      "SKUs FILTERED FOR ACTION\n",
      "============================================================\n",
      "\n",
      "Total SKUs needing action: 138 out of 28124 (0.5%)\n",
      "\n",
      "Breakdown by reason:\n",
      "action_reason\n",
      "wac_increase           99\n",
      "growing_performance    39\n",
      "\n",
      "--- Condition A (WAC increase > 0.5%): 99 SKUs\n",
      "--- Condition B (Last hour growing + UTH good + qty > 5 + NOT high DOH): 39 SKUs\n",
      "--- Condition C (Below commercial minimum): 0 SKUs\n",
      "--- High DOH SKUs blocked from price increase: 262\n",
      "\n",
      "============================================================\n",
      "SAMPLE ACTION SKUs\n",
      "============================================================\n",
      "\n",
      "Total columns in df_action: 47\n",
      "Columns: ['warehouse_id', 'product_id', 'cohort_id', 'sku', 'region', 'brand', 'cat', 'current_price', 'wac_p', 'new_wac', 'current_margin', 'commercial_min_price', 'stocks', 'current_cart_rule', 'doh', 'p80_daily_240d', 'p70_daily_retailers_240d', 'std_daily_240d', 'std_daily_retailers_240d', 'normal_refill', 'refill_stddev', 'target_margin', 'uth_qty', 'uth_qty_status', 'uth_retailers', 'uth_rets_status', 'last_hour_qty', 'last_hour_qty_status', 'last_hour_retailers', 'last_hour_rets_status', 'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market', 'margin_tier_1', 'margin_tier_2', 'margin_tier_3', 'margin_tier_4', 'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2', 'needs_action', 'action_reason', 'qty_price_step_count']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>cohort_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>region</th>\n",
       "      <th>brand</th>\n",
       "      <th>cat</th>\n",
       "      <th>current_price</th>\n",
       "      <th>wac_p</th>\n",
       "      <th>new_wac</th>\n",
       "      <th>...</th>\n",
       "      <th>margin_tier_1</th>\n",
       "      <th>margin_tier_2</th>\n",
       "      <th>margin_tier_3</th>\n",
       "      <th>margin_tier_4</th>\n",
       "      <th>margin_tier_5</th>\n",
       "      <th>margin_tier_above_1</th>\n",
       "      <th>margin_tier_above_2</th>\n",
       "      <th>needs_action</th>\n",
       "      <th>action_reason</th>\n",
       "      <th>qty_price_step_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12925</td>\n",
       "      <td>700</td>\n",
       "      <td>زيت ثمرات خليط - 550 مل</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ثمرات</td>\n",
       "      <td>زيوت</td>\n",
       "      <td>490.75</td>\n",
       "      <td>436.070649</td>\n",
       "      <td>438.604499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.052154</td>\n",
       "      <td>0.060731</td>\n",
       "      <td>0.069308</td>\n",
       "      <td>0.077885</td>\n",
       "      <td>0.086462</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>337</td>\n",
       "      <td>9797</td>\n",
       "      <td>703</td>\n",
       "      <td>شاى ليبتون اخضر بالنعناع - 25 فتلة</td>\n",
       "      <td>Delta West</td>\n",
       "      <td>ليبتون</td>\n",
       "      <td>شاي</td>\n",
       "      <td>30.00</td>\n",
       "      <td>28.464800</td>\n",
       "      <td>28.464800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042000</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.064089</td>\n",
       "      <td>0.075134</td>\n",
       "      <td>0.086179</td>\n",
       "      <td>0.097224</td>\n",
       "      <td>0.108268</td>\n",
       "      <td>True</td>\n",
       "      <td>growing_performance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11271</td>\n",
       "      <td>700</td>\n",
       "      <td>اوكسى جل بلاك - 185 جم</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اوكسي</td>\n",
       "      <td>منظفات</td>\n",
       "      <td>95.25</td>\n",
       "      <td>69.609998</td>\n",
       "      <td>77.689810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042515</td>\n",
       "      <td>0.054386</td>\n",
       "      <td>0.066257</td>\n",
       "      <td>0.078129</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.101871</td>\n",
       "      <td>0.113743</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>236</td>\n",
       "      <td>10780</td>\n",
       "      <td>701</td>\n",
       "      <td>بطارية ريموت افيريدى ازرق - 20 حجر</td>\n",
       "      <td>Giza</td>\n",
       "      <td>افيريدي</td>\n",
       "      <td>بطاريات ولمبات</td>\n",
       "      <td>80.00</td>\n",
       "      <td>63.992631</td>\n",
       "      <td>67.404752</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103458</td>\n",
       "      <td>0.126889</td>\n",
       "      <td>0.150320</td>\n",
       "      <td>0.173751</td>\n",
       "      <td>0.197182</td>\n",
       "      <td>0.220613</td>\n",
       "      <td>0.244045</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>339</td>\n",
       "      <td>5649</td>\n",
       "      <td>704</td>\n",
       "      <td>جبنة عبور لاند شيدر - 500 جم</td>\n",
       "      <td>Delta East</td>\n",
       "      <td>عبور لاند</td>\n",
       "      <td>جبن</td>\n",
       "      <td>457.00</td>\n",
       "      <td>455.018017</td>\n",
       "      <td>455.018017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.020844</td>\n",
       "      <td>0.031396</td>\n",
       "      <td>0.041948</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.063052</td>\n",
       "      <td>0.073604</td>\n",
       "      <td>True</td>\n",
       "      <td>growing_performance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>703</td>\n",
       "      <td>25344</td>\n",
       "      <td>1123</td>\n",
       "      <td>شوكولاتة ديرى ميلك بابلي اوريو - 27 جم</td>\n",
       "      <td>NaN</td>\n",
       "      <td>كادبوري</td>\n",
       "      <td>شوكولاتة</td>\n",
       "      <td>229.00</td>\n",
       "      <td>225.292500</td>\n",
       "      <td>225.292500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039947</td>\n",
       "      <td>0.063687</td>\n",
       "      <td>0.087427</td>\n",
       "      <td>0.111167</td>\n",
       "      <td>0.134907</td>\n",
       "      <td>0.158647</td>\n",
       "      <td>0.182387</td>\n",
       "      <td>True</td>\n",
       "      <td>growing_performance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>401</td>\n",
       "      <td>12553</td>\n",
       "      <td>1126</td>\n",
       "      <td>بطه منظف تواليت سائل ليمون(مستر ماسل) 500 مل</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مستر ماسل</td>\n",
       "      <td>مطهرات و ملمعات</td>\n",
       "      <td>994.50</td>\n",
       "      <td>915.241722</td>\n",
       "      <td>923.710191</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>632</td>\n",
       "      <td>8600</td>\n",
       "      <td>1125</td>\n",
       "      <td>سائل اطباق وفير بلس ليمون اصفر - 725 جم</td>\n",
       "      <td>Upper Egypt</td>\n",
       "      <td>وفير</td>\n",
       "      <td>سائل أطباق</td>\n",
       "      <td>212.75</td>\n",
       "      <td>182.133179</td>\n",
       "      <td>183.485601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.088760</td>\n",
       "      <td>0.107520</td>\n",
       "      <td>0.126280</td>\n",
       "      <td>0.145039</td>\n",
       "      <td>0.163799</td>\n",
       "      <td>0.182559</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>501</td>\n",
       "      <td>11271</td>\n",
       "      <td>1124</td>\n",
       "      <td>اوكسى جل بلاك - 185 جم</td>\n",
       "      <td>NaN</td>\n",
       "      <td>اوكسي</td>\n",
       "      <td>منظفات</td>\n",
       "      <td>95.25</td>\n",
       "      <td>69.609998</td>\n",
       "      <td>77.689810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049927</td>\n",
       "      <td>0.059945</td>\n",
       "      <td>0.069964</td>\n",
       "      <td>0.079982</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>0.100018</td>\n",
       "      <td>0.110036</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>797</td>\n",
       "      <td>12535</td>\n",
       "      <td>702</td>\n",
       "      <td>ريد للحشرات الطائرة - 269 مل</td>\n",
       "      <td>NaN</td>\n",
       "      <td>رايد</td>\n",
       "      <td>مبيدات حشرية</td>\n",
       "      <td>509.00</td>\n",
       "      <td>488.135221</td>\n",
       "      <td>491.967036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035808</td>\n",
       "      <td>0.040866</td>\n",
       "      <td>0.045923</td>\n",
       "      <td>0.050981</td>\n",
       "      <td>0.056038</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.066153</td>\n",
       "      <td>True</td>\n",
       "      <td>wac_increase</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   warehouse_id  product_id  cohort_id  \\\n",
       "0             1       12925        700   \n",
       "1           337        9797        703   \n",
       "2             1       11271        700   \n",
       "3           236       10780        701   \n",
       "4           339        5649        704   \n",
       "5           703       25344       1123   \n",
       "6           401       12553       1126   \n",
       "7           632        8600       1125   \n",
       "8           501       11271       1124   \n",
       "9           797       12535        702   \n",
       "\n",
       "                                            sku       region      brand  \\\n",
       "0                       زيت ثمرات خليط - 550 مل          NaN      ثمرات   \n",
       "1            شاى ليبتون اخضر بالنعناع - 25 فتلة   Delta West     ليبتون   \n",
       "2                        اوكسى جل بلاك - 185 جم          NaN      اوكسي   \n",
       "3            بطارية ريموت افيريدى ازرق - 20 حجر         Giza    افيريدي   \n",
       "4                  جبنة عبور لاند شيدر - 500 جم   Delta East  عبور لاند   \n",
       "5        شوكولاتة ديرى ميلك بابلي اوريو - 27 جم          NaN    كادبوري   \n",
       "6  بطه منظف تواليت سائل ليمون(مستر ماسل) 500 مل          NaN  مستر ماسل   \n",
       "7       سائل اطباق وفير بلس ليمون اصفر - 725 جم  Upper Egypt       وفير   \n",
       "8                        اوكسى جل بلاك - 185 جم          NaN      اوكسي   \n",
       "9                  ريد للحشرات الطائرة - 269 مل          NaN       رايد   \n",
       "\n",
       "               cat  current_price       wac_p     new_wac  ...  margin_tier_1  \\\n",
       "0             زيوت         490.75  436.070649  438.604499  ...       0.035000   \n",
       "1              شاي          30.00   28.464800   28.464800  ...       0.042000   \n",
       "2           منظفات          95.25   69.609998   77.689810  ...       0.042515   \n",
       "3   بطاريات ولمبات          80.00   63.992631   67.404752  ...       0.103458   \n",
       "4              جبن         457.00  455.018017  455.018017  ...       0.010293   \n",
       "5         شوكولاتة         229.00  225.292500  225.292500  ...       0.039947   \n",
       "6  مطهرات و ملمعات         994.50  915.241722  923.710191  ...            NaN   \n",
       "7       سائل أطباق         212.75  182.133179  183.485601  ...       0.070000   \n",
       "8           منظفات          95.25   69.609998   77.689810  ...       0.049927   \n",
       "9     مبيدات حشرية         509.00  488.135221  491.967036  ...       0.035808   \n",
       "\n",
       "   margin_tier_2  margin_tier_3  margin_tier_4  margin_tier_5  \\\n",
       "0       0.043577       0.052154       0.060731       0.069308   \n",
       "1       0.053045       0.064089       0.075134       0.086179   \n",
       "2       0.054386       0.066257       0.078129       0.090000   \n",
       "3       0.126889       0.150320       0.173751       0.197182   \n",
       "4       0.020844       0.031396       0.041948       0.052500   \n",
       "5       0.063687       0.087427       0.111167       0.134907   \n",
       "6            NaN            NaN            NaN            NaN   \n",
       "7       0.088760       0.107520       0.126280       0.145039   \n",
       "8       0.059945       0.069964       0.079982       0.090000   \n",
       "9       0.040866       0.045923       0.050981       0.056038   \n",
       "\n",
       "   margin_tier_above_1  margin_tier_above_2  needs_action  \\\n",
       "0             0.077885             0.086462          True   \n",
       "1             0.097224             0.108268          True   \n",
       "2             0.101871             0.113743          True   \n",
       "3             0.220613             0.244045          True   \n",
       "4             0.063052             0.073604          True   \n",
       "5             0.158647             0.182387          True   \n",
       "6                  NaN                  NaN          True   \n",
       "7             0.163799             0.182559          True   \n",
       "8             0.100018             0.110036          True   \n",
       "9             0.061096             0.066153          True   \n",
       "\n",
       "         action_reason  qty_price_step_count  \n",
       "0         wac_increase                     0  \n",
       "1  growing_performance                     0  \n",
       "2         wac_increase                     0  \n",
       "3         wac_increase                     0  \n",
       "4  growing_performance                     0  \n",
       "5  growing_performance                     0  \n",
       "6         wac_increase                     0  \n",
       "7         wac_increase                     0  \n",
       "8         wac_increase                     0  \n",
       "9         wac_increase                     0  \n",
       "\n",
       "[10 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FETCH MARKET DATA AND MARGIN TIERS\n",
    "# =============================================================================\n",
    "print(\"Fetching market data and margin tiers...\")\n",
    "\n",
    "# Import market_data_module for get_market_data()\n",
    "%run market_data_module.ipynb\n",
    "\n",
    "# 1. Get margin tiers (already available from queries_module)\n",
    "df_margin_tiers = get_margin_tiers()\n",
    "print(f\"✅ Loaded {len(df_margin_tiers)} margin tier records\")\n",
    "\n",
    "# 2. Get market data\n",
    "df_market = get_market_data()\n",
    "print(f\"✅ Loaded {len(df_market)} market data records\")\n",
    "\n",
    "# Verify cohort_id is available in all dataframes\n",
    "print(f\"\\nChecking cohort_id availability:\")\n",
    "print(f\"  - df has cohort_id: {'cohort_id' in df.columns}\")\n",
    "print(f\"  - df_margin_tiers has cohort_id: {'cohort_id' in df_margin_tiers.columns}\")\n",
    "print(f\"  - df_market has cohort_id: {'cohort_id' in df_market.columns}\")\n",
    "\n",
    "# 3. Merge margin tiers with df (by cohort_id + product_id) - ALL COLUMNS\n",
    "merge_keys = ['cohort_id', 'product_id']\n",
    "df = df.drop(columns=[c for c in df_margin_tiers.columns if c in df.columns and c not in merge_keys], errors='ignore')\n",
    "df = df.merge(df_margin_tiers, on=merge_keys, how='left')\n",
    "print(f\"\\n✅ Merged margin tiers: {len(df)} records\")\n",
    "print(f\"   Margin tier columns added: {[c for c in df_margin_tiers.columns if c not in merge_keys]}\")\n",
    "\n",
    "# 4. Merge market data with df (by cohort_id + product_id) - ALL COLUMNS\n",
    "df = df.drop(columns=[c for c in df_market.columns if c in df.columns and c not in merge_keys], errors='ignore')\n",
    "df = df.merge(df_market, on=merge_keys, how='left')\n",
    "print(f\"✅ Merged market data: {len(df)} records\")\n",
    "print(f\"   Market columns added: {[c for c in df_market.columns if c not in merge_keys]}\")\n",
    "\n",
    "# 5. Calculate current margin based on current_price and new_wac\n",
    "df['current_margin'] = (df['current_price'] - df['new_wac']) / df['current_price']\n",
    "df['current_margin'] = df['current_margin'].fillna(0)\n",
    "\n",
    "print(f\"\\nMargin Stats: min={df['current_margin'].min():.2%}, max={df['current_margin'].max():.2%}, mean={df['current_margin'].mean():.2%}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FETCH HIGH DOH SKUS FROM MODULE 3 OUTPUT\n",
    "# =============================================================================\n",
    "# SKUs with high DOH should NOT have price increases (only price decreases in Module 3)\n",
    "print(\"Fetching high DOH SKUs from Module 3...\")\n",
    "\n",
    "HIGH_DOH_QUERY = '''\n",
    "SELECT DISTINCT product_id, warehouse_id, 1 as is_high_doh\n",
    "FROM MATERIALIZED_VIEWS.pricing_periodic_push\n",
    "WHERE created_at::DATE = CURRENT_DATE\n",
    "  AND (uth_status = 'High DOH' OR price_action LIKE '%doh%')\n",
    "'''\n",
    "try:\n",
    "    df_high_doh = query_snowflake(HIGH_DOH_QUERY)\n",
    "    print(f\"  Loaded {len(df_high_doh)} high DOH SKUs from Module 3\")\n",
    "except:\n",
    "    df_high_doh = pd.DataFrame(columns=['product_id', 'warehouse_id', 'is_high_doh'])\n",
    "    print(\"  No high DOH data found (Module 3 may not have run yet)\")\n",
    "\n",
    "# Merge high DOH flag\n",
    "df['is_high_doh'] = 0  # Initialize column first\n",
    "if len(df_high_doh) > 0:\n",
    "    df = df.drop(columns=['is_high_doh'], errors='ignore')\n",
    "    df = df.merge(df_high_doh[['product_id', 'warehouse_id', 'is_high_doh']], \n",
    "                  on=['product_id', 'warehouse_id'], how='left')\n",
    "    df['is_high_doh'] = df['is_high_doh'].fillna(0).astype(int)\n",
    "print(f\"  SKUs marked as high DOH: {(df['is_high_doh'] == 1).sum()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FILTER SKUS FOR ACTION\n",
    "# =============================================================================\n",
    "# Filter SKUs that need action based on:\n",
    "# Pre-condition: below_min_stock_flag != 1 (must be sellable)\n",
    "# Condition A: new_wac > wac_p * 1.005 (WAC increased by more than 0.5%)\n",
    "# Condition B: Last hour growing (qty OR rets) AND UTH (one growing + other on_track/growing) AND last_hour_qty > 5 AND NOT high DOH\n",
    "\n",
    "print(\"Filtering SKUs for action...\")\n",
    "\n",
    "# Skip SKUs with below_min_stock_flag (stock < min selling unit qty)\n",
    "can_sell = df['below_min_stock_flag'].fillna(0) != 1\n",
    "\n",
    "# Condition A: WAC increased significantly\n",
    "condition_a = (df['new_wac'] > df['wac_p'] * 1.005)\n",
    "\n",
    "# Condition B: Last hour growing AND UTH performing well AND last_hour_qty > 5 AND NOT high DOH\n",
    "# UTH good = one must be 'growing' AND the other must be 'on_track' or 'growing'\n",
    "# High DOH SKUs should NOT get price increases (Module 3 handles their price reductions)\n",
    "last_hour_growing = (df['last_hour_qty_status'] == 'growing') | (df['last_hour_rets_status'] == 'growing')\n",
    "uth_good = (\n",
    "    ((df['uth_qty_status'] == 'growing') & (df['uth_rets_status'].isin(['on_track', 'growing']))) |\n",
    "    ((df['uth_rets_status'] == 'growing') & (df['uth_qty_status'].isin(['on_track', 'growing'])))\n",
    ")\n",
    "last_hour_qty_threshold = df['last_hour_qty'] > 5\n",
    "not_high_doh = df['is_high_doh'] == 0\n",
    "condition_b = last_hour_growing & uth_good & last_hour_qty_threshold & can_sell #& not_high_doh\n",
    "\n",
    "# Condition C: Current price below commercial minimum (must enforce commercial min)\n",
    "condition_c = (\n",
    "    (df['commercial_min_price'].notna()) & \n",
    "    (df['commercial_min_price'] > 0) & \n",
    "    (df['current_price'] < df['commercial_min_price'])\n",
    ")\n",
    "\n",
    "# Combine conditions (A OR B OR C)\n",
    "df['needs_action'] = condition_a | condition_b | condition_c\n",
    "df['action_reason'] = 'none'\n",
    "df.loc[condition_a & ~condition_b & ~condition_c, 'action_reason'] = 'wac_increase'\n",
    "df.loc[~condition_a & condition_b & ~condition_c, 'action_reason'] = 'growing_performance'\n",
    "df.loc[~condition_a & ~condition_b & condition_c, 'action_reason'] = 'below_commercial_min'\n",
    "df.loc[condition_a & condition_b & ~condition_c, 'action_reason'] = 'both'\n",
    "df.loc[condition_a & ~condition_b & condition_c, 'action_reason'] = 'wac_and_commercial'\n",
    "df.loc[~condition_a & condition_b & condition_c, 'action_reason'] = 'growing_and_commercial'\n",
    "df.loc[condition_a & condition_b & condition_c, 'action_reason'] = 'all'\n",
    "\n",
    "# Define important columns for df_action\n",
    "action_columns = [\n",
    "    # Identification\n",
    "    'warehouse_id', 'product_id', 'cohort_id', 'sku', 'region', 'brand', 'cat',\n",
    "    # Price & Cost\n",
    "    'current_price', 'wac_p', 'new_wac', 'current_margin', 'commercial_min_price',\n",
    "    # Inventory & Rules\n",
    "    'stocks', 'current_cart_rule', 'doh',\n",
    "    # Performance Targets\n",
    "    'p80_daily_240d', 'p70_daily_retailers_240d', 'std_daily_240d', 'std_daily_retailers_240d',\n",
    "    # Refill columns for cart rule calculation\n",
    "    'normal_refill', 'refill_stddev', 'target_margin',\n",
    "    # UTH Status\n",
    "    'uth_qty', 'uth_qty_status', 'uth_retailers', 'uth_rets_status',\n",
    "    # Last Hour Status\n",
    "    'last_hour_qty', 'last_hour_qty_status', 'last_hour_retailers', 'last_hour_rets_status',\n",
    "    # Market Margins\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', 'market_75', 'market_max', 'above_market',\n",
    "    # Margin Tiers (excluding: effective_min_margin, max_boundary, margin_step, margin_tier_below)\n",
    "    'margin_tier_1', 'margin_tier_2', 'margin_tier_3', 'margin_tier_4', 'margin_tier_5',\n",
    "    'margin_tier_above_1', 'margin_tier_above_2',\n",
    "    # Action Flags\n",
    "    'needs_action', 'action_reason'\n",
    "]\n",
    "\n",
    "# Filter to only columns that exist in df\n",
    "action_columns = [c for c in action_columns if c in df.columns]\n",
    "\n",
    "# Filter to action SKUs with selected columns only\n",
    "df_action = df[df['needs_action']][action_columns].copy()\n",
    "\n",
    "# Merge previous qty_growing_price_step counts\n",
    "df_action = df_action.merge(qty_price_step_counts, on=['product_id', 'warehouse_id'], how='left')\n",
    "df_action['qty_price_step_count'] = df_action['qty_price_step_count'].fillna(0).astype(int)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SKUs FILTERED FOR ACTION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nTotal SKUs needing action: {len(df_action)} out of {len(df)} ({len(df_action)/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nBreakdown by reason:\")\n",
    "print(df_action['action_reason'].value_counts().to_string())\n",
    "\n",
    "print(f\"\\n--- Condition A (WAC increase > 0.5%): {condition_a.sum()} SKUs\")\n",
    "print(f\"--- Condition B (Last hour growing + UTH good + qty > 5 + NOT high DOH): {condition_b.sum()} SKUs\")\n",
    "print(f\"--- Condition C (Below commercial minimum): {condition_c.sum()} SKUs\")\n",
    "print(f\"--- High DOH SKUs blocked from price increase: {(df['is_high_doh'] == 1).sum()}\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SAMPLE ACTION SKUs\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nTotal columns in df_action: {len(df_action.columns)}\")\n",
    "print(f\"Columns: {df_action.columns.tolist()}\")\n",
    "display(df_action.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:18:20.859077Z",
     "iopub.status.busy": "2026-02-10T12:18:20.858865Z",
     "iopub.status.idle": "2026-02-10T12:18:20.929320Z",
     "shell.execute_reply": "2026-02-10T12:18:20.928471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating actions for filtered SKUs...\n",
      "  WAC increase actions: 0 SKUs\n",
      "    (SKUs where wac_p < current_price < new_wac)\n",
      "  Rets growing actions (price increase): 39 SKUs\n",
      "  Qty growing actions (cart rule change): 0 SKUs\n",
      "    (Cart rule: rounded, min=5, max=150)\n",
      "  Qty growing with price step: 0 SKUs\n",
      "  Qty growing blocked (already 2x today): 0 SKUs\n",
      "  Qty growing blocked (high DOH > 30): 0 SKUs\n",
      "\n",
      "============================================================\n",
      "ENFORCING COMMERCIAL MINIMUM PRICE\n",
      "============================================================\n",
      "  SKUs with commercial min: 16\n",
      "  Growing SKUs with commercial min applied: 0\n",
      "  SKUs only needing commercial min: 0\n",
      "  Total commercial min enforcements: 0\n",
      "\n",
      "============================================================\n",
      "ACTION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Price Actions:\n",
      "price_action\n",
      "none            99\n",
      "rets_growing    39\n",
      "\n",
      "Cart Rule Actions:\n",
      "cart_rule_action\n",
      "none    138\n",
      "\n",
      "SKUs with new price: 39\n",
      "  Avg price change: 2.1%\n",
      "\n",
      "SKUs with new cart rule: 0\n",
      "\n",
      "============================================================\n",
      "SAMPLE OUTPUT\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>current_price</th>\n",
       "      <th>new_price</th>\n",
       "      <th>current_cart_rule</th>\n",
       "      <th>new_cart_rule</th>\n",
       "      <th>price_action</th>\n",
       "      <th>cart_rule_action</th>\n",
       "      <th>action_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>شاى ليبتون اخضر بالنعناع - 25 فتلة</td>\n",
       "      <td>30.00</td>\n",
       "      <td>32.600000</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>جبنة عبور لاند شيدر - 500 جم</td>\n",
       "      <td>457.00</td>\n",
       "      <td>462.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>شوكولاتة ديرى ميلك بابلي اوريو - 27 جم</td>\n",
       "      <td>229.00</td>\n",
       "      <td>234.666667</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>مناديل فاميليا مطبخ كلاسيك 5 رول + 1 رول هدية ...</td>\n",
       "      <td>187.50</td>\n",
       "      <td>189.687871</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>سمنة الاصيل اصفر - 750 جم</td>\n",
       "      <td>398.75</td>\n",
       "      <td>402.867636</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>عسل البوادى اسود - 355 جم</td>\n",
       "      <td>21.75</td>\n",
       "      <td>22.830000</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>سبرايت اكشن - 300 مل</td>\n",
       "      <td>109.00</td>\n",
       "      <td>109.937500</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>عصير تانج برتقال بودر برطمان - 450 جم</td>\n",
       "      <td>81.25</td>\n",
       "      <td>82.062500</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ميرندا برتقال كانز جيب - 240 مل</td>\n",
       "      <td>291.50</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>طحينة البوادى - 125 جم</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.675000</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>مناديل زينة تريو عرض خاص - 500 منديل</td>\n",
       "      <td>404.00</td>\n",
       "      <td>406.450000</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>مسحوق باهى يدوى لافندر - 1 كجم</td>\n",
       "      <td>177.75</td>\n",
       "      <td>180.425000</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>سفن اب كانز جيب - 240 مل</td>\n",
       "      <td>286.00</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>تورتا رولز ديلايتس كيـك كاكاو محشو بكريمه الفا...</td>\n",
       "      <td>49.75</td>\n",
       "      <td>51.092910</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>جبنة ديرى فيتا بلس  - 125 جم</td>\n",
       "      <td>282.00</td>\n",
       "      <td>284.695226</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rets_growing</td>\n",
       "      <td>none</td>\n",
       "      <td>growing_performance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  sku  current_price  \\\n",
       "1                  شاى ليبتون اخضر بالنعناع - 25 فتلة          30.00   \n",
       "4                        جبنة عبور لاند شيدر - 500 جم         457.00   \n",
       "5              شوكولاتة ديرى ميلك بابلي اوريو - 27 جم         229.00   \n",
       "10  مناديل فاميليا مطبخ كلاسيك 5 رول + 1 رول هدية ...         187.50   \n",
       "13                          سمنة الاصيل اصفر - 750 جم         398.75   \n",
       "22                          عسل البوادى اسود - 355 جم          21.75   \n",
       "27                               سبرايت اكشن - 300 مل         109.00   \n",
       "28              عصير تانج برتقال بودر برطمان - 450 جم          81.25   \n",
       "39                    ميرندا برتقال كانز جيب - 240 مل         291.50   \n",
       "41                             طحينة البوادى - 125 جم          26.00   \n",
       "46               مناديل زينة تريو عرض خاص - 500 منديل         404.00   \n",
       "50                     مسحوق باهى يدوى لافندر - 1 كجم         177.75   \n",
       "51                           سفن اب كانز جيب - 240 مل         286.00   \n",
       "52  تورتا رولز ديلايتس كيـك كاكاو محشو بكريمه الفا...          49.75   \n",
       "55                       جبنة ديرى فيتا بلس  - 125 جم         282.00   \n",
       "\n",
       "     new_price  current_cart_rule  new_cart_rule  price_action  \\\n",
       "1    32.600000                 21            NaN  rets_growing   \n",
       "4   462.000000                  6            NaN  rets_growing   \n",
       "5   234.666667                 22            NaN  rets_growing   \n",
       "10  189.687871                  8            NaN  rets_growing   \n",
       "13  402.867636                 21            NaN  rets_growing   \n",
       "22   22.830000                 49            NaN  rets_growing   \n",
       "27  109.937500                  8            NaN  rets_growing   \n",
       "28   82.062500                 26            NaN  rets_growing   \n",
       "39  300.000000                  7            NaN  rets_growing   \n",
       "41   26.675000                 65            NaN  rets_growing   \n",
       "46  406.450000                 13            NaN  rets_growing   \n",
       "50  180.425000                  6            NaN  rets_growing   \n",
       "51  290.000000                 12            NaN  rets_growing   \n",
       "52   51.092910                  3            NaN  rets_growing   \n",
       "55  284.695226                  5            NaN  rets_growing   \n",
       "\n",
       "   cart_rule_action        action_reason  \n",
       "1              none  growing_performance  \n",
       "4              none  growing_performance  \n",
       "5              none  growing_performance  \n",
       "10             none  growing_performance  \n",
       "13             none  growing_performance  \n",
       "22             none  growing_performance  \n",
       "27             none  growing_performance  \n",
       "28             none  growing_performance  \n",
       "39             none  growing_performance  \n",
       "41             none  growing_performance  \n",
       "46             none  growing_performance  \n",
       "50             none  growing_performance  \n",
       "51             none  growing_performance  \n",
       "52             none  growing_performance  \n",
       "55             none  growing_performance  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ACTION LOGIC\n",
    "# =============================================================================\n",
    "print(\"Calculating actions for filtered SKUs...\")\n",
    "\n",
    "# Step 0: Preparation - Calculate normal_refill_3std\n",
    "df_action['normal_refill_3std'] = df_action['normal_refill'] + 3 * df_action['refill_stddev']\n",
    "\n",
    "# Initialize output columns\n",
    "df_action['new_price'] = np.nan\n",
    "df_action['new_cart_rule'] = np.nan\n",
    "df_action['price_action'] = 'none'\n",
    "df_action['cart_rule_action'] = 'none'\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER: Calculate all price tiers from margins using wac_p\n",
    "# =============================================================================\n",
    "def calculate_price_from_margin(wac, margin):\n",
    "    \"\"\"Calculate price from WAC and margin: price = wac / (1 - margin)\"\"\"\n",
    "    if pd.isna(margin) or margin >= 1:\n",
    "        return np.nan\n",
    "    return wac / (1 - margin)\n",
    "\n",
    "# Calculate market prices (using wac_p)\n",
    "market_margin_cols = ['market_min', 'market_25', 'market_50', 'market_75', 'market_max']\n",
    "for col in market_margin_cols:\n",
    "    price_col = f'{col}_price'\n",
    "    df_action[price_col] = df_action.apply(\n",
    "        lambda row: calculate_price_from_margin(row['wac_p'], row[col]), axis=1)\n",
    "\n",
    "# Calculate margin tier prices (using wac_p)\n",
    "tier_margin_cols = ['margin_tier_1', 'margin_tier_2', 'margin_tier_3', 'margin_tier_4', 'margin_tier_5',\n",
    "                    'margin_tier_above_1', 'margin_tier_above_2']\n",
    "for col in tier_margin_cols:\n",
    "    price_col = f'{col}_price'\n",
    "    df_action[price_col] = df_action.apply(\n",
    "        lambda row: calculate_price_from_margin(row['wac_p'], row[col]), axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER: Find first price above threshold\n",
    "# =============================================================================\n",
    "def find_first_price_above(row, threshold, price_cols):\n",
    "    \"\"\"Find the first price in price_cols that is above threshold.\"\"\"\n",
    "    for col in price_cols:\n",
    "        price = row.get(col, np.nan)\n",
    "        if pd.notna(price) and price > threshold:\n",
    "            return price\n",
    "    return np.nan\n",
    "\n",
    "# Define price column order (market first, then tiers)\n",
    "market_price_cols = ['market_min_price', 'market_25_price', 'market_50_price', 'market_75_price', 'market_max_price']\n",
    "tier_price_cols = ['margin_tier_1_price', 'margin_tier_2_price', 'margin_tier_3_price', \n",
    "                   'margin_tier_4_price', 'margin_tier_5_price', \n",
    "                   'margin_tier_above_1_price', 'margin_tier_above_2_price']\n",
    "all_price_cols = market_price_cols + tier_price_cols\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: WAC Increase Actions (action_reason = 'both' or 'wac_increase')\n",
    "# =============================================================================\n",
    "# Only apply if: current_price < new_wac AND current_price > wac_p\n",
    "# (price is squeezed between old and new WAC)\n",
    "wac_increase_mask = (\n",
    "    df_action['action_reason'].isin(['both', 'wac_increase']) &\n",
    "    (df_action['current_price'] < df_action['new_wac']) &\n",
    "    (df_action['current_price'] > df_action['wac_p'])\n",
    ")\n",
    "\n",
    "def get_wac_increase_price(row):\n",
    "    \"\"\"Find first market/tier price above current_price.\"\"\"\n",
    "    # Find first price above current_price (not new_wac)\n",
    "    new_price = find_first_price_above(row, row['current_price'], all_price_cols)\n",
    "    return new_price\n",
    "\n",
    "df_action.loc[wac_increase_mask, 'new_price'] = df_action[wac_increase_mask].apply(get_wac_increase_price, axis=1)\n",
    "df_action.loc[wac_increase_mask, 'price_action'] = 'wac_increase'\n",
    "\n",
    "print(f\"  WAC increase actions: {wac_increase_mask.sum()} SKUs\")\n",
    "print(f\"    (SKUs where wac_p < current_price < new_wac)\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: Growing Performance Actions (action_reason = 'growing_performance')\n",
    "# =============================================================================\n",
    "growing_mask = df_action['action_reason'] == 'growing_performance'\n",
    "\n",
    "# Case A: Retailers growing (with or without qty)\n",
    "rets_growing_mask = growing_mask & (df_action['last_hour_rets_status'] == 'growing')\n",
    "\n",
    "def get_rets_growing_price(row):\n",
    "    \"\"\"Find price for rets growing: market/tier >= current_price * 1.005, or fallback to target margin.\"\"\"\n",
    "    min_price = row['current_price'] * 1.005\n",
    "    \n",
    "    # Try market prices first\n",
    "    new_price = find_first_price_above(row, min_price, market_price_cols)\n",
    "    if pd.notna(new_price):\n",
    "        return new_price\n",
    "    \n",
    "    # Try tier prices\n",
    "    new_price = find_first_price_above(row, min_price, tier_price_cols)\n",
    "    if pd.notna(new_price):\n",
    "        return new_price\n",
    "    \n",
    "    # Fallback: wac_p / (1 - (target_margin * 1.15))\n",
    "    target_margin = row.get('target_margin', 0)\n",
    "    if pd.notna(target_margin) and target_margin * 1.15 < 1:\n",
    "        fallback_price = row['wac_p'] / (1 - (target_margin * 1.15))\n",
    "        # If fallback price is lower than current price, use current_price * 1.01\n",
    "        if fallback_price < row['current_price']:\n",
    "            return row['current_price'] * 1.01\n",
    "        return fallback_price\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "df_action.loc[rets_growing_mask, 'new_price'] = df_action[rets_growing_mask].apply(get_rets_growing_price, axis=1)\n",
    "df_action.loc[rets_growing_mask, 'price_action'] = 'rets_growing'\n",
    "\n",
    "print(f\"  Rets growing actions (price increase): {rets_growing_mask.sum()} SKUs\")\n",
    "\n",
    "# Case B: Qty growing only (rets NOT growing)\n",
    "qty_only_growing_mask = growing_mask & (df_action['last_hour_qty_status'] == 'growing') & (df_action['last_hour_rets_status'] != 'growing')\n",
    "\n",
    "def get_qty_growing_cart_rule(row):\n",
    "    \"\"\"Calculate new cart rule for qty growing only.\"\"\"\n",
    "    # Calculate qty per retailer\n",
    "    uth_retailers = row.get('uth_retailers', 0)\n",
    "    if uth_retailers == 0:\n",
    "        qty_per_retailer = np.inf\n",
    "    else:\n",
    "        qty_per_retailer = row['uth_qty'] / uth_retailers\n",
    "    \n",
    "    # Get the three options\n",
    "    option1 = row.get('normal_refill_3std', np.inf)\n",
    "    option2 = qty_per_retailer\n",
    "    option3 = row.get('current_cart_rule', np.inf) * 0.85\n",
    "    \n",
    "    # Return minimum of the three (excluding inf/nan)\n",
    "    options = [opt for opt in [option1, option2, option3] if pd.notna(opt) and opt != np.inf]\n",
    "    if options:\n",
    "        return min(options)\n",
    "    return np.nan\n",
    "\n",
    "df_action.loc[qty_only_growing_mask, 'new_cart_rule'] = df_action[qty_only_growing_mask].apply(get_qty_growing_cart_rule, axis=1)\n",
    "\n",
    "# Round and apply min/max constraints to new_cart_rule\n",
    "df_action['new_cart_rule'] = df_action['new_cart_rule'].round()\n",
    "df_action['new_cart_rule'] = df_action['new_cart_rule'].clip(lower=5, upper=150)\n",
    "\n",
    "# LOW STOCK PROTECTION: Cap cart rule at normal_refill for low stock SKUs with demand\n",
    "# This prevents cart expansion that could deplete inventory before next receiving\n",
    "if 'doh' in df_action.columns:\n",
    "    low_stock_mask = (\n",
    "        (df_action['doh'].fillna(999) <= LOW_STOCK_DOH_THRESHOLD) & \n",
    "        (df_action['uth_qty'].fillna(0) > 0) &\n",
    "        (df_action['new_cart_rule'].notna())\n",
    "    )\n",
    "    if low_stock_mask.sum() > 0:\n",
    "        # Cap cart rule at normal_refill for low stock SKUs\n",
    "        df_action.loc[low_stock_mask, 'new_cart_rule'] = df_action.loc[low_stock_mask].apply(\n",
    "            lambda row: min(row['new_cart_rule'], np.ceil(row.get('normal_refill', row['new_cart_rule']))), axis=1\n",
    "        )\n",
    "        print(f\"  Low stock protection: {low_stock_mask.sum()} SKUs had cart rule capped at normal_refill\")\n",
    "\n",
    "df_action.loc[qty_only_growing_mask, 'cart_rule_action'] = 'qty_growing'\n",
    "\n",
    "print(f\"  Qty growing actions (cart rule change): {qty_only_growing_mask.sum()} SKUs\")\n",
    "print(f\"    (Cart rule: rounded, min=5, max=150)\")\n",
    "\n",
    "# =============================================================================\n",
    "# NEW RULE: If new_cart_rule <= normal_refill AND < 2 price steps today AND DOH <= 30\n",
    "# =============================================================================\n",
    "HIGH_DOH_THRESHOLD = 30\n",
    "can_do_price_step = df_action['qty_price_step_count'] < MAX_QTY_GROWING_PRICE_STEPS_PER_DAY\n",
    "not_high_doh = df_action['doh'].fillna(0) <= HIGH_DOH_THRESHOLD\n",
    "qty_growing_needs_price = qty_only_growing_mask & (df_action['new_cart_rule'] <= df_action['normal_refill']) & can_do_price_step & not_high_doh\n",
    "\n",
    "def get_qty_growing_price_step(row):\n",
    "    \"\"\"Find next tier price above current price (1 step increase).\"\"\"\n",
    "    return find_first_price_above(row, row['current_price'] * 1.001, tier_price_cols)\n",
    "\n",
    "df_action.loc[qty_growing_needs_price, 'new_price'] = df_action[qty_growing_needs_price].apply(get_qty_growing_price_step, axis=1)\n",
    "df_action.loc[qty_growing_needs_price, 'price_action'] = 'qty_growing_price_step'\n",
    "\n",
    "qty_growing_blocked_limit = qty_only_growing_mask & (df_action['new_cart_rule'] <= df_action['normal_refill']) & ~can_do_price_step\n",
    "qty_growing_blocked_doh = qty_only_growing_mask & (df_action['new_cart_rule'] <= df_action['normal_refill']) & can_do_price_step & ~not_high_doh\n",
    "print(f\"  Qty growing with price step: {qty_growing_needs_price.sum()} SKUs\")\n",
    "print(f\"  Qty growing blocked (already {MAX_QTY_GROWING_PRICE_STEPS_PER_DAY}x today): {qty_growing_blocked_limit.sum()} SKUs\")\n",
    "print(f\"  Qty growing blocked (high DOH > {HIGH_DOH_THRESHOLD}): {qty_growing_blocked_doh.sum()} SKUs\")\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL STEP: ENFORCE COMMERCIAL MINIMUM PRICE\n",
    "# =============================================================================\n",
    "# For all SKUs in df_action, ensure new_price >= commercial_min_price\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ENFORCING COMMERCIAL MINIMUM PRICE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "has_commercial_min = (df_action['commercial_min_price'].notna()) & (df_action['commercial_min_price'] > 0)\n",
    "\n",
    "# For SKUs with new_price already calculated (growing/wac): MAX(new_price, commercial_min)\n",
    "has_new_price = df_action['new_price'].notna()\n",
    "below_min_with_new = has_commercial_min & has_new_price & (df_action['new_price'] < df_action['commercial_min_price'])\n",
    "df_action.loc[below_min_with_new, 'new_price'] = df_action.loc[below_min_with_new, 'commercial_min_price']\n",
    "df_action.loc[below_min_with_new, 'price_action'] = df_action.loc[below_min_with_new, 'price_action'].astype(str) + '_commercial_enforced'\n",
    "\n",
    "# For SKUs without new_price (only commercial min violation): new_price = commercial_min\n",
    "no_new_price = df_action['new_price'].isna()\n",
    "below_min_only = has_commercial_min & no_new_price & (df_action['current_price'] < df_action['commercial_min_price'])\n",
    "df_action.loc[below_min_only, 'new_price'] = df_action.loc[below_min_only, 'commercial_min_price']\n",
    "df_action.loc[below_min_only, 'price_action'] = 'commercial_min_enforced'\n",
    "\n",
    "print(f\"  SKUs with commercial min: {has_commercial_min.sum()}\")\n",
    "print(f\"  Growing SKUs with commercial min applied: {below_min_with_new.sum()}\")\n",
    "print(f\"  SKUs only needing commercial min: {below_min_only.sum()}\")\n",
    "print(f\"  Total commercial min enforcements: {below_min_with_new.sum() + below_min_only.sum()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SUMMARY\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ACTION SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\nPrice Actions:\")\n",
    "print(df_action['price_action'].value_counts().to_string())\n",
    "print(f\"\\nCart Rule Actions:\")\n",
    "print(df_action['cart_rule_action'].value_counts().to_string())\n",
    "\n",
    "# Show SKUs with new prices\n",
    "price_changes = df_action[df_action['new_price'].notna()]\n",
    "print(f\"\\nSKUs with new price: {len(price_changes)}\")\n",
    "if len(price_changes) > 0:\n",
    "    print(f\"  Avg price change: {((price_changes['new_price'] - price_changes['current_price']) / price_changes['current_price']).mean()*100:.1f}%\")\n",
    "\n",
    "# Show SKUs with new cart rules\n",
    "cart_changes = df_action[df_action['new_cart_rule'].notna()]\n",
    "print(f\"\\nSKUs with new cart rule: {len(cart_changes)}\")\n",
    "if len(cart_changes) > 0:\n",
    "    print(f\"  Avg cart rule change: {((cart_changes['new_cart_rule'] - cart_changes['current_cart_rule']) / cart_changes['current_cart_rule']).mean()*100:.1f}%\")\n",
    "\n",
    "# Display sample\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SAMPLE OUTPUT\")\n",
    "print(f\"{'='*60}\")\n",
    "output_cols = ['sku', 'current_price', 'new_price', 'current_cart_rule', 'new_cart_rule', \n",
    "               'price_action', 'cart_rule_action', 'action_reason']\n",
    "output_cols = [c for c in output_cols if c in df_action.columns]\n",
    "display(df_action[df_action['new_price'].notna() | df_action['new_cart_rule'].notna()][output_cols].head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:18:20.931148Z",
     "iopub.status.busy": "2026-02-10T12:18:20.930942Z",
     "iopub.status.idle": "2026-02-10T12:18:20.935032Z",
     "shell.execute_reply": "2026-02-10T12:18:20.934247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PUSH MODE: LIVE\n",
      "============================================================\n",
      "🚀 Live mode - files will be uploaded to MaxAB API\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PUSH CONFIGURATION\n",
    "# =============================================================================\n",
    "# Mode: 'testing' = prepare files only, 'live' = actually upload to API\n",
    "PUSH_MODE = 'live'  # Change to 'live' when ready to push\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PUSH MODE: {PUSH_MODE.upper()}\")\n",
    "print(f\"{'='*60}\")\n",
    "if PUSH_MODE == 'testing':\n",
    "    print(\"⚠️ Testing mode - files will be prepared but NOT uploaded\")\n",
    "else:\n",
    "    print(\"🚀 Live mode - files will be uploaded to MaxAB API\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:18:20.936692Z",
     "iopub.status.busy": "2026-02-10T12:18:20.936500Z",
     "iopub.status.idle": "2026-02-10T12:18:20.942187Z",
     "shell.execute_reply": "2026-02-10T12:18:20.941429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved 138 rows for Slack upload\n"
     ]
    }
   ],
   "source": [
    "# Save df_action state before any manipulation for Slack upload later\n",
    "temp_df_for_slack = df_action.copy()\n",
    "print(f\"✅ Saved {len(temp_df_for_slack)} rows for Slack upload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:18:20.943896Z",
     "iopub.status.busy": "2026-02-10T12:18:20.943705Z",
     "iopub.status.idle": "2026-02-10T12:18:21.669740Z",
     "shell.execute_reply": "2026-02-10T12:18:21.668870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push Cart Rules Handler loaded at 2026-02-10 14:18:20 Cairo time\n",
      "✓ API credentials loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Push Prices Handler loaded at 2026-02-10 14:18:21 Cairo time\n",
      "✓ API credentials loaded successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Google Sheets client initialized\n",
      "✅ Push handlers loaded\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORT PUSH HANDLERS\n",
    "# =============================================================================\n",
    "%run push_cart_rules_handler.ipynb\n",
    "%run push_prices_handler.ipynb\n",
    "\n",
    "print(\"✅ Push handlers loaded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:18:21.671774Z",
     "iopub.status.busy": "2026-02-10T12:18:21.671454Z",
     "iopub.status.idle": "2026-02-10T12:18:41.517970Z",
     "shell.execute_reply": "2026-02-10T12:18:41.517029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching packing_units ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loaded 35130 records\n",
      "✅ Loaded 35130 packing units\n",
      "\n",
      "📊 Push Summary:\n",
      "  Price changes: 39 SKUs\n",
      "  Cart rule changes: 0 SKUs\n",
      "  Mode: live\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PREPARE DATA FOR PUSH\n",
    "# =============================================================================\n",
    "# Get packing units for push handlers\n",
    "pus = get_packing_units()\n",
    "print(f\"✅ Loaded {len(pus)} packing units\")\n",
    "\n",
    "# Prepare df_action with required columns for push functions\n",
    "# Prices need: product_id, sku, new_price, warehouse_id, cohort_id, stocks, current_price\n",
    "# Cart rules need: product_id, sku, new_cart_rule, warehouse_id, cohort_id, stocks, current_cart_rule\n",
    "\n",
    "# Rename stocks column if needed\n",
    "if 'current_stocks' in df_action.columns and 'stocks' not in df_action.columns:\n",
    "    df_action['stocks'] = df_action['current_stocks']\n",
    "\n",
    "# Summary of what will be pushed\n",
    "price_changes = df_action[df_action['new_price'].notna() & (df_action['new_price'] != df_action['current_price'])]\n",
    "cart_changes = df_action[df_action['new_cart_rule'].notna() & (df_action['new_cart_rule'] != df_action['current_cart_rule'])]\n",
    "\n",
    "print(f\"\\n📊 Push Summary:\")\n",
    "print(f\"  Price changes: {len(price_changes)} SKUs\")\n",
    "print(f\"  Cart rule changes: {len(cart_changes)} SKUs\")\n",
    "print(f\"  Mode: {PUSH_MODE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:18:41.519820Z",
     "iopub.status.busy": "2026-02-10T12:18:41.519616Z",
     "iopub.status.idle": "2026-02-10T12:18:41.527034Z",
     "shell.execute_reply": "2026-02-10T12:18:41.526242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 1: PUSH CART RULES\n",
      "============================================================\n",
      "\n",
      "🚀 MODE: LIVE\n",
      "   Files will be prepared AND uploaded to API\n",
      "ℹ️ No cart rule changes to push from module_4\n",
      "\n",
      "📊 Cart Rules Push Result:\n",
      "  Total received: 138\n",
      "  Cart rule changes: 0\n",
      "  Pushed: 0\n",
      "  Skipped: 138\n",
      "  Failed: 0\n",
      "  Mode: live\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 1: PUSH CART RULES\n",
    "# =============================================================================\n",
    "# Push cart rules first - if any cohorts fail, we'll skip them for prices too\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"STEP 1: PUSH CART RULES\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "cart_result = push_cart_rules(df_action, pus, source_module='module_4', mode=PUSH_MODE)\n",
    "\n",
    "# Track failed cohorts to skip in price push\n",
    "failed_cohorts = cart_result.get('failed_cohorts', [])\n",
    "\n",
    "print(f\"\\n📊 Cart Rules Push Result:\")\n",
    "print(f\"  Total received: {cart_result['total_received']}\")\n",
    "print(f\"  Cart rule changes: {cart_result['cart_rule_changes']}\")\n",
    "print(f\"  Pushed: {cart_result['pushed']}\")\n",
    "print(f\"  Skipped: {cart_result['skipped']}\")\n",
    "print(f\"  Failed: {cart_result['failed']}\")\n",
    "print(f\"  Mode: {cart_result['mode']}\")\n",
    "\n",
    "if failed_cohorts:\n",
    "    print(f\"  ⚠️ Failed cohorts: {failed_cohorts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:18:41.528961Z",
     "iopub.status.busy": "2026-02-10T12:18:41.528643Z",
     "iopub.status.idle": "2026-02-10T12:19:15.713067Z",
     "shell.execute_reply": "2026-02-10T12:19:15.712303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 2: PUSH PRICES\n",
      "============================================================\n",
      "\n",
      "🚀 MODE: LIVE\n",
      "   Files will be prepared AND uploaded to API\n",
      "Loading disable_pu_visibility from Google Sheets...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Loaded 88 products to disable min PU visibility\n",
      "\n",
      "============================================================\n",
      "PUSH PRICES - Source: module_4\n",
      "============================================================\n",
      "Total received: 138\n",
      "Price changes to push: 39\n",
      "Skipped (no change): 99\n",
      "\n",
      "Price changes summary:\n",
      "  Increases: 39\n",
      "  Decreases: 0\n",
      "\n",
      "📋 Prepared 57 packing unit prices\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 703\n",
      "==================================================\n",
      "  Saved: uploads/module_4_703.xlsx (14 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 179.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 701\n",
      "==================================================\n",
      "  Saved: uploads/module_4_701.xlsx (13 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 159.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 704\n",
      "==================================================\n",
      "  Saved: uploads/module_4_704.xlsx (14 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 200.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 1123\n",
      "==================================================\n",
      "  Saved: uploads/module_4_1123.xlsx (6 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 222.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 702\n",
      "==================================================\n",
      "  Saved: uploads/module_4_702.xlsx (2 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 239.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 1125\n",
      "==================================================\n",
      "  Saved: uploads/module_4_1125.xlsx (1 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 241.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 1126\n",
      "==================================================\n",
      "  Saved: uploads/module_4_1126.xlsx (5 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 226.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 700\n",
      "==================================================\n",
      "  Saved: uploads/module_4_700.xlsx (1 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 244.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "==================================================\n",
      "Processing cohort: 1124\n",
      "==================================================\n",
      "  Saved: uploads/module_4_1124.xlsx (1 rows)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Split into 1 chunks (size: 4000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  Saving chunks: 100%|██████████| 1/1 [00:00<00:00, 241.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Uploading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ✓ Chunk 1 uploaded successfully\n",
      "\n",
      "============================================================\n",
      "🚀 UPLOAD COMPLETE\n",
      "============================================================\n",
      "Mode: live\n",
      "Total prepared: 57\n",
      "Total failed: 0\n",
      "\n",
      "📊 Prices Push Result:\n",
      "  Total received: 138\n",
      "  Price changes: 39\n",
      "  Pushed: 57\n",
      "  Skipped: 99\n",
      "  Failed: 0\n",
      "  Mode: live\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STEP 2: PUSH PRICES (skip failed cohorts from cart rules)\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"STEP 2: PUSH PRICES\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Push prices, skipping any cohorts that failed during cart rules push\n",
    "push_result = push_prices(df_action, pus, source_module='module_4', mode=PUSH_MODE, skip_cohorts=failed_cohorts)\n",
    "\n",
    "print(f\"\\n📊 Prices Push Result:\")\n",
    "print(f\"  Total received: {push_result['total_received']}\")\n",
    "print(f\"  Price changes: {push_result['price_changes']}\")\n",
    "print(f\"  Pushed: {push_result['pushed']}\")\n",
    "print(f\"  Skipped: {push_result['skipped']}\")\n",
    "print(f\"  Failed: {push_result['failed']}\")\n",
    "print(f\"  Mode: {push_result['mode']}\")\n",
    "\n",
    "if push_result.get('skipped_cohorts'):\n",
    "    print(f\"  ⚠️ Skipped cohorts: {push_result['skipped_cohorts']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:19:15.715140Z",
     "iopub.status.busy": "2026-02-10T12:19:15.714792Z",
     "iopub.status.idle": "2026-02-10T12:19:15.725421Z",
     "shell.execute_reply": "2026-02-10T12:19:15.724753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODULE 4 - HOURLY UPDATES COMPLETE\n",
      "============================================================\n",
      "\n",
      "📅 Timestamp: 2026-02-10 14:19:15\n",
      "🔧 Mode: LIVE\n",
      "\n",
      "📊 ACTIONS TAKEN:\n",
      "  Total SKUs analyzed: 28124\n",
      "  SKUs requiring action: 138\n",
      "\n",
      "💰 PRICE ACTIONS:\n",
      "  Total price changes: 39\n",
      "    - rets_growing: 39\n",
      "\n",
      "🛒 CART RULE ACTIONS:\n",
      "  Total cart rule changes: 0\n",
      "\n",
      "📤 PUSH RESULTS:\n",
      "  Cart Rules - Pushed: 0, Failed: 0\n",
      "  Prices - Pushed: 57, Failed: 0\n",
      "\n",
      "✅ LIVE MODE - Changes have been pushed to production!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL SUMMARY\n",
    "# =============================================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODULE 4 - HOURLY UPDATES COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\n📅 Timestamp: {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"🔧 Mode: {PUSH_MODE.upper()}\")\n",
    "\n",
    "print(f\"\\n📊 ACTIONS TAKEN:\")\n",
    "print(f\"  Total SKUs analyzed: {len(df)}\")\n",
    "print(f\"  SKUs requiring action: {len(df_action)}\")\n",
    "\n",
    "# Price actions breakdown\n",
    "print(f\"\\n💰 PRICE ACTIONS:\")\n",
    "if 'price_action' in df_action.columns:\n",
    "    price_actions = df_action[df_action['price_action'] != 'none']\n",
    "    print(f\"  Total price changes: {len(price_actions)}\")\n",
    "    for action_type in df_action['price_action'].unique():\n",
    "        if action_type != 'none':\n",
    "            count = len(df_action[df_action['price_action'] == action_type])\n",
    "            print(f\"    - {action_type}: {count}\")\n",
    "else:\n",
    "    print(f\"  Total price changes: 0\")\n",
    "\n",
    "# Cart rule actions breakdown  \n",
    "print(f\"\\n🛒 CART RULE ACTIONS:\")\n",
    "if 'cart_rule_action' in df_action.columns:\n",
    "    cart_actions = df_action[df_action['cart_rule_action'] != 'none']\n",
    "    print(f\"  Total cart rule changes: {len(cart_actions)}\")\n",
    "    for action_type in df_action['cart_rule_action'].unique():\n",
    "        if action_type != 'none':\n",
    "            count = len(df_action[df_action['cart_rule_action'] == action_type])\n",
    "            print(f\"    - {action_type}: {count}\")\n",
    "else:\n",
    "    print(f\"  Total cart rule changes: 0\")\n",
    "\n",
    "# Push results\n",
    "print(f\"\\n📤 PUSH RESULTS:\")\n",
    "print(f\"  Cart Rules - Pushed: {cart_result.get('pushed', 0)}, Failed: {cart_result.get('failed', 0)}\")\n",
    "print(f\"  Prices - Pushed: {push_result.get('pushed', 0)}, Failed: {push_result.get('failed', 0)}\")\n",
    "\n",
    "if PUSH_MODE == 'testing':\n",
    "    print(f\"\\n⚠️ TESTING MODE - No changes were actually pushed to production!\")\n",
    "    print(f\"   Change PUSH_MODE to 'live' to execute actual pushes.\")\n",
    "else:\n",
    "    print(f\"\\n✅ LIVE MODE - Changes have been pushed to production!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:19:15.727389Z",
     "iopub.status.busy": "2026-02-10T12:19:15.727172Z",
     "iopub.status.idle": "2026-02-10T12:19:15.760818Z",
     "shell.execute_reply": "2026-02-10T12:19:15.760078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAMPLE DATA (First 10 rows with UTH > 0)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>sku</th>\n",
       "      <th>wac1</th>\n",
       "      <th>wac_p</th>\n",
       "      <th>new_wac</th>\n",
       "      <th>p80_daily_240d</th>\n",
       "      <th>std_daily_240d</th>\n",
       "      <th>p70_daily_retailers_240d</th>\n",
       "      <th>std_daily_retailers_240d</th>\n",
       "      <th>...</th>\n",
       "      <th>uth_rets_std</th>\n",
       "      <th>uth_rets_status</th>\n",
       "      <th>last_hour_qty</th>\n",
       "      <th>last_hour_qty_target</th>\n",
       "      <th>last_hour_qty_std</th>\n",
       "      <th>last_hour_qty_status</th>\n",
       "      <th>last_hour_retailers</th>\n",
       "      <th>last_hour_rets_target</th>\n",
       "      <th>last_hour_rets_std</th>\n",
       "      <th>last_hour_rets_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>12353</td>\n",
       "      <td>زيووو اراميش بافس سجق - 5 جنية</td>\n",
       "      <td>45.230000</td>\n",
       "      <td>41.611673</td>\n",
       "      <td>41.611673</td>\n",
       "      <td>22.000</td>\n",
       "      <td>8.768053</td>\n",
       "      <td>11.00</td>\n",
       "      <td>4.713793</td>\n",
       "      <td>...</td>\n",
       "      <td>1.648389</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.947045</td>\n",
       "      <td>0.377443</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498533</td>\n",
       "      <td>0.213635</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>5925</td>\n",
       "      <td>المطبخ مكرونة اسباجتي - 400 جم</td>\n",
       "      <td>210.000000</td>\n",
       "      <td>199.219993</td>\n",
       "      <td>199.219993</td>\n",
       "      <td>8.980</td>\n",
       "      <td>5.962267</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.278181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450281</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409346</td>\n",
       "      <td>0.271785</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.248628</td>\n",
       "      <td>0.063558</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>703</td>\n",
       "      <td>18964</td>\n",
       "      <td>كاتشب هاينز - 6 جرام</td>\n",
       "      <td>454.335584</td>\n",
       "      <td>420.851616</td>\n",
       "      <td>420.851616</td>\n",
       "      <td>13.000</td>\n",
       "      <td>7.326505</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2.356475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819674</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.619225</td>\n",
       "      <td>0.348981</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.290899</td>\n",
       "      <td>0.114249</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>170</td>\n",
       "      <td>2368</td>\n",
       "      <td>لبان تشكلتس بالنعناع صغير - 1.5 ج</td>\n",
       "      <td>88.007997</td>\n",
       "      <td>81.601031</td>\n",
       "      <td>81.601031</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.559436</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.992372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368922</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198167</td>\n",
       "      <td>0.101439</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233149</td>\n",
       "      <td>0.046274</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>236</td>\n",
       "      <td>6422</td>\n",
       "      <td>كسترد كوكس بالفانيلين 12 ظرف - 50 جم</td>\n",
       "      <td>51.664836</td>\n",
       "      <td>50.631540</td>\n",
       "      <td>50.631524</td>\n",
       "      <td>28.599</td>\n",
       "      <td>14.116693</td>\n",
       "      <td>6.00</td>\n",
       "      <td>2.519831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964214</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.093067</td>\n",
       "      <td>0.539547</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.254895</td>\n",
       "      <td>0.107049</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>962</td>\n",
       "      <td>23443</td>\n",
       "      <td>جاجوار ليرز جبنه بارميزان وبيستو 10 جنية</td>\n",
       "      <td>80.999011</td>\n",
       "      <td>78.569040</td>\n",
       "      <td>78.569504</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.497618</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.856419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749132</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.197911</td>\n",
       "      <td>0.098861</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176965</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>20953</td>\n",
       "      <td>ايبون نكهه الفاكهه بكريمه الحليب - 105 جم</td>\n",
       "      <td>110.451262</td>\n",
       "      <td>104.905085</td>\n",
       "      <td>104.905085</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.032078</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.553985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215397</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230113</td>\n",
       "      <td>0.047499</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225205</td>\n",
       "      <td>0.024952</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>21946</td>\n",
       "      <td>بقسماط ناعم ريتش بيك - 400 جرام</td>\n",
       "      <td>403.160217</td>\n",
       "      <td>362.844196</td>\n",
       "      <td>362.844196</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2.049237</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.293048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394031</td>\n",
       "      <td>growing</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.340254</td>\n",
       "      <td>0.139452</td>\n",
       "      <td>growing</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.365772</td>\n",
       "      <td>0.094592</td>\n",
       "      <td>growing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>236</td>\n",
       "      <td>23859</td>\n",
       "      <td>فريدا هاند سوب شرقي عرض 2 عبوة 520 مل</td>\n",
       "      <td>62.060000</td>\n",
       "      <td>62.060000</td>\n",
       "      <td>62.060000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>1.594261</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.912871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.352219</td>\n",
       "      <td>on_track</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245660</td>\n",
       "      <td>0.078329</td>\n",
       "      <td>dropping</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236182</td>\n",
       "      <td>0.043121</td>\n",
       "      <td>dropping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>339</td>\n",
       "      <td>7886</td>\n",
       "      <td>شاى العروسة -.. 250 جم</td>\n",
       "      <td>197.920000</td>\n",
       "      <td>197.920000</td>\n",
       "      <td>197.920000</td>\n",
       "      <td>59.560</td>\n",
       "      <td>19.910812</td>\n",
       "      <td>23.94</td>\n",
       "      <td>7.884940</td>\n",
       "      <td>...</td>\n",
       "      <td>2.478278</td>\n",
       "      <td>on_track</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.428107</td>\n",
       "      <td>1.146011</td>\n",
       "      <td>on_track</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.268130</td>\n",
       "      <td>0.417674</td>\n",
       "      <td>on_track</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    warehouse_id  product_id                                        sku  \\\n",
       "3              8       12353             زيووو اراميش بافس سجق - 5 جنية   \n",
       "7              1        5925             المطبخ مكرونة اسباجتي - 400 جم   \n",
       "8            703       18964                       كاتشب هاينز - 6 جرام   \n",
       "13           170        2368          لبان تشكلتس بالنعناع صغير - 1.5 ج   \n",
       "14           236        6422       كسترد كوكس بالفانيلين 12 ظرف - 50 جم   \n",
       "20           962       23443   جاجوار ليرز جبنه بارميزان وبيستو 10 جنية   \n",
       "22             1       20953  ايبون نكهه الفاكهه بكريمه الحليب - 105 جم   \n",
       "23             8       21946            بقسماط ناعم ريتش بيك - 400 جرام   \n",
       "25           236       23859      فريدا هاند سوب شرقي عرض 2 عبوة 520 مل   \n",
       "48           339        7886                     شاى العروسة -.. 250 جم   \n",
       "\n",
       "          wac1       wac_p     new_wac  p80_daily_240d  std_daily_240d  \\\n",
       "3    45.230000   41.611673   41.611673          22.000        8.768053   \n",
       "7   210.000000  199.219993  199.219993           8.980        5.962267   \n",
       "8   454.335584  420.851616  420.851616          13.000        7.326505   \n",
       "13   88.007997   81.601031   81.601031           5.000        2.559436   \n",
       "14   51.664836   50.631540   50.631524          28.599       14.116693   \n",
       "20   80.999011   78.569040   78.569504           5.000        2.497618   \n",
       "22  110.451262  104.905085  104.905085           5.000        1.032078   \n",
       "23  403.160217  362.844196  362.844196           5.000        2.049237   \n",
       "25   62.060000   62.060000   62.060000           5.000        1.594261   \n",
       "48  197.920000  197.920000  197.920000          59.560       19.910812   \n",
       "\n",
       "    p70_daily_retailers_240d  std_daily_retailers_240d  ...  uth_rets_std  \\\n",
       "3                      11.00                  4.713793  ...      1.648389   \n",
       "7                       5.00                  1.278181  ...      0.450281   \n",
       "8                       6.00                  2.356475  ...      0.819674   \n",
       "13                      5.00                  0.992372  ...      0.368922   \n",
       "14                      6.00                  2.519831  ...      0.964214   \n",
       "20                      5.00                  1.856419  ...      0.749132   \n",
       "22                      5.00                  0.553985  ...      0.215397   \n",
       "23                      5.00                  1.293048  ...      0.394031   \n",
       "25                      5.00                  0.912871  ...      0.352219   \n",
       "48                     23.94                  7.884940  ...      2.478278   \n",
       "\n",
       "    uth_rets_status  last_hour_qty  last_hour_qty_target last_hour_qty_std  \\\n",
       "3          on_track            0.0              0.947045          0.377443   \n",
       "7          on_track            0.0              0.409346          0.271785   \n",
       "8          on_track            0.0              0.619225          0.348981   \n",
       "13         on_track            0.0              0.198167          0.101439   \n",
       "14         on_track            0.0              1.093067          0.539547   \n",
       "20         on_track            0.0              0.197911          0.098861   \n",
       "22         dropping            0.0              0.230113          0.047499   \n",
       "23          growing            2.0              0.340254          0.139452   \n",
       "25         on_track            0.0              0.245660          0.078329   \n",
       "48         on_track            2.0              3.428107          1.146011   \n",
       "\n",
       "    last_hour_qty_status  last_hour_retailers  last_hour_rets_target  \\\n",
       "3               dropping                  0.0               0.498533   \n",
       "7               dropping                  0.0               0.248628   \n",
       "8               dropping                  0.0               0.290899   \n",
       "13              dropping                  0.0               0.233149   \n",
       "14              dropping                  0.0               0.254895   \n",
       "20              dropping                  0.0               0.176965   \n",
       "22              dropping                  0.0               0.225205   \n",
       "23               growing                  1.0               0.365772   \n",
       "25              dropping                  0.0               0.236182   \n",
       "48              on_track                  1.0               1.268130   \n",
       "\n",
       "   last_hour_rets_std  last_hour_rets_status  \n",
       "3            0.213635               dropping  \n",
       "7            0.063558               dropping  \n",
       "8            0.114249               dropping  \n",
       "13           0.046274               dropping  \n",
       "14           0.107049               dropping  \n",
       "20           0.065704               dropping  \n",
       "22           0.024952               dropping  \n",
       "23           0.094592                growing  \n",
       "25           0.043121               dropping  \n",
       "48           0.417674               on_track  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SAMPLE OUTPUT - Current Status\n",
    "# =============================================================================\n",
    "# Show sample of data with all calculated fields\n",
    "\n",
    "sample_cols = [\n",
    "    'warehouse_id', 'product_id', 'sku','wac1','wac_p','new_wac',\n",
    "    # P80/P70 benchmarks and std\n",
    "    'p80_daily_240d', 'std_daily_240d', 'p70_daily_retailers_240d', 'std_daily_retailers_240d',\n",
    "    # Current cart rule\n",
    "    'current_cart_rule',\n",
    "    # UTH performance (with std thresholds)\n",
    "    'uth_qty', 'uth_qty_target', 'uth_qty_std', 'uth_qty_status',\n",
    "    'uth_retailers', 'uth_rets_target', 'uth_rets_std', 'uth_rets_status',\n",
    "    # Last hour performance (with std thresholds)\n",
    "    'last_hour_qty', 'last_hour_qty_target', 'last_hour_qty_std', 'last_hour_qty_status',\n",
    "    'last_hour_retailers', 'last_hour_rets_target', 'last_hour_rets_std', 'last_hour_rets_status'\n",
    "]\n",
    "\n",
    "# Filter to columns that exist\n",
    "sample_cols = [c for c in sample_cols if c in df.columns]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SAMPLE DATA (First 10 rows with UTH > 0)\")\n",
    "print(f\"{'='*60}\")\n",
    "sample = df[df['uth_qty'] > 0][sample_cols].head(10)\n",
    "display(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-10T12:19:15.762714Z",
     "iopub.status.busy": "2026-02-10T12:19:15.762479Z",
     "iopub.status.idle": "2026-02-10T12:20:54.731177Z",
     "shell.execute_reply": "2026-02-10T12:20:54.730306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "UPLOADING RESULTS TO SNOWFLAKE\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.12/site-packages/slack/deprecation.py:14: UserWarning: slack package is deprecated. Please use slack_sdk.web/webhook/rtm package instead. For more info, go to https://docs.slack.dev/tools/python-slack-sdk/v3-migration/\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message Sent\n",
      "✅ Slack notification sent!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/service_account_key.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File module4_hourly_20260210_1420.xlsx sent to Slack\n",
      "✅ Review file sent to Slack\n",
      "✅ 138 records uploaded to Snowflake\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# UPLOAD RESULTS TO SNOWFLAKE AND SEND SLACK NOTIFICATION\n",
    "# =============================================================================\n",
    "\n",
    "from common_functions import upload_dataframe_to_snowflake, send_text_slack, send_file_slack\n",
    "\n",
    "SLACK_CHANNEL_ID = 'C0AAWK97Z3Q'\n",
    "\n",
    "# Add created_at as TIMESTAMP (module runs hourly)\n",
    "df_action['created_at'] = datetime.now(CAIRO_TZ).replace(second=0, microsecond=0)\n",
    "# Drop columns not in database schema (internal columns used for logic only)\n",
    "df_action = df_action.drop(columns=['commercial_min_price', 'doh', 'qty_price_step_count'], errors='ignore')\n",
    "# Upload to Snowflake\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"UPLOADING RESULTS TO SNOWFLAKE\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "upload_status = upload_dataframe_to_snowflake(\n",
    "    \"Egypt\", \n",
    "    df_action, \n",
    "    \"MATERIALIZED_VIEWS\", \n",
    "    \"pricing_hourly_push\", \n",
    "    \"append\", \n",
    "    auto_create_table=True, \n",
    "    conn=None\n",
    ")\n",
    "\n",
    "# Prepare status variables\n",
    "prices_pushed = push_result.get('pushed', 0) if 'push_result' in dir() else 0\n",
    "prices_failed = push_result.get('failed', 0) if 'push_result' in dir() else 0\n",
    "cart_rules_pushed = cart_result.get('pushed', 0) if 'cart_result' in dir() else 0\n",
    "cart_rules_failed = cart_result.get('failed', 0) if 'cart_result' in dir() else 0\n",
    "\n",
    "# Count price and cart rule actions\n",
    "price_changes = len(df_action[df_action['price_action'] != 'none']) if 'price_action' in df_action.columns else 0\n",
    "cart_changes = len(df_action[df_action['cart_rule_action'] != 'none']) if 'cart_rule_action' in df_action.columns else 0\n",
    "\n",
    "if upload_status:\n",
    "    slack_message = f\"\"\"✅ *Module 4 - Hourly Updates Completed*\n",
    "\n",
    "📅 Date: {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d')}\n",
    "⏰ Hour: {datetime.now(CAIRO_TZ).strftime('%H:%M:%S')} Cairo time\n",
    "🔧 Mode: {PUSH_MODE.upper()}\n",
    "\n",
    "📊 *Results:*\n",
    "• Total SKUs analyzed: {len(df):,}\n",
    "• SKUs requiring action: {len(df_action):,}\n",
    "• Price changes: {price_changes:,}\n",
    "• Cart rule changes: {cart_changes:,}\n",
    "\n",
    "📤 *Push Status:*\n",
    "• 💰 Prices: ✅ {prices_pushed} pushed | ❌ {prices_failed} failed\n",
    "• 🛒 Cart Rules: ✅ {cart_rules_pushed} pushed | ❌ {cart_rules_failed} failed\n",
    "\n",
    "🗄️ Results uploaded to: MATERIALIZED_VIEWS.pricing_hourly_push\"\"\"\n",
    "    \n",
    "    send_text_slack('new-pricing-logic', slack_message)\n",
    "    print(\"✅ Slack notification sent!\")\n",
    "    \n",
    "    # Send review file to Slack after the text message (using saved copy before manipulation)\n",
    "    send_file_slack(\n",
    "        temp_df_for_slack, \n",
    "        f'📎 Module 4 Review: {len(temp_df_for_slack)} SKUs processed', \n",
    "        SLACK_CHANNEL_ID,\n",
    "        filename=f'module4_hourly_{datetime.now(CAIRO_TZ).strftime(\"%Y%m%d_%H%M\")}.xlsx'\n",
    "    )\n",
    "    print(\"✅ Review file sent to Slack\")\n",
    "    \n",
    "    print(f\"✅ {len(df_action)} records uploaded to Snowflake\")\n",
    "else:\n",
    "    error_message = f\"\"\"❌ *Module 4 - Hourly Updates Failed*\n",
    "\n",
    "📅 Date: {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d')}\n",
    "⏰ Hour: {datetime.now(CAIRO_TZ).strftime('%H:%M:%S')} Cairo time\n",
    "⚠️ Upload to Snowflake failed - please check logs\n",
    "\n",
    "📤 *Push Status (before upload failure):*\n",
    "• 💰 Prices: ✅ {prices_pushed} pushed | ❌ {prices_failed} failed\n",
    "• 🛒 Cart Rules: ✅ {cart_rules_pushed} pushed | ❌ {cart_rules_failed} failed\"\"\"\n",
    "    \n",
    "    send_text_slack('new-pricing-logic', error_message)\n",
    "    print(\"❌ Error notification sent to Slack!\")\n",
    "    \n",
    "    # Still send review file even on error for debugging (using saved copy before manipulation)\n",
    "    send_file_slack(\n",
    "        temp_df_for_slack, \n",
    "        f'⚠️ Module 4 ERROR Review: {len(temp_df_for_slack)} SKUs', \n",
    "        SLACK_CHANNEL_ID,\n",
    "        filename=f'module4_hourly_ERROR_{datetime.now(CAIRO_TZ).strftime(\"%Y%m%d_%H%M\")}.xlsx'\n",
    "    )\n",
    "    print(\"✅ Error review file sent to Slack\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
