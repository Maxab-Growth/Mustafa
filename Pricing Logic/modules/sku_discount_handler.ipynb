{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SKU Discount Handler Module\n",
        "\n",
        "This module handles the complete lifecycle of SKU discounts based on Module 3 recommendations.\n",
        "\n",
        "**Note:** This module is called from Module 3. Market data should already be refreshed in Module 3 before calling this handler.\n",
        "\n",
        "## Workflow\n",
        "1. **Deactivate Active SKU Discounts** - Clear existing discounts before creating new ones\n",
        "2. **Select Target Retailers** - Identify which retailers should receive the discount\n",
        "3. **Calculate Target Price** - Find optimal discounted price based on market/margin data\n",
        "4. **Calculate Discount Percentage** - Derive discount from current price vs target price\n",
        "5. **Structure DataFrame** - Prepare data in API-expected format\n",
        "6. **Push SKU Discount** - Upload to MaxAB API\n",
        "\n",
        "## Price Selection Logic (from HH-V3)\n",
        "- For **zero demand** or **overstock** (doh > 45): Aggressive price reduction\n",
        "- For **normal products**: Find best price from market tiers and margin tiers\n",
        "- **UTH Status adjustments**:\n",
        "  - On Track: Keep same discount if previously discounted\n",
        "  - Dropping: More aggressive discount (lower price)\n",
        "  - Growing: Less aggressive discount\n",
        "\n",
        "## Input Requirements\n",
        "\n",
        "**From Module 3 (with market data already refreshed):**\n",
        "- `product_id`, `warehouse_id`, `sku`, `cohort_id`, `brand`, `cat`\n",
        "- `activate_sku_discount` - Boolean flag\n",
        "- `current_price`, `wac_p`, `doh`, `uth_qty` (zero demand = uth_qty == 0)\n",
        "- `uth_status` - UTH performance status\n",
        "- `active_sku_disc_pct` - Current active SKU discount percentage (if any)\n",
        "- `target_margin`, `min_boundary` - For fallback price calculations\n",
        "\n",
        "*Market Margins (converted to prices using `wac / (1 - margin)`):*\n",
        "- `below_market`, `market_min`, `market_25`, `market_50`, `market_75`, `market_max`, `above_market`\n",
        "\n",
        "*Margin Tiers (converted to prices using `wac / (1 - margin)`):*\n",
        "- `margin_tier_below`, `margin_tier_1`, `margin_tier_2`, `margin_tier_3`, `margin_tier_4`, `margin_tier_5`, `margin_tier_above_1`, `margin_tier_above_2`\n",
        "\n",
        "## Output\n",
        "- Deactivated existing SKU discounts\n",
        "- Created new SKU discounts for qualifying SKUs\n",
        "- Summary report\n",
        "\n",
        "## Usage (called from Module 3)\n",
        "```python\n",
        "%run sku_discount_handler.ipynb\n",
        "result = process_sku_discounts(df_output, mode='testing')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# IMPORTS & CONFIGURATION\n",
        "# =============================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import base64\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "import pytz\n",
        "\n",
        "# AWS for secrets management\n",
        "import boto3\n",
        "from botocore.exceptions import ClientError\n",
        "\n",
        "# HTTP requests for API calls\n",
        "import requests\n",
        "\n",
        "# Progress bar\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Import setup_environment_2 for credentials\n",
        "import sys\n",
        "sys.path.append('..')\n",
        "import setup_environment_2\n",
        "\n",
        "# Initialize environment (loads Snowflake credentials)\n",
        "setup_environment_2.initialize_env()\n",
        "\n",
        "# Note: Market data is passed from Module 3 (already refreshed)\n",
        "# No need to import market_data_module here\n",
        "\n",
        "# Cairo Timezone\n",
        "CAIRO_TZ = pytz.timezone('Africa/Cairo')\n",
        "CAIRO_NOW = datetime.now(CAIRO_TZ)\n",
        "TODAY = CAIRO_NOW.date()\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION\n",
        "# =============================================================================\n",
        "# Default discount settings\n",
        "DEFAULT_DISCOUNT_DURATION_HOURS = 12  # Discount valid until next run\n",
        "\n",
        "# =============================================================================\n",
        "# EXCLUSION LISTS\n",
        "# =============================================================================\n",
        "# Categories to exclude from SKU discounts\n",
        "EXCLUDED_CATEGORIES = [\n",
        "    'ÙƒØ±ÙˆØª Ø´Ø­Ù†',  # Recharge cards\n",
        "]\n",
        "\n",
        "# Brands to exclude from SKU discounts\n",
        "EXCLUDED_BRANDS = [\n",
        "    'ÙÙŠÙˆØ±ÙŠ',\n",
        "    'Ø§Ù„Ø¹Ø±ÙˆØ³Ø©',\n",
        "]\n",
        "\n",
        "# =============================================================================\n",
        "# PRICE SELECTION PARAMETERS\n",
        "# =============================================================================\n",
        "# Days on Hand threshold for overstock\n",
        "DOH_OVERSTOCK_THRESHOLD = 45\n",
        "\n",
        "# Max discount percentage (cap)\n",
        "MAX_DISCOUNT_PERCENT = 5.0\n",
        "\n",
        "# Minimum discount percentage (skip if below)\n",
        "MIN_DISCOUNT_PERCENT = 0.25\n",
        "\n",
        "# Maximum price reduction from current (as decimal, e.g., 0.05 = 5%)\n",
        "MAX_PRICE_REDUCTION_RATIO = 0.05\n",
        "\n",
        "# Minimum price reduction from current (as decimal)\n",
        "MIN_PRICE_REDUCTION_RATIO = 0.0025\n",
        "\n",
        "# =============================================================================\n",
        "# COLUMN DEFINITIONS\n",
        "# =============================================================================\n",
        "# Market margin columns (prices derived from these using wac / (1 - margin))\n",
        "MARKET_MARGIN_COLS = [\n",
        "    'below_market', 'market_min', 'market_25', 'market_50', \n",
        "    'market_75', 'market_max', 'above_market'\n",
        "]\n",
        "\n",
        "# Margin tier columns (prices derived from these using wac / (1 - margin))\n",
        "MARGIN_TIER_COLS = [\n",
        "    'margin_tier_below', 'margin_tier_1', 'margin_tier_2', 'margin_tier_3', \n",
        "    'margin_tier_4', 'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2'\n",
        "]\n",
        "\n",
        "print(f\"SKU Discount Handler loaded at {CAIRO_NOW.strftime('%Y-%m-%d %H:%M:%S')} Cairo time\")\n",
        "print(f\"Excluded categories: {EXCLUDED_CATEGORIES}\")\n",
        "print(f\"Excluded brands: {EXCLUDED_BRANDS}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# AWS & API FUNCTIONS\n",
        "# =============================================================================\n",
        "\n",
        "def get_secret(secret_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Retrieve a secret from AWS Secrets Manager.\n",
        "    \n",
        "    Args:\n",
        "        secret_name: The name/path of the secret in AWS Secrets Manager\n",
        "    \n",
        "    Returns:\n",
        "        Secret string (JSON format) or decoded binary\n",
        "    \"\"\"\n",
        "    region_name = \"us-east-1\"\n",
        "    session = boto3.session.Session()\n",
        "    client = session.client(service_name='secretsmanager', region_name=region_name)\n",
        "\n",
        "    try:\n",
        "        response = client.get_secret_value(SecretId=secret_name)\n",
        "    except ClientError as e:\n",
        "        print(f\"AWS Error: {e}\")\n",
        "        raise e\n",
        "    \n",
        "    if 'SecretString' in response:\n",
        "        return response['SecretString']\n",
        "    return base64.b64decode(response['SecretBinary'])\n",
        "\n",
        "\n",
        "def get_access_token(url: str, client_id: str, client_secret: str) -> str:\n",
        "    \"\"\"\n",
        "    Get OAuth2 access token for MaxAB API authentication.\n",
        "    \"\"\"\n",
        "    response = requests.post(\n",
        "        url,\n",
        "        data={\n",
        "            \"grant_type\": \"password\",\n",
        "            \"username\": API_USERNAME,\n",
        "            \"password\": API_PASSWORD\n",
        "        },\n",
        "        auth=(client_id, client_secret),\n",
        "    )\n",
        "    return response.json()[\"access_token\"]\n",
        "\n",
        "\n",
        "def _get_api_token() -> str:\n",
        "    \"\"\"\n",
        "    Get a fresh API token for MaxAB API requests.\n",
        "    \"\"\"\n",
        "    return get_access_token(\n",
        "        'https://sso.maxab.info/auth/realms/maxab/protocol/openid-connect/token',\n",
        "        'main-system-externals',\n",
        "        API_SECRET\n",
        "    )\n",
        "\n",
        "print(\"AWS & API functions defined âœ“\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# API CREDENTIALS INITIALIZATION\n",
        "# =============================================================================\n",
        "# Load API credentials from AWS Secrets Manager\n",
        "\n",
        "pricing_api_secret = json.loads(get_secret(\"prod/pricing/api/\"))\n",
        "API_USERNAME = pricing_api_secret[\"egypt_username\"]\n",
        "API_PASSWORD = pricing_api_secret[\"egypt_password\"]\n",
        "API_SECRET = pricing_api_secret[\"egypt_secret\"]\n",
        "\n",
        "print(\"âœ“ API credentials loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FUNCTION 1: DEACTIVATE ACTIVE SKU DISCOUNTS\n",
        "# =============================================================================\n",
        "# Reference: Mustafa/Deactivate_HH.ipynb\n",
        "\n",
        "import snowflake.connector\n",
        "import math\n",
        "\n",
        "def get_snowflake_timezone() -> str:\n",
        "    \"\"\"Get the Snowflake server timezone.\"\"\"\n",
        "    con = snowflake.connector.connect(\n",
        "        user     = os.environ[\"SNOWFLAKE_USERNAME\"],\n",
        "        account  = os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
        "        password = os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
        "        database = os.environ[\"SNOWFLAKE_DATABASE\"]\n",
        "    )\n",
        "    try:\n",
        "        cur = con.cursor()\n",
        "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
        "        cur.execute(\"SHOW PARAMETERS LIKE 'TIMEZONE'\")\n",
        "        result = cur.fetchone()\n",
        "        return result[1] if result else 'UTC'\n",
        "    finally:\n",
        "        cur.close()\n",
        "        con.close()\n",
        "\n",
        "# Get Snowflake timezone for query conversion\n",
        "TIMEZONE = get_snowflake_timezone()\n",
        "print(f\"Snowflake timezone: {TIMEZONE}\")\n",
        "\n",
        "def query_snowflake(query: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Execute a query against Snowflake and return results as DataFrame.\n",
        "    \"\"\"\n",
        "    con = snowflake.connector.connect(\n",
        "        user     = os.environ[\"SNOWFLAKE_USERNAME\"],\n",
        "        account  = os.environ[\"SNOWFLAKE_ACCOUNT\"],\n",
        "        password = os.environ[\"SNOWFLAKE_PASSWORD\"],\n",
        "        database = os.environ[\"SNOWFLAKE_DATABASE\"]\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        cur = con.cursor()\n",
        "        cur.execute(\"USE WAREHOUSE COMPUTE_WH\")\n",
        "        cur.execute(query)\n",
        "        \n",
        "        column_names = [col[0] for col in cur.description]\n",
        "        results = cur.fetchall()\n",
        "        \n",
        "        if not results:\n",
        "            out = pd.DataFrame(columns=[name.lower() for name in column_names])\n",
        "        else:\n",
        "            out = pd.DataFrame(np.array(results), columns=column_names)\n",
        "            out.columns = out.columns.str.lower()\n",
        "        \n",
        "        return out\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Query error: {e}\")\n",
        "        raise\n",
        "        \n",
        "    finally:\n",
        "        cur.close()\n",
        "        con.close()\n",
        "\n",
        "\n",
        "def _call_deactivate_api(ids: list) -> requests.Response:\n",
        "    \"\"\"\n",
        "    Call MaxAB API to deactivate SKU discounts by their IDs.\n",
        "    \n",
        "    Args:\n",
        "        ids: List of SKU discount IDs to deactivate\n",
        "        \n",
        "    Returns:\n",
        "        API response object\n",
        "    \"\"\"\n",
        "    token = _get_api_token()\n",
        "    \n",
        "    url = \"https://api.maxab.info/commerce/api/admins/v1/sku-discounts/status\"\n",
        "    \n",
        "    headers = {\n",
        "        'Authorization': f'bearer {token}',\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "    \n",
        "    payload = {\n",
        "        \"ids\": ids,\n",
        "        \"isActivate\": False\n",
        "    }\n",
        "    \n",
        "    response = requests.put(url, headers=headers, json=payload)\n",
        "    return response\n",
        "\n",
        "\n",
        "def get_active_sku_discount_ids() -> list:\n",
        "    \"\"\"\n",
        "    Query Snowflake to get all currently active SKU discount IDs.\n",
        "    \n",
        "    Returns:\n",
        "        List of active SKU discount IDs\n",
        "    \"\"\"\n",
        "    query = f'''\n",
        "    SELECT sd.id AS sku_discount_id\n",
        "    FROM SKU_DISCOUNTS sd\n",
        "    WHERE active = 'true'\n",
        "    AND CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP()) BETWEEN start_at AND end_at\n",
        "    AND name_en = 'Special Discounts'\n",
        "    '''\n",
        "    \n",
        "    df = query_snowflake(query)\n",
        "    return df['sku_discount_id'].unique().tolist()\n",
        "\n",
        "\n",
        "def deactivate_active_sku_discounts(mode: str = 'testing') -> dict:\n",
        "    \"\"\"\n",
        "    Deactivate all currently active SKU discounts (name = 'Special Discounts').\n",
        "    \n",
        "    This function should be called FIRST before creating new discounts\n",
        "    to ensure a clean slate (no duplicate/overlapping discounts).\n",
        "    \n",
        "    Process:\n",
        "    1. Query Snowflake to get all active SKU discount IDs\n",
        "    2. Break IDs into chunks of 10\n",
        "    3. Call API for each chunk to deactivate\n",
        "    \n",
        "    Args:\n",
        "        mode: 'testing' (don't call API) or 'live' (call API)\n",
        "    \n",
        "    Returns:\n",
        "        dict with:\n",
        "            - success: bool\n",
        "            - deactivated_count: int\n",
        "            - failed_count: int\n",
        "            - errors: list\n",
        "    \"\"\"\n",
        "    print(f\"{'ðŸ§ª' if mode == 'testing' else 'ðŸš€'} Deactivating SKU discounts (mode: {mode})\")\n",
        "    \n",
        "    result = {\n",
        "        \"success\": True,\n",
        "        \"deactivated_count\": 0,\n",
        "        \"failed_count\": 0,\n",
        "        \"errors\": []\n",
        "    }\n",
        "    \n",
        "    # Step 1: Get active SKU discount IDs from Snowflake\n",
        "    print(\"  Querying active SKU discounts from Snowflake...\")\n",
        "    ids_list = get_active_sku_discount_ids()\n",
        "    print(f\"  Found {len(ids_list)} active SKU discounts to deactivate\")\n",
        "    \n",
        "    if len(ids_list) == 0:\n",
        "        print(\"  No active SKU discounts to deactivate\")\n",
        "        return result\n",
        "    \n",
        "    if mode == 'testing':\n",
        "        print(f\"  ðŸ§ª [TESTING] Would deactivate {len(ids_list)} SKU discounts (skipped)\")\n",
        "        result['deactivated_count'] = len(ids_list)\n",
        "        return result\n",
        "    \n",
        "    # Step 2: Deactivate in chunks of 10\n",
        "    chunk_size = 10\n",
        "    total_chunks = math.ceil(len(ids_list) / chunk_size)\n",
        "    failed_chunks = []\n",
        "    \n",
        "    print(f\"  Deactivating in {total_chunks} chunks...\")\n",
        "    \n",
        "    for i in tqdm(range(0, len(ids_list), chunk_size), total=total_chunks, desc=\"Deactivating SKU Discounts\"):\n",
        "        chunk = ids_list[i:i + chunk_size]\n",
        "        \n",
        "        response = _call_deactivate_api(chunk)\n",
        "        \n",
        "        if response.status_code == 200:\n",
        "            result['deactivated_count'] += len(chunk)\n",
        "        else:\n",
        "            result['failed_count'] += len(chunk)\n",
        "            failed_chunks.append({\"ids\": chunk, \"error\": response.text})\n",
        "    \n",
        "    # Step 3: Report results\n",
        "    print(f\"\\n  âœ“ Completed! Deactivated: {result['deactivated_count']}, Failed: {result['failed_count']}\")\n",
        "    \n",
        "    if failed_chunks:\n",
        "        result['success'] = False\n",
        "        result['errors'] = failed_chunks\n",
        "        print(f\"  âœ— Failed chunks: {len(failed_chunks)}\")\n",
        "        for fail in failed_chunks[:5]:  # Show first 5 failures\n",
        "            print(f\"    - IDs: {fail['ids']}, Error: {fail['error'][:100]}...\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "print(\"Function 1: deactivate_active_sku_discounts() defined âœ“\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FUNCTION 2: SELECT TARGET RETAILERS\n",
        "# =============================================================================\n",
        "# Reference: HH-V3.ipynb retailer selection logic\n",
        "\n",
        "# Import retailer selection queries from queries_module\n",
        "%run queries_module.ipynb\n",
        "\n",
        "\n",
        "def create_sku_tuple_string(df: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Create a tuple string from DataFrame for SQL VALUES clause.\n",
        "    Format: \"(product_id, warehouse_id), (product_id, warehouse_id), ...\"\n",
        "    \n",
        "    Args:\n",
        "        df: DataFrame with product_id and warehouse_id columns\n",
        "        \n",
        "    Returns:\n",
        "        String of tuples for SQL VALUES clause\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df['tuple'] = df[['product_id', 'warehouse_id']].apply(tuple, axis=1)\n",
        "    tuple_list = list(df['tuple'].unique())\n",
        "    tuple_str = str(tuple_list)[1:-1]  # Remove outer brackets\n",
        "    return tuple_str\n",
        "\n",
        "\n",
        "def select_target_retailers(df_skus: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Select which retailers should receive the SKU discount.\n",
        "    \n",
        "    This function implements the HH-V3 retailer selection logic:\n",
        "    1. Filter SKUs that got valid discounts (discount > 0)\n",
        "    2. Query 4 types of target retailers:\n",
        "       - Churned/dropped: Were buying but dropped >30%\n",
        "       - Category buyers: Buy the category but not this product\n",
        "       - Out of cycle: Should have reordered by now\n",
        "       - View no orders: Viewed brand but didn't order\n",
        "    3. Apply exclusions (failed orders, inactive, wholesale, existing SKU discounts)\n",
        "    4. Remove retailers who already have quantity discounts on the product\n",
        "    5. Match retailers to their main warehouse\n",
        "    \n",
        "    Args:\n",
        "        df_skus: DataFrame with SKUs to discount (must have discount_percentage column)\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with retailer_id column added (one row per retailer-product combination)\n",
        "    \"\"\"\n",
        "    print(\"\\n  Selecting target retailers...\")\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 1: Filter SKUs with valid discounts\n",
        "    # =========================================================================\n",
        "    df_valid = df_skus[df_skus['discount_percentage'] > 0].copy()\n",
        "    \n",
        "    if len(df_valid) == 0:\n",
        "        print(\"    No SKUs with valid discounts to target retailers for\")\n",
        "        df_result = df_skus.copy()\n",
        "        df_result['retailer_id'] = None\n",
        "        return df_result\n",
        "    \n",
        "    print(f\"    SKUs with valid discounts: {len(df_valid)}\")\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 2: Create tuple string for queries\n",
        "    # =========================================================================\n",
        "    selected_skus_tuple = create_sku_tuple_string(df_valid[['product_id', 'warehouse_id']].drop_duplicates())\n",
        "    print(f\"    Created tuple string for {df_valid[['product_id', 'warehouse_id']].drop_duplicates().shape[0]} unique product-warehouse combinations\")\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 3: Query all retailer sources\n",
        "    # =========================================================================\n",
        "    print(\"\\n    Querying retailer sources...\")\n",
        "    \n",
        "    # Query 1: Churned/Dropped retailers\n",
        "    try:\n",
        "        df_churned_dropped = get_churned_dropped_retailers(selected_skus_tuple)\n",
        "    except Exception as e:\n",
        "        print(f\"    âš  Churned/dropped query failed: {e}\")\n",
        "        df_churned_dropped = pd.DataFrame(columns=['retailer_id', 'product_id', 'warehouse_id'])\n",
        "    \n",
        "    # Query 2: Category not product retailers\n",
        "    try:\n",
        "        df_cat_not_product = get_category_not_product_retailers(selected_skus_tuple)\n",
        "    except Exception as e:\n",
        "        print(f\"    âš  Category-not-product query failed: {e}\")\n",
        "        df_cat_not_product = pd.DataFrame(columns=['retailer_id', 'product_id', 'warehouse_id'])\n",
        "    \n",
        "    # Query 3: Out of cycle retailers\n",
        "    try:\n",
        "        df_out_of_cycle = get_out_of_cycle_retailers(selected_skus_tuple)\n",
        "    except Exception as e:\n",
        "        print(f\"    âš  Out-of-cycle query failed: {e}\")\n",
        "        df_out_of_cycle = pd.DataFrame(columns=['retailer_id', 'product_id', 'warehouse_id'])\n",
        "    \n",
        "    # Query 4: View no orders retailers\n",
        "    try:\n",
        "        df_view_no_orders = get_view_no_orders_retailers(selected_skus_tuple)\n",
        "    except Exception as e:\n",
        "        print(f\"    âš  View-no-orders query failed: {e}\")\n",
        "        df_view_no_orders = pd.DataFrame(columns=['retailer_id', 'product_id', 'warehouse_id'])\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 4: Combine all retailer sources\n",
        "    # =========================================================================\n",
        "    print(\"\\n    Combining retailer sources...\")\n",
        "    all_retailers = pd.concat([\n",
        "        df_churned_dropped,\n",
        "        df_cat_not_product,\n",
        "        df_out_of_cycle,\n",
        "        df_view_no_orders\n",
        "    ]).drop_duplicates().reset_index(drop=True)\n",
        "    \n",
        "    print(f\"    Total retailer-product combinations before filtering: {len(all_retailers)}\")\n",
        "    \n",
        "    if len(all_retailers) == 0:\n",
        "        print(\"    âš  No retailers found from any source\")\n",
        "        df_result = df_skus.copy()\n",
        "        df_result['retailer_id'] = None\n",
        "        return df_result\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 5: Get retailer main warehouse\n",
        "    # =========================================================================\n",
        "    print(\"\\n    Getting retailer main warehouses...\")\n",
        "    try:\n",
        "        df_ret_wh = get_retailer_main_warehouse()\n",
        "        all_retailers = all_retailers.merge(\n",
        "            df_ret_wh, \n",
        "            on=['retailer_id', 'warehouse_id'], \n",
        "            how='left'\n",
        "        )\n",
        "        all_retailers = all_retailers.fillna(0)\n",
        "        \n",
        "        # Rank and filter to main warehouse only\n",
        "        all_retailers['rank'] = all_retailers.groupby(['retailer_id'])['last_wh'].rank(\n",
        "            method='dense', ascending=False\n",
        "        ).astype(int)\n",
        "        all_retailers = all_retailers[all_retailers['rank'] == 1]\n",
        "        all_retailers = all_retailers.drop(columns=['last_wh', 'rank'])\n",
        "    except Exception as e:\n",
        "        print(f\"    âš  Retailer warehouse query failed: {e}\")\n",
        "    \n",
        "    print(f\"    Retailers after warehouse filter: {len(all_retailers)}\")\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 6: Apply exclusions\n",
        "    # =========================================================================\n",
        "    print(\"\\n    Applying exclusions...\")\n",
        "    try:\n",
        "        df_excluded = get_excluded_retailers()\n",
        "        excluded_ids = set(df_excluded['retailer_id'].unique())\n",
        "        before = len(all_retailers)\n",
        "        all_retailers = all_retailers[~all_retailers['retailer_id'].isin(excluded_ids)]\n",
        "        print(f\"    Excluded {before - len(all_retailers)} retailers (failed orders, inactive, wholesale, existing discounts)\")\n",
        "    except Exception as e:\n",
        "        print(f\"    âš  Exclusion query failed: {e}\")\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 7: Remove retailers with quantity discounts on same product\n",
        "    # =========================================================================\n",
        "    print(\"\\n    Removing retailers with existing quantity discounts...\")\n",
        "    try:\n",
        "        df_qd = get_retailers_with_quantity_discount()\n",
        "        if len(df_qd) > 0:\n",
        "            df_qd['have_quantity'] = 1\n",
        "            all_retailers = all_retailers.merge(\n",
        "                df_qd[['retailer_id', 'product_id', 'have_quantity']], \n",
        "                on=['retailer_id', 'product_id'], \n",
        "                how='left'\n",
        "            )\n",
        "            before = len(all_retailers)\n",
        "            all_retailers = all_retailers[all_retailers['have_quantity'].isna()]\n",
        "            all_retailers = all_retailers.drop(columns=['have_quantity'])\n",
        "            print(f\"    Removed {before - len(all_retailers)} retailer-product combinations with existing QD\")\n",
        "    except Exception as e:\n",
        "        print(f\"    âš  Quantity discount query failed: {e}\")\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 8: Final cleanup\n",
        "    # =========================================================================\n",
        "    all_retailers = all_retailers.drop_duplicates(\n",
        "        subset=['product_id', 'warehouse_id', 'retailer_id']\n",
        "    ).reset_index(drop=True)\n",
        "    \n",
        "    print(f\"\\n    âœ“ Final retailer-product combinations: {len(all_retailers)}\")\n",
        "    print(f\"    âœ“ Unique retailers: {all_retailers['retailer_id'].nunique()}\")\n",
        "    print(f\"    âœ“ Unique products: {all_retailers['product_id'].nunique()}\")\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 9: Merge with SKU data\n",
        "    # =========================================================================\n",
        "    # Convert retailer_id and product_id to numeric for merging\n",
        "    for col in ['retailer_id', 'product_id', 'warehouse_id']:\n",
        "        if col in all_retailers.columns:\n",
        "            all_retailers[col] = pd.to_numeric(all_retailers[col], errors='coerce')\n",
        "    \n",
        "    # Merge product data with retailer selections\n",
        "    df_result = df_valid[['product_id', 'warehouse_id', 'cohort_id', 'sku', 'brand', 'cat',\n",
        "                          'current_price', 'new_price', 'wac_p', 'target_price', \n",
        "                          'discount_percentage', 'discount_source']].merge(\n",
        "        all_retailers[['retailer_id', 'product_id', 'warehouse_id']], \n",
        "        on=['product_id', 'warehouse_id'],\n",
        "        how='inner'\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n    âœ“ Final output rows: {len(df_result)}\")\n",
        "    \n",
        "    return df_result\n",
        "\n",
        "\n",
        "print(\"Function 2: select_target_retailers() defined âœ“\")\n",
        "print(\"  - Queries 4 retailer sources (churned, category, cycle, view)\")\n",
        "print(\"  - Applies exclusions (failed orders, inactive, wholesale)\")\n",
        "print(\"  - Removes retailers with existing quantity discounts\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FUNCTION 3: PRICE SELECTION & DISCOUNT CALCULATION (Adapted from HH-V3)\n",
        "# =============================================================================\n",
        "\n",
        "def margin_to_price(wac: float, margin: float) -> float:\n",
        "    \"\"\"\n",
        "    Convert margin to price.\n",
        "    Price = WAC / (1 - margin)\n",
        "    \n",
        "    Args:\n",
        "        wac: Weighted Average Cost\n",
        "        margin: Margin as decimal (e.g., 0.15 for 15%)\n",
        "    \n",
        "    Returns:\n",
        "        Price, or np.nan if invalid\n",
        "    \"\"\"\n",
        "    if pd.isna(margin) or margin >= 1 or wac <= 0:\n",
        "        return np.nan\n",
        "    return wac / (1 - margin)\n",
        "\n",
        "\n",
        "def build_candidate_prices(row: pd.Series) -> list:\n",
        "    \"\"\"\n",
        "    Build a list of candidate prices from market margins and margin tiers.\n",
        "    \n",
        "    Converts margins to prices using: price = wac / (1 - margin)\n",
        "    \n",
        "    Args:\n",
        "        row: Series containing price data\n",
        "    \n",
        "    Returns:\n",
        "        Sorted list of unique valid prices\n",
        "    \"\"\"\n",
        "    wac = float(row.get('wac_p', 0) or 0)\n",
        "    if wac <= 0:\n",
        "        return []\n",
        "    \n",
        "    prices_list = []\n",
        "    \n",
        "    # 1. Add prices from market margins\n",
        "    for col in MARKET_MARGIN_COLS:\n",
        "        margin = row.get(col)\n",
        "        if margin and not pd.isna(margin):\n",
        "            price = margin_to_price(wac, float(margin))\n",
        "            if not pd.isna(price) and price > 0:\n",
        "                prices_list.append(price)\n",
        "    \n",
        "    # 2. Add prices from margin tiers\n",
        "    for col in MARGIN_TIER_COLS:\n",
        "        margin = row.get(col)\n",
        "        if margin and not pd.isna(margin):\n",
        "            price = margin_to_price(wac, float(margin))\n",
        "            if not pd.isna(price) and price > 0:\n",
        "                prices_list.append(price)\n",
        "    \n",
        "    # Clean: remove 0, NaN, inf and duplicates\n",
        "    cleaned_prices = list({\n",
        "        x for x in prices_list \n",
        "        if x > 0 and not pd.isna(x) and np.isfinite(x)\n",
        "    })\n",
        "    \n",
        "    return sorted(cleaned_prices)\n",
        "\n",
        "\n",
        "def select_target_price(\n",
        "    candidate_prices: list,\n",
        "    current_price: float,\n",
        "    wac: float,\n",
        "    target_margin: float,\n",
        "    min_boundary: float,\n",
        "    is_zero_demand: bool,\n",
        "    doh: float,\n",
        "    uth_status: str,\n",
        "    old_discount_price: float = None\n",
        ") -> tuple:\n",
        "    \"\"\"\n",
        "    Select optimal target price from candidates based on HH-V3 logic.\n",
        "    \n",
        "    Logic:\n",
        "    - Zero demand or Overstock: More aggressive - find first valid lower price\n",
        "    - On Track: Keep old discount if available, else find moderate reduction\n",
        "    - Dropping: More aggressive discount (go lower than old discount)\n",
        "    - Growing: Less aggressive (stay closer to current price)\n",
        "    \n",
        "    Args:\n",
        "        candidate_prices: Sorted list of valid prices\n",
        "        current_price: Current selling price\n",
        "        wac: Weighted Average Cost\n",
        "        target_margin: Target margin for the product\n",
        "        min_boundary: Minimum acceptable margin\n",
        "        is_zero_demand: True if zero demand product\n",
        "        doh: Days on Hand\n",
        "        uth_status: UTH performance status\n",
        "        old_discount_price: Previous discounted price if any\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (target_price, source_description)\n",
        "    \"\"\"\n",
        "    if current_price <= 0 or wac <= 0:\n",
        "        return 0.0, 'invalid_data'\n",
        "    \n",
        "    target_price = 0.0\n",
        "    source = ''\n",
        "    \n",
        "    current_margin = (current_price - wac) / current_price\n",
        "    is_overstock = doh > DOH_OVERSTOCK_THRESHOLD\n",
        "    \n",
        "    # Convert to numpy array for vectorized operations\n",
        "    prices_arr = np.array(candidate_prices)\n",
        "    \n",
        "    # Minimum acceptable price (WAC * 0.9 allows small loss margin)\n",
        "    min_acceptable_price = wac * 0.9\n",
        "    \n",
        "    # =========================================================================\n",
        "    # CASE 1: Zero Demand or Overstock - Aggressive Price Reduction\n",
        "    # =========================================================================\n",
        "    if is_zero_demand or is_overstock:\n",
        "        source = 'zero_demand' if is_zero_demand else 'overstock'\n",
        "        \n",
        "        # Find first price that:\n",
        "        # - Is at or above minimum acceptable (wac * 0.9)\n",
        "        # - Reduces price by at most 5% from current\n",
        "        diffs = (prices_arr - current_price) / current_price\n",
        "        valid_mask = (prices_arr >= min_acceptable_price) & (diffs >= -MAX_PRICE_REDUCTION_RATIO)\n",
        "        valid_prices = prices_arr[valid_mask]\n",
        "        \n",
        "        if len(valid_prices) > 0:\n",
        "            # Take the lowest valid price (most aggressive discount)\n",
        "            target_price = valid_prices[0]\n",
        "        else:\n",
        "            # Fallback to margin-based prices\n",
        "            target_margin = float(target_margin) if target_margin and not pd.isna(target_margin) else 0.10\n",
        "            min_boundary = float(min_boundary) if min_boundary and not pd.isna(min_boundary) else 0.05\n",
        "            \n",
        "            if current_margin > target_margin and current_margin - target_margin > MIN_PRICE_REDUCTION_RATIO:\n",
        "                target_price = wac / (1 - target_margin)\n",
        "                source += '_target_margin'\n",
        "            elif current_margin > min_boundary and current_margin - min_boundary > MIN_PRICE_REDUCTION_RATIO:\n",
        "                target_price = wac / (1 - min_boundary)\n",
        "                source += '_min_boundary'\n",
        "            elif current_margin > target_margin / 2 and current_margin - target_margin / 2 > MIN_PRICE_REDUCTION_RATIO:\n",
        "                target_price = wac / (1 - (target_margin / 2))\n",
        "                source += '_half_target'\n",
        "        \n",
        "        return target_price, source\n",
        "    \n",
        "    # =========================================================================\n",
        "    # CASE 2: Normal Products - Based on UTH Status\n",
        "    # =========================================================================\n",
        "    \n",
        "    # Filter prices below current\n",
        "    below_current = prices_arr[prices_arr < current_price]\n",
        "    if len(below_current) == 0:\n",
        "        return 0.0, 'no_lower_prices'\n",
        "    \n",
        "    # Calculate price changes\n",
        "    diffs = (below_current - current_price) / current_price\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # UTH Status: On Track - Use old discount if available\n",
        "    # -------------------------------------------------------------------------\n",
        "    if uth_status in ['on_track', 'On Track']:\n",
        "        if old_discount_price and old_discount_price > 0 and old_discount_price < current_price:\n",
        "            # Validate old discount price is still acceptable\n",
        "            if old_discount_price >= min_acceptable_price:\n",
        "                return old_discount_price, 'on_track_keep_old'\n",
        "        \n",
        "        # No old discount - find moderate reduction (middle of valid range)\n",
        "        valid_mask = (below_current >= min_acceptable_price) & (diffs >= -MAX_PRICE_REDUCTION_RATIO) & (diffs <= -MIN_PRICE_REDUCTION_RATIO)\n",
        "        valid_prices = below_current[valid_mask]\n",
        "        \n",
        "        if len(valid_prices) > 0:\n",
        "            # Take middle price\n",
        "            target_price = valid_prices[len(valid_prices) // 2]\n",
        "            source = 'on_track_moderate'\n",
        "        \n",
        "        return target_price, source\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # UTH Status: Dropping - More Aggressive (lower price than old discount)\n",
        "    # -------------------------------------------------------------------------\n",
        "    if uth_status in ['dropping', 'Dropping', 'critical', 'Critical', 'zero_demand', 'Zero Demand']:\n",
        "        # Valid range: between -0.25% and -5% from current\n",
        "        valid_mask = (below_current >= min_acceptable_price) & (diffs >= -MAX_PRICE_REDUCTION_RATIO) & (diffs <= -MIN_PRICE_REDUCTION_RATIO)\n",
        "        valid_prices = below_current[valid_mask]\n",
        "        \n",
        "        if len(valid_prices) > 0:\n",
        "            if old_discount_price and old_discount_price > 0:\n",
        "                # Go LOWER than old discount (more aggressive)\n",
        "                even_lower = valid_prices[valid_prices < old_discount_price]\n",
        "                if len(even_lower) > 0:\n",
        "                    target_price = even_lower[-1]  # Highest of the lower prices\n",
        "                    source = 'dropping_below_old'\n",
        "                else:\n",
        "                    # No price below old discount, use lowest valid\n",
        "                    target_price = valid_prices[0]\n",
        "                    source = 'dropping_lowest'\n",
        "            else:\n",
        "                # No old discount - take lowest valid price (most aggressive)\n",
        "                target_price = valid_prices[0]\n",
        "                source = 'dropping_aggressive'\n",
        "        \n",
        "        return target_price, source\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # UTH Status: Growing - Less Aggressive (higher price than old discount)\n",
        "    # -------------------------------------------------------------------------\n",
        "    if uth_status in ['growing', 'Growing']:\n",
        "        valid_mask = (below_current >= min_acceptable_price) & (diffs >= -MAX_PRICE_REDUCTION_RATIO) & (diffs <= -MIN_PRICE_REDUCTION_RATIO)\n",
        "        valid_prices = below_current[valid_mask]\n",
        "        \n",
        "        if len(valid_prices) > 0:\n",
        "            if old_discount_price and old_discount_price > 0:\n",
        "                # Go HIGHER than old discount (less aggressive)\n",
        "                higher_prices = valid_prices[valid_prices > old_discount_price]\n",
        "                if len(higher_prices) > 0:\n",
        "                    target_price = higher_prices[0]  # Lowest of the higher prices\n",
        "                    source = 'growing_above_old'\n",
        "                else:\n",
        "                    # No prices higher than old discount - keep old discount\n",
        "                    target_price = old_discount_price\n",
        "                    source = 'growing_keep_old'\n",
        "            else:\n",
        "                # No old discount - take highest valid price (least aggressive)\n",
        "                target_price = valid_prices[-1]\n",
        "                source = 'growing_conservative'\n",
        "        \n",
        "        return target_price, source\n",
        "    \n",
        "    # -------------------------------------------------------------------------\n",
        "    # Default: Find best price in valid range\n",
        "    # -------------------------------------------------------------------------\n",
        "    valid_mask = (below_current >= min_acceptable_price) & (diffs >= -MAX_PRICE_REDUCTION_RATIO) & (diffs <= -MIN_PRICE_REDUCTION_RATIO)\n",
        "    valid_prices = below_current[valid_mask]\n",
        "    \n",
        "    if len(valid_prices) > 0:\n",
        "        target_price = valid_prices[-1]  # Take highest (most conservative)\n",
        "        source = 'default_valid'\n",
        "    \n",
        "    return target_price, source\n",
        "\n",
        "\n",
        "def calculate_discount_for_row(row: pd.Series) -> pd.Series:\n",
        "    \"\"\"\n",
        "    Process a single row to calculate target price and discount percentage.\n",
        "    \n",
        "    Args:\n",
        "        row: Series with all pricing data\n",
        "    \n",
        "    Returns:\n",
        "        Series with 'target_price', 'discount_percentage', 'discount_source'\n",
        "    \"\"\"\n",
        "    # Use new_price if available, otherwise current_price\n",
        "    new_price = row.get('new_price')\n",
        "    if new_price and not pd.isna(new_price) and float(new_price) > 0:\n",
        "        current_price = float(new_price)\n",
        "    else:\n",
        "        current_price = float(row.get('current_price', 0) or 0)\n",
        "    \n",
        "    wac = float(row.get('wac_p', 0) or 0)\n",
        "    \n",
        "    if current_price <= 0 or wac <= 0:\n",
        "        return pd.Series({\n",
        "            'target_price': 0.0,\n",
        "            'discount_percentage': 0.0,\n",
        "            'discount_source': 'invalid_data'\n",
        "        })\n",
        "    \n",
        "    # Get parameters\n",
        "    target_margin = float(row.get('target_margin', 0.10) or 0.10)\n",
        "    min_boundary = float(row.get('min_boundary', 0.05) or 0.05)\n",
        "    doh = float(row.get('doh', 0) or 0)\n",
        "    # For SKU discounts, only use the zero_demand flag (ignore uth_qty)\n",
        "    is_zero_demand = bool(row.get('zero_demand', False))\n",
        "    uth_status = str(row.get('uth_status', 'dropping'))\n",
        "    \n",
        "    # Calculate old discount price if there was an active discount\n",
        "    active_disc_pct = float(row.get('active_sku_disc_pct', 0) or 0)\n",
        "    if active_disc_pct > 0:\n",
        "        old_discount_price = current_price * (1 - active_disc_pct / 100)\n",
        "    else:\n",
        "        old_discount_price = None\n",
        "    \n",
        "    # Build candidate prices\n",
        "    candidate_prices = build_candidate_prices(row)\n",
        "    \n",
        "    if len(candidate_prices) == 0:\n",
        "        return pd.Series({\n",
        "            'target_price': 0.0,\n",
        "            'discount_percentage': 0.0,\n",
        "            'discount_source': 'no_candidates'\n",
        "        })\n",
        "    \n",
        "    # Select target price\n",
        "    target_price, source = select_target_price(\n",
        "        candidate_prices=candidate_prices,\n",
        "        current_price=current_price,\n",
        "        wac=wac,\n",
        "        target_margin=target_margin,\n",
        "        min_boundary=min_boundary,\n",
        "        is_zero_demand=is_zero_demand,\n",
        "        doh=doh,\n",
        "        uth_status=uth_status,\n",
        "        old_discount_price=old_discount_price\n",
        "    )\n",
        "    \n",
        "    # Calculate discount percentage\n",
        "    if target_price > 0 and target_price < current_price:\n",
        "        discount = abs((target_price - current_price) / current_price)\n",
        "        \n",
        "        # Round to nearest 0.1% (same as HH-V3)\n",
        "        discount = discount * 100000\n",
        "        discount = ((discount // 10) + 1) / 10000\n",
        "        \n",
        "        # Cap at max discount\n",
        "        discount = min(discount, MAX_DISCOUNT_PERCENT / 100)\n",
        "        \n",
        "        # Convert to percentage\n",
        "        discount_pct = discount * 100\n",
        "        \n",
        "        # Skip if below minimum\n",
        "        if discount_pct < MIN_DISCOUNT_PERCENT:\n",
        "            discount_pct = 0.0\n",
        "            source = 'below_min_threshold'\n",
        "    else:\n",
        "        discount_pct = 0.0\n",
        "        if source == '':\n",
        "            source = 'no_reduction_needed'\n",
        "    \n",
        "    return pd.Series({\n",
        "        'target_price': target_price,\n",
        "        'discount_percentage': round(discount_pct, 2),\n",
        "        'discount_source': source\n",
        "    })\n",
        "\n",
        "\n",
        "def calculate_discounts_batch(df_skus: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculate discounts for all SKUs in batch.\n",
        "    \n",
        "    Args:\n",
        "        df_skus: DataFrame with SKUs needing discounts\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame with 'target_price', 'discount_percentage', 'discount_source' columns added\n",
        "    \"\"\"\n",
        "    print(f\"Calculating discounts for {len(df_skus)} SKUs...\")\n",
        "    \n",
        "    # Enable progress bar\n",
        "    tqdm.pandas(desc=\"Calculating discounts\")\n",
        "    \n",
        "    # Apply discount calculation to each row\n",
        "    result_cols = df_skus.progress_apply(calculate_discount_for_row, axis=1)\n",
        "    \n",
        "    # Combine with original data\n",
        "    df_result = df_skus.copy()\n",
        "    df_result['target_price'] = result_cols['target_price']\n",
        "    df_result['discount_percentage'] = result_cols['discount_percentage']\n",
        "    df_result['discount_source'] = result_cols['discount_source']\n",
        "    \n",
        "    # Summary statistics\n",
        "    valid_discounts = df_result[df_result['discount_percentage'] > 0]\n",
        "    print(f\"\\n  âœ“ Discounts calculated:\")\n",
        "    print(f\"    - Valid discounts: {len(valid_discounts)}\")\n",
        "    print(f\"    - Avg discount: {valid_discounts['discount_percentage'].mean():.2f}%\" if len(valid_discounts) > 0 else \"    - Avg discount: N/A\")\n",
        "    print(f\"    - Discount sources: {df_result['discount_source'].value_counts().to_dict()}\")\n",
        "    \n",
        "    return df_result\n",
        "\n",
        "\n",
        "print(\"Function 3: Price selection & discount calculation defined âœ“\")\n",
        "print(\"  - margin_to_price()\")\n",
        "print(\"  - build_candidate_prices()\")\n",
        "print(\"  - select_target_price()\")\n",
        "print(\"  - calculate_discount_for_row()\")\n",
        "print(\"  - calculate_discounts_batch()\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FUNCTION 4: STRUCTURE DATAFRAME\n",
        "# =============================================================================\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Output folder for SKU discount sheets\n",
        "SKU_DISCOUNT_OUTPUT_FOLDER = '../output/sku_discount_sheets'\n",
        "SKU_DISCOUNT_TEMP_FOLDER = '../output/sku_discount_temp'\n",
        "\n",
        "# Max retailers per API call\n",
        "MAX_RETAILERS_PER_CHUNK = 100\n",
        "\n",
        "# Max rows per Excel file\n",
        "MAX_ROWS_PER_FILE = 1000\n",
        "\n",
        "\n",
        "def clear_output_folder(folder_path: str, temp_folder: str) -> None:\n",
        "    \"\"\"\n",
        "    Clear all files from the output folder by moving them to temp.\n",
        "    \n",
        "    Args:\n",
        "        folder_path: Path to the folder to clear\n",
        "        temp_folder: Path to move files to before deletion\n",
        "    \"\"\"\n",
        "    # Create folders if they don't exist\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    os.makedirs(temp_folder, exist_ok=True)\n",
        "    \n",
        "    source = Path(folder_path)\n",
        "    \n",
        "    moved_count = 0\n",
        "    error_count = 0\n",
        "    \n",
        "    for file in source.iterdir():\n",
        "        if file.is_file():\n",
        "            try:\n",
        "                # Delete file\n",
        "                file.unlink()\n",
        "                moved_count += 1\n",
        "            except Exception as e:\n",
        "                print(f\"  âœ— Error deleting {file.name}: {e}\")\n",
        "                error_count += 1\n",
        "    \n",
        "    if moved_count > 0:\n",
        "        print(f\"  Cleared {moved_count} files from output folder\")\n",
        "\n",
        "\n",
        "def structure_sku_discount_dataframe(df_skus: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Structure the DataFrame in the format expected by the SKU discount API/upload.\n",
        "    \n",
        "    Transforms the internal data format into the API-expected format with proper \n",
        "    column names, data types, grouping by discount, and chunking for upload.\n",
        "    \n",
        "    Process:\n",
        "    1. Deduplicate SKUs (keep lowest discount per product-warehouse-retailer)\n",
        "    2. Merge with packing units\n",
        "    3. Create HH_data format: [product_id, packing_unit_id, discount]\n",
        "    4. Set start/end times (start = now + 10 mins, end = start + 12 hours)\n",
        "    5. Group by retailer to create discount lists\n",
        "    6. Group by discounts to aggregate retailers\n",
        "    7. Chunk retailer lists (max 100 per chunk)\n",
        "    8. Add required columns (offer names)\n",
        "    \n",
        "    Args:\n",
        "        df_skus: DataFrame with discount calculations and retailer targeting\n",
        "    \n",
        "    Returns:\n",
        "        DataFrame ready for API upload with columns:\n",
        "            - Retailers List\n",
        "            - Start Date/Time\n",
        "            - End Date/Time\n",
        "            - Discounts\n",
        "            - Arabic Offer Name\n",
        "            - French Offer Name\n",
        "            - English Offer Name\n",
        "            - Swahili Offer Name\n",
        "            - Rwandan Offer Name\n",
        "    \"\"\"\n",
        "    print(f\"Structuring {len(df_skus)} SKU discount records for API...\")\n",
        "    \n",
        "    if df_skus.empty:\n",
        "        print(\"  No records to structure\")\n",
        "        return pd.DataFrame()\n",
        "    \n",
        "    df = df_skus.copy()\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 1: Deduplicate - keep lowest discount per product-warehouse-retailer\n",
        "    # =========================================================================\n",
        "    print(\"  Step 1: Deduplicating...\")\n",
        "    df = df.sort_values('discount_percentage').drop_duplicates(\n",
        "        subset=['product_id', 'warehouse_id', 'retailer_id']\n",
        "    )\n",
        "    print(f\"    Records after deduplication: {len(df)}\")\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 2: Merge with packing units\n",
        "    # =========================================================================\n",
        "    print(\"  Step 2: Merging with packing units...\")\n",
        "    try:\n",
        "        pus = get_packing_units()\n",
        "        df = df.merge(pus, on='product_id', how='left')\n",
        "        df = df.drop_duplicates()\n",
        "        print(f\"    Records after PU merge: {len(df)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"    âš  Failed to get packing units: {e}\")\n",
        "        # Use product_id as packing_unit_id fallback\n",
        "        df['packing_unit_id'] = df['product_id']\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 3: Create HH_data format\n",
        "    # =========================================================================\n",
        "    print(\"  Step 3: Creating HH_data format...\")\n",
        "    df['HH_data'] = '[' + df['product_id'].astype(str) + ',' + \\\n",
        "                    df['packing_unit_id'].astype(str) + ',' + \\\n",
        "                    df['discount_percentage'].astype(str) + ']'\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 4: Set start and end times (Cairo timezone)\n",
        "    # =========================================================================\n",
        "    print(\"  Step 4: Setting start/end times...\")\n",
        "    start_time = datetime.now(CAIRO_TZ) + timedelta(minutes=10)\n",
        "    end_time = start_time + timedelta(hours=12)\n",
        "    \n",
        "    # Format for API: \"YYYY-MM-DD HH:MM\" (without seconds)\n",
        "    start_date = start_time.strftime('%Y-%m-%d %H:%M')\n",
        "    end_date = end_time.strftime('%Y-%m-%d %H:%M')\n",
        "    print(f\"    Start: {start_date}\")\n",
        "    print(f\"    End: {end_date}\")\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 5: Group by retailer_id to create discount lists\n",
        "    # =========================================================================\n",
        "    print(\"  Step 5: Grouping by retailer...\")\n",
        "    output_df = df.groupby('retailer_id')['HH_data'].apply(list).reset_index()\n",
        "    output_df['Discounts'] = output_df['HH_data'].astype(str).str.replace(\"'\", '').str.replace(' ', '')\n",
        "    print(f\"    Unique retailers: {len(output_df)}\")\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 6: Group by Discounts to aggregate retailers\n",
        "    # =========================================================================\n",
        "    print(\"  Step 6: Grouping by discount combinations...\")\n",
        "    output_df = output_df.groupby('Discounts')['retailer_id'].agg(list).reset_index()\n",
        "    print(f\"    Unique discount combinations: {len(output_df)}\")\n",
        "    \n",
        "    # Add required columns\n",
        "    output_df['Arabic Offer Name'] = 'Ø®ØµÙˆÙ…Ø§Øª Ø­ØµØ±ÙŠØ©'\n",
        "    output_df['Start Date/Time'] = start_date\n",
        "    output_df['End Date/Time'] = end_date\n",
        "    output_df = output_df[['retailer_id', 'Start Date/Time', 'End Date/Time', 'Discounts', 'Arabic Offer Name']]\n",
        "    output_df['French Offer Name'] = np.nan\n",
        "    output_df['English Offer Name'] = np.nan\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 7: Chunk retailer lists (max 100 per chunk)\n",
        "    # =========================================================================\n",
        "    print(f\"  Step 7: Chunking retailer lists (max {MAX_RETAILERS_PER_CHUNK} per chunk)...\")\n",
        "    data = []\n",
        "    for i, row in output_df.iterrows():\n",
        "        start_date_val = row['Start Date/Time']\n",
        "        end_date_val = row['End Date/Time']\n",
        "        retailers = row['retailer_id']\n",
        "        discount = row['Discounts']\n",
        "        name = row['Arabic Offer Name']\n",
        "        name_f = row['French Offer Name']\n",
        "        name_e = row['English Offer Name']\n",
        "        \n",
        "        length = len(retailers)\n",
        "        if length > MAX_RETAILERS_PER_CHUNK:\n",
        "            # Split into chunks of MAX_RETAILERS_PER_CHUNK\n",
        "            iters = length // MAX_RETAILERS_PER_CHUNK\n",
        "            for j in range(0, iters + 1):\n",
        "                start_idx = j * MAX_RETAILERS_PER_CHUNK\n",
        "                end_idx = (j + 1) * MAX_RETAILERS_PER_CHUNK\n",
        "                rets = retailers[start_idx:end_idx]\n",
        "                if len(rets) > 0:\n",
        "                    data.append({\n",
        "                        'Discounts': discount,\n",
        "                        'retailer_id': rets,\n",
        "                        'Start Date/Time': start_date_val,\n",
        "                        'End Date/Time': end_date_val,\n",
        "                        'Arabic Offer Name': name,\n",
        "                        'French Offer Name': name_f,\n",
        "                        'English Offer Name': name_e\n",
        "                    })\n",
        "        else:\n",
        "            data.append({\n",
        "                'Discounts': discount,\n",
        "                'retailer_id': retailers,\n",
        "                'Start Date/Time': start_date_val,\n",
        "                'End Date/Time': end_date_val,\n",
        "                'Arabic Offer Name': name,\n",
        "                'French Offer Name': name_f,\n",
        "                'English Offer Name': name_e\n",
        "            })\n",
        "    \n",
        "    dfx = pd.DataFrame(data)\n",
        "    print(f\"    Total chunks: {len(dfx)}\")\n",
        "    \n",
        "    # =========================================================================\n",
        "    # Step 8: Add extra columns and rename\n",
        "    # =========================================================================\n",
        "    print(\"  Step 8: Finalizing columns...\")\n",
        "    dfx['English Offer Name'] = 'Special Discounts'\n",
        "    dfx['Swahili Offer Name'] = ''\n",
        "    dfx['Rwandan Offer Name'] = ''\n",
        "    \n",
        "    # Rename and reorder columns\n",
        "    dfx.rename(columns={'retailer_id': 'Retailers List'}, inplace=True)\n",
        "    dfx = dfx[[\n",
        "        'Retailers List', 'Start Date/Time', 'End Date/Time', 'Discounts',\n",
        "        'Arabic Offer Name', 'French Offer Name', 'English Offer Name',\n",
        "        'Swahili Offer Name', 'Rwandan Offer Name'\n",
        "    ]]\n",
        "    \n",
        "    print(f\"  âœ“ Structured {len(dfx)} records for upload\")\n",
        "    \n",
        "    return dfx\n",
        "\n",
        "\n",
        "def save_sku_discount_files(df_structured: pd.DataFrame) -> list:\n",
        "    \"\"\"\n",
        "    Save structured SKU discount data to Excel files.\n",
        "    \n",
        "    Clears the output folder first, then saves files with max 1000 rows each.\n",
        "    \n",
        "    Args:\n",
        "        df_structured: Structured DataFrame from structure_sku_discount_dataframe\n",
        "    \n",
        "    Returns:\n",
        "        List of saved file paths\n",
        "    \"\"\"\n",
        "    if df_structured.empty:\n",
        "        print(\"No data to save\")\n",
        "        return []\n",
        "    \n",
        "    print(f\"\\nSaving SKU discount files...\")\n",
        "    \n",
        "    # Clear output folder\n",
        "    print(\"  Clearing output folder...\")\n",
        "    clear_output_folder(SKU_DISCOUNT_OUTPUT_FOLDER, SKU_DISCOUNT_TEMP_FOLDER)\n",
        "    \n",
        "    # Create output folder if needed\n",
        "    os.makedirs(SKU_DISCOUNT_OUTPUT_FOLDER, exist_ok=True)\n",
        "    \n",
        "    # Reset index\n",
        "    final = df_structured.reset_index(drop=True)\n",
        "    \n",
        "    # Calculate file ranges\n",
        "    mino = final.index.min()\n",
        "    maxo = final.index.max()\n",
        "    ran = [i for i in range(mino, maxo + 1, MAX_ROWS_PER_FILE)]\n",
        "    \n",
        "    saved_files = []\n",
        "    \n",
        "    print(f\"  Saving {len(ran)} files (max {MAX_ROWS_PER_FILE} rows each)...\")\n",
        "    \n",
        "    for i in tqdm(range(len(ran)), desc=\"Saving files\"):\n",
        "        if i + 1 == len(ran):\n",
        "            val1 = ran[i]\n",
        "            val2 = maxo\n",
        "        else:\n",
        "            val1 = ran[i]\n",
        "            val2 = ran[i + 1] - 1\n",
        "        \n",
        "        x = final.loc[val1:val2, :]\n",
        "        \n",
        "        # Generate filename with date\n",
        "        filename = f'sku_discount_{str(datetime.now(CAIRO_TZ).date())}_NO._{i}.xlsx'\n",
        "        filepath = os.path.join(SKU_DISCOUNT_OUTPUT_FOLDER, filename)\n",
        "        \n",
        "        x.to_excel(filepath, index=False)\n",
        "        saved_files.append(filepath)\n",
        "    \n",
        "    print(f\"  âœ“ Saved {len(saved_files)} files to {SKU_DISCOUNT_OUTPUT_FOLDER}\")\n",
        "    \n",
        "    return saved_files\n",
        "\n",
        "\n",
        "print(\"Function 4: structure_sku_discount_dataframe() defined âœ“\")\n",
        "print(\"  - clear_output_folder()\")\n",
        "print(\"  - structure_sku_discount_dataframe()\")\n",
        "print(\"  - save_sku_discount_files()\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FUNCTION 5: PUSH SKU DISCOUNT (via S3 Upload)\n",
        "# =============================================================================\n",
        "# Reference: HH-V3.ipynb upload flow\n",
        "# Flow: Save Excel â†’ Get pre-signed URL â†’ Upload to S3 â†’ Validate â†’ Proceed\n",
        "\n",
        "def _get_presigned_url() -> dict:\n",
        "    \"\"\"\n",
        "    Get a pre-signed S3 URL for uploading SKU discount Excel file.\n",
        "    \n",
        "    Returns:\n",
        "        dict with 'key' and 'preSignedUrl'\n",
        "    \"\"\"\n",
        "    token = _get_api_token()\n",
        "    url = \"https://api.maxab.info/commerce/api/admins/v1/bulk-upload/presigned-url?type=SKU_DISCOUNTS\"\n",
        "    \n",
        "    headers = {\n",
        "        'Authorization': f'bearer {token}'\n",
        "    }\n",
        "    \n",
        "    response = requests.get(url, headers=headers)\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def _upload_file_to_s3(file_path: str, presigned_url: str) -> requests.Response:\n",
        "    \"\"\"\n",
        "    Upload Excel file to S3 using pre-signed URL.\n",
        "    \n",
        "    Args:\n",
        "        file_path: Path to Excel file\n",
        "        presigned_url: Pre-signed S3 URL\n",
        "    \n",
        "    Returns:\n",
        "        Response object\n",
        "    \"\"\"\n",
        "    headers = {'Content-Type': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'}\n",
        "    \n",
        "    with open(file_path, 'rb') as f:\n",
        "        response = requests.put(presigned_url, data=f, headers=headers)\n",
        "    \n",
        "    return response\n",
        "\n",
        "\n",
        "def _validate_sku_discount(key: str) -> requests.Response:\n",
        "    \"\"\"\n",
        "    Validate uploaded SKU discount file.\n",
        "    \n",
        "    Args:\n",
        "        key: S3 key returned from presigned URL\n",
        "    \n",
        "    Returns:\n",
        "        Response object\n",
        "    \"\"\"\n",
        "    token = _get_api_token()\n",
        "    url = 'https://api.maxab.info/commerce/api/admins/v1/bulk-upload/sheets/validate'\n",
        "    \n",
        "    headers = {\n",
        "        'Authorization': f'bearer {token}',\n",
        "        'content-type': 'application/json'\n",
        "    }\n",
        "    \n",
        "    payload = {\"fileName\": key, \"sheetType\": \"SKU_DISCOUNTS\"}\n",
        "    response = requests.post(url, headers=headers, json=payload)\n",
        "    \n",
        "    return response\n",
        "\n",
        "\n",
        "def _proceed_sku_discount(key: str) -> requests.Response:\n",
        "    \"\"\"\n",
        "    Proceed with processing the validated SKU discount file.\n",
        "    \n",
        "    Args:\n",
        "        key: S3 key returned from presigned URL\n",
        "    \n",
        "    Returns:\n",
        "        Response object\n",
        "    \"\"\"\n",
        "    token = _get_api_token()\n",
        "    url = f'https://api.maxab.info/commerce/api/admins/v1/bulk-upload/sheets/proceed/{key}?uploadType=SKU_DISCOUNTS'\n",
        "    \n",
        "    headers = {\n",
        "        'Authorization': f'bearer {token}',\n",
        "        'content-type': 'application/json'\n",
        "    }\n",
        "    \n",
        "    response = requests.post(url, headers=headers)\n",
        "    return response\n",
        "\n",
        "\n",
        "def _upload_single_file(file_path: str) -> dict:\n",
        "    \"\"\"\n",
        "    Upload a single SKU discount Excel file through the full pipeline.\n",
        "    \n",
        "    Flow:\n",
        "    1. Get pre-signed URL\n",
        "    2. Upload file to S3\n",
        "    3. Validate file\n",
        "    4. Proceed with processing\n",
        "    \n",
        "    Args:\n",
        "        file_path: Path to Excel file\n",
        "    \n",
        "    Returns:\n",
        "        dict with upload results\n",
        "    \"\"\"\n",
        "    result = {\n",
        "        'file': file_path,\n",
        "        'timestamp': datetime.now(CAIRO_TZ).strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'status': 'PENDING',\n",
        "        'steps': {}\n",
        "    }\n",
        "    \n",
        "    try:\n",
        "        # Step 1: Get pre-signed URL\n",
        "        pre_data = _get_presigned_url()\n",
        "        key = pre_data['key']\n",
        "        presigned_url = pre_data['preSignedUrl']\n",
        "        result['steps']['presigned_url'] = 'Success'\n",
        "        result['key'] = key\n",
        "        \n",
        "    except Exception as e:\n",
        "        result['steps']['presigned_url'] = f'Failed: {e}'\n",
        "        result['status'] = 'FAILED'\n",
        "        return result\n",
        "    \n",
        "    try:\n",
        "        # Step 2: Upload file to S3\n",
        "        upload_response = _upload_file_to_s3(file_path, presigned_url)\n",
        "        \n",
        "        if upload_response.status_code in [200, 201, 204]:\n",
        "            result['steps']['upload'] = 'Success'\n",
        "        else:\n",
        "            result['steps']['upload'] = f'Failed: {upload_response.status_code}'\n",
        "            result['status'] = 'FAILED'\n",
        "            return result\n",
        "            \n",
        "    except Exception as e:\n",
        "        result['steps']['upload'] = f'Failed: {e}'\n",
        "        result['status'] = 'FAILED'\n",
        "        return result\n",
        "    \n",
        "    try:\n",
        "        # Step 3: Validate file\n",
        "        validation_response = _validate_sku_discount(key)\n",
        "        \n",
        "        if validation_response.ok:\n",
        "            result['steps']['validation'] = 'Success'\n",
        "        else:\n",
        "            result['steps']['validation'] = f'Failed: {validation_response.status_code}'\n",
        "            result['status'] = 'FAILED'\n",
        "            return result\n",
        "            \n",
        "    except Exception as e:\n",
        "        result['steps']['validation'] = f'Failed: {e}'\n",
        "        result['status'] = 'FAILED'\n",
        "        return result\n",
        "    \n",
        "    try:\n",
        "        # Step 4: Proceed with processing\n",
        "        proceed_response = _proceed_sku_discount(key)\n",
        "        \n",
        "        if proceed_response.ok:\n",
        "            result['steps']['proceed'] = 'Success'\n",
        "            result['status'] = 'SUCCESS'\n",
        "        else:\n",
        "            result['steps']['proceed'] = f'Failed: {proceed_response.status_code}'\n",
        "            result['status'] = 'FAILED'\n",
        "            \n",
        "    except Exception as e:\n",
        "        result['steps']['proceed'] = f'Failed: {e}'\n",
        "        result['status'] = 'FAILED'\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "def push_sku_discount(df_api: pd.DataFrame, mode: str = 'testing') -> dict:\n",
        "    \"\"\"\n",
        "    Push SKU discounts - saves files and optionally uploads via S3.\n",
        "    \n",
        "    Flow (live mode):\n",
        "    1. Save Excel files to output folder\n",
        "    2. For each file:\n",
        "       a. Get pre-signed S3 URL\n",
        "       b. Upload file to S3\n",
        "       c. Validate file\n",
        "       d. Proceed with processing\n",
        "    \n",
        "    Args:\n",
        "        df_api: DataFrame structured for API (from structure_sku_discount_dataframe)\n",
        "        mode: 'testing' (save files only) or 'live' (save files and upload via S3)\n",
        "    \n",
        "    Returns:\n",
        "        dict with:\n",
        "            - success: bool\n",
        "            - created_count: int\n",
        "            - failed_count: int\n",
        "            - saved_files: list of file paths\n",
        "            - upload_results: list of upload results per file\n",
        "            - errors: list\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'ðŸ§ª' if mode == 'testing' else 'ðŸš€'} MODE: {mode.upper()}\")\n",
        "    \n",
        "    result = {\n",
        "        \"success\": True,\n",
        "        \"created_count\": 0,\n",
        "        \"failed_count\": 0,\n",
        "        \"saved_files\": [],\n",
        "        \"upload_results\": [],\n",
        "        \"errors\": []\n",
        "    }\n",
        "    \n",
        "    if df_api.empty:\n",
        "        print(\"No SKU discounts to push\")\n",
        "        return result\n",
        "    \n",
        "    print(f\"Processing {len(df_api)} SKU discount records...\")\n",
        "    \n",
        "    # Step 1: Save files to output folder\n",
        "    print(\"\\n  Step 1: Saving files to output folder...\")\n",
        "    saved_files = save_sku_discount_files(df_api)\n",
        "    result['saved_files'] = saved_files\n",
        "    \n",
        "    if mode == 'testing':\n",
        "        print(f\"\\n  ðŸ§ª [TESTING] Files saved but S3 upload skipped\")\n",
        "        print(f\"  Files location: {SKU_DISCOUNT_OUTPUT_FOLDER}\")\n",
        "        print(f\"  Files saved: {len(saved_files)}\")\n",
        "        result['created_count'] = len(df_api)\n",
        "        return result\n",
        "    \n",
        "    # Step 2: Upload each file via S3 (live mode)\n",
        "    print(f\"\\n  Step 2: Uploading {len(saved_files)} files via S3...\")\n",
        "    \n",
        "    success_count = 0\n",
        "    failed_count = 0\n",
        "    \n",
        "    for file_path in tqdm(saved_files, desc=\"Uploading files\"):\n",
        "        print(f\"\\n    Processing: {os.path.basename(file_path)}\")\n",
        "        \n",
        "        upload_result = _upload_single_file(file_path)\n",
        "        result['upload_results'].append(upload_result)\n",
        "        \n",
        "        if upload_result['status'] == 'SUCCESS':\n",
        "            success_count += 1\n",
        "            print(f\"      âœ“ Success\")\n",
        "        else:\n",
        "            failed_count += 1\n",
        "            print(f\"      âœ— Failed: {upload_result['steps']}\")\n",
        "            result['errors'].append({\n",
        "                'file': file_path,\n",
        "                'steps': upload_result['steps']\n",
        "            })\n",
        "    \n",
        "    result['created_count'] = success_count\n",
        "    result['failed_count'] = failed_count\n",
        "    result['success'] = failed_count == 0\n",
        "    \n",
        "    # Summary\n",
        "    print(f\"\\n  {'='*50}\")\n",
        "    print(f\"  UPLOAD SUMMARY\")\n",
        "    print(f\"  {'='*50}\")\n",
        "    print(f\"  Total files: {len(saved_files)}\")\n",
        "    print(f\"  âœ“ Successful: {success_count}\")\n",
        "    print(f\"  âœ— Failed: {failed_count}\")\n",
        "    \n",
        "    if failed_count > 0:\n",
        "        print(f\"\\n  Failed files:\")\n",
        "        for err in result['errors'][:5]:  # Show first 5\n",
        "            print(f\"    - {os.path.basename(err['file'])}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "print(\"Function 5: push_sku_discount() defined âœ“\")\n",
        "print(\"  - _get_presigned_url()\")\n",
        "print(\"  - _upload_file_to_s3()\")\n",
        "print(\"  - _validate_sku_discount()\")\n",
        "print(\"  - _proceed_sku_discount()\")\n",
        "print(\"  - _upload_single_file()\")\n",
        "print(\"  - push_sku_discount()\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MAIN ORCHESTRATION FUNCTION\n",
        "# =============================================================================\n",
        "\n",
        "def process_sku_discounts(\n",
        "    df_module3_output: pd.DataFrame,\n",
        "    mode: str = 'testing'\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Main entry point: Process SKU discounts from Module 3 output.\n",
        "    \n",
        "    Note: Market data should already be refreshed in Module 3 before calling this.\n",
        "    \n",
        "    Orchestrates the full workflow:\n",
        "    1. Deactivate existing SKU discounts\n",
        "    2. Filter to SKUs needing discounts (activate_sku_discount = True)\n",
        "    3. Apply exclusions (categories, brands)\n",
        "    4. Select target retailers\n",
        "    5. Calculate discount percentages using HH-V3 logic\n",
        "    6. Structure DataFrame for API\n",
        "    7. Push to API\n",
        "    \n",
        "    Args:\n",
        "        df_module3_output: DataFrame from Module 3 with columns:\n",
        "            - product_id, warehouse_id, sku, cohort_id\n",
        "            - activate_sku_discount (bool)\n",
        "            - current_price, wac_p, doh, zero_demand\n",
        "            - uth_status, active_sku_disc_pct\n",
        "            - Raw market prices, market margins, margin boundaries, margin tiers\n",
        "        mode: 'testing' or 'live'\n",
        "    \n",
        "    Returns:\n",
        "        dict with summary of all operations\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SKU DISCOUNT HANDLER\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Mode: {mode}\")\n",
        "    print(f\"Input records: {len(df_module3_output)}\")\n",
        "    \n",
        "    result = {\n",
        "        'timestamp': CAIRO_NOW.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'mode': mode,\n",
        "        'total_input': len(df_module3_output),\n",
        "        'excluded_category': 0,\n",
        "        'excluded_brand': 0,\n",
        "        'to_activate': 0,\n",
        "        'deactivated': 0,\n",
        "        'created': 0,\n",
        "        'failed': 0\n",
        "    }\n",
        "    \n",
        "    df = df_module3_output.copy()\n",
        "    \n",
        "    # Step 1: Deactivate existing discounts\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"STEP 1: Deactivating existing SKU discounts\")\n",
        "    print(\"-\"*50)\n",
        "    deactivate_result = deactivate_active_sku_discounts(mode=mode)\n",
        "    result['deactivated'] = deactivate_result['deactivated_count']\n",
        "    \n",
        "    # Step 2: Filter to SKUs needing discounts\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"STEP 2: Filtering SKUs for discount\")\n",
        "    print(\"-\"*50)\n",
        "    df_to_activate = df[\n",
        "        df['activate_sku_discount'] == True\n",
        "    ].copy()\n",
        "    initial_count = len(df_to_activate)\n",
        "    print(f\"SKUs flagged for discount: {initial_count}\")\n",
        "    \n",
        "    # Step 2b: Apply exclusions\n",
        "    print(\"\\n  Applying exclusions...\")\n",
        "    \n",
        "    # Exclude categories\n",
        "    if 'cat' in df_to_activate.columns and len(EXCLUDED_CATEGORIES) > 0:\n",
        "        before = len(df_to_activate)\n",
        "        df_to_activate = df_to_activate[~df_to_activate['cat'].isin(EXCLUDED_CATEGORIES)]\n",
        "        excluded_cat = before - len(df_to_activate)\n",
        "        result['excluded_category'] = excluded_cat\n",
        "        print(f\"    - Excluded by category: {excluded_cat}\")\n",
        "    \n",
        "    # Exclude brands\n",
        "    if 'brand' in df_to_activate.columns and len(EXCLUDED_BRANDS) > 0:\n",
        "        before = len(df_to_activate)\n",
        "        df_to_activate = df_to_activate[~df_to_activate['brand'].isin(EXCLUDED_BRANDS)]\n",
        "        excluded_brand = before - len(df_to_activate)\n",
        "        result['excluded_brand'] = excluded_brand\n",
        "        print(f\"    - Excluded by brand: {excluded_brand}\")\n",
        "    \n",
        "    result['to_activate'] = len(df_to_activate)\n",
        "    print(f\"\\n  Final SKUs to activate: {len(df_to_activate)}\")\n",
        "    \n",
        "    if df_to_activate.empty:\n",
        "        print(\"No SKUs need discounts. Done.\")\n",
        "        return result\n",
        "    \n",
        "    # Step 3: Calculate discounts (BEFORE retailer selection)\n",
        "    # We need to know which SKUs have valid discounts before selecting retailers\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"STEP 3: Calculating discount percentages\")\n",
        "    print(\"-\"*50)\n",
        "    df_with_discounts = calculate_discounts_batch(df_to_activate)\n",
        "    \n",
        "    # Filter to SKUs with valid discounts\n",
        "    df_valid_discounts = df_with_discounts[df_with_discounts['discount_percentage'] > 0].copy()\n",
        "    result['valid_discounts'] = len(df_valid_discounts)\n",
        "    print(f\"\\n  SKUs with valid discounts (>0%): {len(df_valid_discounts)}\")\n",
        "    \n",
        "    if df_valid_discounts.empty:\n",
        "        print(\"No SKUs with valid discounts. Done.\")\n",
        "        return result\n",
        "    \n",
        "    # Step 4: Select target retailers (only for valid discounts)\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"STEP 4: Selecting target retailers\")\n",
        "    print(\"-\"*50)\n",
        "    df_with_retailers = select_target_retailers(df_valid_discounts)\n",
        "    \n",
        "    if len(df_with_retailers) == 0 or df_with_retailers['retailer_id'].isna().all():\n",
        "        print(\"No retailers found for any SKU. Done.\")\n",
        "        return result\n",
        "    \n",
        "    result['retailer_product_combinations'] = len(df_with_retailers)\n",
        "    \n",
        "    # Step 5: Structure DataFrame\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"STEP 5: Structuring data for API\")\n",
        "    print(\"-\"*50)\n",
        "    df_api = structure_sku_discount_dataframe(df_with_retailers)\n",
        "    \n",
        "    # Step 6: Push to API\n",
        "    print(\"\\n\" + \"-\"*50)\n",
        "    print(\"STEP 6: Pushing to API\")\n",
        "    print(\"-\"*50)\n",
        "    push_result = push_sku_discount(df_api, mode=mode)\n",
        "    result['created'] = push_result['created_count']\n",
        "    result['failed'] = push_result['failed_count']\n",
        "    \n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Mode: {result['mode']}\")\n",
        "    print(f\"Total input: {result['total_input']}\")\n",
        "    print(f\"Discounts deactivated: {result['deactivated']}\")\n",
        "    print(f\"SKUs to activate: {result['to_activate']}\")\n",
        "    print(f\"SKUs with valid discounts: {result.get('valid_discounts', 0)}\")\n",
        "    print(f\"Retailer-product combinations: {result.get('retailer_product_combinations', 0)}\")\n",
        "    print(f\"Records created/uploaded: {result['created']}\")\n",
        "    print(f\"Records failed: {result['failed']}\")\n",
        "    if 'saved_files' in push_result:\n",
        "        print(f\"Files saved: {len(push_result['saved_files'])}\")\n",
        "        print(f\"Output folder: {SKU_DISCOUNT_OUTPUT_FOLDER}\")\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "print(\"Main function: process_sku_discounts() defined âœ“\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# USAGE EXAMPLE (Called from Module 3)\n",
        "# =============================================================================\n",
        "# \n",
        "# This module is designed to be called from Module 3 after the periodic\n",
        "# action engine has determined which SKUs need discounts.\n",
        "#\n",
        "# Example usage:\n",
        "#\n",
        "# %run sku_discount_handler.ipynb\n",
        "#\n",
        "# # df_output already contains market margins and margin tiers from Module 3\n",
        "# # Required columns:\n",
        "# #   - product_id, warehouse_id, sku, cohort_id\n",
        "# #   - activate_sku_discount (bool)\n",
        "# #   - current_price, new_price, wac_p\n",
        "# #   - doh, uth_qty, uth_status, active_sku_disc_pct\n",
        "# #   - target_margin, min_boundary\n",
        "# #   - below_market, market_min, market_25, market_50, market_75, market_max, above_market\n",
        "# #   - margin_tier_below, margin_tier_1, ..., margin_tier_above_2\n",
        "#\n",
        "# result = process_sku_discounts(df_output, mode='testing')\n",
        "#\n",
        "# print(f\"Created {result['created']} SKU discounts\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SKU DISCOUNT HANDLER MODULE READY\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nRequired input columns from Module 3:\")\n",
        "print(\"  - product_id, warehouse_id, sku, cohort_id, brand, cat\")\n",
        "print(\"  - activate_sku_discount (bool)\")\n",
        "print(\"  - current_price, new_price, wac_p\")\n",
        "print(\"  - doh, uth_qty, uth_status, active_sku_disc_pct\")\n",
        "print(\"  - target_margin, min_boundary\")\n",
        "print(\"\\nRequired market margin columns (prices derived via wac/(1-margin)):\")\n",
        "for col in MARKET_MARGIN_COLS:\n",
        "    print(f\"  - {col}\")\n",
        "print(\"\\nRequired margin tier columns:\")\n",
        "for col in MARGIN_TIER_COLS:\n",
        "    print(f\"  - {col}\")\n",
        "print(\"\\nRetailer Selection: Queries 4 sources, applies exclusions, removes QD overlap\")\n",
        "print(\"\\nUsage: result = process_sku_discounts(df_output, mode='testing')\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
