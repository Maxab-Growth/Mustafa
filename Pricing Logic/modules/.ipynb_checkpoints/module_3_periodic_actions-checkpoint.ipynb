{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: Periodic Action Module (UTH-Based Adjustments)\n",
    "\n",
    "## Purpose\n",
    "This module runs at 12 PM, 3 PM, 6 PM, 9 PM, and 12 AM Cairo time to:\n",
    "1. Adjust prices based on Up-Till-Hour (UTH) performance vs benchmarks\n",
    "2. Manage SKU discounts and Quantity Discounts based on performance\n",
    "3. Adjust cart rules dynamically\n",
    "\n",
    "## UTH Benchmarks\n",
    "- Calculate historical qty from start of day till current hour over the last 4 months\n",
    "- Multiply by P80 all-time-high quantity and P70 retailers\n",
    "\n",
    "## Action Logic\n",
    "- **On Track (Â±10%)**: No action\n",
    "- **Growing (>110%)**: Deactivate discounts or increase price, reduce cart if too open\n",
    "- **Dropping (<90%)**: Reduce price, increase cart by 20%\n",
    "- **Zero Demand (qty=0 today)**: Market min + SKU discount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Upgrade pip\n",
    "!pip install --upgrade pip\n",
    "# Connectivity\n",
    "!pip install psycopg2-binary\n",
    "!pip install snowflake-connector-python==3.15.0\n",
    "!pip install snowflake-sqlalchemy\n",
    "!pip install warnings\n",
    "!pip install keyring==23.11.0\n",
    "!pip install sqlalchemy==1.4.46\n",
    "!pip install requests\n",
    "!pip install boto3\n",
    "!pip install oauth2client\n",
    "!pip install gspread==5.9.0\n",
    "!pip install gspread_dataframe\n",
    "!pip install google.cloud\n",
    "# Data manipulation and analysis\n",
    "!pip install polars\n",
    "!pip install pandas==2.2.1\n",
    "!pip install numpy\n",
    "!pip install openpyxl\n",
    "!pip install xlsxwriter\n",
    "# Date and time handling\n",
    "!pip install --upgrade datetime\n",
    "!pip install python-time\n",
    "!pip install --upgrade pytz\n",
    "# Progress bar\n",
    "!pip install tqdm\n",
    "# Database data types\n",
    "!pip install db-dtypes\n",
    "# Modeling\n",
    "!pip install statsmodels\n",
    "!pip install scikit-learn\n",
    "!pip install import-ipynb\n",
    "# Plotting\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Run queries_module - this:\n",
    "# 1. Initializes Snowflake credentials (setup_environment_2.initialize_env())\n",
    "# 2. Provides query_snowflake() function\n",
    "# 3. Provides TIMEZONE from Snowflake\n",
    "# 4. Provides get_current_stocks(), get_current_prices(), get_current_wac(), get_current_cart_rules()\n",
    "%run queries_module.ipynb\n",
    "\n",
    "# Run market_data_module - this:\n",
    "# 1. Provides get_market_data() for fetching fresh market prices (NO INPUT REQUIRED)\n",
    "# 2. Provides get_margin_tiers() for fetching margin tiers (NO INPUT REQUIRED)\n",
    "# 3. Fetches Ben Soliman, Marketplace, and Scrapped prices\n",
    "# 4. Fills missing prices from group-level data\n",
    "# 5. Calculates market price percentiles and margin tiers\n",
    "%run market_data_module.ipynb\n",
    "\n",
    "# Cairo timezone\n",
    "CAIRO_TZ = pytz.timezone('Africa/Cairo')\n",
    "CAIRO_NOW = datetime.now(CAIRO_TZ)\n",
    "TODAY = CAIRO_NOW.date()\n",
    "CURRENT_HOUR = CAIRO_NOW.hour\n",
    "\n",
    "# Configuration\n",
    "UTH_GROWING_THRESHOLD = 1.10    # >110% = Growing\n",
    "UTH_DROPPING_THRESHOLD = 0.90   # <90% = Dropping\n",
    "LOW_STOCK_DOH_THRESHOLD = 2     # SKUs with DOH <= this are protected from price reduction\n",
    "CART_INCREASE_PCT = 0.20        # 20% cart increase\n",
    "CART_DECREASE_PCT = 0.20        # 20% cart decrease\n",
    "MIN_CART_RULE = 5\n",
    "MAX_CART_RULE = 150\n",
    "MIN_PRICE_CHANGE_EGP = 0.25     # Minimum 0.25 EGP for any price change\n",
    "CONTRIBUTION_THRESHOLD = 50     # 50% contribution threshold\n",
    "MAX_PRICE_REDUCTIONS_PER_DAY = 2  # Max price reductions per day\n",
    "# SKU discount percentage will be decided in sku_discount_handler\n",
    "\n",
    "# Input/Output configuration\n",
    "# Data is now loaded from Snowflake instead of Excel\n",
    "INPUT_TABLE = 'MATERIALIZED_VIEWS.Pricing_data_extraction'\n",
    "PREVIOUS_OUTPUT_TABLE = 'MATERIALIZED_VIEWS.pricing_periodic_push'\n",
    "OUTPUT_FILE = f'module_3_output_{CAIRO_NOW.strftime(\"%Y%m%d_%H%M\")}.xlsx'\n",
    "\n",
    "print(f\"Module 3: Periodic Actions\")\n",
    "print(f\"Run Time (Cairo): {CAIRO_NOW.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Current Hour (Cairo): {CURRENT_HOUR}\")\n",
    "print(f\"Input: {INPUT_TABLE} (today's data)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD PREVIOUS ACTIONS (Track price reductions per day)\n",
    "# Now loads from Snowflake instead of local Excel files\n",
    "# =============================================================================\n",
    "\n",
    "def load_previous_actions():\n",
    "    \"\"\"Load previous Module 3 outputs from today (from Snowflake) to track price reductions.\"\"\"\n",
    "    try:\n",
    "        # Query today's previous actions from Snowflake\n",
    "        query = f\"\"\"\n",
    "        SELECT * FROM {PREVIOUS_OUTPUT_TABLE}\n",
    "        WHERE DATE(created_at) = '{TODAY}'\n",
    "        ORDER BY created_at\n",
    "        \"\"\"\n",
    "        df = query_snowflake(query)\n",
    "        \n",
    "        if len(df) == 0:\n",
    "            print(\"No previous Module 3 outputs found for today. This is the first run.\")\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        print(f\"Loaded {len(df)} previous action records from Snowflake\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading previous actions from Snowflake: {e}\")\n",
    "        print(\"This may be the first run or table doesn't exist yet.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def count_price_reductions_today(product_id, warehouse_id, previous_df):\n",
    "    \"\"\"Count how many price reductions this SKU has had today.\"\"\"\n",
    "    if previous_df.empty:\n",
    "        return 0\n",
    "    \n",
    "    mask = (\n",
    "        (previous_df['product_id'] == product_id) & \n",
    "        (previous_df['warehouse_id'] == warehouse_id) &\n",
    "        (previous_df['price_action'].str.contains('decrease', na=False))\n",
    "    )\n",
    "    return mask.sum()\n",
    "def count_price_increase_today(product_id, warehouse_id, previous_df):\n",
    "    \"\"\"Count how many price increase this SKU has had today.\"\"\"\n",
    "    if previous_df.empty:\n",
    "        return 0\n",
    "    \n",
    "    mask = (\n",
    "        (previous_df['product_id'] == product_id) & \n",
    "        (previous_df['warehouse_id'] == warehouse_id) &\n",
    "        (previous_df['price_action'].str.contains('increase', na=False))\n",
    "    )\n",
    "    return mask.sum()\n",
    "    \n",
    "\n",
    "print(\"Loading previous actions from today...\")\n",
    "df_previous_actions = load_previous_actions()\n",
    "print(f\"Previous actions loaded: {len(df_previous_actions)} records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    prev_inc = (\n",
    "        df_previous_actions.assign(\n",
    "            inc_flag=df_previous_actions['price_action'].str.contains('increase', case=False, na=False)\n",
    "        )\n",
    "        .groupby(['product_id', 'warehouse_id'])['inc_flag']\n",
    "        .sum()\n",
    "        .reset_index(name='increase_count')\n",
    "    )\n",
    "except:\n",
    "    prev_inc = pd.DataFrame(columns=['product_id', 'warehouse_id','increase_count'])\n",
    "try:    \n",
    "    prev_red = (\n",
    "    df_previous_actions.assign(\n",
    "        red_flag=df_previous_actions['price_action'].str.contains('decrease', case=False, na=False)\n",
    "    )\n",
    "    .groupby(['product_id', 'warehouse_id'])['red_flag']\n",
    "    .sum()\n",
    "    .reset_index(name='reduced_count') \n",
    "    )\n",
    "except:\n",
    "    prev_red = pd.DataFrame(columns=['product_id', 'warehouse_id','reduced_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SNOWFLAKE CONNECTION\n",
    "# =============================================================================\n",
    "# query_snowflake() and TIMEZONE are provided by queries_module.ipynb\n",
    "# (which also initializes Snowflake credentials from setup_environment_2)\n",
    "print(f\"Snowflake connection ready\")\n",
    "print(f\"Timezone: {TIMEZONE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# QUERY 1: TODAY'S UTH PERFORMANCE\n",
    "# =============================================================================\n",
    "UTH_LIVE_QUERY = f'''\n",
    "WITH params AS (\n",
    "    SELECT\n",
    "        CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE AS today,\n",
    "        HOUR(CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())) AS current_hour\n",
    "),\n",
    "\n",
    "-- Map dynamic tags to warehouse IDs using name matching\n",
    "qd_det AS (\n",
    "    SELECT DISTINCT \n",
    "        dt.id AS tag_id, \n",
    "        dt.name AS tag_name,\n",
    "        REPLACE(w.name, ' ', '') AS warehouse_name,\n",
    "        w.id AS warehouse_id,\n",
    "        warehouse_name ILIKE '%' || CASE \n",
    "            WHEN SPLIT_PART(tag_name, '_', 1) = 'El' THEN SPLIT_PART(tag_name, '_', 2) \n",
    "            ELSE SPLIT_PART(tag_name, '_', 1) \n",
    "        END || '%' AS contains_flag\n",
    "    FROM dynamic_tags dt\n",
    "    JOIN dynamic_taggables dta ON dt.id = dta.dynamic_tag_id \n",
    "    CROSS JOIN warehouses w \n",
    "    WHERE dt.id > 3000\n",
    "        AND dt.name LIKE '%QD_rets%'\n",
    "        AND w.id IN (1, 236, 337, 8, 339, 170, 501, 401, 703, 632, 797, 962)\n",
    "        AND contains_flag = 'true'\n",
    "),\n",
    "\n",
    "-- Get current active QD configurations\n",
    "qd_config AS (\n",
    "    SELECT * \n",
    "    FROM (\n",
    "        SELECT \n",
    "            product_id,\n",
    "            start_at,\n",
    "            end_at,\n",
    "            packing_unit_id,\n",
    "            id AS qd_id,\n",
    "            qd.warehouse_id,\n",
    "            MAX(CASE WHEN tier = 1 THEN quantity END) AS tier_1_qty,\n",
    "            MAX(CASE WHEN tier = 1 THEN discount_percentage END) AS tier_1_discount_pct,\n",
    "            MAX(CASE WHEN tier = 2 THEN quantity END) AS tier_2_qty,\n",
    "            MAX(CASE WHEN tier = 2 THEN discount_percentage END) AS tier_2_discount_pct,\n",
    "            MAX(CASE WHEN tier = 3 THEN quantity END) AS tier_3_qty,\n",
    "            MAX(CASE WHEN tier = 3 THEN discount_percentage END) AS tier_3_discount_pct\n",
    "        FROM (\n",
    "            SELECT \n",
    "                qd.id,\n",
    "                qdv.product_id,\n",
    "                qdv.packing_unit_id,\n",
    "                qdv.quantity,\n",
    "                qdv.discount_percentage,\n",
    "                qd.dynamic_tag_id,\n",
    "                qd.start_at,\n",
    "                qd.end_at,\n",
    "                ROW_NUMBER() OVER (\n",
    "                    PARTITION BY qdv.product_id, qdv.packing_unit_id, qd.id \n",
    "                    ORDER BY qdv.quantity\n",
    "                ) AS tier\n",
    "            FROM quantity_discounts qd \n",
    "            JOIN quantity_discount_values qdv ON qdv.quantity_discount_id = qd.id\n",
    "            WHERE active = 'true'\n",
    "        ) qd_tiers\n",
    "        JOIN qd_det qd ON qd.tag_id = qd_tiers.dynamic_tag_id\n",
    "        GROUP BY ALL\n",
    "    )\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY product_id, packing_unit_id, warehouse_id ORDER BY start_at DESC) = 1\n",
    "),\n",
    "\n",
    "-- Today's sales up-till-hour with discount breakdown\n",
    "today_uth_sales AS (\n",
    "    SELECT \n",
    "        pso.warehouse_id,\n",
    "        pso.product_id,\n",
    "        so.retailer_id,\n",
    "        pso.packing_unit_id,\n",
    "        pso.purchased_item_count AS qty,\n",
    "        pso.total_price AS nmv,\n",
    "        pso.ITEM_DISCOUNT_VALUE AS sku_discount_per_unit,\n",
    "        pso.ITEM_QUANTITY_DISCOUNT_VALUE AS qty_discount_per_unit,\n",
    "        qd.tier_1_qty,\n",
    "        qd.tier_2_qty,\n",
    "        qd.tier_3_qty,\n",
    "        -- Determine tier used\n",
    "        CASE \n",
    "            WHEN pso.ITEM_QUANTITY_DISCOUNT_VALUE = 0 OR qd.tier_1_qty IS NULL THEN 'Base'\n",
    "            WHEN qd.tier_3_qty IS NOT NULL AND pso.purchased_item_count >= qd.tier_3_qty THEN 'Tier 3'\n",
    "            WHEN qd.tier_2_qty IS NOT NULL AND pso.purchased_item_count >= qd.tier_2_qty THEN 'Tier 2'\n",
    "            WHEN qd.tier_1_qty IS NOT NULL AND pso.purchased_item_count >= qd.tier_1_qty THEN 'Tier 1'\n",
    "            ELSE 'Base'\n",
    "        END AS tier_used\n",
    "    FROM product_sales_order pso\n",
    "    JOIN sales_orders so ON so.id = pso.sales_order_id\n",
    "    LEFT JOIN qd_config qd \n",
    "        ON qd.product_id = pso.product_id \n",
    "        AND qd.packing_unit_id = pso.packing_unit_id\n",
    "        AND qd.warehouse_id = so.warehouse_id\n",
    "    CROSS JOIN params p\n",
    "    WHERE so.created_at::DATE = p.today\n",
    "        AND HOUR(so.created_at) < p.current_hour\n",
    "        AND so.sales_order_status_id NOT IN (7, 12)\n",
    "        AND so.channel IN ('telesales', 'retailer')\n",
    "        AND pso.purchased_item_count <> 0\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    warehouse_id,\n",
    "    product_id,\n",
    "    SUM(qty) AS uth_qty,\n",
    "    SUM(nmv) AS uth_nmv,\n",
    "    COUNT(DISTINCT retailer_id) AS uth_retailers,\n",
    "    -- SKU discount NMV and contribution\n",
    "    SUM(CASE WHEN sku_discount_per_unit > 0 THEN nmv ELSE 0 END) AS sku_discount_nmv_uth,\n",
    "    ROUND(SUM(CASE WHEN sku_discount_per_unit > 0 THEN nmv ELSE 0 END) * 100.0 / NULLIF(SUM(nmv), 0), 2) AS sku_disc_cntrb_uth,\n",
    "    -- Quantity discount NMV and contribution\n",
    "    SUM(CASE WHEN qty_discount_per_unit > 0 THEN nmv ELSE 0 END) AS qty_discount_nmv_uth,\n",
    "    ROUND(SUM(CASE WHEN qty_discount_per_unit > 0 THEN nmv ELSE 0 END) * 100.0 / NULLIF(SUM(nmv), 0), 2) AS qty_disc_cntrb_uth,\n",
    "    -- Tier-level NMV\n",
    "    SUM(CASE WHEN tier_used = 'Tier 1' THEN nmv ELSE 0 END) AS t1_nmv_uth,\n",
    "    SUM(CASE WHEN tier_used = 'Tier 2' THEN nmv ELSE 0 END) AS t2_nmv_uth,\n",
    "    SUM(CASE WHEN tier_used = 'Tier 3' THEN nmv ELSE 0 END) AS t3_nmv_uth,\n",
    "    -- Tier-level contributions\n",
    "    ROUND(SUM(CASE WHEN tier_used = 'Tier 1' THEN nmv ELSE 0 END) * 100.0 / NULLIF(SUM(nmv), 0), 2) AS t1_cntrb_uth,\n",
    "    ROUND(SUM(CASE WHEN tier_used = 'Tier 2' THEN nmv ELSE 0 END) * 100.0 / NULLIF(SUM(nmv), 0), 2) AS t2_cntrb_uth,\n",
    "    ROUND(SUM(CASE WHEN tier_used = 'Tier 3' THEN nmv ELSE 0 END) * 100.0 / NULLIF(SUM(nmv), 0), 2) AS t3_cntrb_uth\n",
    "FROM today_uth_sales\n",
    "GROUP BY warehouse_id, product_id\n",
    "HAVING SUM(nmv) > 0\n",
    "'''\n",
    "\n",
    "print(\"Loading today's UTH performance with discount contributions...\")\n",
    "df_uth_today = query_snowflake(UTH_LIVE_QUERY)\n",
    "print(f\"Loaded {len(df_uth_today)} UTH records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# QUERY 2: HISTORICAL HOURLY DISTRIBUTION (Last 4 Months) - By Category & Warehouse\n",
    "# =============================================================================\n",
    "# Uses get_hourly_distribution() from queries_module\n",
    "\n",
    "df_hourly_dist = get_hourly_distribution()\n",
    "\n",
    "# Rename column for backwards compatibility with rest of Module 3\n",
    "df_hourly_dist['avg_uth_pct'] = df_hourly_dist['avg_uth_pct_qty']\n",
    "print(f\"Using avg_uth_pct_qty as avg_uth_pct for Module 3 compatibility\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# QUERY 3 & 4: ACTIVE DISCOUNTS\n",
    "# =============================================================================\n",
    "\n",
    "# SKU Discounts query (from data_extraction.ipynb)\n",
    "ACTIVE_SKU_DISCOUNTS_QUERY = f'''\n",
    "WITH active_sku_discount AS ( \n",
    "    SELECT \n",
    "        x.id AS sku_discount_id,\n",
    "        retailer_id,\n",
    "        product_id,\n",
    "        packing_unit_id,\n",
    "        DISCOUNT_PERCENTAGE,\n",
    "        start_at,\n",
    "        end_at \n",
    "    FROM (\n",
    "        SELECT \n",
    "            sd.*,\n",
    "            f.value::INT AS retailer_id \n",
    "        FROM SKU_DISCOUNTS sd,\n",
    "        LATERAL FLATTEN(\n",
    "            input => SPLIT(\n",
    "                REPLACE(REPLACE(REPLACE(sd.retailer_ids, '{{', ''), '}}', ''), '\"', ''), \n",
    "                ','\n",
    "            )\n",
    "        ) f\n",
    "        WHERE start_at::DATE <= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "        and end_at::DATE >= CONVERT_TIMEZONE('{TIMEZONE}', 'Africa/Cairo', CURRENT_TIMESTAMP())::DATE\n",
    "            AND active = 'true'\n",
    "    ) x \n",
    "    JOIN SKU_DISCOUNT_VALUES sdv ON x.id = sdv.sku_discount_id\n",
    "    WHERE name_en = 'Special Discounts'\n",
    "    QUALIFY MAX(start_at) OVER (PARTITION BY retailer_id, product_id, packing_unit_id) = start_at \n",
    ")\n",
    "\n",
    "SELECT \n",
    "    product_id, \n",
    "    warehouse_id,\n",
    "    AVG(DISCOUNT_PERCENTAGE) AS active_sku_disc_pct,\n",
    "    1 AS has_active_sku_discount\n",
    "FROM (\n",
    "    SELECT \n",
    "        asd.*,\n",
    "        warehouse_id \n",
    "    FROM active_sku_discount asd \n",
    "    JOIN materialized_views.retailer_polygon rp ON rp.retailer_id = asd.retailer_id\n",
    "    JOIN WAREHOUSE_DISPATCHING_RULES wdr ON wdr.product_id = asd.product_id\n",
    "    JOIN DISPATCHING_POLYGONS dp ON dp.id = wdr.DISPATCHING_POLYGON_ID AND dp.district_id = rp.district_id\n",
    ")\n",
    "GROUP BY ALL\n",
    "'''\n",
    "\n",
    "# Active QD Query - Reuses the same CTE structure from UTH_LIVE_QUERY\n",
    "ACTIVE_QD_QUERY = f'''\n",
    "WITH qd_det AS (\n",
    "    SELECT DISTINCT \n",
    "        dt.id AS tag_id, \n",
    "        dt.name AS tag_name,\n",
    "        REPLACE(w.name, ' ', '') AS warehouse_name,\n",
    "        w.id AS warehouse_id,\n",
    "        warehouse_name ILIKE '%' || CASE \n",
    "            WHEN SPLIT_PART(tag_name, '_', 1) = 'El' THEN SPLIT_PART(tag_name, '_', 2) \n",
    "            ELSE SPLIT_PART(tag_name, '_', 1) \n",
    "        END || '%' AS contains_flag\n",
    "    FROM dynamic_tags dt\n",
    "    JOIN dynamic_taggables dta ON dt.id = dta.dynamic_tag_id \n",
    "    CROSS JOIN warehouses w \n",
    "    WHERE dt.id > 3000\n",
    "        AND dt.name LIKE '%QD_rets%'\n",
    "        AND w.id IN (1, 236, 337, 8, 339, 170, 501, 401, 703, 632, 797, 962)\n",
    "        AND contains_flag = 'true'\n",
    "),\n",
    "\n",
    "qd_config AS (\n",
    "    SELECT * \n",
    "    FROM (\n",
    "        SELECT \n",
    "            product_id,\n",
    "            packing_unit_id,\n",
    "            qd.warehouse_id,\n",
    "            MAX(CASE WHEN tier = 1 THEN quantity END) AS qd_tier_1_qty,\n",
    "            MAX(CASE WHEN tier = 1 THEN discount_percentage END) AS qd_tier_1_disc_pct,\n",
    "            MAX(CASE WHEN tier = 2 THEN quantity END) AS qd_tier_2_qty,\n",
    "            MAX(CASE WHEN tier = 2 THEN discount_percentage END) AS qd_tier_2_disc_pct,\n",
    "            MAX(CASE WHEN tier = 3 THEN quantity END) AS qd_tier_3_qty,\n",
    "            MAX(CASE WHEN tier = 3 THEN discount_percentage END) AS qd_tier_3_disc_pct\n",
    "        FROM (\n",
    "            SELECT \n",
    "                qd.id,\n",
    "                qdv.product_id,\n",
    "                qdv.packing_unit_id,\n",
    "                qdv.quantity,\n",
    "                qdv.discount_percentage,\n",
    "                qd.dynamic_tag_id,\n",
    "                qd.start_at,\n",
    "                ROW_NUMBER() OVER (\n",
    "                    PARTITION BY qdv.product_id, qdv.packing_unit_id, qd.id \n",
    "                    ORDER BY qdv.quantity\n",
    "                ) AS tier\n",
    "            FROM quantity_discounts qd \n",
    "            JOIN quantity_discount_values qdv ON qdv.quantity_discount_id = qd.id\n",
    "            WHERE  active = TRUE\n",
    "        ) qd_tiers\n",
    "        JOIN qd_det qd ON qd.tag_id = qd_tiers.dynamic_tag_id\n",
    "        GROUP BY ALL\n",
    "    )\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY product_id, packing_unit_id, warehouse_id ORDER BY qd_tier_1_qty DESC) = 1\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    product_id,\n",
    "    warehouse_id,\n",
    "    qd_tier_1_qty,\n",
    "    qd_tier_1_disc_pct,\n",
    "    qd_tier_2_qty,\n",
    "    qd_tier_2_disc_pct,\n",
    "    qd_tier_3_qty,\n",
    "    qd_tier_3_disc_pct,\n",
    "    1 AS has_active_qd\n",
    "FROM qd_config\n",
    "'''\n",
    "\n",
    "print(\"Loading active SKU discounts...\")\n",
    "df_active_sku_disc = query_snowflake(ACTIVE_SKU_DISCOUNTS_QUERY)\n",
    "print(f\"Loaded {len(df_active_sku_disc)} active SKU discount records\")\n",
    "\n",
    "print(\"Loading active Quantity discounts...\")\n",
    "df_active_qd = query_snowflake(ACTIVE_QD_QUERY)\n",
    "print(f\"Loaded {len(df_active_qd)} active QD records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD DATA FROM SNOWFLAKE (Instead of Excel file)\n",
    "# =============================================================================\n",
    "print(\"Loading data from Snowflake...\")\n",
    "\n",
    "# Query to get today's data from Pricing_data_extraction\n",
    "LOAD_QUERY = f\"\"\"\n",
    "SELECT * FROM {INPUT_TABLE}\n",
    "WHERE created_at = '{datetime.now(CAIRO_TZ).date()}'\n",
    "\"\"\"\n",
    "\n",
    "df = query_snowflake(LOAD_QUERY)\n",
    "print(f\"Loaded {len(df)} records from Snowflake\")\n",
    "\n",
    "# Refresh live data using queries_module\n",
    "print(\"\\nRefreshing live data...\")\n",
    "\n",
    "# Refresh stocks\n",
    "df_fresh_stocks = get_current_stocks()\n",
    "df = df.drop(columns=['stocks'], errors='ignore')\n",
    "df = df.merge(df_fresh_stocks, on=['warehouse_id', 'product_id'], how='left')\n",
    "df['stocks'] = df['stocks'].fillna(0)\n",
    "\n",
    "# Refresh current prices\n",
    "df_fresh_prices = get_current_prices()\n",
    "df = df.drop(columns=['current_price'], errors='ignore')\n",
    "df = df.merge(df_fresh_prices[['cohort_id', 'product_id', 'current_price']], \n",
    "              on=['cohort_id', 'product_id'], how='left')\n",
    "\n",
    "# Refresh WAC\n",
    "df_fresh_wac = get_current_wac()\n",
    "df = df.drop(columns=['wac_p'], errors='ignore')\n",
    "df = df.merge(df_fresh_wac, on='product_id', how='left')\n",
    "\n",
    "# Refresh cart rules\n",
    "df_fresh_cart = get_current_cart_rules()\n",
    "df = df.drop(columns=['current_cart_rule'], errors='ignore')\n",
    "df = df.merge(df_fresh_cart, on=['cohort_id', 'product_id'], how='left')\n",
    "\n",
    "print(f\"Live data refreshed: stocks, prices, WAC, cart rules\")\n",
    "\n",
    "# =============================================================================\n",
    "# =============================================================================\n",
    "# LOAD PERCENTILE DATA FOR CART RULES\n",
    "# =============================================================================\n",
    "df_percentiles = get_percentile_data()\n",
    "\n",
    "# Refresh market prices and margin tiers using new standalone functions\n",
    "print(\"\\nRefreshing market prices and margin tiers...\")\n",
    "\n",
    "# Get fresh market data (no input required)\n",
    "df_fresh_market = get_market_data()\n",
    "print(f\"  Fetched {len(df_fresh_market)} market data records\")\n",
    "\n",
    "# Get fresh margin tiers (no input required)\n",
    "df_fresh_tiers = get_margin_tiers()\n",
    "print(f\"  Fetched {len(df_fresh_tiers)} margin tier records\")\n",
    "\n",
    "# Drop old market columns and merge fresh data\n",
    "market_cols_to_drop = [\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', \n",
    "    'market_75', 'market_max', 'above_market',\n",
    "    'minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum',\n",
    "    'ben_soliman_price', 'final_min_price', 'final_max_price', 'final_mod_price',\n",
    "    'final_true_min', 'final_true_max', 'min_scrapped', 'scrapped25', \n",
    "    'scrapped50', 'scrapped75', 'max_scrapped'\n",
    "]\n",
    "df = df.drop(columns=[c for c in market_cols_to_drop if c in df.columns], errors='ignore')\n",
    "\n",
    "# Merge fresh market data\n",
    "df = df.merge(\n",
    "    df_fresh_market, \n",
    "    on=['cohort_id', 'product_id','region'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop old margin tier columns and merge fresh data\n",
    "margin_tier_cols_to_drop = [\n",
    "    'margin_tier_below', 'margin_tier_1', 'margin_tier_2', 'margin_tier_3',\n",
    "    'margin_tier_4', 'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2',\n",
    "    'optimal_bm', 'min_boundary', 'max_boundary', 'median_bm',\n",
    "    'effective_min_margin', 'margin_step'\n",
    "]\n",
    "df = df.drop(columns=[c for c in margin_tier_cols_to_drop if c in df.columns], errors='ignore')\n",
    "\n",
    "# Merge fresh margin tiers\n",
    "df = df.merge(\n",
    "    df_fresh_tiers, \n",
    "    on=['cohort_id', 'product_id','region'], \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Market data refreshed\")\n",
    "\n",
    "# Merge UTH today data - drop old columns first\n",
    "uth_cols = ['uth_qty', 'uth_nmv', 'uth_retailers', 'sku_discount_nmv_uth', 'sku_disc_cntrb_uth',\n",
    "            'qty_discount_nmv_uth', 'qty_disc_cntrb_uth', 't1_nmv_uth', 't2_nmv_uth', 't3_nmv_uth',\n",
    "            't1_cntrb_uth', 't2_cntrb_uth', 't3_cntrb_uth']\n",
    "df = df.drop(columns=[c for c in uth_cols if c in df.columns], errors='ignore')\n",
    "\n",
    "if len(df_uth_today) > 0:\n",
    "    df = df.merge(df_uth_today, on=['warehouse_id', 'product_id'], how='left')\n",
    "else:\n",
    "    for col in uth_cols:\n",
    "        df[col] = 0\n",
    "\n",
    "# Merge hourly distribution - drop old column first (now by warehouse_id + cat)\n",
    "df = df.drop(columns=['avg_uth_pct'], errors='ignore')\n",
    "if len(df_hourly_dist) > 0:\n",
    "    df = df.merge(df_hourly_dist, on=['warehouse_id', 'cat'], how='left')\n",
    "else:\n",
    "    df['avg_uth_pct'] = 0.5  # Default 50%\n",
    "\n",
    "# Merge active SKU discounts - drop old columns first\n",
    "sku_disc_cols = ['has_active_sku_discount', 'active_sku_disc_pct', 'active_sku_discount_value']\n",
    "df = df.drop(columns=[c for c in sku_disc_cols if c in df.columns], errors='ignore')\n",
    "\n",
    "if len(df_active_sku_disc) > 0:\n",
    "    df = df.merge(df_active_sku_disc, on=['warehouse_id', 'product_id'], how='left')\n",
    "else:\n",
    "    df['has_active_sku_discount'] = 0\n",
    "    df['active_sku_disc_pct'] = 0\n",
    "\n",
    "# Merge active QD - drop old columns first\n",
    "qd_cols = ['has_active_qd', 'qd_tier_1_qty', 'qd_tier_1_disc_pct', \n",
    "           'qd_tier_2_qty', 'qd_tier_2_disc_pct', 'qd_tier_3_qty', 'qd_tier_3_disc_pct']\n",
    "df = df.drop(columns=[c for c in qd_cols if c in df.columns], errors='ignore')\n",
    "\n",
    "if len(df_active_qd) > 0:\n",
    "    df = df.merge(df_active_qd, on=['warehouse_id', 'product_id'], how='left')\n",
    "else:\n",
    "    df['has_active_qd'] = 0\n",
    "    df['qd_tier_1_qty'] = 0\n",
    "    df['qd_tier_1_disc_pct'] = 0\n",
    "    df['qd_tier_2_qty'] = 0\n",
    "    df['qd_tier_2_disc_pct'] = 0\n",
    "    df['qd_tier_3_qty'] = 0\n",
    "    df['qd_tier_3_disc_pct'] = 0\n",
    "\n",
    "# Fill NaN\n",
    "df['uth_qty'] = df['uth_qty'].fillna(0)\n",
    "df['uth_retailers'] = df['uth_retailers'].fillna(0)\n",
    "df['avg_uth_pct'] = df['avg_uth_pct'].fillna(0.5)\n",
    "df['has_active_sku_discount'] = df['has_active_sku_discount'].fillna(0)\n",
    "df['active_sku_discount_value'] = df.get('active_sku_discount_value', pd.Series([0]*len(df))).fillna(0)\n",
    "df['has_active_qd'] = df['has_active_qd'].fillna(0)\n",
    "df['qd_tier_1_qty'] = df['qd_tier_1_qty'].fillna(0)\n",
    "df['qd_tier_1_disc_pct'] = df['qd_tier_1_disc_pct'].fillna(0)\n",
    "df['qd_tier_2_qty'] = df['qd_tier_2_qty'].fillna(0)\n",
    "df['qd_tier_2_disc_pct'] = df['qd_tier_2_disc_pct'].fillna(0)\n",
    "df['qd_tier_3_qty'] = df['qd_tier_3_qty'].fillna(0)\n",
    "df['qd_tier_3_disc_pct'] = df['qd_tier_3_disc_pct'].fillna(0)\n",
    "\n",
    "# =============================================================================\n",
    "# TURNOVER-BASED DOH: Calculate responsive_doh and min_induced_price (vectorized)\n",
    "# =============================================================================\n",
    "# responsive_doh = stocks / yesterday_qty (yesterday_qty comes from INPUT_TABLE)\n",
    "df['yesterday_qty'] = pd.to_numeric(df.get('yesterday_qty', 0), errors='coerce').fillna(0)\n",
    "df['responsive_doh'] = np.where(\n",
    "    df['yesterday_qty'] > 0,\n",
    "    df['stocks'] / df['yesterday_qty'],\n",
    "    999  # No sales yesterday = infinite DOH\n",
    ")\n",
    "\n",
    "# min_induced_price = wac_p * (0.9 + target_margin * 0.5)\n",
    "# This is the floor price for induced pricing when DOH > 30\n",
    "df['target_margin'] = pd.to_numeric(df.get('target_margin', 0), errors='coerce').fillna(0)\n",
    "df['min_induced_price'] = df['wac_p'] * (0.9)\n",
    "\n",
    "print(f\"Data merged. Total records: {len(df)}\")\n",
    "print(f\"  SKUs with active SKU discount: {(df['has_active_sku_discount'] == 1).sum()}\")\n",
    "print(f\"  SKUs with active QD: {(df['has_active_qd'] == 1).sum()}\")\n",
    "print(f\"  SKUs with high DOH (>30): {(df['responsive_doh'] > 30).sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def calculate_margin(price, wac):\n",
    "    if pd.isna(price) or pd.isna(wac) or price == 0:\n",
    "        return None\n",
    "    return (price - wac) / price\n",
    "\n",
    "def get_market_tiers(row):\n",
    "    \"\"\"Get sorted list of market price tiers.\"\"\"\n",
    "    tiers = []\n",
    "    for col in ['minimum', 'percentile_25', 'percentile_50', 'percentile_75', 'maximum']:\n",
    "        val = row.get(col)\n",
    "        if pd.notna(val) and val > 0:\n",
    "            tiers.append(val)\n",
    "    return sorted(set(tiers))\n",
    "\n",
    "def get_margin_tiers(row):\n",
    "    \"\"\"Get sorted list of margin-based price tiers (converted to prices).\"\"\"\n",
    "    tiers = []\n",
    "    wac = row.get('wac_p', 0)\n",
    "    if wac <= 0:\n",
    "        return tiers\n",
    "    \n",
    "    for tier_col in ['margin_tier_below','margin_tier_1', 'margin_tier_2', 'margin_tier_3', \n",
    "                     'margin_tier_4', 'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2']:\n",
    "        margin = row.get(tier_col)\n",
    "        if pd.notna(margin) and 0 < margin < 1:\n",
    "            price = wac / (1 - margin)\n",
    "            tiers.append(round(price, 2))\n",
    "    return sorted(set(tiers))\n",
    "\n",
    "def find_next_price_above(current_price, row):\n",
    "    \"\"\"\n",
    "    Find the first price tier ABOVE current_price by at least MIN_PRICE_CHANGE_EGP.\n",
    "    Market first, then margin. Skips tiers less than 0.25 EGP above.\n",
    "    \"\"\"\n",
    "    current_price = float(current_price) if current_price else 0\n",
    "    if pd.isna(current_price) or current_price <= 0:\n",
    "        return current_price\n",
    "    \n",
    "    for tier in get_market_tiers(row):\n",
    "        if tier > current_price + MIN_PRICE_CHANGE_EGP:\n",
    "            return round(tier, 2)\n",
    "    \n",
    "    for tier in get_margin_tiers(row):\n",
    "        if tier > current_price + MIN_PRICE_CHANGE_EGP:\n",
    "            return round(tier, 2)\n",
    "    \n",
    "    return current_price\n",
    "\n",
    "def find_next_price_below(current_price, row):\n",
    "    \"\"\"\n",
    "    Find the first price tier BELOW current_price by at least MIN_PRICE_CHANGE_EGP.\n",
    "    Market first, then margin. Skips tiers less than 0.25 EGP below.\n",
    "    \"\"\"\n",
    "    current_price = float(current_price) if current_price else 0\n",
    "    if pd.isna(current_price) or current_price <= 0:\n",
    "        return current_price\n",
    "    market_tiers = get_market_tiers(row)\n",
    "    for tier in reversed(market_tiers):\n",
    "        if tier < current_price - MIN_PRICE_CHANGE_EGP:\n",
    "            return round(tier, 2)\n",
    "    if len(market_tiers) == 0:\n",
    "        for tier in reversed(get_margin_tiers(row)):\n",
    "            if tier < current_price - MIN_PRICE_CHANGE_EGP:\n",
    "                return round(tier, 2)\n",
    "    \n",
    "    return current_price\n",
    "\n",
    "def find_price_n_steps_below(current_price, n_steps, row):\n",
    "    \"\"\"Find price N steps below current (iteratively find next tier below).\"\"\"\n",
    "    price = current_price\n",
    "    for _ in range(n_steps):\n",
    "        next_price = find_next_price_below(price, row)\n",
    "        if next_price >= price:  # No tier below found\n",
    "            break\n",
    "        price = next_price\n",
    "    return price\n",
    "\n",
    "def is_cart_too_open(row):\n",
    "    \"\"\"Check if cart rule is too open: > normal_refill + 10*std\"\"\"\n",
    "    normal_refill = float(row.get('normal_refill', 5) or 5)\n",
    "    stddev = float(row.get('refill_stddev', 2) or 2)\n",
    "    current_cart = float(row.get('cart_rule', normal_refill) or normal_refill)\n",
    "    threshold = normal_refill + (10 * stddev)\n",
    "    return current_cart > threshold\n",
    "\n",
    "def adjust_cart_rule(current_cart, direction, row):\n",
    "    \"\"\"Adjust cart rule by 20% up or down.\"\"\"\n",
    "    normal_refill = float(row.get('normal_refill', 5) or 5)\n",
    "    stddev = float(row.get('refill_stddev', 2) or 2)\n",
    "    current_cart = float(current_cart or 5)\n",
    "    \n",
    "    if direction == 'increase':\n",
    "        new_cart = current_cart * (1 + CART_INCREASE_PCT)\n",
    "        new_cart = min(new_cart, MAX_CART_RULE)\n",
    "    else:  # decrease\n",
    "        # Formula: max(0.8 * cart, normal_refill + 3*std)\n",
    "        new_cart = current_cart * (1 - CART_DECREASE_PCT)\n",
    "        min_floor = normal_refill + (3 * stddev)\n",
    "        new_cart = max(new_cart, min_floor, MIN_CART_RULE)\n",
    "    \n",
    "    return int(new_cart)\n",
    "\n",
    "def get_highest_qd_tier_contribution(row):\n",
    "    \"\"\"Find which QD tier has highest contribution.\"\"\"\n",
    "    t1 = row.get('yesterday_t1_cntrb', 0) or 0\n",
    "    t2 = row.get('yesterday_t2_cntrb', 0) or 0\n",
    "    t3 = row.get('yesterday_t3_cntrb', 0) or 0\n",
    "    \n",
    "    if t1 >= t2 and t1 >= t3 and t1 > 0:\n",
    "        return 'T1', t1\n",
    "    elif t2 >= t1 and t2 >= t3 and t2 > 0:\n",
    "        return 'T2', t2\n",
    "    elif t3 > 0:\n",
    "        return 'T3', t3\n",
    "    return None, 0\n",
    "\n",
    "print(\"Helper functions loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PERCENTILE HELPER FUNCTIONS FOR CART RULES\n",
    "# =============================================================================\n",
    "\n",
    "def get_current_percentile_level(current_cart_rule, percentile_row):\n",
    "    \"\"\"Determine which percentile level current cart rule corresponds to.\"\"\"\n",
    "    if len(percentile_row) == 0:\n",
    "        return None\n",
    "    \n",
    "    perc_95 = percentile_row.iloc[0]['perc_95']\n",
    "    perc_75 = percentile_row.iloc[0]['perc_75']\n",
    "    perc_50 = percentile_row.iloc[0]['perc_50']\n",
    "    perc_25 = percentile_row.iloc[0]['perc_25']\n",
    "    \n",
    "    # Determine current level (with tolerance for rounding)\n",
    "    if pd.notna(perc_95) and abs(current_cart_rule - perc_95) <= 2:\n",
    "        return 95\n",
    "    elif pd.notna(perc_75) and abs(current_cart_rule - perc_75) <= 2:\n",
    "        return 75\n",
    "    elif pd.notna(perc_50) and abs(current_cart_rule - perc_50) <= 2:\n",
    "        return 50\n",
    "    elif pd.notna(perc_25) and abs(current_cart_rule - perc_25) <= 2:\n",
    "        return 25\n",
    "    return None\n",
    "\n",
    "def get_next_lower_percentile(current_level, percentile_row):\n",
    "    \"\"\"Get next lower percentile value.\"\"\"\n",
    "    if len(percentile_row) == 0:\n",
    "        return None\n",
    "    \n",
    "    if current_level == 95:\n",
    "        return percentile_row.iloc[0]['perc_75']\n",
    "    elif current_level == 75:\n",
    "        return percentile_row.iloc[0]['perc_50']\n",
    "    elif current_level == 50:\n",
    "        return percentile_row.iloc[0]['perc_25']\n",
    "    elif current_level == 25:\n",
    "        return percentile_row.iloc[0]['perc_25']  # Stay at minimum\n",
    "    return None\n",
    "\n",
    "print(\"Percentile helper functions loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HELPER: Calculate margin step from existing tier prices\n",
    "# =============================================================================\n",
    "def calculate_margin_step(row):\n",
    "    \"\"\"\n",
    "    Calculate the margin step size from existing margin tiers.\n",
    "    Used to induce prices below available tiers when DOH > 30.\n",
    "    \n",
    "    Returns:\n",
    "        Average step size between consecutive tiers, or 0.015 (1.5%) as default\n",
    "    \"\"\"\n",
    "    tier_cols = ['margin_tier_1', 'margin_tier_2', 'margin_tier_3', \n",
    "                 'margin_tier_4', 'margin_tier_5']\n",
    "    tiers = [row.get(col) for col in tier_cols]\n",
    "    valid_tiers = [t for t in tiers if pd.notna(t) and t is not None]\n",
    "    \n",
    "    if len(valid_tiers) >= 2:\n",
    "        # Calculate steps between consecutive tiers\n",
    "        steps = [abs(valid_tiers[i+1] - valid_tiers[i]) for i in range(len(valid_tiers)-1)]\n",
    "        return np.mean(steps) if steps else 0.01\n",
    "    \n",
    "    # Fallback: use market margins if available\n",
    "    market_cols = ['market_min', 'market_25', 'market_50', 'market_75', 'market_max']\n",
    "    markets = [row.get(col) for col in market_cols]\n",
    "    valid_markets = [m for m in markets if pd.notna(m) and m is not None]\n",
    "    \n",
    "    if len(valid_markets) >= 2:\n",
    "        steps = [abs(valid_markets[i+1] - valid_markets[i]) for i in range(len(valid_markets)-1)]\n",
    "        return np.mean(steps) if steps else 0.01\n",
    "    \n",
    "    return 0.01 # Default 1% step\n",
    "\n",
    "def calculate_induced_price(row, current_price):\n",
    "    \"\"\"\n",
    "    Calculate induced price by reducing margin by one step.\n",
    "    Used for Zero Demand and High DOH scenarios.\n",
    "    \n",
    "    Returns:\n",
    "        Induced price if valid and lower than current, else None\n",
    "    \"\"\"\n",
    "    wac_p = float(row.get('wac_p', 0) or 0)\n",
    "    if wac_p <= 0 or current_price <= 0:\n",
    "        return None\n",
    "    \n",
    "    current_margin = (current_price - wac_p) / current_price\n",
    "    margin_step = calculate_margin_step(row)\n",
    "    new_margin = current_margin - margin_step\n",
    "    \n",
    "    if new_margin >= 1:\n",
    "        return None\n",
    "    \n",
    "    induced_price = wac_p / (1 - new_margin)\n",
    "    induced_price = round(induced_price * 4) / 4  # Round to 0.25\n",
    "    \n",
    "    # Apply floors: min_induced_price and commercial_min_price\n",
    "    min_induced = float(row.get('min_induced_price', 0) or 0)\n",
    "    commercial_min = float(row.get('commercial_min_price', 0) or 0)\n",
    "    floor_price = max(min_induced, commercial_min) if commercial_min > 0 else min_induced\n",
    "    \n",
    "    if induced_price < floor_price:\n",
    "        return None  # Can't reduce further\n",
    "    \n",
    "    return induced_price if induced_price < current_price else None\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN ENGINE: GENERATE PERIODIC ACTION\n",
    "# =============================================================================\n",
    "\n",
    "def generate_periodic_action(row, previous_df):\n",
    "    \"\"\"\n",
    "    Generate periodic action based on UTH performance.\n",
    "    \n",
    "    Logic:\n",
    "    - Zero Demand: 1 step below current + SKU discount\n",
    "    - On Track: No action\n",
    "    - Growing: Deactivate discounts or increase price, reduce cart if too open\n",
    "    - Dropping: Based on qty_ratio vs retailer_ratio:\n",
    "        - qty OK, retailers dropping: SKU discount (then price if already has)\n",
    "        - qty dropping, retailers OK: QD (then price if already has)\n",
    "        - both dropping: SKU discount (then price if already has)\n",
    "    - Price reduction max 2x per day\n",
    "    \"\"\"\n",
    "    product_id = row.get('product_id')\n",
    "    warehouse_id = row.get('warehouse_id')\n",
    "    \n",
    "    result = {\n",
    "        'product_id': product_id,\n",
    "        'warehouse_id': warehouse_id,\n",
    "        'cohort_id': row.get('cohort_id'),\n",
    "        'sku': row.get('sku'),\n",
    "        'brand': row.get('brand'),\n",
    "        'cat': row.get('cat'),\n",
    "        'stocks': row.get('stocks', 0),\n",
    "        'current_price': row.get('current_price'),\n",
    "        'wac_p': row.get('wac_p'),\n",
    "        'uth_qty': row.get('uth_qty', 0),\n",
    "        'uth_retailers': row.get('uth_retailers', 0),\n",
    "        'p80_daily_240d': row.get('p80_daily_240d', 1),\n",
    "        'p70_daily_retailers_240d': row.get('p70_daily_retailers_240d', 1),\n",
    "        'avg_uth_pct': row.get('avg_uth_pct', 0.5),\n",
    "        # Today's UTH discount contributions\n",
    "        'sku_disc_cntrb_uth': row.get('sku_disc_cntrb_uth', 0) or 0,\n",
    "        't1_cntrb_uth': row.get('t1_cntrb_uth', 0) or 0,\n",
    "        't2_cntrb_uth': row.get('t2_cntrb_uth', 0) or 0,\n",
    "        't3_cntrb_uth': row.get('t3_cntrb_uth', 0) or 0,\n",
    "        'uth_status': None,\n",
    "        'qty_ratio': None,\n",
    "        'retailer_ratio': None,\n",
    "        'new_price': None,\n",
    "        'price_action': None,\n",
    "        'current_cart_rule':row.get('current_cart_rule'),\n",
    "        'new_cart_rule': None,\n",
    "        'activate_sku_discount': False,  # True = SKU should have discount after this run\n",
    "        'activate_qd': False,             # True = SKU should have QD after this run\n",
    "        'keep_qd_tiers': None,            # List of QD tiers to keep (e.g., ['T1', 'T2'])\n",
    "        # QD tier configuration (passed to qd_handler)\n",
    "        'qd_tier_1_qty': row.get('qd_tier_1_qty', 0) or 0,\n",
    "        'qd_tier_1_disc_pct': row.get('qd_tier_1_disc_pct', 0) or 0,\n",
    "        'qd_tier_2_qty': row.get('qd_tier_2_qty', 0) or 0,\n",
    "        'qd_tier_2_disc_pct': row.get('qd_tier_2_disc_pct', 0) or 0,\n",
    "        'qd_tier_3_qty': row.get('qd_tier_3_qty', 0) or 0,\n",
    "        'qd_tier_3_disc_pct': row.get('qd_tier_3_disc_pct', 0) or 0,\n",
    "        'removed_discount': None,         # Which discount was removed (for Growing)\n",
    "        'removed_discount_cntrb': 0,      # Contribution of removed discount\n",
    "        'price_reductions_today': row.get('reduced_count', 0) or 0,\n",
    "        'action_reason': None,\n",
    "        # =====================================================================\n",
    "        # ADDITIONAL COLUMNS FOR QD AND SKU DISCOUNT HANDLERS\n",
    "        # =====================================================================\n",
    "        # Pricing and margin data\n",
    "        'target_margin': row.get('target_margin'),\n",
    "        'min_boundary': row.get('min_boundary'),\n",
    "        'doh': row.get('doh', 0),  # Days on hand - for SKU discount handler\n",
    "        'mtd_qty': row.get('mtd_qty', 0),  # MTD quantity - for QD ranking\n",
    "        # Active SKU discount info - for SKU discount handler\n",
    "        'active_sku_disc_pct': row.get('active_sku_disc_pct', 0),\n",
    "        'has_active_sku_discount': row.get('has_active_sku_discount', 0),\n",
    "        'has_active_qd': row.get('has_active_qd', 0),\n",
    "        # Market margins (converted to prices in handlers)\n",
    "        'below_market': row.get('below_market'),\n",
    "        'market_min': row.get('market_min'),\n",
    "        'market_25': row.get('market_25'),\n",
    "        'market_50': row.get('market_50'),\n",
    "        'market_75': row.get('market_75'),\n",
    "        'market_max': row.get('market_max'),\n",
    "        'above_market': row.get('above_market'),\n",
    "        # Margin tiers (converted to prices in handlers)\n",
    "        'margin_tier_below': row.get('margin_tier_below'),\n",
    "        'margin_tier_1': row.get('margin_tier_1'),\n",
    "        'margin_tier_2': row.get('margin_tier_2'),\n",
    "        'margin_tier_3': row.get('margin_tier_3'),\n",
    "        'margin_tier_4': row.get('margin_tier_4'),\n",
    "        'margin_tier_5': row.get('margin_tier_5'),\n",
    "        'margin_tier_above_1': row.get('margin_tier_above_1'),\n",
    "        'margin_tier_above_2': row.get('margin_tier_above_2'),\n",
    "    }\n",
    "    \n",
    "    # Skip if OOS (price only in Module 2)\n",
    "    if row.get('stocks', 0) <= 0:\n",
    "        result['action_reason'] = 'OOS - skip (price only in Module 2)'\n",
    "        return result\n",
    "    \n",
    "    # Skip if below minimum stock (stock < min selling unit qty)\n",
    "    if row.get('below_min_stock_flag', 0) == 1:\n",
    "        result['action_reason'] = 'Below min stock - skip (cannot sell)'\n",
    "        return result\n",
    "    \n",
    "    # Count previous price reductions today\n",
    "    price_reductions_today = row.get('reduced_count', 0)\n",
    "    can_reduce_price = price_reductions_today < MAX_PRICE_REDUCTIONS_PER_DAY\n",
    "\n",
    "    # Count previous price increase today\n",
    "    price_increase_today = row.get('increase_count', 0)\n",
    "    can_increase_price = price_increase_today < MAX_PRICE_REDUCTIONS_PER_DAY    \n",
    "    \n",
    "    # Calculate UTH benchmark: historical_pct * P80_qty\n",
    "    # Convert to float to handle decimal.Decimal from Snowflake\n",
    "    p80_qty = float(row.get('p80_daily_240d', 1) or 1)\n",
    "    p70_retailers = float(row.get('p70_daily_retailers_240d', 1) or 1)\n",
    "    avg_uth_pct = float(row.get('avg_uth_pct', 0.5) or 0.5)\n",
    "    \n",
    "    uth_qty_target = p80_qty * avg_uth_pct\n",
    "    uth_retailer_target = p70_retailers * avg_uth_pct\n",
    "    \n",
    "    uth_qty = float(row.get('uth_qty', 0) or 0)\n",
    "    uth_retailers = float(row.get('uth_retailers', 0) or 0)\n",
    "    \n",
    "    # Calculate UTH ratios\n",
    "    qty_ratio = uth_qty / uth_qty_target if uth_qty_target > 0 else 0\n",
    "    retailer_ratio = uth_retailers / uth_retailer_target if uth_retailer_target > 0 else 0\n",
    "    \n",
    "    result['uth_qty_target'] = round(uth_qty_target, 2)\n",
    "    result['uth_retailer_target'] = round(uth_retailer_target, 2)\n",
    "    result['qty_ratio'] = round(qty_ratio, 2)\n",
    "    result['retailer_ratio'] = round(retailer_ratio, 2)\n",
    "    \n",
    "    current_price = float(row.get('current_price') or 0)\n",
    "    current_cart = float(row.get('current_cart_rule', row.get('normal_refill', 10)) or 10)\n",
    "    has_sku_disc = row.get('has_active_sku_discount', 0) == 1\n",
    "    has_qd = row.get('has_active_qd', 0) == 1\n",
    "    \n",
    "    # Determine if qty/retailers are dropping (below threshold)\n",
    "    qty_dropping = qty_ratio < UTH_DROPPING_THRESHOLD\n",
    "    qty_ok = qty_ratio >= UTH_DROPPING_THRESHOLD\n",
    "    retailer_dropping = retailer_ratio < UTH_DROPPING_THRESHOLD\n",
    "    retailer_ok = retailer_ratio >= UTH_DROPPING_THRESHOLD\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASE 1: Zero demand today (uth_qty = 0)\n",
    "    # - Reduce price ONCE per day + apply SKU discount\n",
    "    # - If already reduced price today: just keep SKU discount (no additional reduction)\n",
    "    # - Open cart if tight (both cases)\n",
    "    # =========================================================================\n",
    "    if uth_qty == 0:\n",
    "        result['uth_status'] = 'Zero Demand'\n",
    "        result['activate_sku_discount'] = True\n",
    "        \n",
    "        # Check if cart rule is tight (< normal_refill + 10*std) and increase if so\n",
    "        normal_refill = float(row.get('normal_refill', 5) or 5)\n",
    "        stddev = float(row.get('refill_stddev', 2) or 2)\n",
    "        cart_threshold = normal_refill + (10 * stddev)\n",
    "        \n",
    "        if current_cart < cart_threshold:\n",
    "            new_cart = min(cart_threshold, MAX_CART_RULE)\n",
    "            new_cart = max(new_cart, MIN_CART_RULE)\n",
    "            result['new_cart_rule'] = int(new_cart)\n",
    "            cart_action = f' + open cart to {int(new_cart)}'\n",
    "        else:\n",
    "            cart_action = ''\n",
    "        \n",
    "        # NEW RULE: Reduce price once per day if uth_qty = 0\n",
    "        # If we haven't reduced price today -> reduce price + apply SKU discount\n",
    "        # If already reduced today -> just keep SKU discount\n",
    "        if can_reduce_price:\n",
    "            # Reduce price once per day\n",
    "            induced_price = calculate_induced_price(row, current_price)\n",
    "            if induced_price:\n",
    "                result['new_price'] = induced_price\n",
    "                result['price_action'] = 'zero_demand_price_decrease'\n",
    "                result['action_reason'] = f'Zero demand - price reduced ({current_price:.2f} -> {induced_price:.2f}) + SKU discount{cart_action}'\n",
    "            else:\n",
    "                result['price_action'] = 'add_sku_disc'\n",
    "                result['action_reason'] = f'Zero demand - no lower price available + SKU discount{cart_action}'\n",
    "        else:\n",
    "            # Already reduced price today - just keep SKU discount\n",
    "            result['price_action'] = 'keep_sku_disc'\n",
    "            result['action_reason'] = f'Zero demand - price already reduced today, keep SKU discount{cart_action}'\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASE 1.5: HIGH DOH (responsive_doh > 30) - Two-step approach\n",
    "    # - If NO existing SKU discount: Add SKU discount ONLY (wait for next day)\n",
    "    # - If HAS existing SKU discount and qty_ratio >= 0.9 (\"grew\"): Keep discount only\n",
    "    # - If HAS existing SKU discount and qty_ratio < 0.9 (\"didn't grow\"): Keep discount + induced price\n",
    "    # Only applies if inventory value (stocks * price) > 10,000 EGP\n",
    "    # Skip SKUs that were out of stock yesterday (oos_yesterday = 1)\n",
    "    # =========================================================================\n",
    "    DOH_HIGH_TURNOVER_THRESHOLD = 30\n",
    "    HIGH_INVENTORY_VALUE_THRESHOLD = 10000\n",
    "    responsive_doh = float(row.get('responsive_doh', 999) or 999)\n",
    "    stocks = float(row.get('stocks', 0) or 0)\n",
    "    inventory_value = stocks * current_price\n",
    "    oos_yesterday = int(row.get('oos_yesterday', 0) or 0)\n",
    "    \n",
    "    if responsive_doh > DOH_HIGH_TURNOVER_THRESHOLD and inventory_value > HIGH_INVENTORY_VALUE_THRESHOLD and oos_yesterday != 1:\n",
    "        result['uth_status'] = 'High DOH'\n",
    "        result['activate_sku_discount'] = True\n",
    "        result['activate_qd'] = True  # Add QD for bulk purchase incentive to move inventory faster\n",
    "        \n",
    "        if not has_sku_disc:\n",
    "            # First occurrence: Add SKU discount only - wait for next day\n",
    "            result['price_action'] = 'add_sku_disc_doh'\n",
    "            result['action_reason'] = f'High DOH ({responsive_doh:.1f} days) - ADD SKU discount (wait for next day)'\n",
    "            return result\n",
    "        \n",
    "        else:\n",
    "            # Has existing SKU discount - check if \"grew\" (qty_ratio >= 0.9)\n",
    "            if qty_ratio >= 0.9:\n",
    "                # SKU \"grew\" - keep discount but don't reduce price\n",
    "                result['price_action'] = 'keep_sku_disc'\n",
    "                result['action_reason'] = f'High DOH ({responsive_doh:.1f} days) + grew (qty={qty_ratio:.2f}) - KEEP SKU discount only'\n",
    "                return result\n",
    "            else:\n",
    "                # SKU \"didn't grow\" - keep discount + reduce price with induced logic\n",
    "                if can_reduce_price:\n",
    "                    induced_price = calculate_induced_price(row, current_price)\n",
    "                    if induced_price:\n",
    "                        result['new_price'] = induced_price\n",
    "                        result['price_action'] = 'induced_doh_reduction'\n",
    "                        result['action_reason'] = f'High DOH ({responsive_doh:.1f} days) + didn\\'t grow (qty={qty_ratio:.2f}) - INDUCED price ({current_price:.2f} -> {induced_price:.2f})'\n",
    "                        return result\n",
    "                    else:\n",
    "                        result['price_action'] = 'keep_sku_disc'\n",
    "                        result['action_reason'] = f'High DOH ({responsive_doh:.1f} days) - no lower price available'\n",
    "                        return result\n",
    "                else:\n",
    "                    result['price_action'] = 'keep_sku_disc'\n",
    "                    result['action_reason'] = f'High DOH ({responsive_doh:.1f} days) - price reduction limit reached'\n",
    "                    return result\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASE 1.6: LOW STOCK PROTECTION (DOH <= 2 with demand)\n",
    "    # Protect inventory until next receiving - no price reduction, cap cart at normal_refill\n",
    "    # But still allow price INCREASE if growing\n",
    "    # =========================================================================\n",
    "    normal_refill = float(row.get('normal_refill', 5) or 5)\n",
    "    is_low_stock = responsive_doh <= LOW_STOCK_DOH_THRESHOLD and uth_qty > 0\n",
    "    \n",
    "    if is_low_stock:\n",
    "        result['uth_status'] = 'Low Stock Protected'\n",
    "        result['price_action'] = 'hold_low_stock'\n",
    "        \n",
    "        # Cap cart rule at normal_refill (don't open cart wide for low stock)\n",
    "        if current_cart > normal_refill:\n",
    "            result['new_cart_rule'] = np.ceil(max(int(normal_refill),5) + float(row.get('refill_stddev', 2) or 2))\n",
    "            result['action_reason'] = f'Low stock (DOH={responsive_doh:.1f}) - hold price, cap cart to {int(normal_refill)}'\n",
    "        else:\n",
    "            result['action_reason'] = f'Low stock (DOH={responsive_doh:.1f}) - hold price'\n",
    "        \n",
    "        # Still allow price INCREASE if growing\n",
    "        if qty_ratio > UTH_GROWING_THRESHOLD and can_increase_price:\n",
    "            new_price = find_next_price_above(current_price, row)\n",
    "            if pd.notna(new_price) and new_price > current_price:\n",
    "                result['new_price'] = new_price\n",
    "                result['price_action'] = 'low_stock_increase'\n",
    "                result['action_reason'] += f' + increase price ({current_price:.2f} -> {new_price:.2f})'\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASE 2: On Track (both qty and retailers Â±10%)\n",
    "    # If has existing discounts, keep them (they'll be deactivated otherwise)\n",
    "    # =========================================================================\n",
    "    if (UTH_DROPPING_THRESHOLD <= qty_ratio <= UTH_GROWING_THRESHOLD and\n",
    "        UTH_DROPPING_THRESHOLD <= retailer_ratio <= UTH_GROWING_THRESHOLD):\n",
    "        result['uth_status'] = 'On Track'\n",
    "        result['price_action'] = 'hold'\n",
    "        \n",
    "        # Preserve existing discounts (all discounts are deactivated at start of each run)\n",
    "        if has_sku_disc:\n",
    "            result['activate_sku_discount'] = True\n",
    "            result['action_reason'] = f'On Track (qty={qty_ratio:.2f}, ret={retailer_ratio:.2f}) - keep existing SKU discount'\n",
    "        elif has_qd:\n",
    "            result['activate_qd'] = True\n",
    "            result['action_reason'] = f'On Track (qty={qty_ratio:.2f}, ret={retailer_ratio:.2f}) - keep existing QD'\n",
    "        else:\n",
    "            result['action_reason'] = f'On Track (qty={qty_ratio:.2f}, ret={retailer_ratio:.2f}) - no action'\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASE 2.5: Retailers Growing but Qty On Track\n",
    "    # Action: Increase price 1 step (high retailer demand, normal qty = opportunity)\n",
    "    # =========================================================================\n",
    "    if (UTH_DROPPING_THRESHOLD <= qty_ratio <= UTH_GROWING_THRESHOLD and\n",
    "        retailer_ratio > UTH_GROWING_THRESHOLD):\n",
    "        result['uth_status'] = 'Retailers Growing'\n",
    "        if can_increase_price:\n",
    "            new_price = find_next_price_above(current_price, row)\n",
    "        else:\n",
    "            new_price = np.nan\n",
    "        if new_price > current_price:\n",
    "            result['new_price'] = new_price\n",
    "            result['price_action'] = 'retailers_growing_increase'\n",
    "            result['action_reason'] = f'Retailers growing (qty={qty_ratio:.2f}, ret={retailer_ratio:.2f}) - increase price ({current_price:.2f} -> {new_price:.2f})'\n",
    "        else:\n",
    "            result['price_action'] = 'hold'\n",
    "            result['action_reason'] = f'Retailers growing (qty={qty_ratio:.2f}, ret={retailer_ratio:.2f}) - no tier above, hold'\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASE 3: Growing (qty > 110%)\n",
    "    # Find discount with HIGHEST contribution (from TODAY's UTH) and remove it\n",
    "    # Keep (re-activate) the others\n",
    "    # If no discounts -> increase price\n",
    "    # =========================================================================\n",
    "    if qty_ratio > UTH_GROWING_THRESHOLD:\n",
    "        result['uth_status'] = 'Growing'\n",
    "        \n",
    "        # Get TODAY's UTH discount contributions (not yesterday's)\n",
    "        sku_disc_cntrb = row.get('sku_disc_cntrb_uth', 0) or 0\n",
    "        t1_cntrb = row.get('t1_cntrb_uth', 0) or 0\n",
    "        t2_cntrb = row.get('t2_cntrb_uth', 0) or 0\n",
    "        t3_cntrb = row.get('t3_cntrb_uth', 0) or 0\n",
    "        \n",
    "        # Build list of EXISTING discounts with their contributions\n",
    "        # Note: We check if tiers EXIST (qty > 0), not just if they had sales today\n",
    "        # A tier can exist but have 0 contribution if no orders used it yet today\n",
    "        active_discounts = []\n",
    "        \n",
    "        # SKU discount: check if it exists (has_sku_disc from active discount query)\n",
    "        if has_sku_disc:\n",
    "            active_discounts.append(('sku_disc', sku_disc_cntrb))  # Include even if cntrb=0\n",
    "        \n",
    "        # QD tiers: check if each tier EXISTS (qty > 0 means the tier is configured)\n",
    "        if has_qd:\n",
    "            qd_t1_qty = row.get('qd_tier_1_qty', 0) or 0\n",
    "            qd_t2_qty = row.get('qd_tier_2_qty', 0) or 0\n",
    "            qd_t3_qty = row.get('qd_tier_3_qty', 0) or 0\n",
    "            \n",
    "            if qd_t1_qty > 0:  # Tier 1 exists\n",
    "                active_discounts.append(('qd_t1', t1_cntrb))  # Include even if cntrb=0\n",
    "            if qd_t2_qty > 0:  # Tier 2 exists\n",
    "                active_discounts.append(('qd_t2', t2_cntrb))  # Include even if cntrb=0\n",
    "            if qd_t3_qty > 0:  # Tier 3 exists\n",
    "                active_discounts.append(('qd_t3', t3_cntrb))  # Include even if cntrb=0\n",
    "        \n",
    "        if active_discounts:\n",
    "            # Sort by contribution descending - remove the highest\n",
    "            active_discounts.sort(key=lambda x: x[1], reverse=True)\n",
    "            highest_disc, highest_cntrb = active_discounts[0]\n",
    "            remaining_discounts = [d[0] for d in active_discounts[1:]]\n",
    "            \n",
    "            # Determine what to keep (re-activate)\n",
    "            keep_sku_disc = 'sku_disc' in remaining_discounts\n",
    "            keep_qd_t1 = 'qd_t1' in remaining_discounts\n",
    "            keep_qd_t2 = 'qd_t2' in remaining_discounts\n",
    "            keep_qd_t3 = 'qd_t3' in remaining_discounts\n",
    "            keep_any_qd = keep_qd_t1 or keep_qd_t2 or keep_qd_t3\n",
    "            \n",
    "            # Set activation flags\n",
    "            if keep_sku_disc:\n",
    "                result['activate_sku_discount'] = True\n",
    "            \n",
    "            if keep_any_qd:\n",
    "                result['activate_qd'] = True\n",
    "                result['keep_qd_tiers'] = [t for t in ['T1', 'T2', 'T3'] \n",
    "                                           if (t == 'T1' and keep_qd_t1) or \n",
    "                                              (t == 'T2' and keep_qd_t2) or \n",
    "                                              (t == 'T3' and keep_qd_t3)]\n",
    "            \n",
    "            result['removed_discount'] = highest_disc\n",
    "            result['removed_discount_cntrb'] = highest_cntrb\n",
    "            result['price_action'] = f'remove_{highest_disc}'\n",
    "            result['action_reason'] = f'Growing (qty={qty_ratio:.2f}) - remove {highest_disc} (cntrb={highest_cntrb}%)'\n",
    "            \n",
    "            if remaining_discounts:\n",
    "                result['action_reason'] += f', keep {remaining_discounts}'\n",
    "        \n",
    "        elif has_sku_disc or has_qd:\n",
    "            # Has discounts but no contribution data - remove all\n",
    "            result['price_action'] = 'remove_all_disc'\n",
    "            result['action_reason'] = f'Growing (qty={qty_ratio:.2f}) - remove all discounts (no contribution data)'\n",
    "        \n",
    "        else:\n",
    "            # No discounts\n",
    "            result['price_action'] = 'no_discount_growing'\n",
    "            result['action_reason'] = f'Growing (qty={qty_ratio:.2f}) - no discounts'\n",
    "        \n",
    "        # ALWAYS increase price 1 step (regardless of discounts)\n",
    "        if can_increase_price:\n",
    "            new_price = find_next_price_above(current_price, row)\n",
    "            if pd.notna(new_price) and new_price > current_price:\n",
    "                result['new_price'] = new_price\n",
    "                result['action_reason'] += f' + increase price ({current_price:.2f} -> {new_price:.2f})'\n",
    "            else:\n",
    "                result['action_reason'] += ' + no tier above for price increase'\n",
    "        else:\n",
    "            result['action_reason'] += ' + price increase limit reached'\n",
    "        \n",
    "        # Reduce cart rule only if qty_ratio > retailer_ratio * 1.20 (spiking detected)\n",
    "        # Use percentile-based reduction\n",
    "        if qty_ratio > retailer_ratio * 1.20:\n",
    "            # Get percentile data for this SKU\n",
    "            cohort_id = row.get('cohort_id')\n",
    "            product_id = row.get('product_id')\n",
    "            percentile_row = df_percentiles[\n",
    "                (df_percentiles['cohort_id'] == cohort_id) & \n",
    "                (df_percentiles['product_id'] == product_id)\n",
    "            ]\n",
    "            \n",
    "            if len(percentile_row) > 0:\n",
    "                current_level = get_current_percentile_level(current_cart, percentile_row)\n",
    "                if current_level:\n",
    "                    next_perc = get_next_lower_percentile(current_level, percentile_row)\n",
    "                    if pd.notna(next_perc) and next_perc > 0:\n",
    "                        result['new_cart_rule'] = max(MIN_CART_RULE, min(MAX_CART_RULE, int(round(next_perc))))\n",
    "                        result['action_reason'] += f' + reduce cart to {int(round(next_perc))} (percentile-based)'\n",
    "                    else:\n",
    "                        result['action_reason'] += ' + cart already at minimum percentile'\n",
    "                else:\n",
    "                    result['action_reason'] += ' + could not determine current percentile level'\n",
    "            else:\n",
    "                result['action_reason'] += ' + no percentile data available for cart reduction'\n",
    "        else:\n",
    "            # Keep current cart rule - qty not spiking relative to retailers\n",
    "            result['action_reason'] += ' + keep cart (qty not spiking)'\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # =========================================================================\n",
    "    # CASE 4: Dropping - Different actions based on qty vs retailer ratios\n",
    "    # =========================================================================\n",
    "    result['uth_status'] = 'Dropping'\n",
    "    \n",
    "    def apply_price_reduction():\n",
    "        \"\"\"Helper to apply price reduction if allowed.\"\"\"\n",
    "        if not can_reduce_price:\n",
    "            return None, f'Price reduction limit reached ({price_reductions_today}/{MAX_PRICE_REDUCTIONS_PER_DAY} today)'\n",
    "        \n",
    "        new_price = find_next_price_below(current_price, row)\n",
    "        if new_price < current_price:\n",
    "            commercial_min = float(row.get('commercial_min_price', row.get('minimum', 0)) or 0)\n",
    "            if pd.notna(commercial_min) and commercial_min > 0:\n",
    "                new_price = max(new_price, commercial_min)\n",
    "            return new_price, f'decrease ({current_price:.2f} -> {new_price:.2f})'\n",
    "        return None, 'no tier below'\n",
    "    \n",
    "    # CASE 4A: qty OK (â¥90%) but retailers dropping (<90%)\n",
    "    # Action: SKU discount (add new OR keep existing), then price if already has\n",
    "    if qty_ok and retailer_dropping:\n",
    "        # Always set activate_sku_discount = True (either adding new or keeping existing)\n",
    "        result['activate_sku_discount'] = True\n",
    "        \n",
    "        if not has_sku_disc:\n",
    "            # Adding new SKU discount\n",
    "            result['price_action'] = 'add_sku_disc'\n",
    "            result['action_reason'] = f'Retailers dropping (ret={retailer_ratio:.2f}, qty OK) - ADD new SKU discount'\n",
    "        else:\n",
    "            # Keeping existing SKU discount + reduce price\n",
    "            new_price, reason = apply_price_reduction()\n",
    "            if new_price:\n",
    "                #result['new_price'] = new_price\n",
    "                result['price_action'] = 'keep_sku_disc_and_decrease'\n",
    "                result['action_reason'] = f'Retailers dropping - KEEP SKU disc + {reason}'\n",
    "            else:\n",
    "                result['price_action'] = 'keep_sku_disc'\n",
    "                result['action_reason'] = f'Retailers dropping - KEEP SKU disc ({reason})'\n",
    "    \n",
    "    # CASE 4B: qty dropping (<90%) but retailers OK (â¥90%)\n",
    "    # Action: QD (add new OR keep existing), then price if already has\n",
    "    elif qty_dropping and retailer_ok:\n",
    "        # Always set activate_qd = True (either adding new or keeping existing)\n",
    "        result['activate_qd'] = True\n",
    "        \n",
    "        if not has_qd:\n",
    "            # Adding new QD\n",
    "            result['price_action'] = 'add_qd'\n",
    "            result['action_reason'] = f'Qty dropping (qty={qty_ratio:.2f}, ret OK) - ADD new QD'\n",
    "        else:\n",
    "            # Keeping existing QD + reduce price\n",
    "            new_price, reason = apply_price_reduction()\n",
    "            if new_price:\n",
    "                result['new_price'] = new_price\n",
    "                result['price_action'] = 'keep_qd_and_decrease'\n",
    "                result['action_reason'] = f'Qty dropping - KEEP QD + {reason}'\n",
    "            else:\n",
    "                result['price_action'] = 'keep_qd'\n",
    "                result['action_reason'] = f'Qty dropping - KEEP QD ({reason})'\n",
    "    \n",
    "    # CASE 4C: Both dropping (<90%)\n",
    "    # Action: SKU discount (add new OR keep existing), then price if already has\n",
    "    elif qty_dropping and retailer_dropping:\n",
    "        # Always set activate_sku_discount = True (either adding new or keeping existing)\n",
    "        result['activate_sku_discount'] = True\n",
    "        \n",
    "        if not has_sku_disc:\n",
    "            # Adding new SKU discount\n",
    "            result['price_action'] = 'add_sku_disc'\n",
    "            result['action_reason'] = f'Both dropping (qty={qty_ratio:.2f}, ret={retailer_ratio:.2f}) - ADD new SKU discount'\n",
    "        else:\n",
    "            # Keeping existing SKU discount + reduce price\n",
    "            new_price, reason = apply_price_reduction()\n",
    "            if new_price:\n",
    "                result['new_price'] = new_price\n",
    "                result['price_action'] = 'keep_sku_disc_and_decrease'\n",
    "                result['action_reason'] = f'Both dropping - KEEP SKU disc + {reason}'\n",
    "            else:\n",
    "                result['price_action'] = 'keep_sku_disc'\n",
    "                result['action_reason'] = f'Both dropping - KEEP SKU disc ({reason})'\n",
    "    \n",
    "    else:\n",
    "        result['price_action'] = 'hold'\n",
    "        result['action_reason'] = f'Unexpected state (qty={qty_ratio:.2f}, ret={retailer_ratio:.2f})'\n",
    "    \n",
    "    # Increase cart for dropping SKUs\n",
    "    result['new_cart_rule'] = adjust_cart_rule(current_cart, 'increase', row)\n",
    "    result['action_reason'] += ' + increase cart 20%'\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"Main engine function loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(prev_inc,on=['product_id','warehouse_id'],how='left')\n",
    "df = df.merge(prev_red,on=['product_id','warehouse_id'],how='left')\n",
    "df['increase_count'] = df['increase_count'].fillna(0)\n",
    "df['reduced_count'] = df['reduced_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXECUTE MODULE 3\n",
    "# =============================================================================\n",
    "print(f\"Processing {len(df)} SKUs...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "for idx, row in df.iterrows():\n",
    "    result = generate_periodic_action(row, df_previous_actions)\n",
    "    results.append(result)\n",
    "    \n",
    "    if (idx + 1) % 10000 == 0:\n",
    "        print(f\"Processed {idx + 1}/{len(df)} SKUs...\")\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(f\"\\nâ Processed {len(df_results)} SKUs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = df_results.drop_duplicates(subset=['product_id', 'warehouse_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY\n",
    "# =============================================================================\n",
    "print(\"=\"*60)\n",
    "print(\"MODULE 3 SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nTotal SKUs: {len(df_results)}\")\n",
    "\n",
    "print(f\"\\nBy UTH Status:\")\n",
    "print(df_results['uth_status'].value_counts(dropna=False).to_string())\n",
    "\n",
    "# Actions breakdown\n",
    "price_changes = df_results[df_results['new_price'].notna()]\n",
    "cart_changes = df_results[df_results['new_cart_rule'].notna()]\n",
    "sku_disc_activate = df_results[df_results['activate_sku_discount'] == True]\n",
    "qd_activate = df_results[df_results['activate_qd'] == True]\n",
    "discounts_removed = df_results[df_results['removed_discount'].notna()]\n",
    "\n",
    "print(f\"\\nActions:\")\n",
    "print(f\"  Price changes: {len(price_changes)}\")\n",
    "print(f\"  Cart rule changes: {len(cart_changes)}\")\n",
    "print(f\"  SKU discounts to activate: {len(sku_disc_activate)}\")\n",
    "print(f\"  QD to activate: {len(qd_activate)}\")\n",
    "print(f\"  Discounts removed (Growing SKUs): {len(discounts_removed)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXPORT RESULTS\n",
    "# =============================================================================\n",
    "output_cols = [\n",
    "    # Identifiers\n",
    "    'product_id', 'warehouse_id', 'cohort_id', 'sku', 'brand', 'cat', 'stocks',\n",
    "    # Pricing data\n",
    "    'current_price', 'wac_p', 'new_price',\n",
    "    'target_margin', 'min_boundary',\n",
    "    # Performance data\n",
    "    'uth_qty', 'uth_retailers',\n",
    "    'p80_daily_240d', 'p70_daily_retailers_240d', 'avg_uth_pct',\n",
    "    'sku_disc_cntrb_uth', 't1_cntrb_uth', 't2_cntrb_uth', 't3_cntrb_uth',\n",
    "    'uth_qty_target', 'uth_retailer_target', 'qty_ratio', 'retailer_ratio', 'uth_status',\n",
    "    'doh', 'mtd_qty',\n",
    "    # Cart rules\n",
    "    'price_action', 'current_cart_rule', 'new_cart_rule',\n",
    "    # SKU Discount fields\n",
    "    'activate_sku_discount', 'active_sku_disc_pct', 'has_active_sku_discount',\n",
    "    # QD fields (for qd_handler)\n",
    "    'activate_qd', 'keep_qd_tiers', 'has_active_qd',\n",
    "    'qd_tier_1_qty', 'qd_tier_1_disc_pct',\n",
    "    'qd_tier_2_qty', 'qd_tier_2_disc_pct',\n",
    "    'qd_tier_3_qty', 'qd_tier_3_disc_pct',\n",
    "    # Market margins (for handlers to convert to prices)\n",
    "    'below_market', 'market_min', 'market_25', 'market_50',\n",
    "    'market_75', 'market_max', 'above_market',\n",
    "    # Margin tiers (for handlers to convert to prices)\n",
    "    'margin_tier_below', 'margin_tier_1', 'margin_tier_2', 'margin_tier_3', 'margin_tier_4',\n",
    "    'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2',\n",
    "    # Action tracking\n",
    "    'removed_discount', 'removed_discount_cntrb',\n",
    "    'price_reductions_today', 'action_reason'\n",
    "]\n",
    "\n",
    "# Filter to existing columns\n",
    "output_cols = [c for c in output_cols if c in df_results.columns]\n",
    "\n",
    "# Drop duplicates before saving\n",
    "df_output = df_results[output_cols].drop_duplicates(subset=['product_id', 'warehouse_id'], keep='first')\n",
    "# Save df_output state before any manipulation for Slack upload later\n",
    "temp_df_for_slack = df_output.copy()\n",
    "print(f\"\\nâ Saved {len(temp_df_for_slack)} rows for Slack upload\")\n",
    "print(f\"Total records: {len(df_output)} (after removing {len(df_results) - len(df_output)} duplicates)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PUSH CART RULES & PRICES\n",
    "# =============================================================================\n",
    "# Push cart rules FIRST, then prices\n",
    "# If cart rules fail for certain cohorts, skip those cohorts for prices\n",
    "\n",
    "%run push_cart_rules_handler.ipynb\n",
    "%run push_prices_handler.ipynb\n",
    "pus = get_packing_units()\n",
    "\n",
    "# â ï¸ MODE CONFIGURATION:\n",
    "# - 'testing' (default): Prepare files but DON'T upload to API\n",
    "# - 'live': Prepare files AND upload to MaxAB API\n",
    "PUSH_MODE = 'live'  # Change to 'live' when ready to push\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: Push Cart Rules First\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 1: PUSHING CART RULES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cart_result = push_cart_rules(df_output, pus, source_module='module_3', mode=PUSH_MODE)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CART RULES RESULT\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Mode: {cart_result['mode']}\")\n",
    "print(f\"Cart rule changes: {cart_result['cart_rule_changes']}\")\n",
    "print(f\"Pushed: {cart_result['pushed']}\")\n",
    "print(f\"Failed: {cart_result['failed']}\")\n",
    "if cart_result['failed_cohorts']:\n",
    "    print(f\"â ï¸ Failed cohorts: {cart_result['failed_cohorts']}\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: Push Prices (skip failed cohorts)\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 2: PUSHING PRICES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get failed cohorts from cart rules to skip in price push\n",
    "failed_cohorts = cart_result.get('failed_cohorts', [])\n",
    "\n",
    "# Call push_prices with the results, skipping failed cohorts\n",
    "push_result = push_prices(df_output, pus, source_module='module_3', mode=PUSH_MODE, skip_cohorts=failed_cohorts)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"PRICES RESULT\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Mode: {push_result['mode']}\")\n",
    "print(f\"Source: {push_result['source_module']}\")\n",
    "print(f\"Timestamp: {push_result['timestamp']}\")\n",
    "print(f\"Total received: {push_result['total_received']}\")\n",
    "print(f\"Price changes: {push_result['price_changes']}\")\n",
    "print(f\"Pushed: {push_result['pushed']}\")\n",
    "print(f\"Skipped: {push_result['skipped']}\")\n",
    "print(f\"Failed: {push_result['failed']}\")\n",
    "if push_result.get('skipped_cohorts'):\n",
    "    print(f\"â ï¸ Skipped cohorts (cart rules failed): {push_result['skipped_cohorts']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# STEP 3: PROCESS SKU DISCOUNTS\n",
    "# =============================================================================\n",
    "# This step handles SKU discounts for SKUs that need them based on UTH performance.\n",
    "# Market data has already been refreshed, so we pass the df_output directly.\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 3: PROCESSING SKU DISCOUNTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "%run sku_discount_handler.ipynb\n",
    "\n",
    "# Filter to SKUs that need SKU discount\n",
    "df_sku_discount = df_results[df_results['activate_sku_discount'] == True].copy()\n",
    "print(f\"SKUs needing SKU discount: {len(df_sku_discount)}\")\n",
    "\n",
    "# Merge market margins and margin tiers from df (not in df_results)\n",
    "sku_discount_extra_cols = [\n",
    "    'product_id', 'warehouse_id',\n",
    "    # Market margins\n",
    "    'below_market', 'market_min', 'market_25', 'market_50', \n",
    "    'market_75', 'market_max', 'above_market',\n",
    "    # Margin tiers\n",
    "    'margin_tier_below', 'margin_tier_1', 'margin_tier_2', 'margin_tier_3', \n",
    "    'margin_tier_4', 'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2',\n",
    "    # Other needed columns\n",
    "    'doh', 'zero_demand', 'target_margin', 'min_boundary', 'active_sku_disc_pct'\n",
    "]\n",
    "# Filter to columns that exist in df\n",
    "sku_discount_extra_cols = [c for c in sku_discount_extra_cols if c in df.columns]\n",
    "\n",
    "# Merge the extra columns from df\n",
    "df_sku_discount = df_sku_discount.merge(\n",
    "    df[sku_discount_extra_cols].drop_duplicates(subset=['product_id', 'warehouse_id']),\n",
    "    on=['product_id', 'warehouse_id'],\n",
    "    how='left',\n",
    "    suffixes=('', '_from_df')\n",
    ")\n",
    "print(f\"  Merged market margins and margin tiers from df\")\n",
    "\n",
    "if len(df_sku_discount) > 0:\n",
    "    sku_discount_result = process_sku_discounts(df_sku_discount, mode=PUSH_MODE)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"SKU DISCOUNT RESULT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Mode: {sku_discount_result['mode']}\")\n",
    "    print(f\"Total input: {sku_discount_result['total_input']}\")\n",
    "    print(f\"SKUs to activate: {sku_discount_result['to_activate']}\")\n",
    "    print(f\"Deactivated: {sku_discount_result['deactivated']}\")\n",
    "    print(f\"Created: {sku_discount_result['created']}\")\n",
    "    print(f\"Failed: {sku_discount_result['failed']}\")\n",
    "else:\n",
    "    print(\"No SKUs need SKU discounts\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: PROCESSING QUANTITY DISCOUNTS (QD)\n",
    "# =============================================================================\n",
    "# This step handles QD adjustments for SKUs flagged by the action engine.\n",
    "# Only processes SKUs where activate_qd=True and uses keep_qd_tiers to determine\n",
    "# which tiers to maintain.\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"STEP 4: PROCESSING QUANTITY DISCOUNTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "%run qd_handler.ipynb\n",
    "\n",
    "# Filter to SKUs that need QD processing\n",
    "df_qd = df_results[df_results['activate_qd'] == True].copy()\n",
    "print(f\"SKUs needing QD processing: {len(df_qd)}\")\n",
    "\n",
    "# Required columns for QD handler\n",
    "# Include all data needed for tier quantity and price calculations\n",
    "qd_columns = [\n",
    "    # Identifiers\n",
    "    'product_id', 'warehouse_id', 'cohort_id', 'sku', 'brand', 'cat',\n",
    "    # Pricing data\n",
    "    'wac_p', 'current_price', 'new_price', 'target_margin', 'min_boundary',\n",
    "    # Cart rules\n",
    "    'current_cart_rule', 'new_cart_rule',\n",
    "    # Market margins (to be converted to prices)\n",
    "    'below_market', 'market_min', 'market_25', 'market_50',\n",
    "    'market_75', 'market_max', 'above_market',\n",
    "    # Margin tiers (to be converted to prices)\n",
    "    'margin_tier_1', 'margin_tier_2', 'margin_tier_3', 'margin_tier_4',\n",
    "    'margin_tier_5', 'margin_tier_above_1', 'margin_tier_above_2',\n",
    "    # Performance data (for top SKU selection)\n",
    "    'mtd_qty',\n",
    "    # Stock data (for stock value ranking: stocks * wac_p)\n",
    "    'stocks',\n",
    "    # QD configuration\n",
    "    'keep_qd_tiers'\n",
    "]\n",
    "# Filter to columns that exist in df_results\n",
    "qd_columns = [c for c in qd_columns if c in df_results.columns]\n",
    "df_qd = df_qd[qd_columns].copy()\n",
    "\n",
    "if len(df_qd) > 0:\n",
    "    qd_result = process_qd(df_qd, False)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"QD PROCESSING RESULT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Mode: {qd_result['mode']}\")\n",
    "    print(f\"Total input: {qd_result['total_input']}\")\n",
    "    print(f\"Processed: {qd_result['processed']}\")\n",
    "    print(f\"Failed: {qd_result['failed']}\")\n",
    "else:\n",
    "    print(\"No SKUs need QD processing\")\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL SUMMARY\n",
    "# =============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODULE 3 EXECUTION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Total SKUs processed: {len(df_output)}\")\n",
    "print(f\"Price changes: {(df_output['new_price'] != df_output['current_price']).sum()}\")\n",
    "print(f\"Cart rule changes: {(df_output['new_cart_rule'] != df_output['current_cart_rule']).sum()}\")\n",
    "print(f\"SKUs with SKU discount: {df_output['activate_sku_discount'].sum()}\")\n",
    "print(f\"SKUs with QD: {df_output['activate_qd'].sum()}\")\n",
    "print(f\"Output saved to: {OUTPUT_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UPLOAD RESULTS TO SNOWFLAKE AND SEND SLACK NOTIFICATION\n",
    "# =============================================================================\n",
    "from common_functions import upload_dataframe_to_snowflake, send_text_slack, send_file_slack\n",
    "\n",
    "# Add created_at as TIMESTAMP (module runs multiple times per day)\n",
    "df_output = df_output.drop(columns=['keep_qd_tiers'], errors='ignore')\n",
    "df_output['keep_qd_tiers'] = np.nan\n",
    "df_output['created_at'] = datetime.now(CAIRO_TZ).replace(second=0, microsecond=0)\n",
    "# Upload to Snowflake\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"UPLOADING RESULTS TO SNOWFLAKE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "upload_status = upload_dataframe_to_snowflake(\n",
    "    \"Egypt\", \n",
    "    df_output, \n",
    "    \"MATERIALIZED_VIEWS\", \n",
    "    \"pricing_periodic_push\", \n",
    "    \"append\", \n",
    "    auto_create_table=True, \n",
    "    conn=None\n",
    ")\n",
    "\n",
    "# Prepare status variables\n",
    "prices_pushed = push_result.get('pushed', 0) if 'push_result' in dir() else 0\n",
    "prices_failed = push_result.get('failed', 0) if 'push_result' in dir() else 0\n",
    "cart_rules_pushed = cart_result.get('pushed', 0) if 'cart_result' in dir() else 0\n",
    "cart_rules_failed = cart_result.get('failed', 0) if 'cart_result' in dir() else 0\n",
    "\n",
    "# SKU discount status\n",
    "sku_disc_processed = len(df_sku_discount) if 'df_sku_discount' in dir() else 0\n",
    "\n",
    "# QD status\n",
    "qd_processed = qd_result.get('processed', 0) if 'qd_result' in dir() and qd_result else 0\n",
    "qd_failed = qd_result.get('failed', 0) if 'qd_result' in dir() and qd_result else 0\n",
    "df_output.columns = df_output.columns.str.lower()\n",
    "if upload_status:\n",
    "    slack_message = f\"\"\"â *Module 3 - Periodic Actions Completed*\n",
    "\n",
    "ð Date: {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d')}\n",
    "â° Completed at: {datetime.now(CAIRO_TZ).strftime('%H:%M:%S')} Cairo time\n",
    "ð§ Mode: {PUSH_MODE.upper()}\n",
    "\n",
    "ð *Results:*\n",
    "â¢ Total SKUs processed: {len(df_output):,}\n",
    "â¢ Price changes: {(df_output['new_price'] != df_output['current_price']).sum():,}\n",
    "â¢ Induced DOH prices: {(df_output['price_action'] == 'induced_doh_reduction').sum():,}\n",
    "â¢ Cart rule changes: {(df_output['new_cart_rule'] != df_output['current_cart_rule']).sum():,}\n",
    "\n",
    "ð¤ *Push Status:*\n",
    "â¢ ð° Prices: â {prices_pushed} pushed | â {prices_failed} failed\n",
    "â¢ ð Cart Rules: â {cart_rules_pushed} pushed | â {cart_rules_failed} failed\n",
    "â¢ ð·ï¸ SKU Discounts: {sku_disc_processed} processed\n",
    "â¢ ð¦ Quantity Discounts: â {qd_processed} processed | â {qd_failed} failed\n",
    "\n",
    "ðï¸ Results uploaded to: MATERIALIZED_VIEWS.pricing_periodic_push\"\"\"\n",
    "    \n",
    "    send_text_slack('new-pricing-logic', slack_message)\n",
    "    print(\"â Slack notification sent!\")\n",
    "    \n",
    "    # Send output file to Slack after the text message (using saved copy before manipulation)\n",
    "    SLACK_CHANNEL_ID = 'C0AAWK97Z3Q'\n",
    "    send_file_slack(\n",
    "        temp_df_for_slack, \n",
    "        f'ð Module 3 Output: {len(temp_df_for_slack)} SKUs processed', \n",
    "        SLACK_CHANNEL_ID,\n",
    "        filename=f'module3_periodic_{datetime.now(CAIRO_TZ).strftime(\"%Y%m%d_%H%M\")}.xlsx'\n",
    "    )\n",
    "    print(\"â Output file sent to Slack\")\n",
    "    \n",
    "    print(f\"â {len(df_output)} records uploaded to Snowflake\")\n",
    "else:\n",
    "    error_message = f\"\"\"â *Module 3 - Periodic Actions Failed*\n",
    "\n",
    "ð Date: {datetime.now(CAIRO_TZ).strftime('%Y-%m-%d')}\n",
    "â° Failed at: {datetime.now(CAIRO_TZ).strftime('%H:%M:%S')} Cairo time\n",
    "â ï¸ Upload to Snowflake failed - please check logs\n",
    "\n",
    "ð¤ *Push Status (before upload failure):*\n",
    "â¢ ð° Prices: â {prices_pushed} pushed | â {prices_failed} failed\n",
    "â¢ ð Cart Rules: â {cart_rules_pushed} pushed | â {cart_rules_failed} failed\n",
    "â¢ ð·ï¸ SKU Discounts: {sku_disc_processed} processed\n",
    "â¢ ð¦ Quantity Discounts: â {qd_processed} processed | â {qd_failed} failed\"\"\"\n",
    "    \n",
    "    send_text_slack('new-pricing-logic', error_message)\n",
    "    print(\"â Error notification sent to Slack!\")\n",
    "    \n",
    "    # Still send output file even on error for debugging (using saved copy before manipulation)\n",
    "    send_file_slack(\n",
    "        temp_df_for_slack, \n",
    "        f'â ï¸ Module 3 ERROR: {len(temp_df_for_slack)} SKUs', \n",
    "        SLACK_CHANNEL_ID,\n",
    "        filename=f'module3_periodic_ERROR_{datetime.now(CAIRO_TZ).strftime(\"%Y%m%d_%H%M\")}.xlsx'\n",
    "    )\n",
    "    print(\"â Error file sent to Slack\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
